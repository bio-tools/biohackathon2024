{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-mentioning  \n",
    "\n",
    "* Remove preprints from articles\n",
    "* Create co-mentioning matrix\n",
    "* Check if (mentions) articles are about a tool in bio.tools \n",
    "\n",
    "\n",
    "Mentions file should contain a list where each element has (tool name, pmid and list of articles mentioning the tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9453 tools.\n"
     ]
    }
   ],
   "source": [
    "from bh24_literature_mining.utils import read_cites_from_json\n",
    "\n",
    "path = '../var/biotools_cites.json' # REPLACE with the path to the mentions file\n",
    "\n",
    "tools = read_cites_from_json(path)\n",
    "\n",
    "print(f'Loaded {len(tools)} tools.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove preprints from articles in every tool\n",
    "\n",
    "For published articles there can also be preprints included since DOI and other IDs are different from the final publication to the preprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out preprints. Now 9453 tools.\n"
     ]
    }
   ],
   "source": [
    "for tool in tools:\n",
    "    tool['articles'] = [article for article in tool['articles'] if article.pubType != 'preprint']\n",
    "\n",
    "print(f'Filtered out preprints. Now {len(tools)} tools.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect unique article IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 366828 unique publication IDs.\n"
     ]
    }
   ],
   "source": [
    "publication_ids = list({article.id for tool in tools for article in tool['articles']})\n",
    "\n",
    "print(f'Found {len(publication_ids)} unique publication IDs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create binary matrix for tools vs. articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10/20 tools processed (50.00%)\n",
      "Progress: 20/20 tools processed (100.00%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tools_short = tools[:20]  # Replace with the list of tools you want to process\n",
    "\n",
    "# Total number of tools to process\n",
    "total_tools = len(tools_short)\n",
    "\n",
    "# Initialize the matrix\n",
    "matrix = []\n",
    "\n",
    "for i, tool in enumerate(tools_short):\n",
    "    # Compute row with boolean values for each article_id\n",
    "    row = [\n",
    "        article_id in [article.id for article in tool[\"articles\"]]\n",
    "        for article_id in publication_ids\n",
    "    ]\n",
    "    matrix.append(row)\n",
    "\n",
    "    # Print progress every 10 tools, or adjust the frequency as needed\n",
    "    if (i + 1) % 10 == 0 or (i + 1) == total_tools:\n",
    "        print(\n",
    "            f\"Progress: {i + 1}/{total_tools} tools processed ({(i + 1) / total_tools * 100:.2f}%)\"\n",
    "        )\n",
    "\n",
    "comentions_df = pd.DataFrame(matrix, columns=publication_ids)\n",
    "\n",
    "# Set rownames to tool names\n",
    "comentions_df.index = [tool[\"name\"] for tool in tools_short]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_indices = comentions_df.index[comentions_df.index.duplicated(keep=False)]\n",
    "\n",
    "duplicated_rows = comentions_df.loc[duplicated_indices]\n",
    "\n",
    "unique_rows = duplicated_rows.groupby(level=0).filter(lambda x: x.nunique().eq(1).all())\n",
    "\n",
    "# Remove exact duplicates by dropping all but the first instance\n",
    "comentions_matrix = pd.concat([comentions_df.drop(index=unique_rows.index), unique_rows.groupby(level=0).first()])\n",
    "\n",
    "print(\"Deduplicated DataFrame:\")\n",
    "print(comentions_matrix.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if articles are about a tool in bio.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bio.tools data\n",
    "\n",
    "biotoolspath = 'path/to/biotools.json' # REPLACE\n",
    "\n",
    "with open(biotoolspath) as f:\n",
    "    biotools = json.load(f)\n",
    "\n",
    "\n",
    "publication_ids_in_biotools = [\n",
    "    (id, tool['biotoolsID']) \n",
    "    for id in publication_ids \n",
    "    for tool in biotools \n",
    "    if id in [article.get('pmid') or article.get('pmcid') for article in tool.get('publication', [])]\n",
    "]\n",
    "\n",
    "print(f'Matched {len(publication_ids_in_biotools)} publication IDs with a bio.tools tool.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
