{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15005\n"
     ]
    }
   ],
   "source": [
    "from bh24_literature_mining.biotools import get_biotools\n",
    "\n",
    "# Get biotools from the biotoolspub.tsv\n",
    "biotools = get_biotools(\"../biotoolspub/biotoolspub.tsv\")\n",
    "print(len(biotools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from bh24_literature_mining.europepmc_api import identify_tool_mentions_using_europepmc\n",
    "\n",
    "tool_occurrences_df = identify_tool_mentions_using_europepmc(biotools[:1])\n",
    "print(tool_occurrences_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMCID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>NER_Tags</th>\n",
       "      <th>Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMC11286849</td>\n",
       "      <td>The identified proteins also included 52 (70%)...</td>\n",
       "      <td>[(120, 129, SubtiWiki, subtiwiki)]</td>\n",
       "      <td>Molecular interactions, pathways and networks,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PMCID                                           Sentence  \\\n",
       "2  PMC11286849  The identified proteins also included 52 (70%)...   \n",
       "\n",
       "                             NER_Tags  \\\n",
       "2  [(120, 129, SubtiWiki, subtiwiki)]   \n",
       "\n",
       "                                              Topics  \n",
       "2  Molecular interactions, pathways and networks,...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_occurrences_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a CSV file\n",
    "tool_occurrences_df.to_csv(\"../biotoolspub/tmp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of df: 4\n",
      "Train set size: 2\n",
      "Test set size: 1\n",
      "Dev set size: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMCID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>NER_Tags</th>\n",
       "      <th>Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PMC11286849</td>\n",
       "      <td>The localization of 52 of these 445 proteins i...</td>\n",
       "      <td>[(72, 81, SubtiWiki, subtiwiki)]</td>\n",
       "      <td>Molecular interactions, pathways and networks,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PMCID                                           Sentence  \\\n",
       "3  PMC11286849  The localization of 52 of these 445 proteins i...   \n",
       "\n",
       "                           NER_Tags  \\\n",
       "3  [(72, 81, SubtiWiki, subtiwiki)]   \n",
       "\n",
       "                                              Topics  \n",
       "3  Molecular interactions, pathways and networks,...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bh24_literature_mining.europepmc_api import split_train_test_dev\n",
    "train_df, test_df, dev_df = split_train_test_dev(tool_occurrences_df)\n",
    "# Verify the sizes\n",
    "print(\"Size of df:\", len(tool_occurrences_df))\n",
    "print(\"Train set size:\", len(train_df))\n",
    "print(\"Test set size:\", len(test_df))\n",
    "print(\"Dev set size:\", len(dev_df))\n",
    "dev_df.sample(n=min(10, len(dev_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   0%|          | 0/2 [05:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m test_writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(f3, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Process each DataFrame and write to the corresponding file\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mprocess_df_and_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_writer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m process_df_and_write(dev_df, dev_writer)\n\u001b[1;32m     16\u001b[0m process_df_and_write(test_df, test_writer)\n",
      "File \u001b[0;32m~/VS Code/biohack_new/src/bh24_literature_mining/europepmc_api.py:327\u001b[0m, in \u001b[0;36mprocess_df_and_write\u001b[0;34m(df, writer)\u001b[0m\n\u001b[1;32m    325\u001b[0m text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    326\u001b[0m ner_tags \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNER_Tags\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# assuming ner column is a list of tuples\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m iob_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mconvert2IOB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mner_tags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token, tag \u001b[38;5;129;01min\u001b[39;00m iob_pairs:\n\u001b[1;32m    329\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow([token, tag])\n",
      "File \u001b[0;32m~/VS Code/biohack_new/src/bh24_literature_mining/europepmc_api.py:307\u001b[0m, in \u001b[0;36mconvert2IOB\u001b[0;34m(text, ner_tags)\u001b[0m\n\u001b[1;32m    305\u001b[0m entity_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, token_span \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(doc):\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfind_sub_span\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_span\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m entity_flag:\n\u001b[1;32m    309\u001b[0m             iob_tags[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m entity_type\n",
      "File \u001b[0;32m~/VS Code/biohack_new/src/bh24_literature_mining/europepmc_api.py:293\u001b[0m, in \u001b[0;36mfind_sub_span\u001b[0;34m(token_span, entity_span)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_sub_span\u001b[39m(token_span, entity_span):\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtoken_span\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mentity_span\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m token_span[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m entity_span[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(token_span[\u001b[38;5;241m0\u001b[39m], entity_span[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mmin\u001b[39m(token_span[\u001b[38;5;241m1\u001b[39m], entity_span[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "from bh24_literature_mining.europepmc_api import convert_to_IOB_format_from_df\n",
    "\n",
    "\n",
    "output_folder = '../data/'\n",
    "\n",
    "# Convert train, dev, and test dataframes to IOB format\n",
    "convert_to_IOB_format_from_df(train_df, output_folder, 'train_IOB.tsv')\n",
    "convert_to_IOB_format_from_df(dev_df, output_folder, 'dev_IOB.tsv')\n",
    "convert_to_IOB_format_from_df(test_df, output_folder, 'test_IOB.tsv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biohackathon-2024",
   "language": "python",
   "name": "biohackathon-2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
