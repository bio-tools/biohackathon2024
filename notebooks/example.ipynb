{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example notebook\n",
    "\n",
    "Here we get the Article classes for all given bio.tools tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15005\n"
     ]
    }
   ],
   "source": [
    "from bh24_literature_mining.utils import load_biotools_pub\n",
    "\n",
    "tools = load_biotools_pub(\"../biotoolspub/biotoolspub.tsv\")\n",
    "\n",
    "tools_lower = set()\n",
    "\n",
    "\n",
    "for index, row in tools.iterrows():\n",
    "    name = row[\"name\"]\n",
    "    pubmedid = row[\"pubmedid\"]\n",
    "    link = row[\"link\"]\n",
    "    # print(f\"Name: {name}, PubMed ID: {pubmedid}, Link: {link}\")\n",
    "    tools_lower.add(name.lower())\n",
    "\n",
    "\n",
    "print(len(tools_lower))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example on how to use europepmc_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840\n",
      "The first title is: Rescoring Peptide Spectrum Matches: Boosting Proteomics Performance by Integrating Peptide Property Predictors Into Peptide Identification.\n",
      "Type of the first article: research-article; review; journal article\n",
      "This is pmcid: PMC11269915\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "from bh24_literature_mining.europepmc_api import EuropePMCClient\n",
    "\n",
    "\n",
    "client = EuropePMCClient()\n",
    "# Call bio.tools query and get a list of Article objects\n",
    "biotools_articles = client.search_mentions(\"PeptideProphet\")\n",
    "print(len(biotools_articles))\n",
    "\n",
    "first_article = biotools_articles[0]\n",
    "\n",
    "print(\"The first title is:\", first_article.title)\n",
    "print(\"Type of the first article:\", first_article.pubType)\n",
    "print(\"This is pmcid:\", first_article.pmcid)\n",
    "\n",
    "\n",
    "relevant_parahraphs = client.get_relevant_paragraphs(first_article.pmcid)\n",
    "\n",
    "print(len(relevant_parahraphs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of numpy failed: Traceback (most recent call last):\n",
      "  File \"/Users/vedran/git/Workflomics-related/biohackathon2024/.venv/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/vedran/git/Workflomics-related/biohackathon2024/.venv/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/vedran/git/Workflomics-related/biohackathon2024/.venv/lib/python3.11/site-packages/numpy/__init__.py\", line 472, in <module>\n",
      "    from . import exceptions\n",
      "  File \"<frozen importlib._bootstrap>\", line 1231, in _handle_fromlist\n",
      "  File \"/Users/vedran/git/Workflomics-related/biohackathon2024/.venv/lib/python3.11/site-packages/numpy/__init__.py\", line 352, in __getattr__\n",
      "    import numpy.exceptions as exceptions\n",
      "  File \"/Users/vedran/git/Workflomics-related/biohackathon2024/.venv/lib/python3.11/site-packages/numpy/__init__.py\", line 352, in __getattr__\n",
      "    import numpy.exceptions as exceptions\n",
      "RecursionError: maximum recursion depth exceeded\n",
      "]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_sci_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtagger\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlemmatizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_ruler\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m nlp\u001b[38;5;241m.\u001b[39madd_pipe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentencizer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_sci_sm\", disable=[\"tagger\", \"parser\", \"ner\", \"lemmatizer\", \"attribute_ruler\"])\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# this is time consuming. The sentenciser takes 1 minute per article on an average.\n",
    "# final_data = []\n",
    "\n",
    "# for pmcid in tqdm(unique_pmcids, desc=\"Processing PMCIDs\"):\n",
    "#     partial_sentences = annotations_df[annotations_df['pmc_id'] == pmcid]['partial_sentence'].tolist()\n",
    "#     segmented_sentences = get_full_text_xml_paragraphs(pmcid, partial_sentences)\n",
    "#     processed_data = process_pmcid(annotations_df, pmcid, segmented_sentences)   \n",
    "#     if processed_data:\n",
    "#         final_data.extend(processed_data)\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# final_df = pd.DataFrame(final_data, columns=['pmcid', 'sentence', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of the cites articles (within the first 3 pages): 1000\n"
     ]
    }
   ],
   "source": [
    "# Call cites query with a specific PubMed ID and get a list of Article objects\n",
    "cites_articles = client.search_cites(\"32109013\")\n",
    "print(\"The count of the cites articles (within the first 3 pages):\", len(cites_articles))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioHackathon 2024",
   "language": "python",
   "name": "biohackathon-2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
