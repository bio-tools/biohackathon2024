{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example notebook\n",
    "\n",
    "Here we get the Article classes for all given bio.tools tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15005\n"
     ]
    }
   ],
   "source": [
    "from bh24_literature_mining.utils import load_biotools_pub\n",
    "from bh24_literature_mining.biotools import Tool_entry\n",
    "\n",
    "tools = load_biotools_pub(\"../biotoolspub/biotoolspub.tsv\")\n",
    "\n",
    "# Initialize set to track unique names and a list to store Biotool objects\n",
    "tools_lower = set()\n",
    "unique_biotools = []\n",
    "\n",
    "# Iterate over the rows in the DataFrame\n",
    "for _, row in tools.iterrows():\n",
    "    name = row[\"name\"]\n",
    "    biotools_id = row[\"biotoolsID\"]\n",
    "    name_lower = name.lower()\n",
    "\n",
    "    # Only add unique tools based on name\n",
    "    if name_lower not in tools_lower:\n",
    "        tools_lower.add(name_lower)  # Add to the set to track uniqueness\n",
    "        # Create a Biotool object and add it to the list\n",
    "        biotool = Tool_entry(biotool_id=biotools_id, name=name)\n",
    "        unique_biotools.append(biotool)\n",
    "\n",
    "\n",
    "print(len(unique_biotools))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example on how to use europepmc_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No relevant paragraphs found iPHoP\n",
      "No relevant paragraphs found SLiM\n",
      "No relevant paragraphs found BCFtools\n"
     ]
    }
   ],
   "source": [
    "from bh24_literature_mining.europepmc_api import EuropePMCClient, write_tool_mentions_to_file\n",
    "from bh24_literature_mining.europepmc_api import identify_tool_mentions_in_sentences\n",
    "\n",
    "client = EuropePMCClient()\n",
    "\n",
    "for tool in unique_biotools[:10]:\n",
    "    # Call bio.tools query and get a list of Article objects\n",
    "    \n",
    "    biotools_articles = client.search_mentions(tool.name)\n",
    "\n",
    "    if len(biotools_articles) == 0:\n",
    "        continue\n",
    "    first_article = biotools_articles[0]\n",
    "\n",
    "    relevant_parahraphs = client.get_relevant_paragraphs(first_article.pmcid, tool.name)\n",
    "    if len(relevant_parahraphs) == 0:\n",
    "        print(\"No relevant paragraphs found\", tool.name)\n",
    "        continue\n",
    "    \n",
    "    tool.get_topics()\n",
    "    \n",
    "    file_path = \"/Users/vedran/Desktop/tmp.txt\"\n",
    "    result = identify_tool_mentions_in_sentences(first_article.pmcid, tool, relevant_parahraphs)\n",
    "    write_tool_mentions_to_file(result, file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = []\n",
    "\n",
    "for pmcid in tqdm(unique_pmcids, desc=\"Processing PMCIDs\"):\n",
    "    partial_sentences = annotations_df[annotations_df['pmc_id'] == pmcid]['partial_sentence'].tolist()\n",
    "    segmented_sentences = get_full_text_xml_paragraphs(pmcid, partial_sentences)\n",
    "    processed_data = process_pmcid(annotations_df, pmcid, segmented_sentences)   \n",
    "    if processed_data:\n",
    "        final_data.extend(processed_data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "final_df = pd.DataFrame(final_data, columns=['pmcid', 'sentence', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call cites query with a specific PubMed ID and get a list of Article objects\n",
    "cites_articles = client.search_cites(\"32109013\")\n",
    "print(\"The count of the cites articles (within the first 3 pages):\", len(cites_articles))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioHackathon 2024",
   "language": "python",
   "name": "biohackathon-2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
