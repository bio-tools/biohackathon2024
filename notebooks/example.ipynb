{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example notebook\n",
    "\n",
    "Here we get the Article classes for all given bio.tools tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15005\n"
     ]
    }
   ],
   "source": [
    "from bh24_literature_mining.utils import load_biotools_pub\n",
    "\n",
    "tools = load_biotools_pub(\"../biotoolspub/biotoolspub.tsv\")\n",
    "\n",
    "tools_lower = set()\n",
    "\n",
    "for index, row in tools.iterrows():\n",
    "    name = row[\"name\"]\n",
    "    biotoolsID = row[\"biotoolsID\"]\n",
    "\n",
    "    link = row[\"file_path\"]\n",
    "    # print(f\"Name: {name}, PubMed ID: {biotoolsID}, Link: {link}\")\n",
    "    tools_lower.add(name.lower())\n",
    "\n",
    "\n",
    "print(len(tools_lower))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example on how to use europepmc_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No relevant paragraphs found subtiwiki\n",
      "No relevant paragraphs found metapathways\n",
      "No relevant paragraphs found metapathways\n",
      "No relevant paragraphs found mzmine\n",
      "No relevant paragraphs found iphop\n",
      "No relevant paragraphs found jalview\n"
     ]
    }
   ],
   "source": [
    "from bh24_literature_mining.europepmc_api import EuropePMCClient, write_tool_mentions_to_file\n",
    "\n",
    "\n",
    "client = EuropePMCClient()\n",
    "\n",
    "for index, tool in tools.iterrows():\n",
    "    if(index > 10):\n",
    "        break\n",
    "    # Call bio.tools query and get a list of Article objects\n",
    "    tool_name = str(tool[\"name\"]).lower()\n",
    "    tool_id = str(tool[\"biotoolsID\"])\n",
    "    biotools_articles = client.search_mentions(tool_name)\n",
    "\n",
    "    if len(biotools_articles) == 0:\n",
    "        continue\n",
    "    first_article = biotools_articles[0]\n",
    "\n",
    "    relevant_parahraphs = client.get_relevant_paragraphs(first_article.pmcid, tool_name)\n",
    "    if len(relevant_parahraphs) == 0:\n",
    "        print(\"No relevant paragraphs found\", tool_name)\n",
    "        continue\n",
    "    from bh24_literature_mining.europepmc_api import identify_tool_mentions_in_sentences\n",
    "\n",
    "    file_path = '/Users/vedran/Desktop/tmp.txt'\n",
    "    result = identify_tool_mentions_in_sentences(first_article.pmcid, tool_name, tool_id, relevant_parahraphs)\n",
    "    write_tool_mentions_to_file(result, file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of bh24_literature_mining.europepmc_api failed: Traceback (most recent call last):\n",
      "  File \"/home/tess/.cache/pypoetry/virtualenvs/bh24-literature-mining-3mhmtudb-py3.12/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/tess/.cache/pypoetry/virtualenvs/bh24-literature-mining-3mhmtudb-py3.12/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/tess/miniforge3/lib/python3.12/importlib/__init__.py\", line 131, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 866, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"/home/tess/biohackathon2024/src/bh24_literature_mining/europepmc_api.py\", line 8, in <module>\n",
      "    from sentence_splitter import SentenceSplitter\n",
      "ModuleNotFoundError: No module named 'sentence_splitter'\n",
      "]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import spacy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# nlp = spacy.load(\"en_core_sci_sm\", disable=[\"tagger\", \"parser\", \"ner\", \"lemmatizer\", \"attribute_ruler\"])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# nlp.add_pipe(\"sentencizer\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# # this is time consuming. The sentenciser takes 1 minute per article on an average.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m final_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pmcid \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m(unique_pmcids, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing PMCIDs\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      9\u001b[0m     partial_sentences \u001b[38;5;241m=\u001b[39m annotations_df[annotations_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpmc_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m pmcid][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpartial_sentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     10\u001b[0m     segmented_sentences \u001b[38;5;241m=\u001b[39m get_full_text_xml_paragraphs(pmcid, partial_sentences)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "final_data = []\n",
    "\n",
    "for pmcid in tqdm(unique_pmcids, desc=\"Processing PMCIDs\"):\n",
    "    partial_sentences = annotations_df[annotations_df['pmc_id'] == pmcid]['partial_sentence'].tolist()\n",
    "    segmented_sentences = get_full_text_xml_paragraphs(pmcid, partial_sentences)\n",
    "    processed_data = process_pmcid(annotations_df, pmcid, segmented_sentences)   \n",
    "    if processed_data:\n",
    "        final_data.extend(processed_data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "final_df = pd.DataFrame(final_data, columns=['pmcid', 'sentence', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of the cites articles (within the first 3 pages): 1000\n"
     ]
    }
   ],
   "source": [
    "# Call cites query with a specific PubMed ID and get a list of Article objects\n",
    "cites_articles = client.search_cites(\"32109013\")\n",
    "print(\"The count of the cites articles (within the first 3 pages):\", len(cites_articles))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioHackathon 2024",
   "language": "python",
   "name": "biohackathon-2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
