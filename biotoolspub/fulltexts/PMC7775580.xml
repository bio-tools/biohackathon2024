<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Pharmacol</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Pharmacol</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Pharmacol.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Pharmacology</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1663-9812</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7775580</article-id>
    <article-id pub-id-type="publisher-id">565644</article-id>
    <article-id pub-id-type="doi">10.3389/fphar.2020.565644</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Pharmacology</subject>
        <subj-group>
          <subject>Technology and Code</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation Models</article-title>
      <alt-title alt-title-type="left-running-head">Polykovskiy et al.</alt-title>
      <alt-title alt-title-type="right-running-head">Molecular Sets (MOSES)</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Polykovskiy</surname>
          <given-names>Daniil</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="c001">*</xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/600420/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhebrak</surname>
          <given-names>Alexander</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/590537/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sanchez-Lengeling</surname>
          <given-names>Benjamin</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/748418/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Golovanov</surname>
          <given-names>Sergey</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/1147464/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tatanov</surname>
          <given-names>Oktai</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/1147241"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Belyaev</surname>
          <given-names>Stanislav</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/1147111/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kurbanov</surname>
          <given-names>Rauf</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/1147802/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Artamonov</surname>
          <given-names>Aleksey</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/1147262/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Aladinskiy</surname>
          <given-names>Vladimir</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/1147126/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Veselov</surname>
          <given-names>Mark</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/1146987/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kadurin</surname>
          <given-names>Artur</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/850943/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Johansson</surname>
          <given-names>Simon</given-names>
        </name>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/1068247/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Hongming</given-names>
        </name>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/814324/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Nikolenko</surname>
          <given-names>Sergey</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="corresp" rid="c001">*</xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/31995/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Aspuru-Guzik</surname>
          <given-names>Alán</given-names>
        </name>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
        <xref ref-type="aff" rid="aff7">
          <sup>7</sup>
        </xref>
        <xref ref-type="aff" rid="aff8">
          <sup>8</sup>
        </xref>
        <xref ref-type="aff" rid="aff9">
          <sup>9</sup>
        </xref>
        <xref ref-type="corresp" rid="c001">*</xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/96252/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhavoronkov</surname>
          <given-names>Alex</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="c001">*</xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/70940/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><label><sup>1</sup></label>Insilico Medicine Hong Kong Ltd., <addr-line>Pak Shek Kok</addr-line>, <country>Hong Kong</country></aff>
    <aff id="aff2"><label><sup>2</sup></label>Chemistry and Chemical Biology Department, Harvard University, <addr-line>Cambridge</addr-line>, <addr-line>MA</addr-line>, <country>United States</country></aff>
    <aff id="aff3"><label><sup>3</sup></label>Neuromation OU, <addr-line>Tallinn</addr-line>, <country>Estonia</country></aff>
    <aff id="aff4"><label><sup>4</sup></label>Molecular AI, DiscoverySciences, R&amp;D, AstraZeneca, <addr-line>Gothenburg</addr-line>, <country>Sweden</country></aff>
    <aff id="aff5"><label><sup>5</sup></label>Computer Science Department, National Research University Higher School of Economics, <addr-line>St. Petersburg</addr-line>, <country>Russia</country></aff>
    <aff id="aff6"><label><sup>6</sup></label>Chemical Physics Theory Group, Department of Chemistry, University of Toronto, <addr-line>Toronto</addr-line>, <addr-line>ON</addr-line>, <country>Canada</country></aff>
    <aff id="aff7"><label><sup>7</sup></label>Department of Computer Science, University of Toronto, <addr-line>Toronto</addr-line>, <addr-line>ON</addr-line>, <country>Canada</country></aff>
    <aff id="aff8"><label><sup>8</sup></label>CIFAR AI Chair, Vector Institute for Artificial Intelligence, <addr-line>Toronto</addr-line>, <addr-line>ON</addr-line>, <country>Canada</country></aff>
    <aff id="aff9"><label><sup>9</sup></label>Lebovic Fellow, Canadian Institute for Advanced Research (CIFAR), <addr-line>Toronto</addr-line>, <addr-line>ON</addr-line>, <country>Canada</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p><bold>Edited by:</bold><ext-link ext-link-type="uri" xlink:href="https://loop.frontiersin.org/people/489389/overview">Jianxun Ding</ext-link>, Chinese Academy of Sciences, China</p>
      </fn>
      <fn fn-type="edited-by">
        <p><bold>Reviewed by:</bold><ext-link ext-link-type="uri" xlink:href="https://loop.frontiersin.org/people/18477/overview">Nazareno Paolocci</ext-link>, Johns Hopkins University, United States</p>
        <p><ext-link ext-link-type="uri" xlink:href="https://loop.frontiersin.org/people/1082082/overview">Felix Zhou</ext-link>, University of Oxford, United Kingdom</p>
      </fn>
      <corresp id="c001">*Correspondence: Daniil Polykovskiy, <email>daniil@insilico.com</email>; Alex Zhavoronkov, <email>alex@insilico.com</email>; Alán Aspuru-Guzik, <email>alan@aspuru.com</email>; Sergey Nikolenko, <email>snikolenko@gmail.com</email></corresp>
      <fn fn-type="other">
        <p>This article was submitted to Translational Pharmacology, a section of the journal Frontiers in Pharmacology</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>18</day>
      <month>12</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>11</volume>
    <elocation-id>565644</elocation-id>
    <history>
      <date date-type="received">
        <day>25</day>
        <month>5</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>26</day>
        <month>10</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2020 Polykovskiy, Zhebrak, Sanchez-Lengeling, Golovanov, Tatanov, Belyaev, Kurbanov, Artamonov, Aladinskiy, Veselov, Kadurin, Johansson, Chen, Nikolenko, Aspuru-Guzik and Zhavoronkov</copyright-statement>
      <copyright-holder>Polykovskiy, Zhebrak, Sanchez Lengeling, Golovanov, Tatanov, Belyaev, Kurbanov, Artamonov, Aladinskiy, Veselov, Kadurin, Johansson, Chen, Nikolenko, Aspuru-Guzik and Zhavoronkov</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Generative models are becoming a tool of choice for exploring the molecular space. These models learn on a large training dataset and produce novel molecular structures with similar properties. Generated structures can be utilized for virtual screening or training semi-supervized predictive models in the downstream tasks. While there are plenty of generative models, it is unclear how to compare and rank them. In this work, we introduce a benchmarking platform called Molecular Sets (MOSES) to standardize training and comparison of molecular generative models. MOSES provides training and testing datasets, and a set of metrics to evaluate the quality and diversity of generated structures. We have implemented and compared several molecular generation models and suggest to use our results as reference points for further advancements in generative chemistry research. The platform and source code are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/molecularsets/moses">https://github.com/molecularsets/moses</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>generative models</kwd>
      <kwd>drug discovery</kwd>
      <kwd>deep learning</kwd>
      <kwd>benchmark</kwd>
      <kwd>distribution learning</kwd>
    </kwd-group>
    <counts>
      <page-count count="0"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="s1">
    <title>Introduction</title>
    <p>The discovery of new molecules for drugs and materials can bring enormous societal and technological progress, potentially curing rare diseases and providing a pathway for personalized precision medicine (<xref rid="B39" ref-type="bibr">Lee et al., 2018</xref>). However, complete exploration of the huge space of potential chemicals is computationally intractable; it has been estimated that the number of pharmacologically-sensible molecules is in the order of <inline-formula id="inf1"><mml:math id="M1"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> to <inline-formula id="inf111"><mml:math id="M2"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>80</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> compounds (<xref rid="B32" ref-type="bibr">Kirkpatrick and Ellis, 2004</xref>; <xref rid="B55" ref-type="bibr">Reymond, 2015</xref>). Often, this search is constrained based on already discovered structures and desired qualities such as solubility or toxicity. There have been many approaches to exploring the chemical space <italic>in silico</italic> and <italic>in vitro</italic>, including high throughput screening, combinatorial libraries, and evolutionary algorithms (<xref rid="B23" ref-type="bibr">Hu et al., 2009</xref>; <xref rid="B18" ref-type="bibr">Curtarolo et al., 2013</xref>; <xref rid="B76" ref-type="bibr">Pyzer-Knapp et al., 2015</xref>; <xref rid="B37" ref-type="bibr">Le and Winkler, 2016</xref>). Recent works demonstrated that machine learning methods can produce new small molecules (<xref rid="B43" ref-type="bibr">Merk et al., 2018a</xref>; <xref rid="B44" ref-type="bibr">Merk et al., 2018b</xref>; <xref rid="B49" ref-type="bibr">Polykovskiy et al., 2018b</xref>; <xref rid="B72" ref-type="bibr">Zhavoronkov et al., 2019a</xref>) and peptides (<xref rid="B21" ref-type="bibr">Grisoni et al., 2018</xref>) showing biological activity.</p>
    <p>Over the last few years, advances in machine learning, and especially in deep learning, have driven the design of new computational systems for modeling increasingly complex phenomena. One approach that has been proven fruitful for modeling molecular data is deep generative models. Deep generative models have found applications in a wide range of settings, from generating synthetic images (<xref rid="B29" ref-type="bibr">Karras et al., 2018</xref>) and natural language texts (<xref rid="B71" ref-type="bibr">Yu et al., 2017</xref>), to the applications in biomedicine, including the design of DNA sequences (<xref rid="B30" ref-type="bibr">Killoran et al., 2017</xref>), and aging research (<xref rid="B72" ref-type="bibr">Zhavoronkov et al., 2019b</xref>). One important field of application for deep generative models lies in the inverse design of drug compounds (<xref rid="B57" ref-type="bibr">Sanchez-Lengeling and Aspuru-Guzik, 2018</xref>) for a given functionality (solubility, ease of synthesis, toxicity). Deep learning also found other applications in biomedicine (<xref rid="B41" ref-type="bibr">Mamoshina et al., 2016</xref>; <xref rid="B10" ref-type="bibr">Ching et al., 2018</xref>), including target identification (<xref rid="B42" ref-type="bibr">Mamoshina et al., 2018</xref>), antibacterial drug discovery (<xref rid="B24" ref-type="bibr">Ivanenkov et al., 2019</xref>), and drug repurposing (<xref rid="B1" ref-type="bibr">Aliper et al., 2016</xref>; <xref rid="B65" ref-type="bibr">Vanhaelen et al., 2017</xref>).</p>
    <p>Part of the success of deep learning in different fields has been driven by ever-growing availability of large datasets and standard benchmark sets. These sets serve as a common measuring stick for newly developed models and optimization strategies (<xref rid="B38" ref-type="bibr">LeCun et al., 1998</xref>; <xref rid="B14" ref-type="bibr">Deng et al., 2009</xref>). In the context of organic molecules, MoleculeNet (<xref rid="B69" ref-type="bibr">Wu et al., 2018</xref>) was introduced as a standardized benchmark suite for regression and classification tasks. <xref rid="B9" ref-type="bibr">Brown et al. (2019)</xref> proposed to evaluate generative models on goal-oriented and distribution learning tasks with a focus on the former. We focus on standardizing metrics and data for the distribution learning problem that we introduce below.</p>
    <p>In this work, we provide a benchmark suite—Molecular Sets (MOSES)—for molecular generation: a standardized dataset, data preprocessing utilities, evaluation metrics, and molecular generation models. We hope that our platform will serve as a clear and unified testbed for current and future generative models. We illustrate the main components of MOSES in <xref ref-type="fig" rid="fig1">Figure 1</xref>.</p>
    <fig id="fig1" position="float">
      <label>FIGURE 1</label>
      <caption>
        <p>Molecular Sets (MOSES) pipeline. The open-source library provides a dataset, baseline models, and evaluation metrics.</p>
      </caption>
      <graphic xlink:href="fphar-11-565644-g001"/>
    </fig>
    <sec id="s1-1">
      <title>Distribution Learning</title>
      <p>In MOSES, we study distribution learning models. Formally, given a set of training samples <inline-formula id="inf2"><mml:math id="M3"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mtext>tr</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mtext>tr</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>N</mml:mi><mml:mrow><mml:mtext>tr</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> from an unknown distribution <inline-formula id="inf3"><mml:math id="M4"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, distribution learning models approximate <inline-formula id="inf4"><mml:math id="M5"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with some distribution <inline-formula id="inf5"><mml:math id="M6"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p>
      <p>Distribution learning models are mainly used for building virtual libraries (<xref rid="B64" ref-type="bibr">van Hilten et al., 2019</xref>) for computer-assisted drug discovery. While imposing simple rule-based restrictions on a virtual library (such as maximum or minimum weight) is straightforward, it is unclear how to apply implicit or soft restrictions on the library. For example, a medicinal chemist might expect certain substructures to be more prevalent in generated structures. Relying on a set of manually or automatically selected compounds, distribution learning models produce a larger dataset, preserving implicit rules from the dataset. Another application of distribution learning models is extending the training set for downstream semi-supervized predictive tasks: one can add new unlabeled data by sampling compounds from a generative model.</p>
      <p>The quality of a distribution learning model is a deviation measure between <inline-formula id="inf6"><mml:math id="M7"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="inf7"><mml:math id="M8"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The model can define a probability mass function <inline-formula id="inf8"><mml:math id="M9"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> implicitly or explicitly. Explicit models such as Hidden Markov Models, n-gram language models, or normalizing flows (<xref rid="B15" ref-type="bibr">Dinh et al., 2017</xref>; <xref rid="B59" ref-type="bibr">Shi et al., 2019</xref>) can analytically compute <inline-formula id="inf800"><mml:math id="M10"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and sample from it. Implicit models, such as variational autoencoders, adversarial autoencoders, or generative adversarial networks (<xref rid="B27" ref-type="bibr">Kadurin et al., 2016</xref>; <xref rid="B12" ref-type="bibr">De Cao and Kipf, 2018</xref>; <xref rid="B20" ref-type="bibr">Gómez-Bombarelli et al., 2018</xref>) can sample from <inline-formula id="inf9"><mml:math id="M11"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, but can not compute the exact values of the probability mass function. To compare both kinds of models, evaluation metrics considered in this paper depend only on samples from <inline-formula id="inf801"><mml:math id="M12"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p>
    </sec>
    <sec id="s1-2">
      <title>Molecular Representations</title>
      <p>In this section, we discuss different approaches to representing a molecule in a machine learning-friendly way (<xref ref-type="fig" rid="fig2">Figure 2</xref>): string and graph representations.</p>
      <fig id="fig2" position="float">
        <label>FIGURE 2</label>
        <caption>
          <p>Different views on a vanillin molecule.</p>
        </caption>
        <graphic xlink:href="fphar-11-565644-g002"/>
      </fig>
      <p><bold>String representations.</bold> Representing a molecular structure as a string have been quickly adopted (<xref rid="B25" ref-type="bibr">Jaques et al., 2016</xref>; <xref rid="B22" ref-type="bibr">Guimaraes et al., 2017</xref>; <xref rid="B27" ref-type="bibr">Kadurin et al., 2017</xref>; <xref rid="B45" ref-type="bibr">Olivecrona et al., 2017</xref>; <xref rid="B70" ref-type="bibr">Yang et al., 2017</xref>; <xref rid="B28" ref-type="bibr">Kang and Cho, 2018</xref>; <xref rid="B50" ref-type="bibr">Popova et al., 2018</xref>; <xref rid="B53" ref-type="bibr">Putin et al., 2018</xref>; <xref rid="B58" ref-type="bibr">Segler et al., 2018</xref>) for generative models due to the abundance of sequence modeling tools such as recurrent neural networks, attention mechanisms, and dilated convolutions. Simplified molecular input line entry system (SMILES) (<xref rid="B66" ref-type="bibr">Weininger, 1988</xref>) is the most widely used string representation for generative machine learning models. SMILES algorithm traverses a spanning tree of a molecular graph in depth-first order and stores atom and edge tokens. SMILES also uses special tokens for branching and edges not covered with a spanning tree. Note that since a molecule can have multiple spanning trees, different SMILES strings can represent a single molecule. While there is a canonicalization procedure to uniquely construct a SMILES string from a molecule (<xref rid="B67" ref-type="bibr">Weininger et al., 1989</xref>), ambiguity of SMILES can also serve as augmentation and improve generative models (<xref rid="B2" ref-type="bibr">Arús-Pous et al., 2019</xref>).</p>
      <p>DeepSMILES (<xref rid="B46" ref-type="bibr">O’Boyle and Dalke, 2018</xref>) was introduced as an extension of SMILES that seeks to reduce invalid sequences by altering syntax for branches and ring closures. Some methods try to incorporate SMILES syntax into a network architecture to increase the fraction of valid molecules (<xref rid="B34" ref-type="bibr">Kusner et al., 2017</xref>; <xref rid="B11" ref-type="bibr">Dai et al., 2018</xref>). SELFIES (<xref rid="B33" ref-type="bibr">Krenn et al., 2019</xref>) defines a new syntax based on a Chomsky type-2 grammar augmented with self-referencing functions. International Chemical Identifier (InChI) (<xref rid="B61" ref-type="bibr">Stein et al., 2003</xref>) is a more verbose string representation which explicitly specifies a chemical formula, atoms’ charges, hydrogens, and isotopes. However, <xref rid="B20" ref-type="bibr">Gómez-Bombarelli et al. (2018)</xref> reported that InChI-based models perform substantially worse than SMILES-based models in generative modeling—presumably due to a more complex syntax.</p>
      <p><bold>Molecular graphs.</bold> Graph representations have long been used in chemoinformatics for storing and processing molecular data. In a molecular graph, each node corresponds to an atom and each edge corresponds to a bond. Such graph can specify hydrogens either explicitly or implicitly. In the latter case, the number of hydrogens can be deduced from atoms’ valencies.</p>
      <p>Classical machine learning methods mostly utilize molecular descriptors extracted from such graphs. Deep learning models, however, can learn from graphs directly with models such as Graph Convolutional Networks (<xref rid="B16" ref-type="bibr">Duvenaud et al., 2015</xref>), Weave Networks (<xref rid="B69" ref-type="bibr">Wu et al., 2018</xref>), and Message Passing Networks (<xref rid="B19" ref-type="bibr">Gilmer et al., 2017</xref>). Molecular graph can also be represented as adjacency matrix and node feature matrix; this approach has been successfully employed in the MolGAN model (<xref rid="B12" ref-type="bibr">De Cao and Kipf, 2018</xref>) for the QM9 dataset (<xref rid="B54" ref-type="bibr">Ramakrishnan et al., 2014</xref>). Other approaches such as Junction Tree VAE (<xref rid="B26" ref-type="bibr">Jin et al., 2018</xref>) process molecules in terms of their subgraphs.</p>
    </sec>
    <sec id="s1-3">
      <title>Metrics</title>
      <p>In this section, we propose a set of metrics to assess the quality of generative models. The proposed metrics detect common issues in generative models such as overfitting, imbalance of frequent structures or mode collapse. Each metric depends on a generated set <italic>G</italic> and a test (reference) set <italic>R</italic>. We compute all metrics (except for validity) only for valid molecules from the generated set. We suggest generating 30, 000 molecules and obtaining <italic>G</italic> as valid molecules from this set.</p>
      <p><bold>Fraction of valid (Valid) and unique (Unique@k)</bold> molecules report validity and uniqueness of the generated SMILES strings. We define validity using RDKit’s molecular structure parser that checks atoms’ valency and consistency of bonds in aromatic rings. In the experiments, we compute Unique@<italic>K</italic> and for the first <inline-formula id="inf1000"><mml:math id="M13"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>1,000</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="inf10"><mml:math id="M14"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>10,000</mml:mn></mml:mrow></mml:math></inline-formula> valid molecules in the generated set. If the number of valid molecules is less than <italic>K</italic>, we compute uniqueness on all valid molecules. Validity measures how well the model captures explicit chemical constraints such as proper valence. Uniqueness checks that the model does not collapse to producing only a few typical molecules.</p>
      <p><bold>Novelty</bold> is the fraction of the generated molecules that are not present in the training set. Low novelty indicates overfitting.</p>
      <p><bold>Filters</bold> is the fraction of generated molecules that pass filters applied during dataset construction (see <xref ref-type="sec" rid="s5">Section 5</xref>). While the generated molecules are often chemically valid, they may contain unwanted fragments: when constructing the training dataset, we removed molecules with such fragments and expect the models to avoid producing them.</p>
      <p><bold>Fragment similarity (Frag)</bold> compares distributions of BRICS fragments (<xref rid="B13" ref-type="bibr">Degen et al., 2008</xref>) in generated and reference sets. Denoting <inline-formula id="inf11"><mml:math id="M15"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>A</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> a number of times a substructure <italic>f</italic> appears in molecules from set <italic>A</italic>, and a set of fragments that appear in either <italic>G</italic> or <italic>R</italic> as <italic>F</italic>, the metric is defined as a cosine similarity:<disp-formula id="e1"><mml:math id="M16"><mml:mrow><mml:mtext>Frag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>G</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>G</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:msqrt><mml:msqrt><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math><label>(1)</label></disp-formula>
</p>
      <p>If molecules in both sets have similar fragments, Frag metric is large. If some fragments are over- or underrepresented (or never appear) in the generated set, the metric will be lower. Limits of this metric are [0,1].</p>
      <p><bold>Scaffold similarity (Scaff)</bold> is similar to fragment similarity metric, but instead of fragments we compare frequencies of Bemis–Murcko scaffolds (<xref rid="B5" ref-type="bibr">Bemis and Murcko, 1996</xref>). Bemis–Murcko scaffold contains all molecule’s ring structures and linker fragments connecting rings. We use RDKit implementation of this algorithm which additionally considers carbonyl groups attached to rings as part of a scaffold. Denoting <inline-formula id="inf12"><mml:math id="M17"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>A</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> a number of times a scaffold <italic>s</italic> appears in molecules from set <italic>A</italic>, and a set of fragments that appear in either <italic>G</italic> or <italic>R</italic> as <italic>S</italic>, the metric is defined as a cosine similarity:<disp-formula id="e2"><mml:math id="M18"><mml:mrow><mml:mtext>Frag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>G</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>G</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:msqrt><mml:msqrt><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math><label>(2)</label></disp-formula>
</p>
      <p>The purpose of this metric is to show how similar are the scaffolds present in generated and reference datasets. For example, if the model rarely produces a certain chemotype from a reference set, the metric will be low. Limits of this metric are [0,1].</p>
      <p>Note that both fragment and scaffold similarities compare molecules at a substructure level. Hence, it is possible to have a similarity one even when <italic>G</italic> and <italic>R</italic> contain different molecules.</p>
      <p><bold>Similarity to a nearest neighbor (SNN)</bold> is an average Tanimoto similarity <italic>T(m</italic>
<sub><italic>G</italic></sub>
<italic>,m</italic>
<sub><italic>R</italic></sub>
<italic>)</italic> (also known as the Jaccard index) between fingerprints of a molecule <inline-formula id="inf13"><mml:math id="M19"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> from the generated set <italic>G</italic> and its nearest neighbor molecule <inline-formula id="inf14"><mml:math id="M20"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in the reference dataset <italic>R</italic>:<disp-formula id="e3"><mml:math id="M21"><mml:mrow><mml:mtext>SNN</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>G</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>G</mml:mi></mml:mrow></mml:munder><mml:munder><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:munder><mml:mi>T</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math><label>(3)</label></disp-formula>
</p>
      <p>In this work, we used standard Morgan (extended connectivity) fingerprints (<xref rid="B56" ref-type="bibr">Rogers and Hahn, 2010</xref>) with radius 2 and 1024 bits computed using RDKit library (<xref rid="B36" ref-type="bibr">Landrum, 2006</xref>). The resulting similarity metric can be interpreted as precision: if generated molecules are far from the manifold of the reference set, similarity to the nearest neighbor will be low. Limits of this metric are [0,1].</p>
      <p><bold>Internal diversity (IntDiv<sub><italic>p</italic></sub>)</bold> (<xref rid="B6" ref-type="bibr">Benhenda, 2017</xref>) assesses the chemical diversity within the generated set of molecules <italic>G</italic>.<disp-formula id="e4"><mml:math id="M22"><mml:mrow><mml:msub><mml:mrow><mml:mtext>IntDiv</mml:mtext></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>G</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mroot><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>G</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:mi>G</mml:mi></mml:mrow></mml:munder><mml:mi>T</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>p</mml:mi></mml:msup></mml:mrow><mml:mi>p</mml:mi></mml:mroot><mml:mo>.</mml:mo></mml:mrow></mml:math><label>(4)</label></disp-formula>
</p>
      <p>This metric detects a common failure case of generative models—mode collapse. With mode collapse, the model produces a limited variety of samples, ignoring some areas of the chemical space. A higher value of this metric corresponds to higher diversity in the generated set. In the experiments, we report IntDiv<sub>1</sub> (G) and IntDiv<sub>2</sub> (G). Limits of this metric are [0,1].</p>
      <p><bold>Fréchet ChemNet Distance (FCD)</bold> (<xref rid="B51" ref-type="bibr">Preuer et al., 2018</xref>) is calculated using activations of the penultimate layer of a deep neural network ChemNet trained to predict biological activities of drugs. We compute activations for canonical SMILES representations of molecules. These activations capture both chemical and biological properties of the compounds. For two sets of molecules <italic>G</italic> and <italic>R</italic>, FCD is defined as<disp-formula id="e5"><mml:math id="M23"><mml:mrow><mml:mtext>FCD</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mtext>Tr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mtext>Σ</mml:mtext><mml:mi>G</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mtext>Σ</mml:mtext><mml:mi>R</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>Σ</mml:mtext><mml:mi>G</mml:mi></mml:msub><mml:msub><mml:mtext>Σ</mml:mtext><mml:mi>R</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math><label>(5)</label></disp-formula>where <inline-formula id="inf150"><mml:math id="M24"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula id="inf15"><mml:math id="M25"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are mean vectors and <inline-formula id="inf16"><mml:math id="M26"><mml:mrow><mml:msub><mml:mtext>Σ</mml:mtext><mml:mi>G</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula id="inf160"><mml:math id="M27"><mml:mrow><mml:msub><mml:mtext>Σ</mml:mtext><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are full covariance matrices of activations for molecules from sets <italic>G</italic> and <italic>R</italic> respectively. FCD correlates with other metrics. For example, if the generated structures are not diverse enough (low <inline-formula id="inf17"><mml:math id="M28"><mml:mrow><mml:msub><mml:mrow><mml:mtext>IntDiv</mml:mtext></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>) or the model produces too many duplicates (low uniqueness), FCD will decrease, since the variance is smaller. We suggest using FCD for hyperparameter tuning and final model selection. Values of this metric are non-negative, lower is better.</p>
      <p><bold>Properties distribution</bold> is a useful tool for visually assessing the generated structures. To quantitatively compare the distributions in the generated and test sets, we compute a 1D Wasserstein-1 distance between property distributions of generated and test sets. We also visualize a kernel density estimation of these distributions in the Experiments section. We use the following four properties:<list list-type="bullet"><list-item><p>Molecular weight (MW): the sum of atomic weights in a molecule. By plotting histograms of molecular weight for the generated and test sets, one can judge if a generated set is biased toward lighter or heavier molecules.</p></list-item><list-item><p>LogP: the octanol-water partition coefficient, a ratio of a chemical’s concentration in the octanol phase to its concentration in the aqueous phase of a two-phase octanol/water system; computed with RDKit’s Crippen (<xref rid="B68" ref-type="bibr">Wildman and Crippen, 1999</xref>) estimation.</p></list-item><list-item><p>Synthetic Accessibility Score (SA): a heuristic estimate of how hard (10) or how easy (1) it is to synthesize a given molecule. SA score is based on a combination of the molecule’s fragments contributions (<xref rid="B17" ref-type="bibr">Ertl and Schuffenhauer, 2009</xref>). Note that SA score does not adequately assess up-to-date chemical structures, but it is useful for assessing distribution learning models.</p></list-item><list-item><p>Quantitative Estimation of Drug-likeness (QED): a [0,1] value estimating how likely a molecule is a viable candidate for a drug. QED is meant to capture the abstract notion of esthetics in medicinal chemistry (<xref rid="B7" ref-type="bibr">Bickerton et al., 2012</xref>). Similar to SA, descriptor limits in QED have been changing during the last decade and current limits may not cover latest drugs (<xref rid="B60" ref-type="bibr">Shultz, 2018</xref>).</p></list-item></list>
</p>
    </sec>
  </sec>
  <sec id="s2">
    <title>Dataset</title>
    <p>The proposed dataset used for training and testing is based on the ZINC Clean Leads (<xref rid="B62" ref-type="bibr">Sterling and Irwin, 2015</xref>) collection which contains 4, 591, 276 molecules with molecular weight in the range from 250 to 350 Da, a number of rotatable bonds not greater than 7, and XlogP (<xref rid="B35" ref-type="bibr">Wang et al., 1997</xref>) not greater then 3.5. Clean-leads dataset consists of structures suitable for identifying hit compounds and they are small enough to allow for further ADMET optimization of generated molecules (<xref rid="B63" ref-type="bibr">Teague et al., 1999</xref>). We removed molecules containing charged atoms, atoms besides C, N, S, O, F, Cl, Br, H, or cycles larger than eight atoms. The molecules were filtered via custom medicinal chemistry filters (MCFs) and PAINS filters (<xref rid="B4" ref-type="bibr">Baell and Holloway, 2010</xref>). We describe MCFs and discuss PAINS in Supplementary Information 1. We removed charged molecules to avoid ambiguity with tautomers and pH conditions. Note that in the initial set of molecules, functional groups were present in both ionized and unionized forms.</p>
    <p>The final dataset contains molecules, with internal diversity IntDiv<sub>1</sub> = 0.857; it contains <inline-formula id="inf18"><mml:math id="M29"><mml:mrow><mml:mn>448,854</mml:mn></mml:mrow></mml:math></inline-formula> unique Bemis-Murcko (<xref rid="B5" ref-type="bibr">Bemis and Murcko, 1996</xref>) scaffolds and 58,315 unique BRICS (<xref rid="B13" ref-type="bibr">Degen et al., 2008</xref>) fragments. We show example molecules in <xref ref-type="fig" rid="fig3">Figure 3</xref> and a representative diverse subset in Supplementary Information 2. We provide recommended split into three non-intersecting parts: train (<inline-formula id="inf19"><mml:math id="M30"><mml:mrow><mml:mn>1,584,664</mml:mn></mml:mrow></mml:math></inline-formula> molecules), test (<inline-formula id="inf20"><mml:math id="M31"><mml:mrow><mml:mn>176,075</mml:mn></mml:mrow></mml:math></inline-formula> molecules) and scaffold test (176, 226 molecules). The scaffold test set has all molecules containing a Bemis-Murcko scaffold from a random subset of scaffolds. Hence, scaffolds from the scaffold test set differ from scaffolds in both train and test sets. We use scaffold test split to assess whether a model can produce novel scaffolds absent in the training set. The test set is a random subset of the remaining molecules in the dataset.</p>
    <fig id="fig3" position="float">
      <label>FIGURE 3</label>
      <caption>
        <p>Examples of molecules from MOSES dataset.</p>
      </caption>
      <graphic xlink:href="fphar-11-565644-g003"/>
    </fig>
  </sec>
  <sec id="s3">
    <title>Baselines</title>
    <p>We implemented several models that cover different approaches to molecular generation, such as character-level recurrent neural networks (CharRNN) (<xref rid="B51" ref-type="bibr">Preuer et al., 2018</xref>; <xref rid="B58" ref-type="bibr">Segler et al., 2018</xref>), Variational Autoencoders (VAE) (<xref rid="B27" ref-type="bibr">Kadurin et al., 2016</xref>; <xref rid="B8" ref-type="bibr">Blaschke et al., 2018</xref>; <xref rid="B20" ref-type="bibr">Gómez-Bombarelli et al., 2018</xref>), Adversarial Autoencoders (AAE) (<xref rid="B27" ref-type="bibr">Kadurin et al., 2016</xref>; <xref rid="B49" ref-type="bibr">Polykovskiy et al., 2018b</xref>), Junction Tree Variational Autoencoders (JTN-VAE) (<xref rid="B26" ref-type="bibr">Jin et al., 2018</xref>), LatentGAN (<xref rid="B52" ref-type="bibr">Prykhodko et al., 2019</xref>), and non-neural baselines.</p>
    <p>Model comparison can be challenging since different training parameters (number of epochs, batch size, learning rate, initial state, optimizer) and architecture hyperparameters (hidden layer dimension, number of layers, etc.) can significantly alter their performance. For each model, we attempted to preserve its original architecture as published and tuned the hyperparameters to improve the performance. We used random search over multiple architectures for every model and selected the architecture that produced the best value of FCD. Models are implemented in <italic>Python</italic> 3 utilizing PyTorch (<xref rid="B47" ref-type="bibr">Paszke et al., 2017</xref>) framework. Please refer to the Supplementary Information three for the training details and hyperparameters.</p>
    <p><bold>Character-level recurrent neural network (CharRNN)</bold> (<xref rid="B58" ref-type="bibr">Segler et al., 2018</xref>) models a distribution over the next token given previously generated ones. We train this model by maximizing log-likelihood of the training data represented as SMILES strings.</p>
    <p><bold>Variational autoencoder (VAE)</bold> (<xref rid="B31" ref-type="bibr">Kingma and Welling, 2013</xref>) consists of two neural networks—an encoder and a decoder—that infer a mapping from high-dimensional data representation onto a lower-dimensional space and back. The lower-dimensional space is called the latent space, which is often a continuous vector space with normal prior distribution. VAE parameters are optimized to encode and decode data by minimizing reconstruction loss and regularization term in a form of Kullback-Leibler divergence. VAE-based architecture for the molecular generation was studied in multiple previous works (<xref rid="B27" ref-type="bibr">Kadurin et al. 2016</xref>; <xref rid="B8" ref-type="bibr">Blaschke et al. 2018</xref>; <xref rid="B20" ref-type="bibr">Gómez-Bombarelli et al. 2018</xref>). We combine aspects from these implementations and use SMILES as input and output representations.</p>
    <p><bold>Adversarial Autoencoder (AAE)</bold> (<xref rid="B40" ref-type="bibr">Makhzani et al., 2016</xref>) replaces the Kullback-Leibler divergence from VAE with an adversarial objective. An auxiliary discriminator network is trained to distinguish samples from a prior distribution and model’s latent codes. The encoder then adapts its latent codes to minimize discriminator’s predictive accuracy. The training process oscillates between training the encoder-decoder pair and the discriminator. Unlike Kullback-Leibler divergence that has a closed-form analytical solution only for a handful of distributions, a discriminator can be used for any prior distribution. AAE-based models for molecular design were studied in (<xref rid="B27" ref-type="bibr">Kadurin et al., 2016</xref>; <xref rid="B27" ref-type="bibr">Kadurin et al., 2017</xref>; <xref rid="B49" ref-type="bibr">Polykovskiy et al., 2018b</xref>). Similar to VAE, we use SMILES as input and output representations.</p>
    <p><bold>Junction Tree VAE (JTN-VAE)</bold> (<xref rid="B26" ref-type="bibr">Jin et al., 2018</xref>) generates molecules in two phases by exploiting valid subgraphs as components. In the first phase, it generates a tree-structured object (a junction tree) whose role is to represent the scaffold of subgraph components and their coarse relative arrangements. The components are valid chemical substructures automatically extracted from the training set. In the second phase, the subgraphs (nodes of the tree) are assembled together into a coherent molecular graph.</p>
    <p><bold>Latent Vector Based Generative Adversarial Network (LatentGAN)</bold> (<xref rid="B52" ref-type="bibr">Prykhodko et al., 2019</xref>) combines an autoencoder and a generative adversarial network. LatentGAN pretrains an autoencoder to map SMILES structures onto latent vectors. A generative adversarial network is then trained to produce latent vectors for the pre-trained decoder.</p>
    <p><bold>Non-neural baselines</bold> implemented in MOSES are n-gram generative model, Hidden Markov Model (HMM), and a combinatorial generator. N-gram model collects statistics of n-grams frequencies in the training set and uses such distribution to sequentially sample new strings. Hidden Markov models utilize Baum-Welch algorithm to learn a probabilistic distribution over the SMILES strings. The model consists of several states (<italic>s</italic>
<sub>1</sub>,...,<italic>s</italic>
<sub><italic>K</italic></sub>), transition probabilities between states <italic>p</italic>(<italic>s</italic>
<sub><italic>i</italic>+1</sub> | <italic>s</italic>
<sub><italic>i</italic></sub>), and token emission probabilities <italic>p</italic>(<italic>x</italic>
<sub><italic>i</italic></sub> | <italic>s</italic>
<sub><italic>i</italic></sub>). Beginning from a “start” state, at each iteration the model samples a next token and state from emission and transition probabilities correspondingly. A combinatorial generator splits molecular graphs of the training data into BRICS fragments and generates new molecules by randomly connecting random substructures. We sample fragments according to their frequencies in the training set to model the distribution better.</p>
  </sec>
  <sec id="s4">
    <title>Platform</title>
    <p>The dataset, metrics and baseline models are provided in a GitHub repository <ext-link ext-link-type="uri" xlink:href="https://github.com/molecularsets/moses">https://github.com/molecularsets/moses</ext-link> and as a PyPI package molsets. To contribute a new model, one should train a model on MOSES train set, generate 30, 000 samples and compute metrics using the provided utilities. We recommend running the experiment at least three times with different random seeds to estimate sensitivity of the model to random parameter initialization. We store molecular structures in SMILES format; molecular graphs can be reconstructed using RDKit (<xref rid="B36" ref-type="bibr">Landrum, 2006</xref>).</p>
  </sec>
  <sec sec-type="results" id="s5">
    <title>Results</title>
    <p>We trained the baseline models on MOSES train set and provide results in this section. In <xref rid="T1" ref-type="table">Table 1</xref> we compare models with respect to the validity and uniqueness metrics. Hidden Markov Model and NGram models fail to produce valid molecules since they have a limited context. Combinatorial generator and JTN-VAE have built-in validity constraints, so their validity is 100%.</p>
    <table-wrap id="T1" position="float">
      <label>TABLE 1</label>
      <caption>
        <p>Performance metrics for baseline models: fraction of valid molecules, fraction of unique molecules from and molecules.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th rowspan="1" colspan="1">Model</th>
            <th align="center" rowspan="1" colspan="1">Valid (↑)</th>
            <th align="center" rowspan="1" colspan="1">Unique@1k (↑)</th>
            <th align="center" rowspan="1" colspan="1">Unique@10k (↑)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">
              <italic>Train</italic>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <italic>1.0</italic>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <italic>1.0</italic>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <italic>1.0</italic>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">HMM</td>
            <td align="center" rowspan="1" colspan="1">0.076 ± 0.0322</td>
            <td align="center" rowspan="1" colspan="1">0.623 ± 0.1224</td>
            <td align="center" rowspan="1" colspan="1">0.5671 ± 0.1424</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">NGram</td>
            <td align="center" rowspan="1" colspan="1">0.2376 ± 0.0025</td>
            <td align="center" rowspan="1" colspan="1">0.974 ± 0.0108</td>
            <td align="center" rowspan="1" colspan="1">0.9217 ± 0.0019</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Combinatorial</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>1.0 ± 0.0</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">0.9983 ± 0.0015</td>
            <td align="center" rowspan="1" colspan="1">0.9909 ± 0.0009</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">CharRNN</td>
            <td align="center" rowspan="1" colspan="1">0.975 ± 0.026</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>1.0 ± 0.0</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">0.999 ± 0.0</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">VAE</td>
            <td align="center" rowspan="1" colspan="1">0.977 ± 0.001</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>1.0 ± 0.0</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">0.998 ± 0.001</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">AAE</td>
            <td align="center" rowspan="1" colspan="1">0.937 ± 0.034</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>1.0 ± 0.0</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">0.997 ± 0.002</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">JTN-VAE</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>1.0 ± 0.0</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <bold>1.0 ± 0.0</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <bold>0.9996 ±0.0003</bold>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">LatentGAN</td>
            <td align="center" rowspan="1" colspan="1">0.897 ± 0.002</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>1.0 ± 0.0</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">0.997 ± 0.005</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn>
          <p>Reported (mean ± SD) over three independent model initializations.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <p><xref rid="T2" ref-type="table">Table 2</xref> reports additional properties of the generated set: fraction of molecules passing filters, fraction of molecules not present in the training set, and internal diversity. All modules successfully avoid forbidden structures (MCF and PAINS) even though such restrictions were only defined implicitly—using a training dataset. Combinatorial generator has higher diversity than the training dataset, which might be favorable for discovering new chemical structures. Autoencoder-based models show low novelty, indicating that these models overfit to the training set.</p>
    <table-wrap id="T2" position="float">
      <label>TABLE 2</label>
      <caption>
        <p>Performance metrics for baseline models: fraction of molecules passing filters (MCF, PAINS, ring sizes, charge, atom types), novelty, and internal diversity.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th rowspan="1" colspan="1">Model</th>
            <th align="center" rowspan="1" colspan="1">Filters (↑)</th>
            <th align="center" rowspan="1" colspan="1">Novelty (↑)</th>
            <th align="center" rowspan="1" colspan="1">IntDiv<sub>1</sub>
</th>
            <th align="center" rowspan="1" colspan="1">IntDiv<sub>2</sub>
</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">
              <italic>Train</italic>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <italic>1.0</italic>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <italic>0.0</italic>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <italic>0.857</italic>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <italic>0.851</italic>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">HMM</td>
            <td align="center" rowspan="1" colspan="1">0.9024 ± 0.0489</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>0.9994 ± 0.001</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">0.8466 ± 0.0403</td>
            <td align="center" rowspan="1" colspan="1">0.8104 ± 0.0507</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">NGram</td>
            <td align="center" rowspan="1" colspan="1">0.9582 ± 0.001</td>
            <td align="center" rowspan="1" colspan="1">0.9694 ± 0.001</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>0.8738 ± 0.0002</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">0.8644 ± 0.0002</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Combinatorial</td>
            <td align="center" rowspan="1" colspan="1">0.9557 ± 0.0018</td>
            <td align="center" rowspan="1" colspan="1">0.9878 ± 0.0008</td>
            <td align="center" rowspan="1" colspan="1">0.8732 ± 0.0002</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>0.8666 ± 0.0002</bold>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">CharRNN</td>
            <td align="center" rowspan="1" colspan="1">0.994 ± 0.003</td>
            <td align="center" rowspan="1" colspan="1">0.842 ± 0.051</td>
            <td align="center" rowspan="1" colspan="1">0.856 ± 0.0</td>
            <td align="center" rowspan="1" colspan="1">0.85 ± 0.0</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">VAE</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>0.997 ± 0.0</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">0.695 ± 0.007</td>
            <td align="center" rowspan="1" colspan="1">0.856 ± 0.0</td>
            <td align="center" rowspan="1" colspan="1">0.85 ± 0.0</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">AAE</td>
            <td align="center" rowspan="1" colspan="1">0.996 ± 0.001</td>
            <td align="center" rowspan="1" colspan="1">0.793 ± 0.028</td>
            <td align="center" rowspan="1" colspan="1">0.856 ± 0.003</td>
            <td align="center" rowspan="1" colspan="1">0.85 ± 0.003</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">JTN-VAE</td>
            <td align="center" rowspan="1" colspan="1">0.976 ± 0.0016</td>
            <td align="center" rowspan="1" colspan="1">0.9143 ± 0.0058</td>
            <td align="center" rowspan="1" colspan="1">0.8551 ± 0.0034</td>
            <td align="center" rowspan="1" colspan="1">0.8493 ± 0.0035</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">LatentGAN</td>
            <td align="center" rowspan="1" colspan="1">0.973 ± 0.001</td>
            <td align="center" rowspan="1" colspan="1">0.949 ± 0.001</td>
            <td align="center" rowspan="1" colspan="1">0.857 ± 0.0</td>
            <td align="center" rowspan="1" colspan="1">0.85 ± 0.0</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn>
          <p>Reported (mean ± SD) over three independent model initializations.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <p><xref rid="T3" ref-type="table">Table 3</xref> reports Fréchet ChemNet Distance (FCD) and similarity to a nearest neighbor (SNN). All neural network-based models show low FCD, indicating that the models successfully captured the statistics of the dataset. Surprisingly, a simple language model, character level RNN, shows the best results in terms of the FCD measure. Variational autoencoder (VAE) showed the best results in terms of SNN, but combined with low novelty we suppose that the model overfitted on the training set.</p>
    <table-wrap id="T3" position="float">
      <label>TABLE 3</label>
      <caption>
        <p>Performance metrics for baseline models: Fréchet ChemNet Distance (FCD) and Similarity to a nearest neighbor (SNN).</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th rowspan="2" colspan="1">Model</th>
            <th colspan="2" align="center" rowspan="1">FCD (↓)</th>
            <th colspan="2" align="center" rowspan="1">SNN (↑)</th>
          </tr>
          <tr>
            <th align="center" rowspan="1" colspan="1">Test</th>
            <th align="center" rowspan="1" colspan="1">TestSF</th>
            <th align="center" rowspan="1" colspan="1">Test</th>
            <th align="center" rowspan="1" colspan="1">TestSF</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">
              <italic>Train</italic>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <italic>0.008</italic>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <italic>0.476</italic>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <italic>0.642</italic>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <italic>0.586</italic>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">HMM</td>
            <td align="center" rowspan="1" colspan="1">24.4661 ± 2.5251</td>
            <td align="center" rowspan="1" colspan="1">25.4312 ± 2.5599</td>
            <td align="center" rowspan="1" colspan="1">0.3876 ± 0.0107</td>
            <td align="center" rowspan="1" colspan="1">0.3795 ± 0.0107</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">NGram</td>
            <td align="center" rowspan="1" colspan="1">5.5069 ± 0.1027</td>
            <td align="center" rowspan="1" colspan="1">6.2306 ± 0.0966</td>
            <td align="center" rowspan="1" colspan="1">0.5209 ± 0.001</td>
            <td align="center" rowspan="1" colspan="1">0.4997 ± 0.0005</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Combinatorial</td>
            <td align="center" rowspan="1" colspan="1">4.2375 ± 0.037</td>
            <td align="center" rowspan="1" colspan="1">4.5113 ± 0.0274</td>
            <td align="center" rowspan="1" colspan="1">0.4514 ± 0.0003</td>
            <td align="center" rowspan="1" colspan="1">0.4388 ± 0.0002</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">CharRNN</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>0.073 ± 0.025</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <bold>0.52 ± 0.038</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">0.601 ± 0.021</td>
            <td align="center" rowspan="1" colspan="1">0.565 ± 0.014</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">VAE</td>
            <td align="center" rowspan="1" colspan="1">0.099 ± 0.013</td>
            <td align="center" rowspan="1" colspan="1">0.567 ± 0.034</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>0.626 ± 0.0</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <bold>0.578 ± 0.001</bold>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">AAE</td>
            <td align="center" rowspan="1" colspan="1">0.556 ± 0.203</td>
            <td align="center" rowspan="1" colspan="1">1.057 ± 0.237</td>
            <td align="center" rowspan="1" colspan="1">0.608 ± 0.004</td>
            <td align="center" rowspan="1" colspan="1">0.568 ± 0.005</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">JTN-VAE</td>
            <td align="center" rowspan="1" colspan="1">0.3954 ± 0.0234</td>
            <td align="center" rowspan="1" colspan="1">0.9382 ± 0.0531</td>
            <td align="center" rowspan="1" colspan="1">0.5477 ± 0.0076</td>
            <td align="center" rowspan="1" colspan="1">0.5194 ± 0.007</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">LatentGAN</td>
            <td align="center" rowspan="1" colspan="1">0.296 ± 0.021</td>
            <td align="center" rowspan="1" colspan="1">0.824 ± 0.030</td>
            <td align="center" rowspan="1" colspan="1">0.538 ± 0.001</td>
            <td align="center" rowspan="1" colspan="1">0.514 ± 0.009</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn>
          <p>Reported (mean ± SD) over three independent model initializations. Results for random test set (Test) and scaffold split test set (TestSF).</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <p>In <xref rid="T4" ref-type="table">Table 4</xref> we report similarities of substructure distributions—fragments and scaffolds. Scaffold similarity from the training set to the scaffold test set (TestSF) is zero by design. Note that CharRNN successfully discovered many novel scaffolds (11%), suggesting that the model generalizes well.</p>
    <table-wrap id="T4" position="float">
      <label>TABLE 4</label>
      <caption>
        <p>Fragment similarity (Frag), Scaffold similarity (Scaff).</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th rowspan="2" colspan="1">Model</th>
            <th colspan="2" align="center" rowspan="1">Frag (↑)</th>
            <th colspan="2" align="center" rowspan="1">Scaf (↑)</th>
          </tr>
          <tr>
            <th align="center" rowspan="1" colspan="1">Test</th>
            <th align="center" rowspan="1" colspan="1">TestSF</th>
            <th align="center" rowspan="1" colspan="1">Test</th>
            <th align="center" rowspan="1" colspan="1">TestSF</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">
              <italic>Train</italic>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <italic>1.0</italic>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <italic>0.999</italic>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <italic>0.991</italic>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <italic>0.0</italic>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">HMM</td>
            <td align="center" rowspan="1" colspan="1">0.5754 ± 0.1224</td>
            <td align="center" rowspan="1" colspan="1">0.5681 ± 0.1218</td>
            <td align="center" rowspan="1" colspan="1">0.2065 ± 0.0481</td>
            <td align="center" rowspan="1" colspan="1">0.049 ± 0.018</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">NGram</td>
            <td align="center" rowspan="1" colspan="1">0.9846 ± 0.0012</td>
            <td align="center" rowspan="1" colspan="1">0.9815 ± 0.0012</td>
            <td align="center" rowspan="1" colspan="1">0.5302 ± 0.0163</td>
            <td align="center" rowspan="1" colspan="1">0.0977 ± 0.0142</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Combinatorial</td>
            <td align="center" rowspan="1" colspan="1">0.9912 ± 0.0004</td>
            <td align="center" rowspan="1" colspan="1">0.9904 ± 0.0003</td>
            <td align="center" rowspan="1" colspan="1">0.4445 ± 0.0056</td>
            <td align="center" rowspan="1" colspan="1">0.0865 ± 0.0027</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">CharRNN</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>1.0 ± 0.0</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <bold>0.998 ± 0.0</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">0.924 ± 0.006</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>0.11 ± 0.008</bold>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">VAE</td>
            <td align="center" rowspan="1" colspan="1">0.999 ± 0.0</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>0.998 ± 0.0</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">
              <bold>0.939 ± 0.002</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">0.059 ± 0.01</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">AAE</td>
            <td align="center" rowspan="1" colspan="1">0.991 ± 0.005</td>
            <td align="center" rowspan="1" colspan="1">0.99 ± 0.004</td>
            <td align="center" rowspan="1" colspan="1">0.902 ± 0.037</td>
            <td align="center" rowspan="1" colspan="1">0.079 ± 0.009</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">JTN-VAE</td>
            <td align="center" rowspan="1" colspan="1">0.9965 ± 0.0003</td>
            <td align="center" rowspan="1" colspan="1">0.9947 ± 0.0002</td>
            <td align="center" rowspan="1" colspan="1">0.8964 ± 0.0039</td>
            <td align="center" rowspan="1" colspan="1">0.1009 ± 0.0105</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">LatentGAN</td>
            <td align="center" rowspan="1" colspan="1">0.999 ± 0.003</td>
            <td align="center" rowspan="1" colspan="1">
              <bold>0.998 ± 0.003</bold>
            </td>
            <td align="center" rowspan="1" colspan="1">0.886 ± 0.015</td>
            <td align="center" rowspan="1" colspan="1">0.1 ± 0.006</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn>
          <p>Reported (mean ± SD) over three independent model initializations. Results for random test set (Test) and scaffold split test set (TestSF).</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <p>Finally, we compared distributions of four molecular properties in generated and test sets (<xref ref-type="fig" rid="fig4">Figure 4</xref>): molecular weight (MW), octanol-water partition coefficient (logP), quantitative estimation of drug-likeness (QED), and synthetic accessibility score (SA). Deep generative models closely match the data distribution; hidden Markov Model is biased toward lighter molecules, which is consistent with low validity: larger molecules impose more validity constraints. A combinatorial generator has higher variance in molecular weight, producing larger and smaller molecules than those present in the training set.</p>
    <fig id="fig4" position="float">
      <label>FIGURE 4</label>
      <caption>
        <p>Distribution of chemical properties for MOSES dataset and sets of generated molecules. In brackets—Wasserstein-1 distance to MOSES test set. Parameters: molecular weight, octanol-water partition coefficient (logP), quantitative estimation of drug-likeness (QED) and synthetic accessibility score (SA).</p>
      </caption>
      <graphic xlink:href="fphar-11-565644-g004"/>
    </fig>
  </sec>
  <sec sec-type="discussion" id="s6">
    <title>Discussion</title>
    <p>From a wide range of presented models, CharRNN currently performs the best in terms of the key metrics. Specifically, it produces the best FCD, Fragment, and Scaffold scores, indicating that the model not only captured the training distribution well, but also did not overfit on the training set.</p>
    <p>The presented set of metrics assesses models’ performance from different perspectives; therefore, for each specific downstream task, one could consider the most relevant metric. For example, evaluation based on Scaf/TestSF score could be relevant when model’s objective is to discover novel scaffolds. For a general evaluation, we suggest using FCD/Test metric that captures multiple aspects of other metrics in a single number. However, it does not give insights into specific issues that cause high FCD/Test values, hence more interpretable metrics presented in this paper are necessary to investigate the model’s performance thoroughly.</p>
  </sec>
  <sec sec-type="conclusion" id="s7">
    <title>Conclusion</title>
    <p>With MOSES, we have designed a molecular generation benchmark platform that provides a dataset with molecular structures, an implementation of baseline models, and metrics for their evaluation. While standardized comparative studies and test sets are essential for the progress of machine learning applications, the current field of <italic>de novo</italic> drug design lacks evaluation protocols for generative machine learning models. Being on the intersection of mathematics, computer science, and chemistry, these applications are often too challenging to explore for research scientists starting in the field. Hence, it is necessary to develop a transparent approach to implementing new models and assessing their performance. We presented a benchmark suite with unified and extendable programming interfaces for generative models and evaluation metrics.</p>
    <p>This platform should allow for a fair and comprehensive comparison of new generative models. For future work on this project, we will keep extending the MOSES repository with new baseline models and new evaluation metrics. We hope this work will attract researchers interested in tackling drug discovery challenges.</p>
  </sec>
  <sec sec-type="data-availability" id="s8">
    <title>Data Availability Statement</title>
    <p>The data and code of the MOSES platform is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/molecularsets/moses">https://github.com/molecularsets/moses</ext-link>.</p>
  </sec>
  <sec id="s9">
    <title>Author Contributions</title>
    <p>DP, AZhe, SG, OT, SB, RK, AA, AK, SJ, and HC designed and conducted the experiments; DP and AZhe, BS-L, VA, MV, SJ, HC, SN, AA-G, AZha wrote the manuscript.</p>
  </sec>
  <sec sec-type="COI-statement" id="s10">
    <title>Conflict of Interest</title>
    <p>DP, AZhe, VA, MV, and AZha work for Insilico Medicine, a commercial artificial intelligence company. SG, OT, SB, RK, AA, and SN work for Neuromation OU, a company engaged in AI development through synthetic data and generative models. SJ and HC work for a pharmaceutical company AstraZeneca. AA-G is a cofounder and board member of, and consultant for, Kebotix, an artificial intelligence-driven molecular discovery company and a member of the science advisory board of Insilico Medicine.</p>
  </sec>
</body>
<back>
  <ack>
    <p>This manuscript has been released as a pre-print at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1811.12823">https://arxiv.org/abs/1811.12823</ext-link> (<xref rid="B48" ref-type="bibr">Polykovskiy et al., 2018a</xref>).</p>
  </ack>
  <sec id="s11">
    <title>Supplementary Material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fphar.2020.565644/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/fphar.2020.565644/full#supplementary-material</ext-link>.</p>
    <supplementary-material content-type="local-data" id="SM1">
      <media xlink:href="datasheet1.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aliper</surname><given-names>A.</given-names></name><name><surname>Plis</surname><given-names>S.</given-names></name><name><surname>Artemov</surname><given-names>A.</given-names></name><name><surname>Ulloa</surname><given-names>A.</given-names></name><name><surname>Mamoshina</surname><given-names>P.</given-names></name><name><surname>Zhavoronkov</surname><given-names>A.</given-names></name></person-group> (<year>2016</year>). <article-title>Deep learning applications for predicting pharmacological properties of drugs and drug repurposing using transcriptomic data</article-title>. <source>Mol. Pharm.</source>
<volume>13</volume>, <fpage>2524</fpage>–<lpage>2530</lpage>. <pub-id pub-id-type="doi">10.1021/acs.molpharmaceut.6b00248</pub-id>
<pub-id pub-id-type="pmid">27200455</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arús-Pous</surname><given-names>J.</given-names></name><name><surname>Johansson</surname><given-names>S. V.</given-names></name><name><surname>Prykhodko</surname><given-names>O.</given-names></name><name><surname>Bjerrum</surname><given-names>E. J.</given-names></name><name><surname>Tyrchan</surname><given-names>C.</given-names></name><name><surname>Reymond</surname><given-names>J.-L.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Randomized smiles strings improve the quality of molecular generative models</article-title>. <source>J. Cheminf.</source>
<volume>11</volume>, <fpage>1</fpage>–<lpage>13</lpage>. <pub-id pub-id-type="doi">10.1186/s13321-019-0393-0</pub-id>
</mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baell</surname><given-names>J. B.</given-names></name><name><surname>Holloway</surname><given-names>G. A.</given-names></name></person-group> (<year>2010</year>). <article-title>New substructure filters for removal of pan assay interference compounds (PAINS) from screening libraries and for their exclusion in bioassays</article-title>. <source>J. Med. Chem.</source>
<volume>53</volume>, <fpage>2719</fpage>–<lpage>2740</lpage>. <pub-id pub-id-type="doi">10.1021/jm901137j</pub-id>
<pub-id pub-id-type="pmid">20131845</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bemis</surname><given-names>G. W.</given-names></name><name><surname>Murcko</surname><given-names>M. A.</given-names></name></person-group> (<year>1996</year>). <article-title>The properties of known drugs. 1. molecular frameworks</article-title>. <source>J. Med. Chem.</source>
<volume>39</volume>, <fpage>2887</fpage>–<lpage>2893</lpage>. <pub-id pub-id-type="doi">10.1021/jm9602928</pub-id>
<pub-id pub-id-type="pmid">8709122</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Benhenda</surname><given-names>M.</given-names></name></person-group> (<year>2017</year>). <article-title>ChemGAN challenge for drug discovery: can AI reproduce natural chemical diversity?</article-title>
<comment>Available from: <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1708.08227">https://arxiv.org/abs/1708.08227</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bickerton</surname><given-names>G. R.</given-names></name><name><surname>Paolini</surname><given-names>G. V.</given-names></name><name><surname>Besnard</surname><given-names>J.</given-names></name><name><surname>Muresan</surname><given-names>S.</given-names></name><name><surname>Hopkins</surname><given-names>A. L.</given-names></name></person-group> (<year>2012</year>). <article-title>Quantifying the chemical beauty of drugs</article-title>. <source>Nat. Chem.</source>
<volume>4</volume>, <fpage>90</fpage>–<lpage>98</lpage>. <pub-id pub-id-type="doi">10.1038/nchem.1243</pub-id>
<pub-id pub-id-type="pmid">22270643</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blaschke</surname><given-names>T.</given-names></name><name><surname>Olivecrona</surname><given-names>M.</given-names></name><name><surname>Engkvist</surname><given-names>O.</given-names></name><name><surname>Bajorath</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>H.</given-names></name></person-group> (<year>2018</year>). <article-title>Application of generative autoencoder in de novo molecular design</article-title>. <source>Mol. Inform.</source>
<volume>37</volume>, <fpage>1700123</fpage>
<pub-id pub-id-type="doi">10.1002/minf.201700123</pub-id>
</mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>N.</given-names></name><name><surname>Fiscato</surname><given-names>M.</given-names></name><name><surname>Segler</surname><given-names>M. H. S.</given-names></name><name><surname>Vaucher</surname><given-names>A. C.</given-names></name></person-group> (<year>2019</year>). <article-title>Guacamol: benchmarking models for de novo molecular design</article-title>. <source>J. Chem. Inf. Model.</source>
<volume>59</volume>, <fpage>1096</fpage>–<lpage>1108</lpage>. <pub-id pub-id-type="doi">10.1021/acs.jcim.8b00839</pub-id>
<pub-id pub-id-type="pmid">30887799</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ching</surname><given-names>T.</given-names></name><name><surname>Himmelstein</surname><given-names>D. S.</given-names></name><name><surname>Beaulieu-Jones</surname><given-names>B. K.</given-names></name><name><surname>Kalinin</surname><given-names>A. A.</given-names></name><name><surname>Do</surname><given-names>B. T.</given-names></name><name><surname>Way</surname><given-names>G. P.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Opportunities and obstacles for deep learning in biology and medicine</article-title>. <source>J. R. Soc. Interface</source>
<volume>15</volume>, <fpage>20170387</fpage>
<pub-id pub-id-type="doi">10.1098/rsif.2017.0387</pub-id>
<pub-id pub-id-type="pmid">29618526</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Dai</surname><given-names>H.</given-names></name><name><surname>Tian</surname><given-names>Y.</given-names></name><name><surname>Dai</surname><given-names>B.</given-names></name><name><surname>Skiena</surname><given-names>S.</given-names></name><name><surname>Song</surname><given-names>L.</given-names></name></person-group> (<year>2018</year>). “<article-title>Syntax-directed variational autoencoder for structured data</article-title>,” in <conf-name>International conference on learning representations</conf-name>.</mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>De Cao</surname><given-names>N.</given-names></name><name><surname>Kipf</surname><given-names>T.</given-names></name></person-group> (<year>2018</year>). “<article-title>MolGAN: an implicit generative model for small molecular graphs</article-title>,” in <conf-name>ICML 2018 workshop on Theoretical Foundations and Applications of Deep Generative Models</conf-name>.</mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Degen</surname><given-names>J.</given-names></name><name><surname>Wegscheid-Gerlach</surname><given-names>C.</given-names></name><name><surname>Zaliani</surname><given-names>A.</given-names></name><name><surname>Rarey</surname><given-names>M.</given-names></name></person-group> (<year>2008</year>). <article-title>On the art of compiling and using 'drug-like' chemical fragment spaces</article-title>. <source>ChemMedChem</source>
<volume>3</volume>, <fpage>1503</fpage>–<lpage>1507</lpage>. <pub-id pub-id-type="doi">10.1002/cmdc.200800178</pub-id>
<pub-id pub-id-type="pmid">18792903</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>J.</given-names></name><name><surname>Dong</surname><given-names>W.</given-names></name><name><surname>Socher</surname><given-names>R.</given-names></name><name><surname>Li</surname><given-names>L.-J.</given-names></name><name><surname>Li</surname><given-names>K.</given-names></name><name><surname>Fei-Fei</surname><given-names>L.</given-names></name></person-group> (<year>2009</year>). <source>CVPR09</source>.<article-title>ImageNet: a large-scale hierarchical image database</article-title>,” in <conf-name>2009 IEEE Conference on Computer Vision and Pattern Recognition</conf-name>, <conf-loc>Miami, FL</conf-loc>, <conf-date>June 20–25, 2009</conf-date>
<publisher-name>IEEE</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Dinh</surname><given-names>L.</given-names></name><name><surname>Sohl-Dickstein</surname><given-names>J.</given-names></name><name><surname>Bengio</surname><given-names>S.</given-names></name></person-group> (<year>2017</year>). <article-title>Density estimation using real NVP</article-title>. <comment>Available at: <ext-link ext-link-type="uri" xlink:href="https://library.seg.org/doi/10.1190/segam2017-17559486.1">https://library.seg.org/doi/10.1190/segam2017-17559486.1</ext-link></comment>
</mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Duvenaud</surname><given-names>D. K.</given-names></name><name><surname>Maclaurin</surname><given-names>D.</given-names></name><name><surname>Iparraguirre</surname><given-names>J.</given-names></name><name><surname>Bombarell</surname><given-names>R.</given-names></name><name><surname>Hirzel</surname><given-names>T.</given-names></name><name><surname>Aspuru-Guzik</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2015</year>). “<article-title>Convolutional networks on graphs for learning molecular fingerprints</article-title>,” in <source>Advances in neural information processing systems 28</source>. Editors <person-group person-group-type="editor"><name><surname>Cortes</surname><given-names>C.</given-names></name><name><surname>Lawrence</surname><given-names>N. D.</given-names></name><name><surname>Lee</surname><given-names>D. D.</given-names></name><name><surname>Sugiyama</surname><given-names>M.</given-names></name><name><surname>Garnett</surname><given-names>R.</given-names></name></person-group> (<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Curran Associates, Inc.</publisher-name>), <fpage>2224</fpage>–<lpage>2232</lpage>.</mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ertl</surname><given-names>P.</given-names></name><name><surname>Schuffenhauer</surname><given-names>A.</given-names></name></person-group> (<year>2009</year>). <article-title>Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions</article-title>. <source>J. Cheminf.</source>
<volume>1</volume>, <fpage>8</fpage>
<pub-id pub-id-type="doi">10.1186/1758-2946-1-8</pub-id>
</mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferrero</surname><given-names>S.</given-names></name><name><surname>Hart</surname><given-names>G. L. W.</given-names></name><name><surname>Nardelli</surname><given-names>M. B.</given-names></name><name><surname>Mingo</surname><given-names>N.</given-names></name><name><surname>Sanvito</surname><given-names>S.</given-names></name><name><surname>Levy</surname><given-names>O.</given-names></name></person-group> (<year>2013</year>). <article-title>The high-throughput highway to computational materials design</article-title>. <source>Nat. Mater.</source>
<volume>12</volume>, <fpage>191</fpage>–<lpage>201</lpage>. <pub-id pub-id-type="doi">10.1038/nmat3568</pub-id>
<pub-id pub-id-type="pmid">23422720</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Gilmer</surname><given-names>J.</given-names></name><name><surname>Schoenholz</surname><given-names>S. S.</given-names></name><name><surname>Riley</surname><given-names>P. F.</given-names></name><name><surname>Vinyals</surname><given-names>O.</given-names></name><name><surname>Dahl</surname><given-names>G. E.</given-names></name></person-group> (<year>2017</year>). <article-title>Neural message passing for quantum chemistry</article-title>,” in <conf-name>Proceedings of the 34th international conference on machine learning</conf-name>
<publisher-name>JMLR</publisher-name>, <fpage>1263</fpage>–<lpage>1272</lpage>
</mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gómez-Bombarelli</surname><given-names>R.</given-names></name><name><surname>Wei</surname><given-names>J. N.</given-names></name><name><surname>Duvenaud</surname><given-names>D.</given-names></name><name><surname>Hernández-Lobato</surname><given-names>J. M.</given-names></name><name><surname>Sánchez-Lengeling</surname><given-names>B.</given-names></name><name><surname>Sheberla</surname><given-names>D.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Automatic chemical design using a Data-Driven continuous representation of molecules</article-title>. <source>ACS Cent. Sci.</source>
<volume>4</volume>, <fpage>268</fpage>–<lpage>276</lpage>. <pub-id pub-id-type="doi">10.1021/acscentsci.7b00572</pub-id>
<pub-id pub-id-type="pmid">29532027</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grisoni</surname><given-names>F.</given-names></name><name><surname>Neuhaus</surname><given-names>C. S.</given-names></name><name><surname>Gabernet</surname><given-names>G.</given-names></name><name><surname>Müller</surname><given-names>A. T.</given-names></name><name><surname>Hiss</surname><given-names>J. A.</given-names></name><name><surname>Schneider</surname><given-names>G.</given-names></name></person-group> (<year>2018</year>). <article-title>Designing anticancer peptides by constructive machine learning</article-title>. <source>ChemMedChem</source>
<volume>13</volume>, <fpage>1300</fpage>–<lpage>1302</lpage>. <pub-id pub-id-type="doi">10.1002/cmdc.201800204</pub-id>
<pub-id pub-id-type="pmid">29679519</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Guimaraes</surname><given-names>G. L.</given-names></name><name><surname>Sanchez-Lengeling</surname><given-names>B.</given-names></name><name><surname>Farias</surname><given-names>P. L. C.</given-names></name><name><surname>Aspuru-Guzik</surname><given-names>A.</given-names></name></person-group> (<year>2017</year>). <article-title>Objective-Reinforced generative adversarial networks (ORGAN) for sequence generation models</article-title>. <comment>Available at: <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1705.10843">https://arxiv.org/abs/1705.10843</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>X.</given-names></name><name><surname>Beratan</surname><given-names>D. N.</given-names></name><name><surname>Yang</surname><given-names>W.</given-names></name></person-group> (<year>2009</year>). <article-title>Emergent strategies for inverse molecular design</article-title>. <source>Sci. China Ser. B-Chem.</source>
<volume>52</volume>, <fpage>1769</fpage>–<lpage>1776</lpage>. <pub-id pub-id-type="doi">10.1007/s11426-009-0260-3</pub-id>
</mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ivanenkov</surname><given-names>Y. A.</given-names></name><name><surname>Zhavoronkov</surname><given-names>A.</given-names></name><name><surname>Yamidanov</surname><given-names>R. S.</given-names></name><name><surname>Osterman</surname><given-names>I. A.</given-names></name><name><surname>Sergiev</surname><given-names>P. V.</given-names></name><name><surname>Aladinskiy</surname><given-names>V. A.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Identification of novel antibacterials using machine learning techniques</article-title>. <source>Front. Pharmacol.</source>
<volume>10</volume>, <fpage>913</fpage>
<pub-id pub-id-type="doi">10.3389/fphar.2019.00913</pub-id>
<pub-id pub-id-type="pmid">31507413</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Jaques</surname><given-names>N.</given-names></name><name><surname>Gu</surname><given-names>S.</given-names></name><name><surname>Bahdanau</surname><given-names>D.</given-names></name><name><surname>Hernández-Lobato</surname><given-names>J. M.</given-names></name><name><surname>Turner</surname><given-names>R. E.</given-names></name><name><surname>Eck</surname><given-names>D.</given-names></name></person-group> (<year>2016</year>). <article-title>Sequence tutor: conservative fine-tuning of sequence generation models with KL-control</article-title>. <comment>Available at: <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1611.02796">https://arxiv.org/abs/1611.02796</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Jin</surname><given-names>W.</given-names></name><name><surname>Barzilay</surname><given-names>R.</given-names></name><name><surname>Jaakkola</surname><given-names>T.</given-names></name></person-group> (<year>2018</year>). “<article-title>Junction tree variational autoencoder for molecular graph generation</article-title>,” in <conf-name>Proceedings of the 35th international conference on machine learning</conf-name> Editors <person-group person-group-type="editor"><name><surname>Dy</surname><given-names>J.</given-names></name><name><surname>Krause</surname><given-names>A.</given-names></name></person-group> (<publisher-loc>Stockholmsmässan, Stockholm Sweden</publisher-loc>: <publisher-name>PMLR</publisher-name>), <fpage>2323</fpage>–<lpage>2332</lpage>.</mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kadurin</surname><given-names>A.</given-names></name><name><surname>Aliper</surname><given-names>A.</given-names></name><name><surname>Kazennov</surname><given-names>A.</given-names></name><name><surname>Mamoshina</surname><given-names>P.</given-names></name><name><surname>Vanhaelen</surname><given-names>Q.</given-names></name><name><surname>Khrabrov</surname><given-names>K.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>The cornucopia of meaningful leads: applying deep adversarial autoencoders for new molecule development in oncology</article-title>. <source>Oncotarget</source>
<volume>8</volume>, <fpage>10883</fpage>–<lpage>10890</lpage>. <pub-id pub-id-type="doi">10.18632/oncotarget.14073</pub-id>
</mixed-citation>
    </ref>
    <ref id="B75">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kadurin</surname><given-names>A.</given-names></name><name><surname>Nikolenko</surname><given-names>S.</given-names></name><name><surname>Khrabrov</surname><given-names>K.</given-names></name><name><surname>Aliper</surname><given-names>A.</given-names></name><name><surname>Zhavoronkov</surname><given-names>A.</given-names></name></person-group> (<year>2017</year>). <article-title>druGAN: an advanced generative adversarial autoencoder model for de novo generation of new molecules with desired molecular properties in silico</article-title>. <source>Mol. Pharm.</source>
<volume>14</volume>, <fpage>3098</fpage>–<lpage>3104</lpage>. <pub-id pub-id-type="doi">10.1021/acs.molpharmaceut.7b00346</pub-id>
<pub-id pub-id-type="pmid">28703000</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kang</surname><given-names>S.</given-names></name><name><surname>Cho</surname><given-names>K.</given-names></name></person-group> (<year>2018</year>). <article-title>Conditional molecular design with deep generative models</article-title>. <source>J. Chem. Inf. Model.</source>
<volume>59</volume>, <fpage>43</fpage>–<lpage>52</lpage>. <pub-id pub-id-type="doi">10.1021/acs.jcim.8b00263</pub-id>
<pub-id pub-id-type="pmid">30016587</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Karras</surname><given-names>T.</given-names></name><name><surname>Aila</surname><given-names>T.</given-names></name><name><surname>Laine</surname><given-names>S.</given-names></name><name><surname>Lehtinen</surname><given-names>J.</given-names></name></person-group> (<year>2018</year>). <article-title>Progressive growing of gans for improved quality, stability, and variation</article-title>,” in <conf-name>International conference on learning representations</conf-name>
<publisher-name>ICLR</publisher-name>
<fpage>1</fpage>–<lpage>26</lpage>.</mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Killoran</surname><given-names>N.</given-names></name><name><surname>Lee</surname><given-names>L. J.</given-names></name><name><surname>Delong</surname><given-names>A.</given-names></name><name><surname>Duvenaud</surname><given-names>D.</given-names></name><name><surname>Frey</surname><given-names>B. J.</given-names></name></person-group> (<year>2017</year>). <article-title>Generating and designing DNA with deep generative models</article-title>. <comment>Available from: <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1712.06148">https://arxiv.org/abs/1712.06148</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>D. P.</given-names></name><name><surname>Welling</surname><given-names>M.</given-names></name></person-group> (<year>2013</year>). <article-title>Auto-Encoding variational bayes</article-title>,” in <conf-name>International conference on learning representations</conf-name>.</mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kirkpatrick</surname><given-names>P.</given-names></name><name><surname>Ellis</surname><given-names>C.</given-names></name></person-group> (<year>2004</year>). <article-title>Chemical space</article-title>. <source>Nature</source>
<volume>432</volume>, <fpage>823</fpage>
<pub-id pub-id-type="doi">10.1038/432823a</pub-id>
</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Krenn</surname><given-names>M.</given-names></name><name><surname>Häse</surname><given-names>F.</given-names></name><name><surname>Nigam</surname><given-names>A.</given-names></name><name><surname>Friederich</surname><given-names>P.</given-names></name><name><surname>Aspuru-Guzik</surname><given-names>A.</given-names></name></person-group> (<year>2019</year>). <article-title>Selfies: a robust representation of semantically constrained graphs with an example application in chemistry</article-title>. <comment>Available at: <ext-link ext-link-type="uri" xlink:href="https://grlearning.github.io/papers/59.pdf">https://grlearning.github.io/papers/59.pdf</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kusner</surname><given-names>M. J.</given-names></name><name><surname>Paige</surname><given-names>B.</given-names></name><name><surname>Hernández-Lobato</surname><given-names>J. M.</given-names></name></person-group> (<year>2017</year>). “<article-title>Grammar variational autoencoder</article-title>,”in <source>Proceedings of the 34th international conference on machine learning</source>. Editors <person-group person-group-type="editor"><name><surname>Precup</surname><given-names>D.</given-names></name><name><surname>Teh</surname><given-names>Y. W.</given-names></name></person-group> (<publisher-loc>Sydney, Australia</publisher-loc>: <publisher-name>Proceedings of Machine Learning Research</publisher-name>), <volume>Vol. 70</volume>
<fpage>1945</fpage>–<lpage>1954</lpage>.</mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Labat</surname><given-names>R.</given-names></name><name><surname>Fu</surname><given-names>Y.</given-names></name><name><surname>Lai</surname><given-names>L.</given-names></name></person-group> (<year>1997</year>). <article-title>A new atom-additive method for calculating partition coefficients</article-title>. <source>J. Chem. Inf. Comput. Sci.</source>
<volume>37</volume>, <fpage>615</fpage>–<lpage>621</lpage>. <pub-id pub-id-type="doi">10.1021/ci960169p</pub-id>
</mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Landrum</surname><given-names>G.</given-names></name></person-group> (<year>2006</year>). <article-title>RDKit: open-source cheminformatics</article-title>. <comment>Available at: <ext-link ext-link-type="uri" xlink:href="http://www.rdkit.org/">http://www.rdkit.org/</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le</surname><given-names>T. C.</given-names></name><name><surname>Winkler</surname><given-names>D. A.</given-names></name></person-group> (<year>2016</year>). <article-title>Discovery and optimization of materials using evolutionary approaches</article-title>. <source>Chem. Rev.</source>
<volume>116</volume>, <fpage>6107</fpage>–<lpage>6132</lpage>. <pub-id pub-id-type="doi">10.1021/acs.chemrev.5b00691</pub-id>
<pub-id pub-id-type="pmid">27171499</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y.</given-names></name><name><surname>Bottou</surname><given-names>L.</given-names></name><name><surname>Bengio</surname><given-names>Y.</given-names></name><name><surname>Haffner</surname><given-names>P.</given-names></name></person-group> (<year>1998</year>). <article-title>Gradient-based learning applied to document recognition</article-title>. <source>Proc. IEEE</source>
<volume>86</volume>, <fpage>2278</fpage>–<lpage>2324</lpage>. <pub-id pub-id-type="doi">10.1109/5.726791</pub-id>
</mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>S.-I.</given-names></name><name><surname>Celik</surname><given-names>S.</given-names></name><name><surname>Logsdon</surname><given-names>B. A.</given-names></name><name><surname>Lundberg</surname><given-names>S. M.</given-names></name><name><surname>Martins</surname><given-names>T. J.</given-names></name><name><surname>Oehler</surname><given-names>V. G.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>A machine learning approach to integrate big data for precision medicine in acute myeloid leukemia</article-title>. <source>Nat. Commun.</source>
<volume>9</volume>, <fpage>42</fpage>
<pub-id pub-id-type="doi">10.1038/s41467-017-02465-5</pub-id>
<pub-id pub-id-type="pmid">29298978</pub-id></mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Makhzani</surname><given-names>A.</given-names></name><name><surname>Shlens</surname><given-names>J.</given-names></name><name><surname>Jaitly</surname><given-names>N.</given-names></name><name><surname>Goodfellow</surname><given-names>I.</given-names></name></person-group> (<year>2016</year>). “<article-title>Adversarial autoencoders</article-title>,” in <conf-name>International conference on learning representations</conf-name>.</mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mamoshina</surname><given-names>P.</given-names></name><name><surname>Vieira</surname><given-names>A.</given-names></name><name><surname>Putin</surname><given-names>E.</given-names></name><name><surname>Zhavoronkov</surname><given-names>A.</given-names></name></person-group> (<year>2016</year>). <article-title>Applications of deep learning in biomedicine</article-title>. <source>Mol. Pharm.</source>
<volume>13</volume>, <fpage>1445</fpage>–<lpage>1454</lpage>. <pub-id pub-id-type="doi">10.1021/acs.molpharmaceut.5b00982</pub-id>
<pub-id pub-id-type="pmid">27007977</pub-id></mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mamoshina</surname><given-names>P.</given-names></name><name><surname>Volosnikova</surname><given-names>M.</given-names></name><name><surname>Ozerov</surname><given-names>I. V.</given-names></name><name><surname>Putin</surname><given-names>E.</given-names></name><name><surname>Skibina</surname><given-names>E.</given-names></name><name><surname>Cortese</surname><given-names>F.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Machine learning on human muscle transcriptomic data for biomarker discovery and tissue-specific drug target identification</article-title>. <source>Front. Genet.</source>
<volume>9</volume>, <fpage>242</fpage>
<pub-id pub-id-type="doi">10.3389/fgene.2018.00242</pub-id>
<pub-id pub-id-type="pmid">30050560</pub-id></mixed-citation>
    </ref>
    <ref id="B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merk</surname><given-names>D.</given-names></name><name><surname>Friedrich</surname><given-names>L.</given-names></name><name><surname>Grisoni</surname><given-names>F.</given-names></name><name><surname>Schneider</surname><given-names>G.</given-names></name></person-group> (<year>2018a</year>). <article-title>De novo design of bioactive small molecules by artificial intelligence</article-title>. <source>Mol. Inf.</source>
<volume>37</volume>, <fpage>1700153</fpage>
<pub-id pub-id-type="doi">10.1002/minf.201700153</pub-id>
</mixed-citation>
    </ref>
    <ref id="B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merk</surname><given-names>D.</given-names></name><name><surname>Grisoni</surname><given-names>F.</given-names></name><name><surname>Friedrich</surname><given-names>L.</given-names></name><name><surname>Schneider</surname><given-names>G.</given-names></name></person-group> (<year>2018b</year>). <article-title>Tuning artificial intelligence on the de novo design of natural-product-inspired retinoid x receptor modulators</article-title>. <source>Commun. Chem.</source>
<volume>1</volume>, <fpage>68</fpage>
<pub-id pub-id-type="doi">10.1038/s42004-018-0068-1</pub-id>
</mixed-citation>
    </ref>
    <ref id="B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olivecrona</surname><given-names>M.</given-names></name><name><surname>Blaschke</surname><given-names>T.</given-names></name><name><surname>Engkvist</surname><given-names>O.</given-names></name><name><surname>Chen</surname><given-names>H.</given-names></name></person-group> (<year>2017</year>). <article-title>Molecular de-novo design through deep reinforcement learning</article-title>. <source>J. Cheminf.</source>
<volume>9</volume>, <fpage>48</fpage>
<pub-id pub-id-type="doi">10.1186/s13321-017-0235-x</pub-id>
</mixed-citation>
    </ref>
    <ref id="B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Boyle</surname><given-names>N.</given-names></name><name><surname>Dalke</surname><given-names>A.</given-names></name></person-group> (<year>2018</year>). <article-title>DeepSMILES: an adaptation of SMILES for use in machine-learning of chemical structures</article-title>. <source>ChemRxiv</source>. <pub-id pub-id-type="doi">10.26434/chemrxiv.7097960</pub-id>
</mixed-citation>
    </ref>
    <ref id="B47">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A.</given-names></name><name><surname>Gross</surname><given-names>S.</given-names></name><name><surname>Chintala</surname><given-names>S.</given-names></name><name><surname>Chanan</surname><given-names>G.</given-names></name><name><surname>Yang</surname><given-names>E.</given-names></name><name><surname>DeVito</surname><given-names>Z.</given-names></name><etal/></person-group> (<year>2017</year>). “<article-title>Automatic differentiation in pytorch</article-title>,” in <conf-name>NIPS workshop</conf-name>. </mixed-citation>
    </ref>
    <ref id="B48">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Polykovskiy</surname><given-names>D.</given-names></name><name><surname>Zhebrak</surname><given-names>A.</given-names></name><name><surname>Sanchez-Lengeling</surname><given-names>B.</given-names></name><name><surname>Golovanov</surname><given-names>S.</given-names></name><name><surname>Tatanov</surname><given-names>O.</given-names></name><name><surname>Belyaev</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2018a</year>). <article-title>Molecular sets (moses): a benchmarking platform for molecular generation models</article-title>. <comment>Available from: <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1811.12823">https://arxiv.org/abs/1811.12823</ext-link></comment>. </mixed-citation>
    </ref>
    <ref id="B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polykovskiy</surname><given-names>D.</given-names></name><name><surname>Zhebrak</surname><given-names>A.</given-names></name><name><surname>Vetrov</surname><given-names>D.</given-names></name><name><surname>Ivanenkov</surname><given-names>Y.</given-names></name><name><surname>Aladinskiy</surname><given-names>V.</given-names></name><name><surname>Mamoshina</surname><given-names>P.</given-names></name><etal/></person-group> (<year>2018b</year>). <article-title>Entangled conditional adversarial autoencoder for de novo drug discovery</article-title>. <source>Mol. Pharm.</source>
<volume>15</volume>, <fpage>4398</fpage>–<lpage>4405</lpage>. <pub-id pub-id-type="doi">10.1021/acs.molpharmaceut.8b00839</pub-id>
<pub-id pub-id-type="pmid">30180591</pub-id></mixed-citation>
    </ref>
    <ref id="B50">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Popova</surname><given-names>M.</given-names></name><name><surname>Isayev</surname><given-names>O.</given-names></name><name><surname>Tropsha</surname><given-names>A.</given-names></name></person-group> (<year>2018</year>). <article-title>Deep reinforcement learning for de novo drug design</article-title>. <source>Sci. Adv.</source>
<volume>4</volume>, <fpage>eaap7885</fpage>
<pub-id pub-id-type="doi">10.1126/sciadv.aap7885</pub-id>
<pub-id pub-id-type="pmid">30050984</pub-id></mixed-citation>
    </ref>
    <ref id="B51">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preuer</surname><given-names>K.</given-names></name><name><surname>Renz</surname><given-names>P.</given-names></name><name><surname>Unterthiner</surname><given-names>T.</given-names></name><name><surname>Hochreiter</surname><given-names>S.</given-names></name><name><surname>Klambauer</surname><given-names>G.</given-names></name></person-group> (<year>2018</year>). <article-title>Fréchet ChemNet distance: a metric for generative models for molecules in drug discovery</article-title>. <source>J. Chem. Inf. Model.</source>
<volume>58</volume>, <fpage>1736</fpage>–<lpage>1741</lpage>. <pub-id pub-id-type="doi">10.1021/acs.jcim.8b00234</pub-id>
<pub-id pub-id-type="pmid">30118593</pub-id></mixed-citation>
    </ref>
    <ref id="B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prykhodko</surname><given-names>O.</given-names></name><name><surname>Johansson</surname><given-names>S. V.</given-names></name><name><surname>Kotsias</surname><given-names>P.-C.</given-names></name><name><surname>Arús-Pous</surname><given-names>J.</given-names></name><name><surname>Bjerrum</surname><given-names>E. J.</given-names></name><name><surname>Engkvist</surname><given-names>O.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>A de novo molecular generation method using latent vector based generative adversarial network</article-title>. <source>J. Cheminf.</source>
<volume>11</volume>, <fpage>74</fpage>
<pub-id pub-id-type="doi">10.1186/s13321-019-0397-9</pub-id>
</mixed-citation>
    </ref>
    <ref id="B53">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Putin</surname><given-names>E.</given-names></name><name><surname>Asadulaev</surname><given-names>A.</given-names></name><name><surname>Vanhaelen</surname><given-names>Q.</given-names></name><name><surname>Ivanenkov</surname><given-names>Y.</given-names></name><name><surname>Aladinskaya</surname><given-names>A. V.</given-names></name><name><surname>Aliper</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Adversarial threshold neural computer for molecular de novo design</article-title>. <source>Mol. Pharm.</source>
<volume>15</volume>, <fpage>4386</fpage>–<lpage>4397</lpage>. <pub-id pub-id-type="doi">10.1021/acs.molpharmaceut.7b01137</pub-id>
<pub-id pub-id-type="pmid">29569445</pub-id></mixed-citation>
    </ref>
    <ref id="B76">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pyzer-Knapp</surname><given-names>E. O.</given-names></name><name><surname>Suh</surname><given-names>C.</given-names></name><name><surname>Gómez-Bombarelli</surname><given-names>R.</given-names></name><name><surname>Aguilera-Iparraguirre</surname><given-names>J.</given-names></name><name><surname>Aspuru-Guzik</surname><given-names>A.</given-names></name></person-group> (<year>2015</year>). <article-title>What is High-Throughput virtual screening? a perspective from organic materials discovery</article-title>. <source>Annu. Rev. Mater. Res.</source>
<volume>45</volume>, <fpage>195</fpage>–<lpage>216</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-matsci-070214-020823</pub-id>
</mixed-citation>
    </ref>
    <ref id="B54">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramakrishnan</surname><given-names>R.</given-names></name><name><surname>Dral</surname><given-names>P. O.</given-names></name><name><surname>Rupp</surname><given-names>M.</given-names></name><name><surname>von Lilienfeld</surname><given-names>O. A.</given-names></name></person-group> (<year>2014</year>). <article-title>Quantum chemistry structures and properties of 134 kilo molecules</article-title>. <source>Scientific Data</source>
<volume>1</volume>, <fpage>140022</fpage>
<pub-id pub-id-type="doi">10.1038/sdata.2014.22</pub-id>
<pub-id pub-id-type="pmid">25977779</pub-id></mixed-citation>
    </ref>
    <ref id="B55">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reymond</surname><given-names>J.-L.</given-names></name></person-group> (<year>2015</year>). <article-title>The chemical space project</article-title>. <source>Acc. Chem. Res.</source>
<volume>48</volume>, <fpage>722</fpage>–<lpage>730</lpage>. <pub-id pub-id-type="doi">10.1021/ar500432k</pub-id>
<pub-id pub-id-type="pmid">25687211</pub-id></mixed-citation>
    </ref>
    <ref id="B56">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rogers</surname><given-names>D.</given-names></name><name><surname>Hahn</surname><given-names>M.</given-names></name></person-group> (<year>2010</year>). <article-title>Extended-connectivity fingerprints</article-title>. <source>J. Chem. Inf. Model.</source>
<volume>50</volume>, <fpage>742</fpage>–<lpage>754</lpage>. <pub-id pub-id-type="doi">10.1021/ci100050t</pub-id>
<pub-id pub-id-type="pmid">20426451</pub-id></mixed-citation>
    </ref>
    <ref id="B57">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanchez-Lengeling</surname><given-names>B.</given-names></name><name><surname>Aspuru-Guzik</surname><given-names>A.</given-names></name></person-group> (<year>2018</year>). <article-title>Inverse molecular design using machine learning: generative models for matter engineering</article-title>. <source>Science</source>
<volume>361</volume>, <fpage>360</fpage>–<lpage>365</lpage>. <pub-id pub-id-type="doi">10.1126/science.aat2663</pub-id>
<pub-id pub-id-type="pmid">30049875</pub-id></mixed-citation>
    </ref>
    <ref id="B58">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Segler</surname><given-names>M. H. S.</given-names></name><name><surname>Kogej</surname><given-names>T.</given-names></name><name><surname>Tyrchan</surname><given-names>C.</given-names></name><name><surname>Waller</surname><given-names>M. P.</given-names></name></person-group> (<year>2018</year>). <article-title>Generating focused molecule libraries for drug discovery with recurrent neural networks</article-title>. <source>ACS Cent. Sci.</source>
<volume>4</volume>, <fpage>120</fpage>–<lpage>131</lpage>. <pub-id pub-id-type="doi">10.1021/acscentsci.7b00512</pub-id>
<pub-id pub-id-type="pmid">29392184</pub-id></mixed-citation>
    </ref>
    <ref id="B59">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Shi</surname><given-names>C.</given-names></name><name><surname>Xu</surname><given-names>M.</given-names></name><name><surname>Zhu</surname><given-names>Z.</given-names></name><name><surname>Zhang</surname><given-names>W.</given-names></name><name><surname>Zhang</surname><given-names>M.</given-names></name><name><surname>Tang</surname><given-names>J.</given-names></name></person-group> (<year>2019</year>). “<article-title>Graphaf: a flow-based autoregressive model for molecular graph generation</article-title>,” in <conf-name>International conference on learning representations</conf-name>. </mixed-citation>
    </ref>
    <ref id="B60">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shultz</surname><given-names>M. D.</given-names></name></person-group> (<year>2018</year>). <article-title>Two decades under the influence of the rule of five and the changing properties of approved oral drugs</article-title>. <source>J. Med. Chem.</source>
<volume>62</volume>, <fpage>1701</fpage>–<lpage>1714</lpage>. <pub-id pub-id-type="doi">10.1021/acs.jmedchem.8b00686</pub-id>
<pub-id pub-id-type="pmid">30212196</pub-id></mixed-citation>
    </ref>
    <ref id="B61">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Stein</surname><given-names>S. E.</given-names></name><name><surname>Heller</surname><given-names>S. R.</given-names></name><name><surname>Tchekhovskoi</surname><given-names>D. V.</given-names></name></person-group> (<year>2003</year>). “<article-title>An open standard for chemical structure representation: the iupac chemical identifier</article-title>.” in <conf-name>International chemical information conference</conf-name>. </mixed-citation>
    </ref>
    <ref id="B62">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sterling</surname><given-names>T.</given-names></name><name><surname>Irwin</surname><given-names>J. J.</given-names></name></person-group> (<year>2015</year>). <article-title>Zinc 15 - ligand discovery for everyone</article-title>. <source>J. Chem. Inf. Model.</source>
<volume>55</volume>, <fpage>2324</fpage>–<lpage>2337</lpage>. <pub-id pub-id-type="doi">10.1021/acs.jcim.5b00559</pub-id>
<pub-id pub-id-type="pmid">26479676</pub-id></mixed-citation>
    </ref>
    <ref id="B63">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Teague</surname><given-names>S. J.</given-names></name><name><surname>Davis</surname><given-names>A. M.</given-names></name><name><surname>Leeson</surname><given-names>P. D.</given-names></name><name><surname>Oprea</surname><given-names>T.</given-names></name></person-group> (<year>1999</year>). <article-title>The design of leadlike combinatorial libraries</article-title>. <source>Angew. Chem. Int. Ed.</source>
<volume>38</volume>, <fpage>3743</fpage>–<lpage>3748</lpage>. <pub-id pub-id-type="doi">10.1002/(SICI)1521-3773(19991216)38:24&lt;3743::AID-ANIE3743&gt;3.0.CO;2-U</pub-id>
</mixed-citation>
    </ref>
    <ref id="B64">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Hilten</surname><given-names>N.</given-names></name><name><surname>Chevillard</surname><given-names>F.</given-names></name><name><surname>Kolb</surname><given-names>P.</given-names></name></person-group> (<year>2019</year>). <article-title>Virtual compound libraries in computer-assisted drug discovery</article-title>. <source>J. Chem. Inf. Model.</source>
<volume>59</volume>, <fpage>644</fpage>–<lpage>651</lpage>. <pub-id pub-id-type="doi">10.1021/acs.jcim.8b00737</pub-id>
<pub-id pub-id-type="pmid">30624918</pub-id></mixed-citation>
    </ref>
    <ref id="B65">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanhaelen</surname><given-names>Q.</given-names></name><name><surname>Mamoshina</surname><given-names>P.</given-names></name><name><surname>Aliper</surname><given-names>A. M.</given-names></name><name><surname>Artemov</surname><given-names>A.</given-names></name><name><surname>Lezhnina</surname><given-names>K.</given-names></name><name><surname>Ozerov</surname><given-names>I.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Design of efficient computational workflows for in silico drug repurposing</article-title>. <source>Drug Discov. Today</source>
<volume>22</volume>, <fpage>210</fpage>–<lpage>222</lpage>. <pub-id pub-id-type="doi">10.1016/j.drudis.2016.09.019</pub-id>
<pub-id pub-id-type="pmid">27693712</pub-id></mixed-citation>
    </ref>
    <ref id="B66">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weininger</surname><given-names>D.</given-names></name></person-group> (<year>1988</year>). <article-title>Smiles, a chemical language and information system. 1. introduction to methodology and encoding rules</article-title>. <source>J. Chem. Inf. Model.</source>
<volume>28</volume>, <fpage>31</fpage>–<lpage>36</lpage>. <pub-id pub-id-type="doi">10.1021/ci00057a005</pub-id>
</mixed-citation>
    </ref>
    <ref id="B67">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weininger</surname><given-names>D.</given-names></name><name><surname>Weininger</surname><given-names>A.</given-names></name><name><surname>Weininger</surname><given-names>J. L.</given-names></name></person-group> (<year>1989</year>). <article-title>Smiles. 2. algorithm for generation of unique smiles notation</article-title>. <source>J. Chem. Inf. Model.</source>
<volume>29</volume>, <fpage>97</fpage>–<lpage>101</lpage>. <pub-id pub-id-type="doi">10.1021/ci00062a008</pub-id>
</mixed-citation>
    </ref>
    <ref id="B68">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wildman</surname><given-names>S. A.</given-names></name><name><surname>Crippen</surname><given-names>G. M.</given-names></name></person-group> (<year>1999</year>). <article-title>Prediction of physicochemical parameters by atomic contributions</article-title>. <source>J. Chem. Inf. Comput. Sci.</source>
<volume>39</volume>, <fpage>868</fpage>–<lpage>873</lpage>. <pub-id pub-id-type="doi">10.1021/ci990307l</pub-id>
</mixed-citation>
    </ref>
    <ref id="B69">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Z.</given-names></name><name><surname>Ramsundar</surname><given-names>B.</given-names></name><name><surname>Feinberg</surname><given-names>E. N.</given-names></name><name><surname>Gomes</surname><given-names>J.</given-names></name><name><surname>Geniesse</surname><given-names>C.</given-names></name><name><surname>Pappu</surname><given-names>A. S.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>MoleculeNet: a benchmark for molecular machine learning</article-title>. <source>Chem. Sci.</source>
<volume>9</volume>, <fpage>513</fpage>–<lpage>530</lpage>. <pub-id pub-id-type="doi">10.1039/c7sc02664a</pub-id>
<pub-id pub-id-type="pmid">29629118</pub-id></mixed-citation>
    </ref>
    <ref id="B70">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Yoshizoe</surname><given-names>K.</given-names></name><name><surname>Terayama</surname><given-names>K.</given-names></name><name><surname>Tsuda</surname><given-names>K.</given-names></name></person-group> (<year>2017</year>). <article-title>ChemTS: an efficient python library for de novo molecular generation</article-title>. <source>Sci. Technol. Adv. Mater.</source>
<volume>18</volume>, <fpage>972</fpage>–<lpage>976</lpage>. <pub-id pub-id-type="doi">10.1080/14686996.2017.1401424</pub-id>
<pub-id pub-id-type="pmid">29435094</pub-id></mixed-citation>
    </ref>
    <ref id="B71">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>L.</given-names></name><name><surname>Zhang</surname><given-names>W.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Yu</surname><given-names>Y.</given-names></name></person-group> (<year>2017</year>). “<article-title>Seqgan: sequence generative adversarial nets with policy gradient</article-title>,” in <conf-name>Thirty-first AAAI conference on artificial intelligence</conf-name>. </mixed-citation>
    </ref>
    <ref id="B72">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhavoronkov</surname><given-names>A.</given-names></name><name><surname>Ivanenkov</surname><given-names>Y. A.</given-names></name><name><surname>Aliper</surname><given-names>A.</given-names></name><name><surname>Veselov</surname><given-names>M. S.</given-names></name><name><surname>Aladinskiy</surname><given-names>V. A.</given-names></name><name><surname>Aladinskaya</surname><given-names>A. V.</given-names></name><etal/></person-group> (<year>2019a</year>). <article-title>Deep learning enables rapid identification of potent DDR1 kinase inhibitors</article-title>. <source>Nat. Biotechnol.</source>, <volume>37</volume>, <fpage>1038</fpage>–<lpage>1040</lpage>. <pub-id pub-id-type="doi">10.1038/s41587-019-0224-x</pub-id>
<pub-id pub-id-type="pmid">31477924</pub-id></mixed-citation>
    </ref>
    <ref id="B73">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhavoronkov</surname><given-names>A.</given-names></name><name><surname>Mamoshina</surname><given-names>P.</given-names></name><name><surname>Vanhaelen</surname><given-names>Q.</given-names></name><name><surname>Scheibye-Knudsen</surname><given-names>M.</given-names></name><name><surname>Moskalev</surname><given-names>A.</given-names></name><name><surname>Aliper</surname><given-names>A.</given-names></name></person-group> (<year>2019b</year>). <article-title>Artificial intelligence for aging and longevity research: recent advances and perspectives</article-title>. <source>Ageing Res. Rev.</source>
<volume>49</volume>, <fpage>49</fpage>–<lpage>66</lpage>. <pub-id pub-id-type="doi">10.1016/j.arr.2018.11.003</pub-id>
<pub-id pub-id-type="pmid">30472217</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
