<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?covid-19-tdm?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Appl Intell (Dordr)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Appl Intell (Dordr)</journal-id>
    <journal-title-group>
      <journal-title>Applied Intelligence (Dordrecht, Netherlands)</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">0924-669X</issn>
    <issn pub-type="epub">1573-7497</issn>
    <publisher>
      <publisher-name>Springer US</publisher-name>
      <publisher-loc>New York</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7502308</article-id>
    <article-id pub-id-type="pmid">34764551</article-id>
    <article-id pub-id-type="publisher-id">1904</article-id>
    <article-id pub-id-type="doi">10.1007/s10489-020-01904-z</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>OptCoNet: an optimized convolutional neural network for an automatic diagnosis of COVID-19</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Goel</surname>
          <given-names>Tripti</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <bio>
          <sec id="FPar1">
            <title>Tripti Goel</title>
            <p>obtained his Bachelor of Engineering (Hons) from Maharishi Dayanand University in 2004. She obtained her MTech in 2008 from Chottu Ram State College of Engineering, Haryana and Ph.D in 2017 from BPS Mahilla Vishwavidyalaya, Haryana. She joined Bhagwan Mahaveer Institute of Engineering and Technology, Haryana as Lecturer in Auguat 2005. After completing her M. Tech. She joined Guru Premsukh Memorial College of Engg. as lecturer in 2009 and became an Senior Lecturer in 2012. She joined at NIT, Delhi as an Assistant Professor in July, 2015. After that she Joined National Brain Research Center, Gurugram as Research Scientist in February, 2018. She joined NIT, Silchar as an Assistant Professor in June 2018. Her research interest which includes Medical Image Processing, Machine Learning, Deep Learning, Pattern Recognition, Neuroimaging.<graphic position="anchor" xlink:href="10489_2020_1904_Figa_HTML" id="MO21"/></p>
          </sec>
        </bio>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9341-3810</contrib-id>
        <name>
          <surname>Murugan</surname>
          <given-names>R.</given-names>
        </name>
        <address>
          <email>murugan.rmn@ece.nits.ac.in</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <bio>
          <sec id="FPar2">
            <title>R Murugan</title>
            <p>received his B.E. degree in Electronics and Communication Engineering, and M.E. degree in Embedded System Technologies from Anna University, Chennai, Tamilnadu, in 2005, and 2010 respectively. He received his Ph.D. degree from Information and Communication Engineering, Centre for Research, Anna University, Chennai, Tamilnadu, India. He is working as an Assistant Professor, in the Department of Electronics and Communication Engineering, National Institute of Technology Silchar since 15th June 2018. He published more than 26 journal publications, 22 conference proceedings, 2 books, 9 book chapters and 4 patents in his credit. His area of interest which includes Bio-medical signal and image processing, medical imaging, Retinal image analysis, computer vision, pattern recognition, machine learning and deep learning.<graphic position="anchor" xlink:href="10489_2020_1904_Figb_HTML" id="MO22"/></p>
          </sec>
        </bio>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mirjalili</surname>
          <given-names>Seyedali</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <bio>
          <sec id="FPar3">
            <title>Seyedali Mirjalili</title>
            <p>is an Associate Professor at Torrens University Center for Artificial Intelligence Research and Optimization and internationally recognized for his advances in nature-inspired Artificial Intelligence (AI) techniques. He received his B.Sc. degree in Computer Engineering (software) from Yazd University, M.Sc. degree in Computer Science from Universiti Teknologi Malaysia (UTM), and Ph.D. in Computer Science from Griffith University. He was a member of Soft Computing Research Group (SCRG) at UTM. His research interests include Robust Optimization, Multi-objective Optimization, Swarm Intelligence, Evolutionary Algorithms, and Artificial Neural Networks. He is working on the application of multi-objective and robust metaheuristic optimization techniques. He is the author of more than 150 publications including five books, 100 journal articles, 20 conference papers, and 30 book chapters. With over 15,000 citations and H-index of 45, he is one of the most influential AI researchers in the world. From Google Scholar metrics, he is globally the most cited researcher in Optimization using AI techniques, which is his main area of expertise. He has been the keynote speaker of several international conferences and is serving as an associate editor of top AI journals including Neurocomputing, Applied Soft Computing, Advances in Engineering Software, Applied Intelligence, IEEE Access, and the Journal of Algorithms.<graphic position="anchor" xlink:href="10489_2020_1904_Figc_HTML" id="MO23"/></p>
          </sec>
        </bio>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chakrabartty</surname>
          <given-names>Deba Kumar</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <bio>
          <sec id="FPar4">
            <title>Deba Kumar Chakrabartty</title>
            <p>received the MBBS degree from Gauhati Medical College, India, in 1998 and the M.D. degree in Radio Diagnosis from Gauhati Medical College, India. He Joined as Registrar on Silchar Medical College, Assam, India in 1995. He Promoted to Assistant Professor and Associate Professor in 1995 and 2004 respectively on Silchar Medical College, Assam, India. Presently he working as Professor and Head of Radiology Department of Silchar Medical College and Hospital. He served various administrative responsibilities which includes PG thesis examiner from January 2014 and PG External Examiner on 2019 to North Bengal Medical College etc.<graphic position="anchor" xlink:href="10489_2020_1904_Figd_HTML" id="MO24"/></p>
          </sec>
        </bio>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.444720.1</institution-id><institution>Department of Electronics and Communication Engineering, </institution><institution>National Institute of Technology Silchar, </institution></institution-wrap>Silchar, Assam 788010 India </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.449625.8</institution-id><institution-id institution-id-type="ISNI">0000 0004 4654 2104</institution-id><institution>Centre for Artificial Intelligence Research and Optimisation, </institution><institution>Torrens University Australia, </institution></institution-wrap>Fortitude Valley, Brisbane, QLD 4006 Australia </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.460826.e</institution-id><institution-id institution-id-type="ISNI">0000 0004 1804 6306</institution-id><institution>Department of Radiology, </institution><institution>Silchar Medical College and Hospital, </institution></institution-wrap>Silchar, Assam 788014 India </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>21</day>
      <month>9</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <year>2021</year>
    </pub-date>
    <volume>51</volume>
    <issue>3</issue>
    <fpage>1351</fpage>
    <lpage>1366</lpage>
    <permissions>
      <copyright-statement>© Springer Science+Business Media, LLC, part of Springer Nature 2020</copyright-statement>
      <license>
        <license-p>This article is made available via the PMC Open Access Subset for unrestricted research re-use and secondary analysis in any form or by any means with acknowledgement of the original source. These permissions are granted for the duration of the World Health Organization (WHO) declaration of COVID-19 as a global pandemic.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">The quick spread of coronavirus disease (COVID-19) has become a global concern and affected more than 15 million confirmed patients as of July 2020. To combat this spread, clinical imaging, for example, X-ray images, can be utilized for diagnosis. Automatic identification software tools are essential to facilitate the screening of COVID-19 using X-ray images. This paper aims to classify COVID-19, normal, and pneumonia patients from chest X-ray images. As such, an Optimized Convolutional Neural network (OptCoNet) is proposed in this work for the automatic diagnosis of COVID-19. The proposed OptCoNet architecture is composed of optimized feature extraction and classification components. The Grey Wolf Optimizer (GWO) algorithm is used to optimize the hyperparameters for training the CNN layers. The proposed model is tested and compared with different classification strategies utilizing an openly accessible dataset of COVID-19, normal, and pneumonia images. The presented optimized CNN model provides accuracy, sensitivity, specificity, precision, and F1 score values of 97.78%, 97.75%, 96.25%, 92.88%, and 95.25%, respectively, which are better than those of state-of-the-art models. This proposed CNN model can help in the automatic screening of COVID-19 patients and decrease the burden on medicinal services frameworks.</p>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Automatic diagnosis</kwd>
      <kwd>Coronavirus</kwd>
      <kwd>COVID-19</kwd>
      <kwd>Convolutional neural network</kwd>
      <kwd>Grey wolf optimizer</kwd>
      <kwd>Stochastic gradient descent</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© Springer Science+Business Media, LLC, part of Springer Nature 2021</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par2">Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is a novel virus that is enveloped with a large, single-stranded RNA genome. It emerged in Wuhan, China in December 2019 and caused the greatest pandemic of the millennium [<xref ref-type="bibr" rid="CR1">1</xref>]. According to the World Health Organization (WHO) report, the total number of people infected by the disease as of 27 July 2020 is 16,114,449 with 646,641 deaths. The typical symptoms of the disease are fever, breathlessness, cough, fatigue, and loss of taste and smell [<xref ref-type="bibr" rid="CR2">2</xref>]. The standard method for diagnosing COVID-19 is reverse transcription-polymerase chain reaction from a nasopharyngeal swab. Even though the continuous polymerase chain reaction examination of the sputum has the best quality for detecting COVID-19, the time required to confirm COVID-19 in infected patients can be high given the elevated false positive results of the examination [<xref ref-type="bibr" rid="CR3">3</xref>]. Therefore, clinical imaging modalities, for example, chest X-ray (CXR), can play an important role in diagnosing individuals where there is a high doubt of infection according to symptoms and hazard factors, with the exception of pregnant women and children outside of emergency situations [<xref ref-type="bibr" rid="CR4">4</xref>]. CXR images have been explored in the ongoing pandemic for detecting COVID-19.</p>
    <p id="Par3">Chest computed tomography (CT) imaging may likewise aid in the diagnosis of COVID-19; however, current guidelines do not suggest utilizing CT imaging for routine screening. Hence radiologists recommend CXR for the diagnosis of COVID-19. The advantage of X-ray machines is that most radiological laboratories and hospitals are capable of acquiring 2-dimensional projection images of the patient’s chest. In general, CXR images play a vital role for radiologists in perceiving the chest pathology and have been applied in the confirmation or recommendation of COVID-19 in infected patients [<xref ref-type="bibr" rid="CR5">5</xref>]. Figure <xref rid="Fig1" ref-type="fig">1a, b, and c</xref> show sample CXR images of a normal, COVID-19, and pneumonia patient, respectively [<xref ref-type="bibr" rid="CR6">6</xref>].<fig id="Fig1"><label>Fig. 1</label><caption><p>Sample CXR images <bold>a</bold> Normal <bold>b</bold> COVID-19 <bold>c</bold> Pneumonia</p></caption><graphic xlink:href="10489_2020_1904_Fig1_HTML" id="MO1"/></fig></p>
    <p id="Par4">Computer-aided diagnosis (CAD) frameworks assist with a rapid, automatic diagnosis using graphical processing units (GPUs) by processing medical images. To the best of our knowledge, deep learning (DL) architecture has been used in many CAD frameworks and in numerous medical imaging applications, such as for COVID-19 [<xref ref-type="bibr" rid="CR7">7</xref>]. In recent years, the convolutional neural network (CNN) has yielded the most promising results in classifying radiological images. CNNs are DL algorithms and have been used in many applications, including image classification. These advantages motivated our attempt to propose a CNN algorithm for COVID-19 diagnosis in this paper.</p>
    <p id="Par5">The hyperparameters of CNNs have an important influence on the network’s performance, as they directly control the training process. The selection of appropriate hyperparameters plays a vital role in the training of the CNN network. For example, if the learning rate is too low, the network may lose important details in the data. By contrast, if the learning rate is too high, it may lead the model to converge too quickly. Therefore, there is a need to optimize the hyperparameters of CNNs for proper training and optimum performance results.</p>
    <p id="Par6">The novelty of this work is twofold. First, we optimized the hyperparameters of a CNN using the Grey Wolf Optimization algorithm according to CXR images. In addition, the proposed method avoids the overfitting of input images and real-time images with better performance metrics.</p>
    <p id="Par7">The details of the contributions are as follows:<list list-type="simple"><list-item><label>I.</label><p id="Par8">Hyperparameters of the CNN are optimized using Grey Wolf Optimization to determine the best accurate results in diagnosing COVID-19, normal, and pneumonia patients from CXR images.</p></list-item><list-item><label>II.</label><p id="Par9">Grey Wolf Optimization is compared with other optimization algorithms for tuning the CNN’s hyperparameters.</p></list-item><list-item><label>III.</label><p id="Par10">A CNN model is proposed for the automatic diagnosis of COVID-19 using CXR images with an accuracy of 97.78%.</p></list-item></list></p>
    <p id="Par11">The rest of this paper is arranged as follows: Related works are introduced in Section <xref rid="Sec2" ref-type="sec">2</xref>. The theoretical and mathematical fundamentals are given in Section <xref rid="Sec3" ref-type="sec">3</xref>. The material and methodology are presented in Section <xref rid="Sec4" ref-type="sec">4</xref>. The experiments are given in Section <xref rid="Sec9" ref-type="sec">5</xref>. Finally, the conclusion is presented in Section <xref rid="Sec25" ref-type="sec">6</xref>.</p>
  </sec>
  <sec id="Sec2">
    <title>Related works</title>
    <p id="Par12">Recently, AI-based techniques for identifying and tracing COVID-19 have been popular in the global attempt to end the pandemic. This section briefly covers ongoing attempts at determining a COVID-19 diagnosis utilizing CXR images. Since uncovering the possibility of using CXR images in recognizing COVID-19 and the shortcomings of manual detection, there have been a number of investigations attempting to create automatic COVID-19 classification frameworks, mainly utilizing CNNs. Narin et al. [<xref ref-type="bibr" rid="CR8">8</xref>] introduced a study of three distinctive CNN models, including InceptionV3, ResNet50, and Inception-ResNetV2, that were proposed for the recognition of COVID-19 utilizing CXR images.</p>
    <p id="Par13">Hemdan et al. [<xref ref-type="bibr" rid="CR9">9</xref>] presented COVIDX-Net, which incorporates seven unique designs of deep convolutional neural network (DCNN) including an improved VGG19 and the second form of Google MobileNet. Each DCNN model can inspect the normalized forces in CXR images to portray the patient status as either negative or positive COVID-19. The DenseNet and VGG19 models were capable of automatically detecting COVID-19. Khan et al. [<xref ref-type="bibr" rid="CR10">10</xref>] proposed CoroNet, a DCNN model, to perform image processing on X-ray images and classify them positively or negatively. Li et al. [<xref ref-type="bibr" rid="CR11">11</xref>] demonstrated a mobile-based lightweight DL network architecture, namely, COVID-MobileXpert.</p>
    <p id="Par14">Maghdid et al. [<xref ref-type="bibr" rid="CR12">12</xref>] proposed an AI model for radiologists and health experts to analyze COVID-19 cases quickly and accurately. This involved constructing an extensive dataset of CXR and CT images from various sources and developed a necessary yet compelling COVID-19 identification procedure utilizing DL and TL techniques. Mahdy et al. [<xref ref-type="bibr" rid="CR13">13</xref>] introduced a strategy for identifying COVID-19-infected persons utilizing CXR images. Multilevel thresholding and a support vector machine (SVM) were introduced to achieve high accuracy with images of the infected lungs of COVID-19 patients. Rehman et al. [<xref ref-type="bibr" rid="CR14">14</xref>] utilized pretrained information to improve demonstrative execution using TL methods and performed a comparative analysis with different CNN structures.</p>
    <p id="Par15">Abbas et al. [<xref ref-type="bibr" rid="CR15">15</xref>] validated and adapted their recently created Decompose, Transfer, and Compose (DeTraC) CNN for the diagnosis of COVID-19 with CXR images. DeTraC can manage any anomalies in the image dataset by researching its class limits utilizing a class disintegration system. The TL was used for tweaking the parameters.</p>
    <p id="Par16">Afshar et al. [<xref ref-type="bibr" rid="CR16">16</xref>] introduced an elective demonstrating system dependent on capsule networks (rather than CNNs), alluded to as the COVID-CAPS, which was equipped to work with small datasets vitally because of the abrupt and fast development of COVID-19. Apostolopoulos et al. (2020) [<xref ref-type="bibr" rid="CR17">17</xref>] depicted a method to assess the performance of best-in-class CNN models proposed over recent years for clinical image classification. More specifically, a methodology called TL was employed in their work.</p>
    <p id="Par17">Apostolopoulos et al. (2020) [<xref ref-type="bibr" rid="CR18">18</xref>] additionally introduced the best-in-class CNN called Mobile Net. This was utilized and developed without any preparation to research the significance of the extricated features for the characterization of COVID-19. Farook et al. [<xref ref-type="bibr" rid="CR19">19</xref>] built open source datasets for COVID-19. They introduced an exact CNN structure for separating COVID-19 from pneumonia cases. This work utilized the best training techniques, including dynamic resizing, TL, and discriminative learning, to train the CNN quickly and accurately using DL frameworks.</p>
    <p id="Par18">All the techniques on DL–based COVID-19 screening have so far used CNNs, which, despite their incredible image handling capability, are unable to identify the unique relations between image examples. Because of this disadvantage, CNNs cannot perceive items as similar when one has been rotated or subject to another sort of change. As a result, CNNs require large datasets, including all possible changes to which images can be subjected. Nonetheless, in clinical imaging settings, including COVID-19 screening, large datasets are most certainly not adequately available. The proposed Optimized Convolutional Neural Network (OptCoNet) is an alternative model capable of screening COVID-19 without a vast dataset since it captures spatial information coming from instances and object parts using potential changes in the existence of the objects.</p>
  </sec>
  <sec id="Sec3">
    <title>Grey wolf optimizer</title>
    <p id="Par19">The Grey Wolf Optimizer (GWO) [<xref ref-type="bibr" rid="CR20">20</xref>], a recently developed swarm intelligence (SI) algorithm, has proven to be a reliable optimization algorithm compared to conventional evolutionary and swarm-based algorithms. The gray wolf belongs to the Canidae family. It is considered a high-level predator and dwells at the top of the food chain. They live in a pack that comprises 5–12 wolves on the whole. In gatherings, an exact predominance order is maintained. The pack is driven by alphas and trailed by betas, the subordinate wolves who are mindful to help the alpha in maintaining the dynamics of the pack.</p>
    <p id="Par20">The beta wolf strengthens the alpha’s orders all through the pack and offers input to the alpha. In the interim, the lowest rung among the gray wolves is the omega, who generally assumes the scapegoat’s job. They are the last wolves allowed to eat from the prey. On the off chance that a wolf is not alpha, beta, or omega, the individual in question is known as a delta. Delta wolves act as scouts, sentinels, seniors, trackers, and guardians.</p>
    <p id="Par21">The motivation for proposing the GWO algorithm for COVID-19 diagnosis is twofold. First, it is a very competitive optimization algorithm. It has been applied to various research fields, such as feature selection, economic load dispatch problems, and flow scheduling problems. In addition, the GWO algorithm benefits from avoiding high local optima, which leads to avoidance of overlapping features in the problem of feature selection.</p>
    <p id="Par22">The main mechanisms of GWO, including social pecking order, following, circling, and attacking prey, are introduced as follows.</p>
    <p id="Par23">In the GWO algorithm, the fittest solution can be represented as the alpha (α), with the second and third-best solutions represented as beta (β) and delta (δ), respectively. The remainder of the up-and-coming solutions are considered omegas (ω). GWO uses these simple principles to rank the solutions in each iteration and update their positions.</p>
    <p id="Par24">When wolves hunt, they will, in general, enclose their prey. The following mathematical equations delineate this encircling behavior<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathrm{D}=\mid \mathrm{C}.{\mathrm{X}}_{\mathrm{p}}\left(\mathrm{t}\right)-\mathrm{X}\left(\mathrm{t}\right)\mid $$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mi mathvariant="normal">D</mml:mi><mml:mo>=</mml:mo><mml:mo>∣</mml:mo><mml:mi mathvariant="normal">C</mml:mi><mml:mo>.</mml:mo><mml:msub><mml:mi mathvariant="normal">X</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">t</mml:mi></mml:mfenced><mml:mo>−</mml:mo><mml:mi mathvariant="normal">X</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">t</mml:mi></mml:mfenced><mml:mo>∣</mml:mo></mml:math><graphic xlink:href="10489_2020_1904_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathrm{X}\left(\mathrm{t}+1\right)={\mathrm{X}}_{\mathrm{p}}-\mathrm{A}.\mathrm{D} $$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mi mathvariant="normal">X</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">X</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi mathvariant="normal">A</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">D</mml:mi></mml:math><graphic xlink:href="10489_2020_1904_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <italic>D</italic> denotes distance, t represents the present iteration, <italic>A</italic> and <italic>C</italic> are coefficients, <italic>X</italic><sub><italic>p</italic></sub> is the prey’s location, and <italic>X</italic> denotes the position of a gray wolf.</p>
    <p id="Par25">The coefficients <italic>A</italic> and <italic>C</italic> are calculated as follows:<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ A=2 ar1-a $$\end{document}</tex-math><mml:math id="M6" display="block"><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi mathvariant="italic">ar</mml:mi><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>a</mml:mi></mml:math><graphic xlink:href="10489_2020_1904_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ C=2r2 $$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:math><graphic xlink:href="10489_2020_1904_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where r<sub>1</sub> and r<sub>2</sub> are random values between 0 and 1 and ‘a’ is a decreasing parameter.</p>
    <p id="Par26">As mentioned above, the three best solutions (alpha, beta, and delta) are updated first, and then, the other search agents (omega wolves) update their positions, all using the following equations:<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathrm{D}\upalpha =\mid \mathrm{C}1\mathrm{X}\upalpha -\mathrm{X}\mid, \mathrm{D}\upbeta =\mid \mathrm{C}1\mathrm{X}\upbeta -\mathrm{X}\mid, \mathrm{D}\updelta =\mid \mathrm{C}1\mathrm{X}\upalpha -\mathrm{X}\mid $$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mi>Dα</mml:mi><mml:mo>=</mml:mo><mml:mo>∣</mml:mo><mml:mi mathvariant="normal">C</mml:mi><mml:mn>1</mml:mn><mml:mi>Xα</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="normal">X</mml:mi><mml:mo>∣</mml:mo><mml:mo>,</mml:mo><mml:mi>Dβ</mml:mi><mml:mo>=</mml:mo><mml:mo>∣</mml:mo><mml:mi mathvariant="normal">C</mml:mi><mml:mn>1</mml:mn><mml:mi>Xβ</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="normal">X</mml:mi><mml:mo>∣</mml:mo><mml:mo>,</mml:mo><mml:mi>Dδ</mml:mi><mml:mo>=</mml:mo><mml:mo>∣</mml:mo><mml:mi mathvariant="normal">C</mml:mi><mml:mn>1</mml:mn><mml:mi>Xα</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="normal">X</mml:mi><mml:mo>∣</mml:mo></mml:math><graphic xlink:href="10489_2020_1904_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ X1= X\alpha -A1.\left( D\alpha \right),X2= X\beta -A1.\left( D\beta \right),X1= X\delta -A1.\left( D\delta \right) $$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mi>X</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mi mathvariant="italic">Xα</mml:mi><mml:mo>−</mml:mo><mml:mi>A</mml:mi><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mfenced close=")" open="("><mml:mi mathvariant="italic">Dα</mml:mi></mml:mfenced><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mn>2</mml:mn><mml:mo>=</mml:mo><mml:mi mathvariant="italic">Xβ</mml:mi><mml:mo>−</mml:mo><mml:mi>A</mml:mi><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mfenced close=")" open="("><mml:mi mathvariant="italic">Dβ</mml:mi></mml:mfenced><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mi mathvariant="italic">Xδ</mml:mi><mml:mo>−</mml:mo><mml:mi>A</mml:mi><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mfenced close=")" open="("><mml:mi mathvariant="italic">Dδ</mml:mi></mml:mfenced></mml:math><graphic xlink:href="10489_2020_1904_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathrm{X}\left(\mathrm{t}+1\right)=\frac{X_{1+}+{X}_{2+}{X}_3}{3} $$\end{document}</tex-math><mml:math id="M14" display="block"><mml:mi mathvariant="normal">X</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mn>3</mml:mn></mml:mfrac></mml:math><graphic xlink:href="10489_2020_1904_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula></p>
    <p id="Par27">To summarize, the optimization approach for GWO commence with making an arbitrary populace of grey wolves, which can be called applicants of solution. During the recreation, alpha, beta, and delta wolves gauge the conceivable situation of the prey. The parameter of ‘a’ in Eq. (<xref rid="Equ3" ref-type="">3</xref>) can be demonstrated as investigation and abuse forms by diminishing the incentive from 2 to 0. Up-and-comer arrangements have separated from the prey if |A| &gt; 1 and converged toward the prey |A| &lt; 1. The GWO algorithm iteratively updates and evaluation candidate solutions until an end condition is met.</p>
    <p id="Par28">To summarize, the optimization approach for GWO begins with making an arbitrary populace of gray wolves, which can be called applicants of solution. During recreation, alpha, beta, and delta wolves gauge the conceivable situations of the prey. The parameter ‘a’ in Eq. (<xref rid="Equ3" ref-type="">3</xref>) can represent investigation or abuse by decreasing the value from 2 to 0. Up-and-comer solutions indicate distancing from the prey if |A| &gt; 1 and convergence toward the prey if |A| &lt; 1. The GWO algorithm iteratively updates and evaluates candidate solutions until an end condition is met.</p>
  </sec>
  <sec id="Sec4">
    <title>Materials and methodology</title>
    <sec id="Sec5">
      <title>Dataset</title>
      <p id="Par29">CXR images of COVID-19, normal, and pneumonia patients collected from publicly available repositories [<xref ref-type="bibr" rid="CR21">21</xref>–<xref ref-type="bibr" rid="CR26">26</xref>] were used in this work. These repositories yielded a total of 2700 images, out of which 900 were COVID-19 images. The resolution of all images was set to 224x224x3 pixel size. The details of the images are stated in Table <xref rid="Tab1" ref-type="table">1</xref>.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Dataset used in this study</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Dataset</th><th>Images category</th><th>No. of images</th><th>Reference</th></tr></thead><tbody><tr><td>Chest imaging</td><td>COVID-19</td><td>134</td><td>[<xref ref-type="bibr" rid="CR21">21</xref>]</td></tr><tr><td>COVID-19</td><td>COVID-19</td><td>64</td><td>[<xref ref-type="bibr" rid="CR22">22</xref>]</td></tr><tr><td>Covid-chestxray</td><td>COVID-19</td><td>646</td><td>[<xref ref-type="bibr" rid="CR23">23</xref>]</td></tr><tr><td>Figure <xref rid="Fig1" ref-type="fig">1</xref> COVID-19 Chest X-ray</td><td>COVID-19</td><td>55</td><td>[<xref ref-type="bibr" rid="CR24">24</xref>]</td></tr><tr><td>Provincial peoples hospital</td><td>COVID-19</td><td>1</td><td>[<xref ref-type="bibr" rid="CR25">25</xref>]</td></tr><tr><td>Kaggle</td><td>Normal</td><td>900</td><td>[<xref ref-type="bibr" rid="CR26">26</xref>]</td></tr><tr><td>Kaggle</td><td>Pneumonia</td><td>900</td><td>[<xref ref-type="bibr" rid="CR26">26</xref>]</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec6">
      <title>Workflow</title>
      <p id="Par30">A CNN is a type of DL model that extends the capability of the artificial neural network (ANN) by adding more layers to its architecture. CNNs have excellent feature extraction, pattern recognition, and classification performance of the raw input data without any preprocessing. The CNN architecture is divided into two parts: feature extraction and classification. Feature extraction is performed using several layers, including a convolutional layer (CL) followed by a max-pooling layer (MPL). Classification consists of a fully connected layer (FCL) and a classification layer to classify the input features into a particular class. CLs and FCLs are composed of weights and biases, which should be tuned using a gradient descent training algorithm. The training algorithm should also include many hyperparameters, which strongly reflect the CNN model’s performance. These parameters are the training algorithm, momentum, learning rate, number of epochs, validation frequency, and L2Regularization. The current work is focused on optimizing these hyperparameters for training the CNN to yield optimal performance results. Although hyperparameters are very important for producing better performance, testing each hyperparameter is computationally expensive. Therefore, GWO is proposed in this architecture to optimize the hyperparameters for training the layers of the CNN. Figure <xref rid="Fig2" ref-type="fig">2</xref> shows the flow diagram of the proposed network of hyperparameter optimization for a CNN using GWO. The description of the proposed model is discussed as follows.<fig id="Fig2"><label>Fig. 2</label><caption><p>Flow diagram of grey wolf optimized CNN for COVID-19 diagnosis</p></caption><graphic xlink:href="10489_2020_1904_Fig2_HTML" id="MO2"/></fig></p>
    </sec>
    <sec id="Sec7">
      <title>Convolutional neural network</title>
      <p id="Par31">The CNN architecture is composed of an input layer, CL, MPL, FCL, and output layer. The CL layer of the CNN is responsible for extracting features from the input images using several convolutional filters. These convolutional filters perform the convolutional operation at every offset of the input image. The CL contains weights that should be optimized using gradient descent training, which adjusts the parameters of the CL. The features extracted from the CL are mapped into feature space using a nonlinear rectified linear unit (ReLU) activation function. A batch normalization layer (BNL) is used between the CL and ReLU to normalize the gradients and activations through the network. The PL is used to reduce the dimensions of the feature maps obtained from the CL and retain the most relevant information of the image. Pooling methods include max-pooling and average pooling. There are no weights or biases in the PL of the CNN to train. The last layer is a fully connected classifier layer that classifies the extracted features from the CL and MPL into a particular class.</p>
      <p id="Par32">CNN training involves adjusting the parameters of the convolutional kernels and hidden neurons in the fully connected classification layer. Generally, CNNs utilize stochastic gradient descent (SGD) training to tune the CL and fully connected layer parameters. SGD minimizes the cost function by updating the weights of the network in the backward direction.</p>
      <p id="Par33">The disadvantage of using SGD is that it contains many hyperparameters that influence the network’s performance. The next section explains the algorithm used to optimize these hyperparameters to achieve the best network performance. Details of the layers of the proposed CNN are given in Table <xref rid="Tab2" ref-type="table">2</xref>.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Architecture of proposed CNN</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Layer</th><th>Type</th><th>Filter size</th><th>No .of filters</th><th>stride</th></tr></thead><tbody><tr><td>Input</td><td>224x224x3</td><td/><td/><td/></tr><tr><td>Conv_1</td><td>CL + BN + ReLu</td><td>3 × 3</td><td>64</td><td>1 × 1</td></tr><tr><td>MPL_1</td><td/><td>2 × 2</td><td/><td>2 × 2</td></tr><tr><td>Conv_2</td><td>CL + BN + ReLu</td><td>3 × 3</td><td>64</td><td>1 × 1</td></tr><tr><td>MPL_2</td><td/><td>2 × 2</td><td/><td>2 × 2</td></tr><tr><td>Conv_3</td><td>CL + BN + ReLu</td><td>3 × 3</td><td>32</td><td>1 × 1</td></tr><tr><td>MPL_3</td><td/><td>2 × 2</td><td/><td>2 × 2</td></tr><tr><td>Conv_4</td><td>CL + BN + ReLu</td><td>3 × 3</td><td>16</td><td>1 × 1</td></tr><tr><td>MPL_5</td><td/><td>2 × 2</td><td/><td>2 × 2</td></tr><tr><td>Conv_5</td><td>CL + BN + ReLu</td><td>3 × 3</td><td>8</td><td>1 × 1</td></tr><tr><td>Fully connected</td><td>Output size =3</td><td/><td/><td/></tr><tr><td>Output</td><td>Classification layer</td><td>Soft-max</td><td/><td/></tr></tbody></table><table-wrap-foot><p><italic>BN</italic> Batch Normalization Layer</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec8">
      <title>Hyperparameter optimization using GWO</title>
      <p id="Par34">In this work, the hyperparameters are optimized using GWO. Hyperparameters play a crucial role in determining the accuracy and convergence of the CNN. Selecting the network’s hyperparameters is essential and depends on the application for which the CNN is used. The learning rate, number of epochs, momentum, and regularization coefficient are the most common CNN training hyperparameters. The learning rate controls the gradient descent algorithm’s speed, and the momentum controls the influence of the update of previous weights on the update of current weights. The number of epochs determines the number of times the learning algorithm will update the network parameters according to the training dataset. Regularization overcomes the issue of overfitting in the network. Therefore, to address all these settings, optimizing these hyperparameters is required to help the network yield the most accurate results. The GWO algorithm for the optimization of hyperparameters in SGD training is given in Algorithm (1).<graphic position="anchor" xlink:href="10489_2020_1904_Fige_HTML" id="MO26"/></p>
    </sec>
  </sec>
  <sec id="Sec9">
    <title>Experiments</title>
    <p id="Par35">To benchmark the performance of the proposed GWO-based CNN for COVID-19, normal, and pneumonia images, tests were conducted for classification using different optimization techniques.</p>
    <sec id="Sec10">
      <title>Implementation details</title>
      <p id="Par36">The algorithm was implemented in MATLAB 2020a and executed using Windows 10 Pro with a 64 GB RAM Nvidia GPU. The proposed architecture was tested for both normal, phenomena, and COVID-19 CXR images using publicly available datasets.</p>
      <sec id="Sec11">
        <title>Training</title>
        <p id="Par37">For the diagnosis of COVID-19 from CXR images, a six CL CNN is used. The A total of 70% of the data are used for training, and the remaining 30% of the data are used for testing the network. The proposed architecture classifies images into three categories: normal, pneumonia, and COVID-19. The dataset is partitioned randomly into training and test sets. All the images are resized to 224x224x3 using data augmentation and converted to color images. A six convolutional layer architecture is used to classify the images, and parameters are tuned using SGD training, whose hyperparameters are optimized using GWO at the time of training. The optimized hyperparameters obtained using GWO optimization are given in Table <xref rid="Tab3" ref-type="table">3</xref>, and sample training images are provided in Fig. <xref rid="Fig3" ref-type="fig">3</xref>.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Training options using GWO optimization</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Training algorithm</th><th>Momentum</th><th>Initial learning rate</th><th>Maximum epoch</th><th>Validation frequency</th><th>L2Regularization</th></tr></thead><tbody><tr><td>SGD</td><td>0.6</td><td>0.015</td><td>10</td><td>30</td><td>1.0000e-04</td></tr></tbody></table></table-wrap><fig id="Fig3"><label>Fig. 3</label><caption><p>Sample training images <bold>a</bold>-<bold>b</bold> COVID-19 <bold>c</bold>-<bold>d</bold> Normal <bold>e</bold>-<bold>f</bold> Pneumonia</p></caption><graphic xlink:href="10489_2020_1904_Fig3_HTML" id="MO4"/></fig></p>
      </sec>
      <sec id="Sec12">
        <title>Testing</title>
        <p id="Par38">First, the images are resized to 224x224x3 using data augmentation and training the proposed network. After that, the test images are given as input to the trained CNN, where all the parameters of the CLs and FCLs are already optimized. Then, the CNN first extracts the images features and classifies them into the appropriate class using FCL and soft-max classifiers. The sample testing images are given in Fig. <xref rid="Fig4" ref-type="fig">4</xref>.<fig id="Fig4"><label>Fig. 4</label><caption><p>Sample testing images <bold>a</bold>-<bold>b</bold> COVID-19 <bold>c</bold>-<bold>d</bold> Normal <bold>e</bold>-<bold>f</bold> Pneumonia</p></caption><graphic xlink:href="10489_2020_1904_Fig4_HTML" id="MO5"/></fig></p>
      </sec>
    </sec>
    <sec id="Sec13">
      <title>Performance indicators and evaluation metrics</title>
      <p id="Par39">This subsection presents the proposed methodology’s performance in classifying the images into COVID-19, normal, and pneumonia. The proposed method is validated using the performance metrics of accuracy, sensitivity, specificity, precision, and F1-score, and receiver operating characteristic (ROC) analysis will be used for verifying the results from actual cases. The performance metrics equations are summarized in Table <xref rid="Tab4" ref-type="table">4</xref>.<table-wrap id="Tab4"><label>Table 4</label><caption><p>Performance measures for COVID-19</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Parameters</th><th>Formula</th></tr></thead><tbody><tr><td>Accuracy</td><td><inline-formula id="IEq1"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{\mathrm{TP}+\mathrm{TN}}{\mathrm{TP}+\mathrm{TN}+\mathrm{FP}+\mathrm{FN}} $$\end{document}</tex-math><mml:math id="M16" display="inline"><mml:mfrac><mml:mrow><mml:mi>TP</mml:mi><mml:mo>+</mml:mo><mml:mi>TN</mml:mi></mml:mrow><mml:mrow><mml:mi>TP</mml:mi><mml:mo>+</mml:mo><mml:mi>TN</mml:mi><mml:mo>+</mml:mo><mml:mi>FP</mml:mi><mml:mo>+</mml:mo><mml:mi>FN</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="10489_2020_1904_Article_IEq1.gif"/></alternatives></inline-formula></td></tr><tr><td>Sensitivity or recall</td><td><inline-formula id="IEq2"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}} $$\end{document}</tex-math><mml:math id="M18" display="inline"><mml:mfrac><mml:mi>TP</mml:mi><mml:mrow><mml:mi>TP</mml:mi><mml:mo>+</mml:mo><mml:mi>FN</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="10489_2020_1904_Article_IEq2.gif"/></alternatives></inline-formula></td></tr><tr><td>Specificity</td><td><inline-formula id="IEq3"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{\mathrm{TN}}{\mathrm{TN}+\mathrm{FP}} $$\end{document}</tex-math><mml:math id="M20" display="inline"><mml:mfrac><mml:mi>TN</mml:mi><mml:mrow><mml:mi>TN</mml:mi><mml:mo>+</mml:mo><mml:mi>FP</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="10489_2020_1904_Article_IEq3.gif"/></alternatives></inline-formula></td></tr><tr><td>Precision</td><td><inline-formula id="IEq4"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FP}} $$\end{document}</tex-math><mml:math id="M22" display="inline"><mml:mfrac><mml:mi>TP</mml:mi><mml:mrow><mml:mi>TP</mml:mi><mml:mo>+</mml:mo><mml:mi>FP</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="10489_2020_1904_Article_IEq4.gif"/></alternatives></inline-formula></td></tr><tr><td>F1 Score</td><td>2 <inline-formula id="IEq5"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{\mathrm{Precision}\ \mathrm{x}\ \mathrm{Recall}}{\mathrm{Precision}+\mathrm{Recall}} $$\end{document}</tex-math><mml:math id="M24" display="inline"><mml:mfrac><mml:mrow><mml:mtext>Precision</mml:mtext><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">x</mml:mi><mml:mspace width="0.25em"/><mml:mtext>Recall</mml:mtext></mml:mrow><mml:mrow><mml:mtext>Precision</mml:mtext><mml:mo>+</mml:mo><mml:mtext>Recall</mml:mtext></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="10489_2020_1904_Article_IEq5.gif"/></alternatives></inline-formula></td></tr><tr><td>True Positive Rate</td><td><inline-formula id="IEq6"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}} $$\end{document}</tex-math><mml:math id="M26" display="inline"><mml:mfrac><mml:mi>TP</mml:mi><mml:mrow><mml:mi>TP</mml:mi><mml:mo>+</mml:mo><mml:mi>FN</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="10489_2020_1904_Article_IEq6.gif"/></alternatives></inline-formula></td></tr><tr><td>False Positive Rate</td><td><inline-formula id="IEq7"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{\mathrm{FP}}{\mathrm{FP}+\mathrm{TN}} $$\end{document}</tex-math><mml:math id="M28" display="inline"><mml:mfrac><mml:mi>FP</mml:mi><mml:mrow><mml:mi>FP</mml:mi><mml:mo>+</mml:mo><mml:mi>TN</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="10489_2020_1904_Article_IEq7.gif"/></alternatives></inline-formula></td></tr></tbody></table></table-wrap>where TP indicate True Positive; TN indicate True Negative; FP indicate False Positive; FN indicate False Negative.</p>
      <p id="Par40">Accuracy evaluates the ability of the classifier to differentiate between COVID-19 and non–COVID-19 cases. A TP is where the model adequately predicts a positive case. Therefore, a TN is where the model viably predicts a negative instance. An FP is where the model erroneously predicts a positive case, and an FN is where the model mistakenly predicts a negative situation. Sensitivity gauges the proportion of correctly classified positive instances. Specificity is a measure of the correctly classified negative instances. Precision measures the fraction of relevant cases among the retrieved cases and is also known as the positive predictive value. The F1-score measures a test’s accuracy and is defined as the weighted harmonic mean of the test’s precision and recall. The receiver operating characteristic (ROC) curve is the characteristic representation of the classification method performance executed for all values. This curve is drawn as the relationship between 1-specificity and sensitivity.</p>
    </sec>
    <sec id="Sec14">
      <title>Experimental results</title>
      <p id="Par41">In this paper, CXR images are used to diagnose COVID-19 from normal and pneumonia-infected persons. X-ray imaging is a noninvasive technique for diagnosis and is also available in most hospitals. Using the trained proposed optimized CNN, testing of the images will take less than 5 s. The proposed network results are given in Table <xref rid="Tab5" ref-type="table">5</xref>, which shows that an accuracy of 97.78% is achieved.<table-wrap id="Tab5"><label>Table 5</label><caption><p>Experimental results of the proposed network model</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Accuracy</th><th>Sensitivity</th><th>Specificity</th><th>Precision</th><th>F1 Score</th></tr></thead><tbody><tr><td>97.78%</td><td>97.75%</td><td>96.25%</td><td>92.88%</td><td>95.25</td></tr></tbody></table></table-wrap></p>
      <sec id="Sec15">
        <title>Receiver operating characteristics (ROC) and confusion matrix</title>
        <p id="Par42">The ROC curve (in Fig. <xref rid="Fig5" ref-type="fig">5</xref>) and confusion matrix (in Fig. <xref rid="Fig6" ref-type="fig">6</xref>) were generated for the proposed method to analyze the classification effectiveness. Following application of the proposed methodology for 2700 chest X-ray images, 98.5% were classified as COVID-19, 97.4% were classified as normal images and 97.4% were classified as pneumonia images. The proposed method has high accuracy for all three cases. Hence, this OptCoNet can be used for automatic screening of COVID-19. This OptCoNet will substantially help radiologists by overcoming the burden on the healthcare system.<fig id="Fig5"><label>Fig. 5</label><caption><p>Generated ROC curves of the proposed GWO optimized CNN (Class 1-COVID-19, Class 2- Normal, Class 3-Pneumonia)</p></caption><graphic xlink:href="10489_2020_1904_Fig5_HTML" id="MO6"/></fig><fig id="Fig6"><label>Fig. 6</label><caption><p>Generated confusion matrix from the GWO optimized CNN</p></caption><graphic xlink:href="10489_2020_1904_Fig6_HTML" id="MO7"/></fig></p>
      </sec>
      <sec id="Sec16">
        <title>Training progress of the proposed OptCoNet</title>
        <p id="Par43">As the selection of hyperparameters in training the CNN plays an important role, this subsection presents the results of an experiment comparing the training progress and loss functions between the GWO-optimized and nonoptimized CNNs. The training progress of the optimized and nonoptimized CNNs is shown in Fig. <xref rid="Fig7" ref-type="fig">7a and b</xref>, respectively. The proposed OptCoNet achieves better accuracy and minimum loss in all epochs. The training parameters of the optimized GWO are described in Table <xref rid="Tab6" ref-type="table">6</xref>.<fig id="Fig7"><label>Fig. 7</label><caption><p>Training progress for the (a) GWO-optimized (a) Nonoptimized CNNs</p></caption><graphic xlink:href="10489_2020_1904_Fig7_HTML" id="MO8"/></fig><table-wrap id="Tab6"><label>Table 6</label><caption><p>Parameters of GWO</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Batch Size</th><th>Number search Agent’s</th><th>Dimensions</th><th>No. of optimizations iterations</th><th>Lower bound</th><th>Upper bound</th><th>Hyperparameter evaluation function</th></tr></thead><tbody><tr><td>32</td><td>30</td><td>4</td><td>30</td><td>[0.5, 0.01, 5, 1.0000e-04]</td><td>[1, 0.5, 15, 5.0000e-04]</td><td>Error rate = (FP + FN)/ (TP + TN + FP + FN)</td></tr></tbody></table></table-wrap></p>
      </sec>
    </sec>
    <sec id="Sec17">
      <title>Performance analysis</title>
      <p id="Par44">In this work, five standard optimization techniques other than GWO are used in the classification of images. These are Genetic Algorithm (GA) [<xref ref-type="bibr" rid="CR27">27</xref>], Pattern Search (PS) [<xref ref-type="bibr" rid="CR28">28</xref>], Particle Swarm Optimization (PSO) [<xref ref-type="bibr" rid="CR29">29</xref>], Simulated Annealing (SA) [<xref ref-type="bibr" rid="CR30">30</xref>], and Whale Optimization Algorithm (WOA) [<xref ref-type="bibr" rid="CR31">31</xref>]. For training the DL networks, 70% of the data are used; the remaining 30% of the data are used for testing. A comparison of all these networks in terms of the metrics accuracy, specificity, sensitivity, precision, and F1-score is given in Table <xref rid="Tab7" ref-type="table">7</xref>. Comparisons in terms of ROC curves and confusion matrixes are illustrated in Figs. <xref rid="Fig8" ref-type="fig">8</xref> and <xref rid="Fig9" ref-type="fig">9</xref>. The results of these comparisons indicates that the CNN optimized by GWO provides the best accuracy. Therefore, the proposed network can be reliably used to diagnose COVID-19 in real-time applications.<table-wrap id="Tab7"><label>Table 7</label><caption><p>Performance analysis with other optimization methods</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>Accuracy</th><th>Sensitivity</th><th>Specificity</th><th>Precision</th><th>F1 Score</th></tr></thead><tbody><tr><td>Nonoptimization</td><td>91.23</td><td>93.33</td><td>90.19</td><td>82.62</td><td>87.64</td></tr><tr><td>GA</td><td>96.05</td><td>98.61</td><td>95.83</td><td>92.21</td><td>96.39</td></tr><tr><td>Pattern search</td><td>95.31</td><td>99.13</td><td>93.15</td><td>87.91</td><td>93.40</td></tr><tr><td>SA</td><td>95.93</td><td>95.93</td><td>92.17</td><td>95.93</td><td>95.93</td></tr><tr><td>PSO</td><td>95.76</td><td>97.75</td><td>94.76</td><td>90.31</td><td>93.88</td></tr><tr><td>WOA</td><td>96.41</td><td>95.93</td><td>96.67</td><td>93.50</td><td>94.70</td></tr><tr><td>Proposed optimization</td><td>97.78</td><td>97.75</td><td>96.25</td><td>92.88</td><td>95.25</td></tr></tbody></table></table-wrap><fig id="Fig8"><label>Fig. 8</label><caption><p>ROC curves of the <bold>a</bold> GWO <bold>b</bold> GA <bold>c</bold> PS <bold>d</bold> PSO <bold>e</bold> SA and <bold>f</bold> WOA-optimized CNNs (Class 1-COVID-19, Class 2- Normal, Class 3-Pneumonia)</p></caption><graphic xlink:href="10489_2020_1904_Fig8_HTML" id="MO9"/></fig><fig id="Fig9"><label>Fig. 9</label><caption><p>Confusion matrixes of the <bold>a</bold> GWO <bold>b</bold> GA <bold>c</bold> Pattern search <bold>d</bold> PSO, <bold>e</bold> Stimulated annealing, and <bold>f</bold> WOA-optimized CNNs</p></caption><graphic xlink:href="10489_2020_1904_Fig9_HTML" id="MO10"/></fig></p>
    </sec>
    <sec id="Sec18">
      <title>Comparative analysis</title>
      <p id="Par45">This subsection presents a comparative analysis for the proposed methodology in classifying the images into COVID-19, normal, and pneumonia. Comparisons are made with other state-of-the-art methods using the aforementioned performance metrics. A discussion and limitations of the proposed work are given at the end of this subsection as well.</p>
      <sec id="Sec19">
        <title>Comparison with nonoptimized CNN</title>
        <p id="Par46">Figures <xref rid="Fig10" ref-type="fig">10</xref> and <xref rid="Fig11" ref-type="fig">11</xref> show the performance comparison in terms of the ROC curves and confusion matrixes between the optimized and nonoptimized CNNs. From Figs. <xref rid="Fig10" ref-type="fig">10</xref> and <xref rid="Fig11" ref-type="fig">11</xref>, the optimized CNN yields a better accuracy than the nonoptimized CNN.<fig id="Fig10"><label>Fig. 10</label><caption><p>Generated ROC curves for the <bold>a</bold> GWO-optimized CNN and <bold>b</bold> Nonoptimized CNNs (Class 1-COVID-19, Class 2- Normal, Class 3-Pneumonia)</p></caption><graphic xlink:href="10489_2020_1904_Fig10_HTML" id="MO11"/></fig><fig id="Fig11"><label>Fig. 11</label><caption><p>Confusion matrixes for the <bold>a</bold> GWO-optimized CNN and <bold>b</bold> Nonoptimized CNN</p></caption><graphic xlink:href="10489_2020_1904_Fig11_HTML" id="MO12"/></fig></p>
      </sec>
      <sec id="Sec20">
        <title>Comparison using cross-validation</title>
        <p id="Par47">Cross-validation (CV) is an important tool in predicting network performance by splitting the data k times into training and testing sets. In the present work, <italic>k</italic> is set to 10. Therefore, the X-ray data of each class are split into ten subsets. For every iteration of the CV, one subset from the <italic>k</italic> subsets is used for testing, and the remaining <italic>k-1</italic> subsets are used for training the network. Then, the error rate is calculated k times for the proposed optimized nonoptimized CNN. A comparison of the CV results is shown in Fig. <xref rid="Fig12" ref-type="fig">12</xref>.<fig id="Fig12"><label>Fig. 12</label><caption><p>Comparison with cross-validation</p></caption><graphic xlink:href="10489_2020_1904_Fig12_HTML" id="MO13"/></fig></p>
      </sec>
      <sec id="Sec21">
        <title>Comparison with grid search optimization</title>
        <p id="Par48">The conventional method for optimizing the hyperparameters of a neural network is the grid search strategy (GSS) [<xref ref-type="bibr" rid="CR32">32</xref>]. In the GSS, a subset of each hyperparameter space is manually specified and evaluated for a particular performance metric. The GSS evaluates the network performance by making a grid of all possible candidates within the hyperparameter space. The combination of hyperparameters that yields the best performance metric will be selected as the optimized hyperparameter values. The main drawback of the GSS is the exponential increase in the number of evaluations as a new parameter is added. Therefore, with only four hyperparameters with five candidates for each, the number of iterations is 758, making this optimization impractical.</p>
        <p id="Par49">On the other hand, GWO uses random values for the parameters and stops according to prespecified stopping criteria such as maximum time, number of parameters, or performance goal. In this way, it avoids overfitting the data and is practical for real-time problems with good performance results. The accuracy comparison of GWO with GSS is shown in Fig. <xref rid="Fig13" ref-type="fig">13</xref>.<fig id="Fig13"><label>Fig. 13</label><caption><p>Comparison of GWO with GSS</p></caption><graphic xlink:href="10489_2020_1904_Fig13_HTML" id="MO14"/></fig></p>
      </sec>
      <sec id="Sec22">
        <title>Comparison with different CNN architectures</title>
        <p id="Par50">An experiment was conducted to compare the proposed OptCoNet architecture with other nonoptimized CNN architectures, namely, network2, network3, network4, and network5. The proposed OptCoNet provides better accuracy than the other CNN architectures. The results and the developed architectures are found in Figs. <xref rid="Fig14" ref-type="fig">14</xref> and <xref rid="Fig15" ref-type="fig">15</xref>, respectively.<fig id="Fig14"><label>Fig. 14</label><caption><p>Comparison with different CNNs</p></caption><graphic xlink:href="10489_2020_1904_Fig14_HTML" id="MO15"/></fig><fig id="Fig15"><label>Fig. 15</label><caption><p>Architecture information of different CNNs <bold>a</bold> OptCoNet <bold>b</bold> Network2 <bold>c</bold> Network3 <bold>d</bold> Network4 <bold>e</bold> Network5</p></caption><graphic xlink:href="10489_2020_1904_Fig15_HTML" id="MO16"/></fig></p>
      </sec>
      <sec id="Sec23">
        <title>Comparisons of the results with state-of-the-art CNN methods</title>
        <p id="Par51">For further analysis of the results, the performance metrics, such as accuracy, sensitivity, specificity, precision, and F1-score, are also compared between the proposed CNN and pretrained DL networks. The acquired performance parameters for the proposed CNN are better than those of other state-of-the-art approaches, as shown in Table <xref rid="Tab8" ref-type="table">8</xref>. The advantage of the proposed method is that no settings are required while training the images. Consequently, no tuning is needed for different databases, as opposed to other model-based methodologies, as in [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR14">14</xref>]. In this way, the proposed approach can successfully deal with any concealed databases with no particular parameter tuning. The specialists in [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR32">32</xref>] accomplished a marginally poorer accuracy with their DLs compared to the proposed OptCoNet because of the absence of primary data in the images. Likewise, the proposed method is compared with recently published works in terms of the accuracy and F1-score. The proposed approach produced better results than other state-of-the-art techniques.<table-wrap id="Tab8"><label>Table 8</label><caption><p>Comparison of the results with state of the art CNN methods using X-ray images</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Reference</th><th>Task</th><th>No of images</th><th>Method</th><th>Accuracy</th><th>Sensitivity</th><th>Specificity</th><th>Precision</th><th>F1 Score</th></tr></thead><tbody><tr><td>Narin et al. [<xref ref-type="bibr" rid="CR8">8</xref>]</td><td>COVID-19</td><td>50</td><td>ResNet-50</td><td>98</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td/><td>Normal</td><td>50</td><td/><td/><td/><td/><td/><td/></tr><tr><td>Hemdan et al. [<xref ref-type="bibr" rid="CR9">9</xref>]</td><td>COVID-19(+)</td><td>90</td><td>COVIDX-Net</td><td>90</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td/><td>Normal</td><td>25</td><td/><td/><td/><td/><td/><td/></tr><tr><td>Khan et al. [<xref ref-type="bibr" rid="CR10">10</xref>]</td><td>COVID-19</td><td>284</td><td>CoroNet</td><td>89.5</td><td>97</td><td>100</td><td>–</td><td>–</td></tr><tr><td>Maghdid et al. [<xref ref-type="bibr" rid="CR12">12</xref>]</td><td>COVID-19</td><td>85</td><td>AlexNet</td><td>94.1</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td>Razzak et al. [<xref ref-type="bibr" rid="CR14">14</xref>]</td><td>COVID-19</td><td>200</td><td>DL</td><td>98.75</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td>Abbas et al. [<xref ref-type="bibr" rid="CR15">15</xref>]</td><td>COVID-19</td><td>105</td><td>DCNN</td><td>95.12</td><td>97.91</td><td>91.87</td><td>–</td><td>93.36</td></tr><tr><td>Afshar et al. [<xref ref-type="bibr" rid="CR16">16</xref>]</td><td>COVID-19</td><td>1668</td><td>COVID-CAPS</td><td>95.7</td><td>90</td><td>95.8</td><td>–</td><td>–</td></tr><tr><td>Farook et al. [<xref ref-type="bibr" rid="CR19">19</xref>]</td><td>COVID-19</td><td>68</td><td>COVID-Net</td><td>96.23</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td>Ghoshal et al. [<xref ref-type="bibr" rid="CR33">33</xref>]</td><td>COVID-19</td><td>70</td><td>CNN</td><td>92.9</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td>Wang et al. [<xref ref-type="bibr" rid="CR34">34</xref>]</td><td>COVID-19</td><td>45</td><td>CNN</td><td>83.5</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td/><td>Bac.Pneu*</td><td>931</td><td/><td/><td/><td/><td/><td/></tr><tr><td/><td>Vir.Pneu#</td><td>660</td><td/><td/><td/><td/><td/><td/></tr><tr><td>Zhang et al. [<xref ref-type="bibr" rid="CR35">35</xref>]</td><td>COVID-19</td><td>70</td><td>ResNet</td><td>–</td><td>96.6</td><td>70.7</td><td>–</td><td>–</td></tr><tr><td>Ioannis et al. [<xref ref-type="bibr" rid="CR36">36</xref>]</td><td>COVID-19</td><td>224</td><td>VGG-19</td><td>93.48</td><td/><td/><td/><td/></tr><tr><td/><td>Pneumonia</td><td>700</td><td/><td/><td/><td/><td/><td/></tr><tr><td/><td>Normal</td><td>504</td><td/><td/><td/><td/><td/><td/></tr><tr><td>Sethy et al. [<xref ref-type="bibr" rid="CR37">37</xref>]</td><td>COVID-19 (+)</td><td>25</td><td>ResNet-50 + SVM</td><td>95.38</td><td/><td/><td/><td/></tr><tr><td/><td>COVID-19(−)</td><td>25</td><td/><td/><td/><td/><td/><td/></tr><tr><td>Ozturk et al. [<xref ref-type="bibr" rid="CR38">38</xref>]</td><td>COVID-19(+)</td><td>125</td><td>DarkCovidNet</td><td>98.8</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td/><td>No findings</td><td>500</td><td/><td/><td/><td/><td/><td/></tr><tr><td/><td>COVID-19(+)</td><td>125</td><td/><td>87.02</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td/><td>Pneumonia</td><td>500</td><td/><td/><td/><td/><td/><td/></tr><tr><td/><td>No findings</td><td>500</td><td/><td/><td/><td/><td/><td/></tr><tr><td>Proposed</td><td>COVID-19</td><td>1000</td><td>OptCoNet</td><td>97.78</td><td>97.75</td><td>96.25</td><td>92.88</td><td>95.25</td></tr><tr><td/><td>Normal</td><td>900</td><td/><td/><td/><td/><td/><td/></tr><tr><td/><td>Pneumonia</td><td>900</td><td/><td/><td/><td/><td/><td/></tr></tbody></table><table-wrap-foot><p>*Bacterial Pneumonia, # Virus Pneumonia</p></table-wrap-foot></table-wrap></p>
      </sec>
    </sec>
    <sec id="Sec24">
      <title>Discussion</title>
      <p id="Par52">Given how COVID-19 has infected millions of people worldwide, there is a need for quick and accurate diagnosis of the disease. The proposed network can discriminate COVID-19 patients from normal and pneumonia patients using X-ray images. X-ray image diagnosis is a noninvasive, cost-effective technique that is available in almost all hospitals. The proposed optimized CNN network was trained using 1890 images and then tested on 810 images. It provides an accuracy of 97.78%, which is the best accuracy achieved on X-ray images to date with more number of images. The optimized CNN was compared with state-of-the-art optimization techniques and four other CNN to show its efficiency. The advantages of the proposed optimized CNN include its ability to directly give diagnostics results from X-ray images without the need of a radiologist. In this way, it can help clinicians test patients with accurate results quickly. There is no need to preprocess the test images; the data augmentation step will resize all the test images to 224 × 224 pixels. Finally, the CNN hyperparameters are optimized using the GWO algorithm on X-ray images to avoid the problem of overfitting and mode collapse and give the best performance results.</p>
      <p id="Par53">Similar to any other new methods, the proposed method also has some limitations. One of the limitations is that the proposed OptCoNet does not encode the position orientation of the input images, so some preprocessing steps are required. In addition, OptCoNet is not spatially invariant to the input images. Finally, GWO has a number of controlling parameters that need to be carefully chosen if applied to problems with an extremely large number of features and parameters.</p>
    </sec>
  </sec>
  <sec id="Sec25">
    <title>Conclusions</title>
    <p id="Par54">This work proposes OptCoNet, which depends on an optimized CNN structure for the automatic diagnosis of COVID-19, normal, and pneumonia patients from X-ray images. This system comprises a number of convolutional, batch normalization, and pooling layers. The acquired outcomes show that the OptCoNet performed well, even with a low number of trainable parameters. The proposed OptCoNet produced better performance metrics such as accuracy, sensitivity, specificity, precision, and F1-score than current state-of-the-art methods. As increasingly more COVID-19 cases are being recognized all around the globe, larger datasets are being created. Future studies will focus on advancing and altering the architecture of the OptCoNet and fusing newly accessible datasets to test the network.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <p>The authors acknowledge the authors of Chest imaging, COVID-19, Covid-chestxray, Figure 1 COVID-19 Chest X-ray, Provincial peoples hospital and Kaggle datasets for making publicly online. The authors also acknowledge the medical imaging laboratory of Computer Science and Engineering, National Institute of Technology Silchar, Assam for providing the necessary facilities to carry out this work.</p>
  </ack>
  <notes notes-type="ethics">
    <title>Compliance with ethical standards</title>
    <notes id="FPar5" notes-type="COI-statement">
      <title>Conflict of interest</title>
      <p id="Par55">The authors declare no conflict of interest.</p>
    </notes>
    <notes id="FPar6">
      <title>Ethical standard</title>
      <p id="Par56">This article does not contain any studies with human participants performed by any of the authors. This article does not contain any studies with animals performed by any of the authors. This article does not contain any studies with human participants or animals performed by any of the authors.</p>
    </notes>
    <notes id="FPar7">
      <title>Informed consent</title>
      <p id="Par57">There is no individual participant included in the study.</p>
    </notes>
    <notes id="FPar8">
      <title>Code availability</title>
      <p id="Par58">The source code of the OptCoNet are publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/biomedicallabecenitsilchar/optconet">https://github.com/biomedicallabecenitsilchar/optconet</ext-link></p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <mixed-citation publication-type="other">Calvo C, López-Hortelano MG, De Carlos Vicente JC, Martínez JLV, De Trabajo de la Asociación G (2020) Recommendations on the clinical management of the COVID-19 infection by the «new coronavirus» SARS-CoV2. Spanish Paediatric Association working group. An Pediatría (English Edition) 92(4):241.e1–241.e11</mixed-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <mixed-citation publication-type="other">COVID-19 Coronavirus Pandemic (20120, February). Worldometers, Retrieved July 23, 2020, from <ext-link ext-link-type="uri" xlink:href="https://www.worldometers.info/coronavirus/?utm_campaign=homeAdvegas1?">https://www.worldometers.info/coronavirus/?utm_campaign=homeAdvegas1?</ext-link></mixed-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <mixed-citation publication-type="other">Butt C, Gill J, Chun D, Babu BA (2020) Deep learning system to screen coronavirus disease 2019 pneumonia. Appl Intell p.1. 10.1007/s10489-020-01714-3</mixed-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Lan</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Clinical and CT imaging features of the COVID-19 pneumonia: focus on pregnant women and children</article-title>
        <source>J Inf Secur</source>
        <year>2020</year>
        <volume>80</volume>
        <fpage>e7</fpage>
        <lpage>e13</lpage>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bai</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Jin</surname>
            <given-names>DY</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Presumed asymptomatic carrier transmission of COVID-19</article-title>
        <source>JAMA</source>
        <year>2020</year>
        <volume>323</volume>
        <issue>14</issue>
        <fpage>1406</fpage>
        <lpage>1407</lpage>
        <pub-id pub-id-type="doi">10.1001/jama.2020.2565</pub-id>
        <pub-id pub-id-type="pmid">32083643</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sohrabi</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Alsafi</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>O’Neill</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Khan</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kerwan</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Al-Jabir</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Agha</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>World Health Organization declares global emergency: a review of the 2019 novel coronavirus (COVID-19)</article-title>
        <source>Int J Surg</source>
        <year>2020</year>
        <volume>76</volume>
        <fpage>71</fpage>
        <lpage>76</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ijsu.2020.02.034</pub-id>
        <pub-id pub-id-type="pmid">32112977</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <mixed-citation publication-type="other">Kang H, Xia L, Yan F, Wan Z, Shi F, Yuan H, Jiang H, Wu D, Sui H, Zhang C, Shen D (2020) Diagnosis of coronavirus disease 2019 (COVID-19) with structured latent multi-view representation learning. IEEE transactions on medical Imaging. Preprint may 5 2020</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <mixed-citation publication-type="other">Narin A, Kaya C, Pamuk Z (2020) Automatic detection of coronavirus disease (COVID-19) using x-ray images and deep convolutional neural networks. arXiv preprint arXiv:2003.10849</mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Hemdan EED, Shouman MA, Karar ME (2020) COVIDX-NET: a framework of deep learning classifiers to diagnose COVID-19 in x-ray images. arXiv preprint arXiv:2003.11055</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">Khan AI, Shah JL, Bhat M (2020) CORONET: a deep neural network for detection and diagnosis of COVID-19 from chest X-ray images. arXiv preprint arXiv:2004.04931</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Li L, Qin L, Xu Z, Yin Y, Wang X, Kong B, Cao K (2020) Artificial intelligence distinguishes covid-19 from community acquired pneumonia on chest CT. Radiology, 200905</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Maghdid HS, Asaad AT, Ghafoor K, Sadiq AS, Khan MK (2020) Diagnosing COVID-19 pneumonia from X-ray and CT images using deep learning and transfer learning algorithms. arXiv preprint arXiv:2004.00038</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">Hassanien AE, Mahdy LN, Ezzat KA, Elmousalami HH, Ella HA (2020) Automatic X-ray COVID-19 lung image classification system based on multi-level Thresholding and support vector machine. medRxiv</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Razzak I, Naz S, Rehman A, Khan A, Zaib A (2020) Improving coronavirus (COVID-19) diagnosis using deep transfer learning. medRxiv</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Abbas A, Abdelsamea MM, Gaber MM (2020) Classification of COVID-19 in chest X-ray images using DeTraC deep convolutional neural network. arXiv preprint arXiv:2003.13815</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Afshar P., Heidarian, S., Naderkhani, F., Oikonomou, A., Plataniotis, K. N., &amp; Mohammadi, A. (2020). COVID-CAPS: a capsule network-based framework for identification of COVID-19 cases from X-ray images. arXiv preprint arXiv:2004.02696</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Apostolopoulos</surname>
            <given-names>ID</given-names>
          </name>
          <name>
            <surname>Mpesiana</surname>
            <given-names>TA</given-names>
          </name>
        </person-group>
        <article-title>Covid-19: automatic detection from x-ray images utilizing transfer learning with convolutional neural networks</article-title>
        <source>Australas Phys Eng Sci Med</source>
        <year>2020</year>
        <volume>43</volume>
        <fpage>635</fpage>
        <lpage>640</lpage>
        <pub-id pub-id-type="doi">10.1007/s13246-020-00865-4</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Apostolopoulos</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Aznaouridis</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Tzani</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Extracting possibly representative COVID-19 biomarkers from X-ray images with deep learning approach and image data related to pulmonary diseases</article-title>
        <source>J Med Biol Eng</source>
        <year>2020</year>
        <volume>14</volume>
        <fpage>1</fpage>
        <lpage>8</lpage>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Farooq M, Hafeez A (2020) COVID-ResNet: a deep learning framework for screening of COVID19 from radiographs. arXiv preprint arXiv:2003.14395</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mirjalili</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Mirjalili</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Lewis</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Grey wolf optimizer</article-title>
        <source>Adv Eng Softw</source>
        <year>2014</year>
        <volume>69</volume>
        <fpage>46</fpage>
        <lpage>61</lpage>
        <pub-id pub-id-type="doi">10.1016/j.advengsoft.2013.12.007</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Chest Imaging (2020, March). This is a thread of COVID-19 CXR (all SARS-CoV-2 PCR+) from my hospital (Spain), version 1. Retrieved may 06, 2020, from <ext-link ext-link-type="uri" xlink:href="https://twitter.com/ChestImaging/status/1243928581983670272">https://twitter.com/ChestImaging/status/1243928581983670272</ext-link></mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">SIRM COVID-19 Database (2020, May) Italian Society of Medical and Interventional Radiology COVID-19 dataset, Version 1. Retrieved may 05, 2020, from <ext-link ext-link-type="uri" xlink:href="https://www.sirm.org/category/senza-categoria/covid-19/">https://www.sirm.org/category/senza-categoria/covid-19/</ext-link></mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Cohen, J. P., Morrison, P., Dao, L., Roth, K., Duong, T. Q., &amp; Ghassemi, M. (2020). COVID-19 image data collection: prospective predictions are the future. arXiv preprint arXiv:2006.11988</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">Wang L, Wong A, Lin ZQ, Lee J, McInnis P, Chung A, Ross M, van Berlo B, Ebadi A. “FIgure 1 COVID-19 Chest X-ray Dataset Initiative”, version 1, Retrieved may 05, 2020, from <ext-link ext-link-type="uri" xlink:href="https://github.com/agchung/Figure1-COVID-chestxray-dataset">https://github.com/agchung/Figure1-COVID-chestxray-dataset</ext-link></mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kong</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Agarwal</surname>
            <given-names>PP</given-names>
          </name>
        </person-group>
        <article-title>Chest imaging appearance of COVID-19 infection</article-title>
        <source>Radiology</source>
        <year>2020</year>
        <volume>2</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>22</lpage>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Mooney, P. (2018, March). Chest X-ray images (pneumonia), version 2. Retrieved May 05, 2020, from <ext-link ext-link-type="uri" xlink:href="https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia/metadata">https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia/metadata</ext-link></mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Holland</surname>
            <given-names>JH</given-names>
          </name>
        </person-group>
        <article-title>Genetic algorithms</article-title>
        <source>Sci Am</source>
        <year>1992</year>
        <volume>267</volume>
        <issue>1</issue>
        <fpage>66</fpage>
        <lpage>72</lpage>
        <pub-id pub-id-type="doi">10.1038/scientificamerican0792-66</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hooke</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Jeeves</surname>
            <given-names>TA</given-names>
          </name>
        </person-group>
        <article-title>Direct search solution of numerical and statistical problems</article-title>
        <source>J ACM</source>
        <year>1961</year>
        <volume>8</volume>
        <issue>2</issue>
        <fpage>212</fpage>
        <lpage>229</lpage>
        <pub-id pub-id-type="doi">10.1145/321062.321069</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Kennedy J, Eberhart R (1995) Particle swarm optimization. In: Proceedings of the IEEE international conference on neural networks 1942–1948</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Van Laarhoven</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Aarts</surname>
            <given-names>EH</given-names>
          </name>
        </person-group>
        <source>Simulated annealing. In simulated annealing: theory and applications</source>
        <year>1987</year>
        <publisher-loc>Dordrecht</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>7</fpage>
        <lpage>15</lpage>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mirjalili</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lewis</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>The whale optimization algorithm</article-title>
        <source>Adv Eng Softw</source>
        <year>2016</year>
        <volume>95</volume>
        <fpage>51</fpage>
        <lpage>67</lpage>
        <pub-id pub-id-type="doi">10.1016/j.advengsoft.2016.01.008</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lerman</surname>
            <given-names>PM</given-names>
          </name>
        </person-group>
        <article-title>Fitting segmented regression models by grid search</article-title>
        <source>J R Stat Soc: Ser C: Appl Stat</source>
        <year>1980</year>
        <volume>29</volume>
        <issue>1</issue>
        <fpage>77</fpage>
        <lpage>84</lpage>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <mixed-citation publication-type="other">Ghoshal B, Tucker A (2020) Estimating uncertainty and interpretability in deep learning for coronavirus (COVID-19) detection. arXiv preprint arXiv:2003.10769</mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <mixed-citation publication-type="other">Wang L, Wong A (2020) COVID-net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest radiography images. arXiv preprint arXiv:2003.09871</mixed-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">Zheng C, Deng X, Fu Q, Zhou Q, Feng J, Ma H, Wang X (2020) Deep learning-based detection for COVID-19 from chest CT using weak label. medRxiv</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Apostolopoulos ID, Tzani B (2020) COVID-19: Automatic Detection from X-Ray Images Utilizing Transfer Learning with Convolutional Neural Networks, arXiv:2003.11617</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Sethy PK, Behera SK (2020) Detection of coronavirus disease (COVID-19) based on deep features. Preprints, 2020030300, p.2020</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ozturk</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Talo</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Yildirim</surname>
            <given-names>EA</given-names>
          </name>
          <name>
            <surname>Baloglu</surname>
            <given-names>UB</given-names>
          </name>
          <name>
            <surname>Yildirim</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Acharya</surname>
            <given-names>UR</given-names>
          </name>
        </person-group>
        <article-title>Automated detection of COVID-19 cases using deep neural networks with X-ray images</article-title>
        <source>Comput Biol Med</source>
        <year>2020</year>
        <volume>121</volume>
        <fpage>1</fpage>
        <lpage>11</lpage>
        <pub-id pub-id-type="doi">10.1016/j.compbiomed.2020.103792</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
