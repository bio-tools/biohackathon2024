<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8097755</article-id>
    <article-id pub-id-type="pmid">33051674</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa881</article-id>
    <article-id pub-id-type="publisher-id">btaa881</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Systems Biology</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Learning graph representations of biochemical networks and its application to enzymatic link prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-4260-282X</contrib-id>
        <name>
          <surname>Jiang</surname>
          <given-names>Julie</given-names>
        </name>
        <aff><institution>Department of Computer Science, Tufts University</institution>, Medford 02155, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Liu</surname>
          <given-names>Li-Ping</given-names>
        </name>
        <xref rid="btaa881-cor1" ref-type="corresp"/>
        <aff><institution>Department of Computer Science, Tufts University</institution>, Medford 02155, <country country="US">USA</country></aff>
        <!--liping.liu@tufts.edu-->
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Hassoun</surname>
          <given-names>Soha</given-names>
        </name>
        <xref rid="btaa881-cor1" ref-type="corresp"/>
        <aff><institution>Department of Computer Science, Tufts University</institution>, Medford 02155, <country country="US">USA</country></aff>
        <aff><institution>Department of Chemical and Biological Engineering, Tufts University</institution>, Medford 02155, <country country="US">USA</country></aff>
        <!--soha.hassoun@tufts.edu-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btaa881-cor1">To whom correspondence should be addressed. <email>liping.liu@tufts.edu</email> or <email>soha.hassoun@tufts.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>15</day>
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-10-14">
      <day>14</day>
      <month>10</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>14</day>
      <month>10</month>
      <year>2020</year>
    </pub-date>
    <volume>37</volume>
    <issue>6</issue>
    <fpage>793</fpage>
    <lpage>799</lpage>
    <history>
      <date date-type="received">
        <day>25</day>
        <month>2</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>01</day>
        <month>8</month>
        <year>2020</year>
      </date>
      <date date-type="editorial-decision">
        <day>28</day>
        <month>9</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>9</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa881.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>The complete characterization of enzymatic activities between molecules remains incomplete, hindering biological engineering and limiting biological discovery. We develop in this work a technique, enzymatic link prediction (ELP), for predicting the likelihood of an enzymatic transformation between two molecules. ELP models enzymatic reactions cataloged in the KEGG database as a graph. ELP is innovative over prior works in using graph embedding to learn molecular representations that capture not only molecular and enzymatic attributes but also graph connectivity.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We explore transductive (test nodes included in the training graph) and inductive (test nodes not part of the training graph) learning models. We show that ELP achieves high AUC when learning node embeddings using both graph connectivity and node attributes. Further, we show that graph embedding improves link prediction by 30% in area under curve over fingerprint-based similarity approaches and by 8% over support vector machines. We compare ELP against rule-based methods. We also evaluate ELP for predicting links in pathway maps and for reconstruction of edges in reaction networks of four common gut microbiota phyla: actinobacteria, bacteroidetes, firmicutes and proteobacteria. To emphasize the importance of graph embedding in the context of biochemical networks, we illustrate how graph embedding can guide visualization.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The code and datasets are available through <ext-link xlink:href="https://github.com/HassounLab/ELP" ext-link-type="uri">https://github.com/HassounLab/ELP</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Science Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>1909536</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Science Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>1850358</award-id>
        <award-id>1908617</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R01GM132391</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Characterizing enzymes through sequencing, annotation and homology has enabled the creation of complex system models that have played a critical role in advancing many biomedical and bioengineering applications. Insufficient characterization of enzymes, however, fundamentally limits our understanding of metabolism and creates knowledge gaps across many applications. For example, while nearly 300 β-glucuronidases (gut-bacterial enzymes that hydrolyze glucuronate-containing polysaccharides such as heparin and hyaluronate as well as small-molecule drug glucuronides) have been cataloged, functional information is available for only a small fraction (&lt;10%) (<xref rid="btaa881-B22" ref-type="bibr">Pellock <italic toggle="yes">et al.</italic>, 2019</xref>), thus limiting our ability to analyze host–microbiota interactions. Importantly, most enzymes if not all are promiscuous, acting on substrates other than the enzymes’ natural substrates (<xref rid="btaa881-B7" ref-type="bibr">Hult and Berglund, 2007</xref>; <xref rid="btaa881-B9" ref-type="bibr">Khersonsky and Tawfik, 2010</xref>). At least one-third of protein superfamilies are functionally diverse, each superfamily catalyzing multiple reactions (<xref rid="btaa881-B1" ref-type="bibr">Almonacid and Babbitt, 2011</xref>). Despite progress in functional annotation, the complete characterization or curation of enzyme function and the reactions they catalyze remains elusive. Computational prediction of enzymatic transformations promises to complement existing databases and provide new opportunities for biological discovery.</p>
    <p>A common predictor of enzyme–compound interaction is compound and/or enzyme similarity to those within known enzymatic reactions. In biological engineering, molecular similarity between a query molecule and native substrates that are known to be catalyzed by the enzyme inform putative enzymatic transformations (<xref rid="btaa881-B24" ref-type="bibr">Pertusi <italic toggle="yes">et al.</italic>, 2015</xref>). A high similarity score indicates a likely transformation. In drug–protein interaction analysis, molecular similarity and machine learning are utilized to predict the likelihood of interactions (<xref rid="btaa881-B17" ref-type="bibr">Kurgan and Wang, 2018</xref>). Some techniques quantify similarity between reactions. EC-BLAST quantifies similarities between enzymatic reactions based on the similarities of bond changes, reaction centers and substrates and products (<xref rid="btaa881-B25" ref-type="bibr">Rahman <italic toggle="yes">et al.</italic>, 2014</xref>). SimCAL computes reaction similarity at different levels such as the transformation region between substrates and products, or the similarity across all products-substrates within a reaction (<xref rid="btaa881-B30" ref-type="bibr">Sivakumar <italic toggle="yes">et al.</italic>, 2018</xref>).</p>
    <p>In addition to predicting aspects of enzymatic reaction similarities, there are rule-based methods to predict products of promiscuous reactions. Typically, such rules specify how a substrate molecule can be transformed to a product molecule. The rules can be hand curated based on common biotransformations (<xref rid="btaa881-B18" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2004</xref>; <xref rid="btaa881-B21" ref-type="bibr">Morreel <italic toggle="yes">et al.</italic>, 2014</xref>), extracted from existing sources, e.g. the KEGG RPAIR (<xref rid="btaa881-B11" ref-type="bibr">Kotera <italic toggle="yes">et al.</italic>, 2004</xref>) RCLASS database (<xref rid="btaa881-B16" ref-type="bibr">Kotera <italic toggle="yes">et al.</italic>, 2014b</xref>) or automatically extracted from reactions (<xref rid="btaa881-B29" ref-type="bibr">Sivakumar <italic toggle="yes">et al.</italic>, 2016</xref>). As each rule is associated with a particular set of reactions, the presence of a rule directly correlates with the ability of predicting its associated enzymatic transformations.</p>
    <p>In this article, we address the problem of predicting enzymatic transformations (links) between two molecules, a problem known as ‘link prediction’, where a link is a connection between two nodes within a network graph (<xref rid="btaa881-B19" ref-type="bibr">Liben-Nowell and Kleinberg, 2007</xref>). Earlier work used the Tanimoto coefficient to score the maximum common substructure (MCS) between two molecules (<xref rid="btaa881-B12" ref-type="bibr">Kotera <italic toggle="yes">et al.</italic>, 2008</xref>). Citing the computational inefficiency of MCS, an NP-hard problem, <xref rid="btaa881-B14" ref-type="bibr">Kotera <italic toggle="yes">et al.</italic> (2013b</xref>, <xref rid="btaa881-B15" ref-type="bibr">2014a</xref>) utilized support vector machines (SVMs) to predict such links. Compound pairs in the KEGG RPAIR data were used as positive examples, while unknown interactions between compound pairs were utilized as negative examples. Feature vectors were constructed using either common or differential features based on various fingerprints. The use of SVMs along with additional substructures in the format of KCF-S [KEGG Chemical Function (KCF)-and-Substructures (<xref rid="btaa881-B13" ref-type="bibr">Kotera <italic toggle="yes">et al.</italic>, 2013a</xref>)] and of aligned molecular graphs (<xref rid="btaa881-B33" ref-type="bibr">Yamanishi <italic toggle="yes">et al.</italic>, 2015</xref>) further improved link prediction. <xref rid="btaa881-B31" ref-type="bibr">Tabei <italic toggle="yes">et al.</italic> (2016)</xref> utilized joint-learning classifiers for link prediction and for predicting enzyme orthologs that could catalyze predicted transformations between compound pairs.</p>
    <p>We present in this article a novel technique, enzymatic link prediction (ELP), for predicting enzymatic transformations between two molecules. ELP advances over the state of the art in two ways. First, ELP maps known enzymatic reactions already cataloged in databases [here, the KEGG database (<xref rid="btaa881-B8" ref-type="bibr">Kanehisa and Goto, 2000</xref>)] to a graph structure, where compounds are represented as graph nodes while reactions are represented as graph edges. While snippets of such graph structures have been previously utilized as training data for multi-step pathway reconstruction (<xref rid="btaa881-B15" ref-type="bibr">Kotera <italic toggle="yes">et al.</italic>, 2014a</xref>) and exploited during synthesis pathway construction (<xref rid="btaa881-B34" ref-type="bibr">Yousofshahi et al., 2011</xref>), ELP utilizes all graph connectivity when predicting enzymatic links. Second, ELP uses graph embeddings (<xref rid="btaa881-B2" ref-type="bibr">Cai <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btaa881-B5" ref-type="bibr">Goyal and Ferrara, 2018</xref>) to learn molecular representations that reflect not only molecular structural properties but also relationships with other molecules in the network graph. Such embeddings have proven effective in predicting missing information, identifying spurious interactions, predicting links appearing in future evolving network, and analyzing biomedical networks (<xref rid="btaa881-B2" ref-type="bibr">Cai <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btaa881-B5" ref-type="bibr">Goyal and Ferrara, 2018</xref>; <xref rid="btaa881-B36" ref-type="bibr">Yue <italic toggle="yes">et al.</italic>, 2019</xref>). We analyze both transductive (test nodes included in the training graph) and inductive (test nodes not part of the training graph) models. We evaluate ELP when learning node embeddings using both graph connectivity and node attributes and compare to similarity-based approaches.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Constructing graph from the KEGG database</title>
      <p>While proteins can interact with other proteins, the focus of this article is on enzymatic transformations between small molecules (those with masses less than 1000 Da). Such transformations form the backbone of metabolic networks. The KEGG database catalogs such enzymatic reactions and can be used to construct a data graph. Molecules in the KEGG database are represented as nodes. Each substrate-product pair within a reaction is modeled as an edge in the graph. As most KEGG reactions are reversible, we construct a non-directional graph. Biochemical networks have cofactor molecules (e.g. NADP, H<sub>2</sub>O) that participate in many reactions, forming high-connectivity hub nodes within the graph (<xref rid="btaa881-B26" ref-type="bibr">Ravasz <italic toggle="yes">et al.</italic>, 2002</xref>). As we aim to predict connectivity between non-cofactor metabolites, such high-connectivity nodes and their edges are excluded from the graph.</p>
      <p>Nodes are assigned molecular fingerprints as attributes. The fingerprints are encoded as binary vectors of fixed length <italic toggle="yes">K</italic>. We select two fingerprints that reflect the presence or absence of pre-defined structural molecular fragments: the MACCS fingerprint with <italic toggle="yes">K </italic>=<italic toggle="yes"> </italic>166 structural keys (<xref rid="btaa881-B4" ref-type="bibr">Durant <italic toggle="yes">et al.</italic>, 2002</xref>), and the PubChem fingerprint with <italic toggle="yes">K </italic>=<italic toggle="yes"> </italic>881 structural keys (<xref rid="btaa881-B10" ref-type="bibr">Kim <italic toggle="yes">et al.</italic>, 2016</xref>).</p>
      <p>Enzymatic reaction data are assigned as edge attributes. Each edge is assigned the enzyme commission (EC) number that catalyzes the associated chemical reaction. EC numbers are represented as four numbers separated by periods (e.g. <sc>l</sc>-lactate dehydrogenase is assigned EC number 1.1.1.27). Each edge is also assigned an RCLASS label (<xref rid="btaa881-B16" ref-type="bibr">Kotera <italic toggle="yes">et al.</italic>, 2014b</xref>), five digit label. Each such label is associated with a group of reactions that share the same localized structural change between a substrate and a product (e.g. the addition or removal of a hydroxyl group). Although a reaction may be associated with one or more RC labels, each substrate-product pair is associated with only one RC label. If a reaction has no label, we assign it a null label. Thus, each edge in the graph is associated with an EC label and a RC label. A graph <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> therefore consists of a set of vertices <italic toggle="yes">V</italic> and a set of edges <italic toggle="yes">E</italic>. Every node <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:math></inline-formula> represents a molecule and every edge <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:math></inline-formula> for some <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:math></inline-formula> represents an enzymatic reaction connecting two molecules <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic>.</p>
    </sec>
    <sec>
      <title>2.2 The ELP method</title>
      <p>ELP has two steps (<xref rid="btaa881-F1" ref-type="fig">Fig. 1</xref>): (A) learning embedding vectors of graph nodes, and (B) predicting interaction between a pair of nodes from their embedding vectors. Embeddings are low-dimensional vector representations of each node. An embedding is characteristically similar to molecular fingerprint in the sense that they both quantitatively describe the molecules. Unlike fingerprints, however, entries in an embedding vector cannot be directly interpreted, but rather can be decoded by a suitable learning algorithm. Importantly, embeddings capture the inherent structure of the graph as well as attributes of the nodes and edges in the graph, which allow them to be used as input for downstream tasks such as link prediction. For the first step, we use the embedding propagation (EP) algorithm (<xref rid="btaa881-B3" ref-type="bibr">García-Durán and Niepert, 2017</xref>). EP was selected because it almost consistently outperformed several other methods in the presence of node attributes on several datasets. Further, EP has the advantage of fewer parameters and hyperparameters when compared to other methods (e.g. <xref rid="btaa881-B6" ref-type="bibr">Grover and Leskovec, 2016</xref>; <xref rid="btaa881-B23" ref-type="bibr">Perozzi <italic toggle="yes">et al.</italic>, 2014</xref>; <xref rid="btaa881-B32" ref-type="bibr">Tang <italic toggle="yes">et al.</italic>, 2015</xref>). For the second step, we train a neural network that takes pairs of learned embedding vectors as input and predicts the connectivity of two molecules.</p>
      <fig position="float" id="btaa881-F1">
        <label>Fig. 1</label>
        <caption>
          <p>ELP Overview. (<bold>A</bold>) Molecular representations are learned using graph embedding. (<bold>B</bold>) Learned embeddings are used to predict links</p>
        </caption>
        <graphic xlink:href="btaa881f1" position="float"/>
      </fig>
      <sec>
        <title>2.2.1 Connectivity-based learned embeddings</title>
        <p>The simplest form of EP is to learn a set of node embedding vectors <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">U</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup><mml:mo>:</mml:mo><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">d</italic> is the embedding size. Embeddings are randomly initialized prior to training. Node embeddings are learned via an iterative process, by propagating forward (representations of nodes) and backward (gradients) messages between neighboring nodes. The iterative process repeats until a convergence threshold is reached. Suppose <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mo>:</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>E</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> is the set of neighboring nodes of node <italic toggle="yes">i</italic>. The model aims to reconstruct embeddings <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> from the embeddings of <italic toggle="yes">i’</italic>s neighbors. The reconstructed node embedding <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for node <italic toggle="yes">i</italic> is:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi><mml:mo stretchy="true">˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p>
        <p>The learning objective of EP is to maximize the similarly between <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Instead of maximizing the absolute values of inner products for all such nodes, EP maximizes their values in a relative sense: the reconstruction should be more similar to the corresponding embedding vector than any other embedding vectors. The error in reconstruction is therefore minimized through a margin-based ranking loss (<xref rid="btaa881-B3" ref-type="bibr">García-Durán and Niepert, 2017</xref>):
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">L</mml:mi><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo>γ</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mo>γ</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> is a chosen margin hyperparameter. The objective is optimized by stochastic gradient descent. However, summing over all nodes as indicated by the inner sum is very expensive. For performance, we randomly select one node as the negative example for each real node in every iteration to compute an estimation of <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mi>ℓ</mml:mi></mml:math></inline-formula> and its gradient, as was done in <xref rid="btaa881-B3" ref-type="bibr">García-Durán and Niepert (2017)</xref>.</p>
      </sec>
      <sec>
        <title>2.2.2 Attribute-based learned embeddings</title>
        <p>To incorporate information from edge attributes, EP learns embedding vectors <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Z</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup><mml:mo>:</mml:mo><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> for the <italic toggle="yes">C</italic> reaction labels. The reconstructed node embedding <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for node <italic toggle="yes">i</italic> is modified as follows:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi><mml:mo stretchy="true">˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mo>α</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the edge label of the edge (<italic toggle="yes">i</italic>, <italic toggle="yes">j</italic>) and <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the corresponding edge embedding. The hyperparameter <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mo>α</mml:mo><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> weights the importance of edge features. The vector <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> corresponding to null edge attributes is fixed to zero to avoid affecting the reconstruction. Embeddings based on edge attributes can be learned simultaneously while learning connectivity-based embeddings. While the edge embeddings are used during training, they are not used to compute the final embeddings of nodes after EP training.</p>
        <p>EP can also learn <italic toggle="yes">K</italic> fingerprint embedding vectors <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">V</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup><mml:mo>:</mml:mo><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. Specifically, the node-attribute-based embedding <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> of a node <italic toggle="yes">i</italic> is the mean of fingerprint embeddings <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> corresponding to positive fingerprint entries in the fingerprint vector <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mi>K</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>:
<disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula></p>
        <p>When computing embeddings based on node attributes, we optimize the fingerprint embeddings <bold>V</bold>, instead of <bold>U</bold>, through the learning objective in <xref rid="E2" ref-type="disp-formula">Equation (2)</xref>. An advantage of the EP algorithm is its ability to learn only one of the node embedding types or all. If both node attributes and connectivity embeddings are trained, we simply concatenate <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> to form the final node embedding vector of node <italic toggle="yes">i</italic> before applying the link prediction model. L2 regularization is applied to all variables <bold>U</bold>, <bold>V</bold> and <bold>Z</bold>.</p>
      </sec>
      <sec>
        <title>2.2.3 Link prediction</title>
        <p>The trained node embeddings are used as inputs to a logistics link prediction model. Pairs of embeddings of nodes involved in a known reaction are positive examples; pairs of embeddings of nodes that have no or unknown interaction are treated as negative examples. To make link predictions, the neural network outputs the likelihood of an edge for every pair of input node embeddings. The final result of the model is evaluated based on the area under curve (AUC) metric, wherein the false positive rate and true positive rate are evaluated at every threshold to compute the area under the receiver operating characteristic (ROC) curve.</p>
      </sec>
    </sec>
    <sec>
      <title>2.3 Training and testing</title>
      <p>We explore two learning scenarios—transductive and inductive—that we apply to ELP and our baseline methods. In the transductive setting, we train on all available nodes and evaluate the edge recovery for a set of test edges that were withheld from training. Hence, the graph is split into training and testing sets by partitioning on the edges. During training, all non-training edges are considered negative examples, including those that are test edges. During testing, we evaluate the AUC using the withheld test edges as positive examples and an equal-sized sample of the negative edges as the negative examples. In the inductive scenario, the model predicts interactions for <italic toggle="yes">out-of-sample</italic> nodes excluded from the training set. In the case of ELP, we compute embeddings for out-of-sample nodes from their attributes and predict possible enzymatic reactions for them. Due to the lack of prior connectivity information for out-of-sample nodes, only embeddings based solely on node attributes are learned during training for the ELP method. To generate the training and testing sets, we reserve a certain portion of nodes and their incident edges for the test graph. All other nodes and edges are included in the training graph. Similar to the evaluation of the transductive learning scenario, we sample a set of negative edges equal in size with the test edges.</p>
      <p>For all experiments, the embedding dimension is set to 128. The learning rate for the EP framework is set to 0.01, the regularization to 0.0002, and the γ margin is set to 10. The embedding vectors are trained batch size of 2048 for 500 epochs or until convergence, whichever one comes earliest. The deep neural network decoder predicts the connectivity of two molecules based on their embeddings consists of two hidden layers of sizes 32 and 16. It is trained for 40 epochs on a batch size of 2048 with a learning rate of 0.01. The margin hyperparameter <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:mo>γ</mml:mo><mml:mo>&gt;</mml:mo></mml:mrow></mml:math></inline-formula> is set to 10. In experiments using edge features, α is set to 1.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <p>Once cofactors were excluded, and MACCS and PubChem fingerprints were generated for all our nodes, our dataset representing the biochemical network underlying the KEGG database consisted of 7049 nodes and 12 507 edges, with an average node degree of 3.5. We evaluate both scenarios and all techniques using 5-fold cross-validation.</p>
    <sec>
      <title>3.1 Transductive link prediction</title>
      <p>Results for several transductive scenarios are reported [<xref rid="btaa881-T1" ref-type="table">Table 1</xref>, partitions (A)–(D)]. When performing connectivity-based prediction (partition A), we compare ELP against different variants of node2vec (<xref rid="btaa881-B6" ref-type="bibr">Grover and Leskovec, 2016</xref>), an algorithm for learning node embeddings based on random walks of the graph. Node2vec maximizes the probability of occurrence of nearby nodes in fixed-length random walks, thus preserving higher-order proximity between nodes. The characteristics of the random walks can be specified using the return (backtrack) parameter <italic toggle="yes">p</italic>, the in–out parameter <italic toggle="yes">q</italic>, the length of the walks <italic toggle="yes">l</italic> and the context window <italic toggle="yes">k</italic>, which controls for the neighborhood of nodes considered as nearby. The embedding dimension of node2vec is fixed to be the same as the one used in ELP. We compare ELP to several node2vec variants. The first variant (default) is the node2vec model with default parameters <italic toggle="yes">p </italic>=<italic toggle="yes"> </italic>1, <italic toggle="yes">q </italic>=<italic toggle="yes"> </italic>1, <italic toggle="yes">l</italic> = 80, and <italic toggle="yes">k</italic> = 10; the second variant (short walks) reduces the length of the walk to 10 and the context size to 5. Based on the improvement in AUC from 0.80 to 0.82 using shorter walks, we fix <italic toggle="yes">l</italic> = 10 and <italic toggle="yes">k</italic> = 5 and explore the differences between a DFS-style random walk and a BFS-style random walk, which is defined as <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, respectively. We found a DFS-style random walk led to poorer results (0.75 AUC) but a BFS-style random walk gave the best node2vec result (0.83 AUC), suggesting that localized neighborhoods are more effective in learning node representations than larger neighborhoods. In contrast, ELP, which explicitly considers only the immediate neighbors of every node, outperforms all node2vec variants with an AUC of 0.88.</p>
      <table-wrap position="float" id="btaa881-T1">
        <label>Table 1</label>
        <caption>
          <p>Link prediction results for the transductive learning scenario</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Model</th>
              <th rowspan="1" colspan="1">Connectivity</th>
              <th rowspan="1" colspan="1">Fingerprint</th>
              <th align="left" rowspan="1" colspan="1">Enzyme label</th>
              <th align="left" rowspan="1" colspan="1">AUC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">A. <bold>Connectivity only</bold></td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> node2vec (default)</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">
                <inline-formula id="IE28">
                  <mml:math id="IM28" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mn>0.80</mml:mn>
                      <mml:mo>±</mml:mo>
                      <mml:mn>.011</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> node2vec (short walks)</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">
                <inline-formula id="IE29">
                  <mml:math id="IM29" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mn>0.83</mml:mn>
                      <mml:mo>±</mml:mo>
                      <mml:mn>.020</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> node2vec (DFS)</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">
                <inline-formula id="IE30">
                  <mml:math id="IM30" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mn>0.75</mml:mn>
                      <mml:mo>±</mml:mo>
                      <mml:mn>.152</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> node2vec (BFS)</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">
                <inline-formula id="IE31">
                  <mml:math id="IM31" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mn>0.83</mml:mn>
                      <mml:mo>±</mml:mo>
                      <mml:mn>.004</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> ELP</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">
                <inline-formula id="IE32">
                  <mml:math id="IM32" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mn>0.88</mml:mn>
                      <mml:mo>±</mml:mo>
                      <mml:mn>.003</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">B. <bold>Fingerprints only</bold></td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> Jaccard</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">MACCS</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">
                <inline-formula id="IE33">
                  <mml:math id="IM33" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mn>0.67</mml:mn>
                      <mml:mo>±</mml:mo>
                      <mml:mn>.006</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> Jaccard</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">PubChem</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">
                <inline-formula id="IE34">
                  <mml:math id="IM34" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mn>0.65</mml:mn>
                      <mml:mo>±</mml:mo>
                      <mml:mn>.006</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> L2SVM</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">MACCS</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">
                <inline-formula id="IE35">
                  <mml:math id="IM35" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mn>0.89</mml:mn>
                      <mml:mo>±</mml:mo>
                      <mml:mn>.002</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> ELP</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">MACCS</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">
                <inline-formula id="IE36">
                  <mml:math id="IM36" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mn>0.93</mml:mn>
                      <mml:mo>±</mml:mo>
                      <mml:mn>.004</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> ELP</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">PubChem</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">
                <inline-formula id="IE37">
                  <mml:math id="IM37" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mn>0.93</mml:mn>
                      <mml:mo>±</mml:mo>
                      <mml:mn>.002</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <bold>C. Connectivity and fingerprint</bold>
              </td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> ELP</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">MACCS</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">
                <inline-formula id="IE38">
                  <mml:math id="IM38" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mn>0.97</mml:mn>
                      <mml:mo>±</mml:mo>
                      <mml:mn>.003</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> ELP</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">PubChem</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">
                <inline-formula id="IE39">
                  <mml:math id="IM39" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mn>0.97</mml:mn>
                      <mml:mo>±</mml:mo>
                      <mml:mn>.001</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <bold>D. Connectivity, fingerprint, and enzyme labels</bold>
              </td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> ELP</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">MACCS</td>
              <td rowspan="1" colspan="1">EC</td>
              <td rowspan="1" colspan="1">
                <inline-formula id="IE40">
                  <mml:math id="IM40" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mn>0.97</mml:mn>
                      <mml:mo>±</mml:mo>
                      <mml:mn>.001</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> ELP</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">PubChem</td>
              <td rowspan="1" colspan="1">RC</td>
              <td rowspan="1" colspan="1">
                <inline-formula id="IE41">
                  <mml:math id="IM41" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mn>0.97</mml:mn>
                      <mml:mo>±</mml:mo>
                      <mml:mn>.001</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p>The AUC results and the standard deviations obtained using 5-fold cross-validation. We partitioned the experiments to facilitate comparisons. (A) Using only network connectivity to learn embeddings. (B) Using only MACCS or Pubchem fingerprints. ELP still uses network connectivity to indirectly learn fingerprint embeddings. (C) Using both network connectivity and fingerprints. (D) Using network connectivity, fingerprints and enzyme labels.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Partition (B) explores the effects of using only the MACCS or PubChem fingerprints without utilizing graph-connectivity embeddings. As a baseline, we apply the Jaccard similarity model on the fingerprints of every substrate-product pair in the test set. The Jaccard AUC results are 0.67 using MACCS and 0.65 using PubChem. Another baseline for this partition, denoted L2SVM, is a link prediction model similar to <xref rid="btaa881-B14" ref-type="bibr">Kotera <italic toggle="yes">et al.</italic> (2013b</xref>) based on molecular fingerprints. It uses the similarities and differences between the two fingerprints of a given pair of molecules as inputs to an SVM. We chose the L2-regularized SVM as it was the best performing model in <xref rid="btaa881-B14" ref-type="bibr">Kotera <italic toggle="yes">et al.</italic> (2013b</xref>). The original model proposed by <xref rid="btaa881-B14" ref-type="bibr">Kotera <italic toggle="yes">et al.</italic> (2013b</xref>) uses reactant pairs based on an earlier definition of “main” type transformations that was present in the RPAIR database within KEGG (<xref rid="btaa881-B14" ref-type="bibr">Kotera <italic toggle="yes">et al.</italic>, 2013b</xref>). To facilitate a meaningful comparison, we apply <xref rid="btaa881-B14" ref-type="bibr">Kotera <italic toggle="yes">et al.</italic> (2013b</xref>)’s model directly on our described network, maintaining the assumption that all substrate-product pairs are reversible. Using L2SVM on the MACCS fingerprints yields a mean AUC of 0.89. L2SVM requires significant compute time and memory to process all possible ordered pairs of molecules. As such, the experiment using L2SVM on the PubChem fingerprints required over 1 terabyte of memory on a CPU Processor. The experiment could not be completed using our available resources. As for the ELP model, both the MACCS and PubChem fingerprints achieve a mean AUC of 0.93. Using ELP with MACCS fingerprints leads to slightly larger variabilities (+0.002 std) across 5-fold cross-validation than with the PubChem fingerprints.</p>
      <p>Per partition (C), using a combination of both connectivity information and fingerprint attributes with ELP yields the best results, with both MACCS and PubChem fingerprints achieving an AUC of 0.97. We see again that the MACCS fingerprints lead to 0.002 more variation in terms of standard deviation, but the computational advantages of using MACCS fingerprints is its smaller size (<italic toggle="yes">K </italic>=<italic toggle="yes"> </italic>166) compared to PubChem fingerprints (<italic toggle="yes">K </italic>=<italic toggle="yes"> </italic>881). In partition (D) we incorporate enzyme labels as edge labels. This addition does little to enhance predictive accuracy but decreases the standard deviation, indicating that the inclusion of enzyme labels leads to more stable results. There is little difference in AUC when utilizing the two enzyme labels.</p>
      <p><xref rid="btaa881-F2" ref-type="fig">Figure 2</xref> presents plots for two scenarios using ELP: (A) connectivity only and (B) connectivity with MACCS fingerprints as node attributes. The plot reveals that the lower AUC performance is mostly attributed to having a higher FPR when there is a higher TPR. In other words, we can achieve an almost 0.50 TPR at little cost (little sacrifice in FPR), but as the need to observe improvement in TPR increases, the FPR rises dramatically.</p>
      <fig position="float" id="btaa881-F2">
        <label>Fig. 2</label>
        <caption>
          <p>ROC curve plot for transductive learning with and without MACCS fingerprint as node attributes</p>
        </caption>
        <graphic xlink:href="btaa881f2" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.2 Inductive link prediction</title>
      <p>Several inductive scenarios were investigated (<xref rid="btaa881-T2" ref-type="table">Table 2</xref>). In these scenarios, 5% of all nodes were removed from the graph during training. ELP based on MACCS node attributes achieves an AUC of 0.93 and ELP based on PubChem node attributes achieves an AUC of 0.94. This performance is nearly identical to ELP’s performance in the transductive learning scenarios, wherein an AUC of 0.93 is achieved using either MACCS or PubChem fingerprints. Despite the out-of-sample nodes in the test set not being part of the training graph, ELP robustly leveraged fingerprint information for nodes within the training graph to achieve higher AUC. Similarity analyses based on the Jaccard similarity scores are much lower, with 0.68 and 0.67 AUCs for MACCS and PubChem, respectively.</p>
      <table-wrap position="float" id="btaa881-T2">
        <label>Table 2</label>
        <caption>
          <p>Link prediction results for the inductive learning scenario</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Model</th>
              <th rowspan="1" colspan="1">Connectivity</th>
              <th rowspan="1" colspan="1">Fingerprint</th>
              <th align="left" rowspan="1" colspan="1">AUC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Jaccard</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">MACCS</td>
              <td rowspan="1" colspan="1">
                <inline-formula id="IE42">
                  <mml:math id="IM42" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mn>0.68</mml:mn>
                      <mml:mo> ± </mml:mo>
                      <mml:mn>0.004</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Jaccard</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">Pubchem</td>
              <td rowspan="1" colspan="1">0.67 ± 0.014</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ELP</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">MACCS</td>
              <td rowspan="1" colspan="1">0.93 ± 0.005</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ELP</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">Pubchem</td>
              <td rowspan="1" colspan="1">0.94 ± 0.005</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p>The AUC results and the standard deviations obtained using five random sample of held-out test nodes (5% of all nodes). All models are tested on recovering edges incident to the test nodes.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.3 Pathway reconstruction</title>
      <p>To evaluate how ELP recovers links within metabolic pathways, we reconstruct pathway edges that are omitted during training. We select the same set of pathway groups that was used in <xref rid="btaa881-B14" ref-type="bibr">Kotera <italic toggle="yes">et al.</italic> (2013b</xref>). For each pathway, we reserve its edges as the test graph and use an equal-size random sample of negative edges in the test graph. We evaluate the ability of the ELP model with the MACCS fingerprints to recover edges within each individual pathway.</p>
      <p>We illustrate our results in <xref rid="btaa881-F3" ref-type="fig">Figures 3</xref> and <xref rid="btaa881-F4" ref-type="fig">4</xref>. Similar to earlier findings (<xref rid="btaa881-B14" ref-type="bibr">Kotera <italic toggle="yes">et al.</italic>, 2013b</xref>), the results for individual pathways are overall lower than a random 5-fold split (<xref rid="btaa881-F3" ref-type="fig">Fig. 3</xref>), with a mean AUC of 0.88. The results for the glycan biosynthesis and metabolism pathway group spans a wide range from 0.5 (same as pure chance) to 1 (perfect prediction). The variability is due to the small number of edges within these pathways, where some have as little as 2 true edges. In general, there is little difference in the reconstruction of different pathway maps using ELP. To further benchmark our results, we applied the Jaccard similarity scoring on the same task. <xref rid="btaa881-F4" ref-type="fig">Figure 4</xref> shows that our results are almost always better than results given by Jaccard scores (above the <italic toggle="yes">x </italic>=<italic toggle="yes"> y</italic> line).</p>
      <fig position="float" id="btaa881-F3">
        <label>Fig. 3</label>
        <caption>
          <p>AUC results using the ELP model for each pathway within each pathway group, shown for various functional pathway groups. The size of each marker is proportional to the number of edges being tested for each pathway</p>
        </caption>
        <graphic xlink:href="btaa881f3" position="float"/>
      </fig>
      <fig position="float" id="btaa881-F4">
        <label>Fig. 4</label>
        <caption>
          <p>AUC results using the Jaccard score model and the ELP model shown for various functional pathways groups. Markers are color-coded by pathway groups and the size of each marker is proportional to the number of edges being tested</p>
        </caption>
        <graphic xlink:href="btaa881f4" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.4 Organism reconstruction</title>
      <p>We assess how ELP recovers enzymatic reactions at the organism level. We explore link reconstruction for four gut microbiota phyla: actinobacteria, bacteroidetes, firmicutes and proteobacteria <xref rid="btaa881-B27" ref-type="bibr">(Rinninella <italic toggle="yes">et al.</italic>, 2019</xref>). For each phyla, we retrieved available corresponding organisms from the KEGG database. Due to the high number of affiliated edges for each phylum (<xref rid="btaa881-T3" ref-type="table">Table 3</xref>) and the conservation of metabolism across many organisms, we tested link construction for a large subset of such edges. We test the reconstruction of 1024 randomly sampled edges per phylum. We report the average AUC and standard deviation across five 1024-edge reconstructions for each phylum using the Jaccard similarity model and the ELP model with MACCS fingerprints. For all phyla, the Jaccard similarity model consistently yields AUCs between 0.76 and 0.77 with standard deviations around 0.01. The ELP model achieves higher AUCs ranging between 0.89 and 0.91, and the results show smaller variations.</p>
      <table-wrap position="float" id="btaa881-T3">
        <label>Table 3</label>
        <caption>
          <p>Organism reconstruction result (mean AUC scores and the standard deviation) for each phylum</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Phylum</th>
              <th rowspan="1" colspan="1"># Test Edges</th>
              <th rowspan="1" colspan="1">Jaccard AUC</th>
              <th align="left" rowspan="1" colspan="1">ELP AUC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Proteobacteria</td>
              <td rowspan="1" colspan="1">4982</td>
              <td rowspan="1" colspan="1">0.77 ± 0.007</td>
              <td rowspan="1" colspan="1">0.89 ± 0.001</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Firmicutes</td>
              <td rowspan="1" colspan="1">5454</td>
              <td rowspan="1" colspan="1">0.77 ± 0.010</td>
              <td rowspan="1" colspan="1">0.91 ± 0.004</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Bacteroidetes</td>
              <td rowspan="1" colspan="1">3674</td>
              <td rowspan="1" colspan="1">0.76 ± 0.009</td>
              <td rowspan="1" colspan="1">0.90 ± 0.005</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Actinobacteria</td>
              <td rowspan="1" colspan="1">5968</td>
              <td rowspan="1" colspan="1">0.77 ± 0.010</td>
              <td rowspan="1" colspan="1">0.91 ± 0.001</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn3">
            <p>Each phylum is repeated five times, each with five different random samples of 1024 test edges.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.5 Rule reconstruction</title>
      <p>In contrast to a data-driven machine learning framework like ELP, rule-based models [e.g. PROXIMAL (<xref rid="btaa881-B35" ref-type="bibr">Yousofshahi <italic toggle="yes">et al.</italic>, 2015</xref>) and ReactPred (<xref rid="btaa881-B29" ref-type="bibr">Sivakumar <italic toggle="yes">et al.</italic>, 2016</xref>)] rely on transformation rules. The accuracy of rule-based methods depends entirely on the availability of transformation rules and the ability to apply such rules to query substrate molecules. We design a rule reconstruction experiment with the goal of evaluating how ELP recover edges associated with the most prevalent rules.</p>
      <p>To this end, we compile a list of reaction rules (RCLASSES) in the KEGG database. Given that cofactors were not included in our graph, we remove RLCASSES associated with cofactors, which accounts for less than 5% of all RCLASSES. For each RCLASS, we find the list of associated graph edges through all reactions linked to the RCLASS. <xref rid="btaa881-F5" ref-type="fig">Figure 5</xref> depicts the distribution of the number of associated edges of RCLASSES. We observe that the distribution is heavy tailed, where the majority of rules have very few associated edges and a few rules have many associated edges. To test the reconstruction of one rule, we hide all of its associated edges and train on the rest of the edges using the ELP model with the MACCS fingerprints. Similar to previous testing frameworks, we evaluate the reconstruction of the associated edges against a randomly sampled set of negative edges of equal size. We evaluate ELP’s performance when hiding the top 20 most popular RCLASSES, one RCLASS at a time.</p>
      <fig position="float" id="btaa881-F5">
        <label>Fig. 5</label>
        <caption>
          <p>Histogram distribution of the number of graph edges associated with reactions in each RCLASS</p>
        </caption>
        <graphic xlink:href="btaa881f5" position="float"/>
      </fig>
      <p>We report our ELP results along with the Jaccard similarity scoring results as a baseline comparison (<xref rid="btaa881-T4" ref-type="table">Table 4</xref>). The AUC results over the top 20 RCLASSES using the Jaccard similarity have a mean of 0.65 and standard deviation of 0.15. In contrast, the results using ELP are higher and vary considerably less with a mean and standard deviation of 0.83 and 0.07, respectively. The AUC results using ELP are consistently above 0.75, with the exception of RC00279 (0.69). This RCLASS is associated with enzymes with E.C. numbers 2.5.1.* and denotes the transfer of alkyl or aryl groups other than methyl groups. All edges in the KEGG graph associated with this RCLASS involve isopentenyl diphosphate and a larger molecule, resulting in low similarity between substrate and product. This RCLASS therefore presents an ostensibly difficult rule to predict, as demonstrated by its Jaccard AUC of 0.14. Importantly, ELP performance is not negatively impacted by the prevalence of rules. This result shows that even with the lack of certain rules all together, ELP is successful at recovering missing reactions and its performance is stable, suggesting that ELP is a promising framework in place of rule-based prediction models that completely fail to recover missing reactions if the relevant rule is not considered.</p>
      <table-wrap position="float" id="btaa881-T4">
        <label>Table 4</label>
        <caption>
          <p>Rule reconstruction results of the top 20 rules with the most number of associated test edges</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Rule</th>
              <th rowspan="1" colspan="1"># Test edges</th>
              <th rowspan="1" colspan="1">Jaccard AUC</th>
              <th rowspan="1" colspan="1">ELP AUC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">RC00003</td>
              <td rowspan="1" colspan="1">1364</td>
              <td rowspan="1" colspan="1">0.79</td>
              <td rowspan="1" colspan="1">0.95</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00006</td>
              <td rowspan="1" colspan="1">565</td>
              <td rowspan="1" colspan="1">0.74</td>
              <td rowspan="1" colspan="1">0.89</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00392</td>
              <td rowspan="1" colspan="1">550</td>
              <td rowspan="1" colspan="1">0.66</td>
              <td rowspan="1" colspan="1">0.93</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00049</td>
              <td rowspan="1" colspan="1">438</td>
              <td rowspan="1" colspan="1">0.74</td>
              <td rowspan="1" colspan="1">0.82</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00014</td>
              <td rowspan="1" colspan="1">279</td>
              <td rowspan="1" colspan="1">0.40</td>
              <td rowspan="1" colspan="1">0.76</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00171</td>
              <td rowspan="1" colspan="1">210</td>
              <td rowspan="1" colspan="1">0.61</td>
              <td rowspan="1" colspan="1">0.75</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00021</td>
              <td rowspan="1" colspan="1">207</td>
              <td rowspan="1" colspan="1">0.77</td>
              <td rowspan="1" colspan="1">0.79</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00041</td>
              <td rowspan="1" colspan="1">205</td>
              <td rowspan="1" colspan="1">0.71</td>
              <td rowspan="1" colspan="1">0.77</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00010</td>
              <td rowspan="1" colspan="1">171</td>
              <td rowspan="1" colspan="1">0.58</td>
              <td rowspan="1" colspan="1">0.82</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00055</td>
              <td rowspan="1" colspan="1">169</td>
              <td rowspan="1" colspan="1">0.71</td>
              <td rowspan="1" colspan="1">0.77</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00020</td>
              <td rowspan="1" colspan="1">152</td>
              <td rowspan="1" colspan="1">0.71</td>
              <td rowspan="1" colspan="1">0.83</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00046</td>
              <td rowspan="1" colspan="1">141</td>
              <td rowspan="1" colspan="1">0.80</td>
              <td rowspan="1" colspan="1">0.86</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00062</td>
              <td rowspan="1" colspan="1">136</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.87</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00008</td>
              <td rowspan="1" colspan="1">124</td>
              <td rowspan="1" colspan="1">0.62</td>
              <td rowspan="1" colspan="1">0.76</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00279</td>
              <td rowspan="1" colspan="1">121</td>
              <td rowspan="1" colspan="1">0.14</td>
              <td rowspan="1" colspan="1">0.69</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00460</td>
              <td rowspan="1" colspan="1">102</td>
              <td rowspan="1" colspan="1">0.66</td>
              <td rowspan="1" colspan="1">0.90</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00523</td>
              <td rowspan="1" colspan="1">101</td>
              <td rowspan="1" colspan="1">0.62</td>
              <td rowspan="1" colspan="1">0.79</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00466</td>
              <td rowspan="1" colspan="1">92</td>
              <td rowspan="1" colspan="1">0.64</td>
              <td rowspan="1" colspan="1">0.93</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00059</td>
              <td rowspan="1" colspan="1">89</td>
              <td rowspan="1" colspan="1">0.76</td>
              <td rowspan="1" colspan="1">0.83</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RC00661</td>
              <td rowspan="1" colspan="1">81</td>
              <td rowspan="1" colspan="1">0.60</td>
              <td rowspan="1" colspan="1">0.85</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>3.6 Biochemical network visualization</title>
      <p>To further illustrate the importance of graph embedding in the context of biochemical networks, we show how graph embedding can be used for visualization. <xref rid="btaa881-F6" ref-type="fig">Figure 6</xref> presents a visualization of the embeddings for two reference pathways, the citrate cycle (TCA) cycle and Glycolysis/Gluconeogenesis, as documented in the KEGG database. The resulting subgraph for the TCA cycle consists of 25 nodes and 70 edges, while the subgraph for glycolysis/gluconeogenesis pathway consists of 46 nodes and 126 edges. Twelve compounds are common to both pathways, and include phosphate, diphosphate, pyruvate, thiamine diphosphate, lysine, oxaloacetate and phosphoenolpyruvate. These compounds contribute to 23 edges that overlap in both pathways. To visualize embeddings of these metabolites, we reduce the dimensionality of the embeddings to 2 via t-SNE <xref rid="btaa881-B20" ref-type="bibr">(Maaten and Hinton, 2008</xref>). For the connectivity only plot (top), we observe tight clustering of metabolites within each pathway, while we observe looser clustering when using MACCS fingerprints as node attributes (bottom). Nodes that are embedded far away from the clusters, phosphate, diphosphate, and carbon dioxide, exhibit high connectivity within the KEGG graph, with node degrees of 460, 398, and 545, respectively. On the contrary, nodes within the KEGG graph have an average degree of 3.5, and nodes within the two reference pathways have an average degree of 5.5.</p>
      <fig position="float" id="btaa881-F6">
        <label>Fig. 6</label>
        <caption>
          <p>2D t-SNE (<xref rid="btaa881-B20" ref-type="bibr">Maaten and Hinton, 2008</xref>) visualization of embeddings for two transductive scenarios using ELP. Top: using graph connectivity only. Bottom: using both graph connectivity and MACCS fingerprints</p>
        </caption>
        <graphic xlink:href="btaa881f6" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.7 Runtime</title>
      <p>A single reconstruction using embeddings in ELP has worst case time complexity linearly proportional to the maximum degree of a node (<xref rid="btaa881-B3" ref-type="bibr">García-Durán and Niepert, 2017</xref>). Combined with negative sampling, a single iteration of ELP takes <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo>|</mml:mo><mml:mi>V</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>deg</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">K</italic> is the length of fingerprints. The space complexity of ELP is <italic toggle="yes">O</italic>(<italic toggle="yes">dKn</italic>), where <italic toggle="yes">d</italic> is the embedding dimension. For benchmarking purposes, our experiments using ELP with MACCS fingerprints completed in under 40 min of wall-clock time with 50 GB of available memory. In contrast, each experiment using L2SVM with the MACCS fingerprints took 7˜5 min with 500 GB of available memory. SVM is space bound due to the large number of <italic toggle="yes">n</italic><sup>2</sup> ordered compound pairs and requires <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> memory.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>This work uses EP to learn molecular representations that capture both graph connectivity, enzymatic properties and structural molecular properties. We show that link prediction using only graph connectivity is on par with using molecular similarity. Importantly, we show high accuracy in link prediction when using both graph connectivity and molecular attributes. Link prediction outperforms prior techniques based on similarity methods, SVMs and rule-based methods. Link prediction was shown effective in reconstructing metabolic pathways and reactions within the gut microbiota. This work has broader and practical impact. ELP can be used to guide many biological discoveries and engineering applications such as identifying catalyzing enzymes when constructing novel synthesis pathways or predicting interaction between microbes and human hosts. Graph embedding can be used for other applications such as biochemical network visualization, as demonstrated herein. Further, while our approach is applied to biochemical enzymatic networks, it can enhance link prediction in chemical networks, where rule-based and path-based link prediction respectively yielded 52.7% and 67.5% prediction accuracy (<xref rid="btaa881-B28" ref-type="bibr">Segler and Waller, 2017</xref>).</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This research was supported by National Science Foundation [Award 1909536]. Li-Ping Liu was supported by National Science Foundation [Award 1850358, 1908617]. The research was also supported by the NIGMS of the National Institutes of Health [Award R01GM132391]. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa881-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Almonacid</surname>
 <given-names>D.E.</given-names></string-name>, <string-name><surname>Babbitt</surname><given-names>P.C.</given-names></string-name></person-group> (<year>2011</year>) 
<article-title>Toward mechanistic classification of enzyme functions</article-title>. <source>Curr. Opin. Chem. Biol</source>., <volume>15</volume>, <fpage>435</fpage>–<lpage>442</lpage>.<pub-id pub-id-type="pmid">21489855</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cai</surname>
 <given-names>H.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2018</year>) 
<article-title>A comprehensive survey of graph embedding: problems, techniques, and applications</article-title>. <source>IEEE Trans. Knowl. Data Eng</source>., <volume>30</volume>, <fpage>1616</fpage>–<lpage>1637</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa881-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>García-Durán</surname>
 <given-names>A.</given-names></string-name>, <string-name><surname>Niepert</surname><given-names>M.</given-names></string-name></person-group> (<year>2017</year>) 
<article-title>Learning graph representations with embedding propagation</article-title>. In: <italic toggle="yes">Proceedings of the International Conference on Neural Information Processing Systems, NIPS'17</italic>, pp. <fpage>5119</fpage>–<lpage>5130</lpage>, Red Hook, NY, USA. Curran Associates Inc.</mixed-citation>
    </ref>
    <ref id="btaa881-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Durant</surname>
 <given-names>J.L.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2002</year>) 
<article-title>Reoptimization of mdl keys for use in drug discovery</article-title>. <source>J. Chem. Inform. Comput. Sci</source>., <volume>42</volume>, <fpage>1273</fpage>–<lpage>1280</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa881-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goyal</surname>
 <given-names>P.</given-names></string-name>, <string-name><surname>Ferrara</surname><given-names>E.</given-names></string-name></person-group> (<year>2018</year>) 
<article-title>Graph embedding techniques, applications, and performance: a survey</article-title>. <source>Knowl. Based Syst</source>., <volume>151</volume>, <fpage>78</fpage>–<lpage>94</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa881-B6">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Grover</surname>
 <given-names>A.</given-names></string-name>, <string-name><surname>Leskovec</surname><given-names>J.</given-names></string-name></person-group> (<year>2016</year>) <part-title>Node2vec: scalable feature learning for networks</part-title>. In: <italic toggle="yes"><italic toggle="yes">Proceedings of 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD'16</italic>,</italic> pp. <fpage>855</fpage>–<lpage>864</lpage>, New York, NY, USA. ACM.</mixed-citation>
    </ref>
    <ref id="btaa881-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hult</surname>
 <given-names>K.</given-names></string-name>, <string-name><surname>Berglund</surname><given-names>P.</given-names></string-name></person-group> (<year>2007</year>) 
<article-title>Enzyme promiscuity: mechanism and applications</article-title>. <source>Trends Biotechnol</source>., <volume>25</volume>, <fpage>231</fpage>–<lpage>238</lpage>.<pub-id pub-id-type="pmid">17379338</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kanehisa</surname>
 <given-names>M.</given-names></string-name>, <string-name><surname>Goto</surname><given-names>S.</given-names></string-name></person-group> (<year>2000</year>) 
<article-title>Kegg: Kyoto encyclopedia of genes and genomes</article-title>. <source>Nucleic Acids Res</source>., <volume>28</volume>, <fpage>27</fpage>–<lpage>30</lpage>.<pub-id pub-id-type="pmid">10592173</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Khersonsky</surname>
 <given-names>O.</given-names></string-name>, <string-name><surname>Tawfik</surname><given-names>D.S.</given-names></string-name></person-group> (<year>2010</year>) 
<article-title>Enzyme promiscuity: a mechanistic and evolutionary perspective</article-title>. <source>Annu. Rev. Biochem</source>., <volume>79</volume>, <fpage>471</fpage>–<lpage>505</lpage>.<pub-id pub-id-type="pmid">20235827</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname>
 <given-names>S.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2016</year>) 
<article-title>PubChem substance and compound databases</article-title>. <source>Nucleic Acids Res</source>., <volume>44</volume>, <fpage>D1202</fpage>–<lpage>D1213</lpage>.<pub-id pub-id-type="pmid">26400175</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kotera</surname>
 <given-names>M.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2004</year>) 
<article-title>Computational assignment of the EC numbers for genomic-scale analysis of enzymatic reactions</article-title>. <source>J. Am. Chem. Soc</source>., <volume>126</volume>, <fpage>16487</fpage>–<lpage>16498</lpage>.<pub-id pub-id-type="pmid">15600352</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kotera</surname>
 <given-names>M.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2008</year>) 
<article-title>Eliciting possible reaction equations and metabolic pathways involving orphan metabolites</article-title>. <source>J. Chem. Inform. Model</source>., <volume>48</volume>, <fpage>2335</fpage>–<lpage>2349</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa881-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kotera</surname>
 <given-names>M.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2013</year>a) 
<article-title>KCF-S: KEGG Chemical Function and Substructure for improved interpretability and prediction in chemical bioinformatics</article-title>. <source>BMC Syst. Biol</source>., <volume>7</volume>, <fpage>S2</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa881-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kotera</surname>
 <given-names>M.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2013</year>b) 
<article-title>Supervised <italic toggle="yes">de novo</italic> reconstruction of metabolic pathways from metabolome-scale compound sets</article-title>. <source>Bioinformatics</source>, <volume>29</volume>, <fpage>i135</fpage>–<lpage>i144</lpage>.<pub-id pub-id-type="pmid">23812977</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kotera</surname>
 <given-names>M.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2014</year>a) 
<article-title>Metabolome-scale prediction of intermediate compounds in multistep metabolic pathways with a recursive supervised approach</article-title>. <source>Bioinformatics</source>, <volume>30</volume>, <fpage>i165</fpage>–<lpage>i174</lpage>.<pub-id pub-id-type="pmid">24931980</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kotera</surname>
 <given-names>M.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2014</year>b) 
<article-title>Predictive genomic and metabolomic analysis for the standardization of enzyme data</article-title>. <source>Perspect. Sci</source>., <volume>1</volume>, <fpage>24</fpage>–<lpage>32</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa881-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kurgan</surname>
 <given-names>L.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>C.</given-names></string-name></person-group> (<year>2018</year>) 
<article-title>Survey of similarity-based prediction of drug-protein interactions</article-title>. <source>Curr Med Chem</source>., 27, 5856–5886.</mixed-citation>
    </ref>
    <ref id="btaa881-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>
 <given-names>C.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2004</year>) 
<article-title>Computational discovery of biochemical routes to specialty chemicals</article-title>. <source>Chem. Eng. Sci</source>., <volume>59</volume>, <fpage>5051</fpage>–<lpage>5060</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa881-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liben-Nowell</surname>
 <given-names>D.</given-names></string-name>, <string-name><surname>Kleinberg</surname><given-names>J.</given-names></string-name></person-group> (<year>2007</year>) 
<article-title>The link-prediction problem for social networks</article-title>. <source>J. Am. Soc. Inform. Sci. Technol</source>., <volume>58</volume>, <fpage>1019</fpage>–<lpage>1031</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa881-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maaten</surname>
 <given-names>L. v d.</given-names></string-name>, <string-name><surname>Hinton</surname><given-names>G.</given-names></string-name></person-group> (<year>2008</year>) 
<article-title>Visualizing data using t-SNE</article-title>. <source>J. Mach. Learn. Res</source>., <volume>9</volume>, <fpage>2579</fpage>–<lpage>2605</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa881-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Morreel</surname>
 <given-names>K.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2014</year>) 
<article-title>Systematic structural characterization of metabolites in Arabidopsis via candidate substrate-product pair networks</article-title>. <source>Plant Cell</source>, <volume>26</volume>, <fpage>929</fpage>–<lpage>945</lpage>.<pub-id pub-id-type="pmid">24685999</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pellock</surname>
 <given-names>S.J.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2019</year>) 
<article-title>Discovery and characterization of fmn-binding <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mo>β</mml:mo></mml:math></inline-formula>-glucuronidases in the human gut microbiome</article-title>. <source>J. Mol. Biol</source>., <volume>431</volume>, <fpage>970</fpage>–<lpage>980</lpage>.<pub-id pub-id-type="pmid">30658055</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B23">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Perozzi</surname>
 <given-names>B.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2014</year>) <part-title>Deepwalk: online learning of social representations</part-title>. In: <italic toggle="yes">Proceedings of 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD'14</italic>, pp. <fpage>701</fpage>–<lpage>710</lpage>, New York, NY, USA,
<publisher-name> ACM.</publisher-name></mixed-citation>
    </ref>
    <ref id="btaa881-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pertusi</surname>
 <given-names>D.A.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2015</year>) 
<article-title>Efficient searching and annotation of metabolic networks using chemical similarity</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>1016</fpage>–<lpage>1024</lpage>.<pub-id pub-id-type="pmid">25417203</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rahman</surname>
 <given-names>S.A.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2014</year>) 
<article-title>Ec-blast: a tool to automatically search and compare enzyme reactions</article-title>. <source>Nat. Methods</source>, <volume>11</volume>, <fpage>171</fpage>–<lpage>174</lpage>.<pub-id pub-id-type="pmid">24412978</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ravasz</surname>
 <given-names>E.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2002</year>) 
<article-title>Hierarchical organization of modularity in metabolic networks</article-title>. <source>Science</source>, <volume>297</volume>, <fpage>1551</fpage>–<lpage>1555</lpage>.<pub-id pub-id-type="pmid">12202830</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rinninella</surname>
 <given-names>E.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2019</year>) 
<article-title>What is the healthy gut microbiota composition? A changing ecosystem across age, environment, diet, and diseases</article-title>. <source>Microorganisms</source>, <volume>7</volume>, <fpage>14</fpage>.<pub-id pub-id-type="pmid">30634578</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Segler</surname>
 <given-names>M.H.</given-names></string-name>, <string-name><surname>Waller</surname><given-names>M.P.</given-names></string-name></person-group> (<year>2017</year>) 
<article-title>Modelling chemical reasoning to predict and invent reactions</article-title>. <source>Chemistry</source>, <volume>23</volume>, <fpage>6118</fpage>–<lpage>6128</lpage>.<pub-id pub-id-type="pmid">27862477</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sivakumar</surname>
 <given-names>T.V.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2016</year>) 
<article-title>ReactPRED: a tool to predict and analyze biochemical reactions</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>3522</fpage>–<lpage>3524</lpage>.<pub-id pub-id-type="pmid">27485447</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sivakumar</surname>
 <given-names>T.V.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2018</year>) 
<article-title>Simcal: a flexible tool to compute biochemical reaction similarity</article-title>. <source>BMC Bioinformatics</source>, <volume>19</volume>, <fpage>254</fpage>.<pub-id pub-id-type="pmid">29969981</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tabei</surname>
 <given-names>Y.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2016</year>) 
<article-title>Simultaneous prediction of enzyme orthologs from chemical transformation patterns for <italic toggle="yes">de novo</italic> metabolic pathway reconstruction</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>i278</fpage>–<lpage>i287</lpage>.<pub-id pub-id-type="pmid">27307627</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B32">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Tang</surname>
 <given-names>J.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2015</year>) LINE: Large-scale information network embedding. In: <italic toggle="yes"><italic toggle="yes">Proceedings of 24th International Conference on World Wide Web</italic>, WWW'15</italic>, pp. 1067–1077, Republic and Canton of Geneva, CHE. </mixed-citation>
    </ref>
    <ref id="btaa881-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yamanishi</surname>
 <given-names>Y.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2015</year>) 
<article-title>Metabolome-scale <italic toggle="yes">de novo</italic> pathway reconstruction using regioisomer-sensitive graph alignments</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>i161</fpage>–<lpage>i170</lpage>.<pub-id pub-id-type="pmid">26072478</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yousofshahi</surname>
 <given-names>M.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2011</year>) 
<article-title>Probabilistic pathway construction</article-title>. <source>Metabol. Eng</source>., <volume>13</volume>, <fpage>435</fpage>–<lpage>444</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa881-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yousofshahi</surname>
 <given-names>M.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2015</year>) 
<article-title>PROXIMAL: a method for prediction of xenobiotic metabolism</article-title>. <source>BMC Syst. Biol</source>., <volume>9</volume>, <fpage>94</fpage>.<pub-id pub-id-type="pmid">26695483</pub-id></mixed-citation>
    </ref>
    <ref id="btaa881-B36">
      <mixed-citation publication-type="journal">Yue,X. et al. (<year>2019</year>) Graph embedding on biomedical networks: methods, applications and evaluations. <italic toggle="yes">Bioinformatics</italic>, 36, 1241–1251.</mixed-citation>
    </ref>
  </ref-list>
</back>
