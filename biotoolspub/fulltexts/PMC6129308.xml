<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6129308</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/bty223</article-id>
    <article-id pub-id-type="publisher-id">bty223</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Genome Analysis</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DeepSimulator: a deep simulator for Nanopore sequencing</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Yu</given-names>
        </name>
        <xref ref-type="aff" rid="bty223-aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Han</surname>
          <given-names>Renmin</given-names>
        </name>
        <xref ref-type="aff" rid="bty223-aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bi</surname>
          <given-names>Chongwei</given-names>
        </name>
        <xref ref-type="aff" rid="bty223-aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Mo</given-names>
        </name>
        <xref ref-type="aff" rid="bty223-aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Sheng</given-names>
        </name>
        <xref ref-type="aff" rid="bty223-aff1">1</xref>
        <xref ref-type="corresp" rid="bty223-cor1"/>
        <!--<email>sheng.wang@kaust.edu.sa</email>-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gao</surname>
          <given-names>Xin</given-names>
        </name>
        <xref ref-type="aff" rid="bty223-aff1">1</xref>
        <xref ref-type="corresp" rid="bty223-cor1"/>
        <!--<email>xin.gao@kaust.edu.sa</email>-->
      </contrib>
    </contrib-group>
    <aff id="bty223-aff1"><label>1</label>Computational Bioscience Research Center (CBRC), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal, Saudi Arabia</aff>
    <aff id="bty223-aff2"><label>2</label>Biological and Environmental Sciences and Engineering (BESE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia</aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Berger</surname>
          <given-names>Bonnie</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="bty223-cor1">To whom correspondence should be addressed. E-mail: <email>xin.gao@kaust.edu.sa</email> or <email>sheng.wang@kaust.edu.sa</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <day>01</day>
      <month>9</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2018-04-06">
      <day>06</day>
      <month>4</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>06</day>
      <month>4</month>
      <year>2018</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>34</volume>
    <issue>17</issue>
    <fpage>2899</fpage>
    <lpage>2908</lpage>
    <history>
      <date date-type="received">
        <day>13</day>
        <month>12</month>
        <year>2017</year>
      </date>
      <date date-type="rev-recd">
        <day>31</day>
        <month>3</month>
        <year>2018</year>
      </date>
      <date date-type="accepted">
        <day>04</day>
        <month>4</month>
        <year>2018</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2018. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2018</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="bty223.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Oxford Nanopore sequencing is a rapidly developed sequencing technology in recent years. To keep pace with the explosion of the downstream data analytical tools, a versatile Nanopore sequencing simulator is needed to complement the experimental data as well as to benchmark those newly developed tools. However, all the currently available simulators are based on simple statistics of the produced reads, which have difficulty in capturing the complex nature of the Nanopore sequencing procedure, the main task of which is the generation of raw electrical current signals.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Here we propose a deep learning based simulator, DeepSimulator, to mimic the entire pipeline of Nanopore sequencing. Starting from a given reference genome or assembled contigs, we simulate the electrical current signals by a context-dependent deep learning model, followed by a base-calling procedure to yield simulated reads. This workflow mimics the sequencing procedure more naturally. The thorough experiments performed across four species show that the signals generated by our context-dependent model are more similar to the experimentally obtained signals than the ones generated by the official context-independent pore model. In terms of the simulated reads, we provide a parameter interface to users so that they can obtain the reads with different accuracies ranging from 83 to 97%. The reads generated by the default parameter have almost the same properties as the real data. Two case studies demonstrate the application of DeepSimulator to benefit the development of tools in <italic>de novo</italic> assembly and in low coverage SNP detection.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The software can be accessed freely at: <ext-link ext-link-type="uri" xlink:href="https://github.com/lykaust15/DeepSimulator">https://github.com/lykaust15/DeepSimulator</ext-link>.</p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">King Abdullah University of Science and Technology</named-content>
          <named-content content-type="funder-identifier">10.13039/501100004052</named-content>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">KAUST</named-content>
          <named-content content-type="funder-identifier">10.13039/501100004052</named-content>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Office of Sponsored Research</named-content>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">OSR</named-content>
        </funding-source>
        <award-id>FCC/1/1976-04</award-id>
        <award-id>URF/1/2602-01</award-id>
        <award-id>URF/1/3007-01</award-id>
        <award-id>URF/1/3412-01</award-id>
        <award-id>URF/1/3450-01</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Next-generation sequencing (NGS) technologies allow researchers to sequence DNA and RNA in a high-throughput manner, which have facilitated numerous breakthroughs in genomics, transcriptomics and epigenomics (<xref rid="bty223-B29" ref-type="bibr">MacLean <italic>et al.</italic>, 2009</xref>; <xref rid="bty223-B30" ref-type="bibr">Metzker, 2010</xref>; <xref rid="bty223-B34" ref-type="bibr">Shi <italic>et al.</italic>, 2016</xref>; <xref rid="bty223-B44" ref-type="bibr">Wu <italic>et al.</italic>, 2017</xref>). The most popular NGS technologies on the market include Illumina, PacBio and Nanopore. Unlike the other sequencing technologies, Nanopore, whose core component is the pore chemistry that contains a voltage-biased membrane embedded with nanopores, would detect the electrical current signal changes when DNA or RNA molecules are forced to pass through the pore by voltage. Inputting the detected signals to a basecaller specifically designed for Nanopore, one can obtain the nucleotide sequence reads. Benefited from the underlying design, Nanopore sequencing owns the advantages of long-reads (<xref rid="bty223-B6" ref-type="bibr">Byrne <italic>et al.</italic>, 2017</xref>), point-of-care (<xref rid="bty223-B28" ref-type="bibr">Lu <italic>et al.</italic>, 2016</xref>) and PCR-free (<xref rid="bty223-B35" ref-type="bibr">Simpson <italic>et al.</italic>, 2017</xref>), which enable <italic>de novo</italic> genome or transcriptome assembly with repetitive regions, field real-time analysis and direct epigenetic detection, respectively.</p>
    <p>Along with the rapid development in Nanopore sequencing, the downstream data analytical methods and tools have also been rapidly emerging. For example, Graphmap (<xref rid="bty223-B36" ref-type="bibr">Sović <italic>et al.</italic>, 2016</xref>), Minimap2 (<xref rid="bty223-B25" ref-type="bibr">Li, 2017</xref>) and MashMap2 (<xref rid="bty223-B18" ref-type="bibr">Jain <italic>et al.</italic>, 2017</xref>) were designed to map the Nanopore data to the genome. Canu (<xref rid="bty223-B21" ref-type="bibr">Koren <italic>et al.</italic>, 2017</xref>) and Racon (<xref rid="bty223-B42" ref-type="bibr">Vaser <italic>et al.</italic>, 2017</xref>) were created to assemble long and noisy reads produced by Nanopore. It is foreseeable that an even larger number of methods and tools would be developed in the near future. Therefore, it is quite important to benchmark those new methods using either empirical data (i.e. experimentally obtained) or simulated data (<xref rid="bty223-B12" ref-type="bibr">Escalona <italic>et al.</italic>, 2016</xref>). Although it is essential that one should finally run the method on the empirical data, the empirical data are sometimes difficult and expensive to obtain, with unknown ground truth. On the contrary, the simulated data can be easily obtained at a low cost, and its ground truth can be under full control. These features allow the simulated data to serve as the cornerstone to benchmark new methods.</p>
    <p>Despite the existence of more than twenty simulators for NGS technologies (<xref rid="bty223-B12" ref-type="bibr">Escalona <italic>et al.</italic>, 2016</xref>), there are only three simulators created for the Nanopore sequencing, namely ReadSim (<xref rid="bty223-B22" ref-type="bibr">Lee <italic>et al.</italic>, 2014</xref>), SiLiCO (<xref rid="bty223-B4" ref-type="bibr">Baker <italic>et al.</italic>, 2016</xref>) and NanoSim (<xref rid="bty223-B45" ref-type="bibr">Yang <italic>et al.</italic>, 2017</xref>). Although there are some differences between the three simulators (shown in Section S1), they share the same property of generating simulated data utilizing the input nucleotide sequence and the explicit <italic>profiles</italic> (Here the profiles refer to a set of parameters, such as insertion and deletion rates, substitution rates, read lengths, error rates and quality scores. For instance, ReadSim uses the fixed profile; SiLiCO uses the user provided profile; and NanoSim uses the user provided empirical data to learn the profile which would be used in the simulation stage.) with a statistical model. However, those simulators do not truly capture the complex nature of the Nanopore sequencing procedure, which contains multiple stages including sample preparation, current signal collection and basecalling (<xref ref-type="fig" rid="bty223-F1">Fig. 1A</xref>). More importantly, the current signal is the essence of Nanopore sequencing, yet there is no such simulator that attempts to mimic the signal generation step.
</p>
    <fig id="bty223-F1" orientation="portrait" position="float">
      <label>Fig. 1.</label>
      <caption>
        <p>(<bold>A</bold>) The Nanopore sequencing procedure. (<bold>B</bold>) The main workflow of DeepSimulator. It simulates the entire pipeline of the empirical Nanopore sequencing experiment, producing both the simulated signals and the final simulated reads. In addition, DeepSimulator is highly modularized, which means it can be customized and updated easily to keep up with the development pace of the Nanopore sequencing technologies. Unlike the real data, the ground truth and the annotation of the simulated reads are easy to acquire. In the simulated reads on the bottom of the figure, the red colored bases are the mismatches. The green colored bases indicate that there are indel (insertion and deletion) before them</p>
      </caption>
      <graphic xlink:href="bty223f1"/>
    </fig>
    <p>Instead of following the commonly adapted scenario of designing a simulator from the statistical aspect, we tackle the problem from a different angle, proposing a novel simulator that is designed more naturally for Nanopore sequencing. To run the simulator, the user just need to input a reference genome or assembled contigs, specifying the coverage or the number of reads. The sequence would first go through a preprocessing stage, which produces several shorter sequences, satisfying the input coverage requirement and the read length distribution of real Nanopore reads. Then, those sequences would pass through the signal generation module, which contains the pore model component and the signal repeating component. The pore model component is used to model the expected current signal of a given <italic>k</italic>-mer (<italic>k</italic> usually equals to 5 or 6 and here we use 5-mer without loss of generality), which is followed by the signal repeating component to produce the simulated current signals. These simulated signals are similar to the real signals in both strength and scale. Finally, the simulated signal would go through Albacore (<ext-link ext-link-type="uri" xlink:href="https://community.nanoporetech.com/protocols/albacore-offline-basecalli/v/abec_2003_v1_revad_29nov2016/linux">https://community.nanoporetech.com/protocols/albacore-offline-basecalli/v/abec_2003_v1_revad_29nov2016/linux</ext-link>), the Oxford Nanopore Technology (ONT) official basecaller, to produce the final simulated reads.</p>
    <p>It is obvious that the core component of our simulator is the pore model in the signal generation module. Currently, all the existing pore models (<ext-link ext-link-type="uri" xlink:href="https://github.com/nanoporetech/kmer_models">https://github.com/nanoporetech/kmer_models</ext-link>) are context-independent, which assign each 5-mer a fixed value for the expected current signal regardless of its location on the nucleotide sequence. In order to further polish our simulator, we propose a novel context-dependent pore model, taking advantage of deep learning techniques, which have shown great potential in bioinformatics (<xref rid="bty223-B8" ref-type="bibr">Dai <italic>et al.</italic>, 2017</xref>; <xref rid="bty223-B27" ref-type="bibr">Li <italic>et al.</italic>, 2018</xref>). Nonetheless, it is not straightforward to train the deep learning model because of the fact that the current signal is usually 8–10 times longer than the nucleotide sequence. To conquer this difficulty, we propose a novel deep learning strategy, BiLSTM-extended Deep Canonical Time Warping (BDCTW), which combines bi-directional long short-term memory (Bi-LSTM) (<xref rid="bty223-B16" ref-type="bibr">Graves and Schmidhuber, 2005</xref>) with deep canonical time warping (DCTW) (<xref rid="bty223-B41" ref-type="bibr">Trigeorgis <italic>et al.</italic>, 2016</xref>) to solve the scale difference issue.</p>
    <p>As described above and shown in <xref ref-type="fig" rid="bty223-F1">Figure 1B</xref>, our DeepSimulator is ‘deep’ in two folds. First, instead of being a simulator that only mimics the result, our simulator mimics Nanopore sequencing deeply by simulating the entire processing pipeline. Secondly, when translating the sequences into the current signals, we build a context-dependent pore model using deep learning methods. By mimicking the way Nanopore works, our simulator simulates the complete Nanopore sequencing process, producing both the simulated current signals and the final reads. Besides, employing the official basecaller, our simulator not only eliminates the procedure of learning the parameters in the profile, but also indeed deploys the actual parameters implicitly. Furthermore, by dividing the simulation procedure into several modules, our simulator offers more flexibility. For instance, the user can choose to use a different basecaller (<xref rid="bty223-B5" ref-type="bibr">Boža <italic>et al.</italic>, 2018</xref>; <xref rid="bty223-B40" ref-type="bibr">Teng <italic>et al.</italic>, 2018</xref>), or tune the parameters in the signal generation module to obtain the final reads with different accuracies.</p>
    <p>In summary, the main contributions of this paper are as follows:
<list list-type="order"><list-item><p>We propose the first process-based simulator, DeepSimulator, which can fully simulate the entire procedure of Nanopore sequencing, producing not only the final simulated reads but also the intermediate electrical current signals.</p></list-item><list-item><p>We propose a novel method to simultaneously handle the temporal alignment and the correlation analysis between the current signals and the DNA sequence that have large differences in the temporal scale. In doing so, our method is based on DCTW with Bi-LSTM as the feature mapping function to handle the sequential data.</p></list-item><list-item><p>We propose the first context-dependent pore model, which can accurately and specifically predict the expected current signal for each 5-mer of the DNA sequence, taking into account the sequentially contextual information.</p></list-item></list></p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Main workflow</title>
      <p>The main workflow of our DeepSimulator is shown in <xref ref-type="fig" rid="bty223-F1">Figure 1</xref>. Unlike the previous simulators (<xref rid="bty223-B4" ref-type="bibr">Baker <italic>et al.</italic>, 2016</xref>; <xref rid="bty223-B45" ref-type="bibr">Yang <italic>et al.</italic>, 2017</xref>) that only simulate the final reads from statistical models, our simulator attempts to mimic the entire pipeline of Nanopore sequencing. There are three main stages in Nanopore sequencing. The first stage is sample preparation which would result in the nucleotide specimen used in the experiment. After obtaining the specimen, the next stage is to measure the electrical current signals of the nucleotide sequences using a Nanopore sequencing device, such as the MinION. These collected signals are usually stored in a FAST5 file. Finally, we would obtain the reads by applying a basecaller to the current signals. Correspondingly, DeepSimulator has three modules. The first module is the sequence generator. Providing the whole genome or the assembled contigs, as well as the desired coverage requirement, DeepSimulator generates relatively short sequences, which satisfy the coverage requirement and the length distribution of Nanopore reads. The read length distribution is described in Section 2.2. Then, those generated sequences are fed into the second module, namely the signal generation module. As the core module of DeepSimulator, it is used to generate the simulated current signals which aim to approximate the current signals produced by the MinION. There are two components within this module: the pore model component and the signal simulation component. The pore model component takes as input a nucleotide sequence and outputs the context-dependent expected current signal for each 5-mer in the sequence, which is discussed in details in Section 2.3. The signal simulation component repeats an expected signal several times at each position based on the signal repeat time distribution and then adds random noise to produce the simulated current signals. This component is discussed in Section 2.4. The last module of DeepSimulator is the commonly used basecallers.</p>
      <p>Notice that during the entire simulating process, we do not explicitly introduce mismatches and indels (insertions and deletions), which is usually performed in the statistical simulators (<xref rid="bty223-B4" ref-type="bibr">Baker <italic>et al.</italic>, 2016</xref>; <xref rid="bty223-B45" ref-type="bibr">Yang <italic>et al.</italic>, 2017</xref>) directly at the read-level. Instead, we try to mimic the current signal produced by Nanopore sequencing as similar as possible, making the basecaller introduce mismatches and indels by itself. Thus, the mismatches and indels in our method are implicitly introduced at the signal-level, which is more reasonable and closer to the real-world situation.</p>
    </sec>
    <sec>
      <title>2.2 Sequence generation</title>
      <p>The first module of our simulator is the sequence generator. Given the user-specified reference genome or assembled contigs, as well as the desired coverage or the number of reads, the sequence generation module randomly chooses a starting position on the genome or contigs to produce the relatively short sequences, which satisfy the coverage requirement and the length distribution of the experimental Nanopore reads.</p>
      <p>As discussed in the previous papers (<xref rid="bty223-B4" ref-type="bibr">Baker <italic>et al.</italic>, 2016</xref>; <xref rid="bty223-B45" ref-type="bibr">Yang <italic>et al.</italic>, 2017</xref>), the read length of Nanopore sequencing is not very straightforward to model. Many factors, such as the experimental purpose and the experimenter’s experience, would influence the read length distribution greatly. By investigating the dataset published by Nanoporetech and datasets provided by our collaborators (in Section 2.5), we find that the distribution of the read length can be categorized into three patterns by using DBSCAN (<xref rid="bty223-B13" ref-type="bibr">Ester <italic>et al.</italic>, 1996</xref>) as the clustering method and histogram intersection (<xref rid="bty223-B39" ref-type="bibr">Swain and Ballard, 1991</xref>) as the distance metric (<xref ref-type="fig" rid="bty223-F2">Fig. 2</xref>). For the first pattern shown in <xref ref-type="fig" rid="bty223-F2">Figure 2A</xref>, we use an exponential distribution to fit it (e.g. reads from the human genome). For the second pattern shown in the <xref ref-type="fig" rid="bty223-F2">Figure 2B</xref>, we use a beta distribution to fit it (e.g. reads from the <italic>E. coli</italic> genome). For the last pattern shown in <xref ref-type="fig" rid="bty223-F2">Figure 2C</xref>, it is not easy to fit it using a single distribution (e.g. reads from the lambda phage genome). To deal with this pattern, we use a mixture distribution with two gamma distributions to fit it. When using the simulator, the users can choose either of the three patterns. The distribution details could be referred to Section S2. Alternatively, the user can also specify the other distribution patterns for the read length.
</p>
      <fig id="bty223-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>The three common read length distribution patterns in Nanopore sequencing. The distribution of the experimental reads from (<bold>A</bold>) human, (<bold>B</bold>) <italic>E.coli</italic> K-12 sub-strain MG1655 and (<bold>C</bold>) lambda phage</p>
        </caption>
        <graphic xlink:href="bty223f2"/>
      </fig>
    </sec>
    <sec>
      <title>2.3 Context-dependent pore model</title>
      <p>Given a nucleotide sequence, the first step to simulate its corresponding electrical current signals (i.e. raw signal) is the transformation to its expected current signals via the pore model. In this subsection, we would first formulate the problem of building the pore model, followed by the proposed solution, BiLSTM-extended Deep Canonical Time Warping (BDCTW). We divide BDCTW into three parts: general framework of deep canonical time warping, feature representation and neural network architecture. Finally, we introduce our context-dependent pore model.</p>
      <sec>
        <title><italic>2.3.1</italic> Problem formulation</title>
        <p>A pore model is defined as the correspondence between the expected current signal and the 5-mer nucleotide sequence that is in the pore at the same time (<xref rid="bty223-B10" ref-type="bibr">Deamer <italic>et al.</italic>, 2016</xref>). The pore model prediction problem is formulated as follows: given an input nucleotide sequence <inline-formula id="IE1"><mml:math id="IM1"><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> with <italic>T</italic><sub>1</sub> nucleotides where <italic>x<sub>i</sub></italic> is a 4-state nucleotide base that can take one of the four values from <inline-formula id="IE2"><mml:math id="IM2"><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant="normal">A</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">C</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">G</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> for DNA or <inline-formula id="IE3"><mml:math id="IM3"><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant="normal">A</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">U</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">C</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">G</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> for RNA, we need to predict the corresponding expected electrical current signals <inline-formula id="IE4"><mml:math id="IM4"><mml:mrow><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, where <italic>y<sub>i</sub></italic> is the predicted expected current signal of a 5-mer starting from position <italic>i</italic> in <italic>X</italic> (e, g, ‘ACGTT’).</p>
        <p>Here, we propose a novel method for building the pore model in consideration of the contextual information. Specifically, our method learns the context-dependent (or position-specific) pore model <italic>Y<sup>dep</sup></italic> with length <inline-formula id="IE5"><mml:math id="IM5"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> for the nucleotide sequence <italic>X</italic> with length <italic>T</italic><sub>1</sub> from the raw signals (i.e. the observed electrical current signals from a Nanopore sequencing device) <inline-formula id="IE6"><mml:math id="IM6"><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> with length <italic>T</italic><sub>2</sub>.</p>
        <p>There are three challenges for learning the context-dependent pore model.
<list list-type="bullet"><list-item><p><bold>Scale difference</bold>. Since the frequency of the electrical current measurements (taken at 4000 Hz) is about 8-10 times faster than the speed at which the single-strand nucleotide sequence passes through the pore (the translocation speed is around 450 bases per second for Rapid Kit, for example) (<xref rid="bty223-B38" ref-type="bibr">Stoiber and Brown, 2017</xref>), the temporal scale difference between the raw signals <inline-formula id="IE7"><mml:math id="IM7"><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and the nucleotide sequence <italic>X</italic> is large.</p></list-item><list-item><p><bold>Dimensionality difference</bold>. The feature space dimensionality is different between <italic>X</italic> and <inline-formula id="IE8"><mml:math id="IM8"><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, due to the fact that <inline-formula id="IE9"><mml:math id="IM9"><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is a one-dimensional electrical current signal sequence whereas <italic>X</italic> is a nucleotide sequence with the feature dimension being at least four. This is because in order to preserve the original sequence information, one-hot encoding is commonly used (<xref rid="bty223-B15" ref-type="bibr">Graves, 2013</xref>) and thus four-dimension is needed to encode the four nucleotide bases.</p></list-item><list-item><p><bold>Complex non-linear correlation</bold>. The measurement of the raw signals <inline-formula id="IE10"><mml:math id="IM10"><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is under a noisy sequencing environment because of voltage changes, noise and interactions between nanopore channels, etc (<xref rid="bty223-B9" ref-type="bibr">David <italic>et al.</italic>, 2017</xref>). Thus, the relationship between <italic>X</italic> and <inline-formula id="IE11"><mml:math id="IM11"><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is very complex, having high-order or non-linear correlation.</p></list-item></list></p>
      </sec>
      <sec>
        <title><italic>2.3.2</italic> General framework of deep canonical time warping</title>
        <p>The goal of deep canonical time warping (DCTW) is to discover a hierarchical or recurrent non-linear relationship between two input linearly structured datasets <italic>X</italic>1 and <italic>X</italic>2 with different lengths <italic>T</italic><sub>1</sub>, <italic>T</italic><sub>2</sub> and feature dimensionality <italic>d</italic><sub>1</sub>, <italic>d</italic><sub>2</sub> (i.e. <inline-formula id="IE12"><mml:math id="IM12"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mo>ℝ</mml:mo><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) (<xref rid="bty223-B41" ref-type="bibr">Trigeorgis <italic>et al.</italic>, 2016</xref>). That is, DCTW simultaneously performs spatial transformation and temporal alignment between the two input data sequences. In our case, the two inputs are the nucleotide sequence <italic>X</italic> and the observed electrical current signal sequence <inline-formula id="IE13"><mml:math id="IM13"><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>. As shown in <xref ref-type="fig" rid="bty223-F3">Figure 3</xref>, after DCTW, the transformed features from <italic>X</italic> and <inline-formula id="IE14"><mml:math id="IM14"><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> are not only temporally aligned with each other, but also maximally correlated. To this end, let us consider that <inline-formula id="IE15"><mml:math id="IM15"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mo>θ</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:math></inline-formula> representing the activation function of the final layer of the corresponding deep neural network (DNN) for <italic>X<sub>i</sub></italic>, which has <italic>d</italic> maximally correlated units where <inline-formula id="IE16"><mml:math id="IM16"><mml:mrow><mml:mi>d</mml:mi><mml:mo>≤</mml:mo><mml:mtext>min</mml:mtext><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:math></inline-formula>. Such an operation reduces the input data samples to the same feature dimension and then performs a maximal correlation analysis, which essentially resembles the classical canonical correlation analysis (CCA) (<xref rid="bty223-B2" ref-type="bibr">Akaike, 1976</xref>). Consequently, we try to optimize the following objective function,
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mtext>argmin</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="true">)</mml:mo><mml:msub><mml:mi>Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="true">)</mml:mo><mml:msub><mml:mi>Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mo>|</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mtext>subject to: </mml:mtext><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">)</mml:mo><mml:msub><mml:mi>Δ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>1</mml:mn></mml:mstyle><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>0</mml:mn></mml:mstyle><mml:mi>d</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">)</mml:mo><mml:msub><mml:mi>Δ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mi>Δ</mml:mi><mml:mi>i</mml:mi><mml:mi mathvariant="normal">⊤</mml:mi></mml:msubsup><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>d</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="true">)</mml:mo><mml:msub><mml:mi>Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msubsup><mml:mi>Δ</mml:mi><mml:mn>2</mml:mn><mml:mi mathvariant="normal">⊤</mml:mi></mml:msubsup><mml:msub><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mi>d</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>Δ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <italic>X</italic><sub>1</sub> = <italic>X</italic> and <inline-formula id="IE17"><mml:math id="IM17"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>. <italic>T</italic><sub>1</sub>, <italic>T</italic><sub>2</sub> and <italic>T</italic> are the length of <italic>X</italic>, <inline-formula id="IE18"><mml:math id="IM18"><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and the final alignment, respectively. Δ<sub><italic>i</italic></sub> are the binary selection matrices that encode the alignment paths for <italic>X<sub>i</sub></italic>. That is, Δ<sub>1</sub> and Δ<sub>2</sub> remap the nucleotide sequence <italic>X</italic> with length <italic>T</italic><sub>1</sub> and raw signals <inline-formula id="IE19"><mml:math id="IM19"><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> with length <italic>T</italic><sub>2</sub> to a common temporal scale <italic>T</italic>. <bold>D</bold> is a diagonal matrix. <bold>I</bold> is the identity matrix. And <bold>1</bold> (<bold>0</bold>) is an appropriate dimensionality vector of all 1’s (0’s).
</p>
        <fig id="bty223-F3" orientation="portrait" position="float">
          <label>Fig. 3.</label>
          <caption>
            <p>Illustration of the deep canonical time warping (DCTW) architecture with two deep neural networks (DNNs), one for the input nucleotide sequence (here we use one-hot encoding for each nucleotide and thus the feature dimension is four) and the other for the observed electrical current measurements (denoted as raw signals with feature dimension one). We train this model in an end-to-end manner, which first performs a spatial transformation that efficiently reduces the input data samples to the same feature dimension, followed by a temporal alignment that effectively maps the samples of each input sequence to a common temporal scale. The objective function of the model is to make the transformed input data samples to be maximally correlated under the canonical correlation analysis (CCA) loss</p>
          </caption>
          <graphic xlink:href="bty223f3"/>
        </fig>
        <p>Such an objective function can be solved via alternating optimization (<xref rid="bty223-B41" ref-type="bibr">Trigeorgis <italic>et al.</italic>, 2016</xref>). Specifically, given the final layer output <inline-formula id="IE20"><mml:math id="IM20"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mo>θ</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:math></inline-formula>, we employ dynamic time warping (DTW) (<xref rid="bty223-B33" ref-type="bibr">Salvador and Chan, 2007</xref>) to obtain the optimal warping matrices Δ<sub><italic>i</italic></sub> which temporally align the input sequence <italic>X<sub>i</sub></italic> and the final alignment. After obtaining the warping matrices Δ<sub><italic>i</italic></sub> via DTW, we infer the maximally correlated nonlinear transformation on the temporally aligned input features <inline-formula id="IE21"><mml:math id="IM21"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mo>θ</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:math></inline-formula> by maximizing the following function,
<disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:mrow><mml:mtext>corr</mml:mtext><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mo>θ</mml:mo><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="true">)</mml:mo><mml:msub><mml:mo>Δ</mml:mo><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mo>θ</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="true">)</mml:mo><mml:msub><mml:mo>Δ</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi mathvariant="bold">K</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>C</mml:mi><mml:mi>T</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mo>|</mml:mo><mml:mo>*</mml:mo></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE22"><mml:math id="IM22"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo>.</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mo>|</mml:mo><mml:mo>*</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> is the nuclear norm, <inline-formula id="IE23"><mml:math id="IM23"><mml:mrow><mml:msub><mml:mi mathvariant="bold">K</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>C</mml:mi><mml:mi>T</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>22</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is the kernel matrix of DCTW, <inline-formula id="IE24"><mml:math id="IM24"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mo>θ</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">)</mml:mo><mml:msub><mml:mo>Δ</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:msubsup><mml:mo>Δ</mml:mo><mml:mi>j</mml:mi><mml:mi mathvariant="normal">⊤</mml:mi></mml:msubsup><mml:msub><mml:mi>F</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mo>θ</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> denotes the empirical covariance between the transformed datasets, where <inline-formula id="IE25"><mml:math id="IM25"><mml:mrow><mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the centering matrix, <inline-formula id="IE26"><mml:math id="IM26"><mml:mrow><mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold">I</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mn>1</mml:mn><mml:mi mathvariant="normal">⊤</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>.</p>
        <p>The gradient of the objective function <inline-formula id="IE27"><mml:math id="IM27"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi mathvariant="bold">K</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>C</mml:mi><mml:mi>T</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mo>|</mml:mo><mml:mo>*</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> with respect to the activation layer of one neural network, such as <inline-formula id="IE28"><mml:math id="IM28"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mo>θ</mml:mo><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:math></inline-formula>, can be calculated as
<disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi mathvariant="bold">K</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>C</mml:mi><mml:mi>T</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mo>|</mml:mo><mml:mo>*</mml:mo></mml:msub></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo stretchy="true">(</mml:mo><mml:msup><mml:mi mathvariant="bold">F</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mi mathvariant="bold">F</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="true">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi mathvariant="bold">F</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi mathvariant="bold">U</mml:mi><mml:msup><mml:mi mathvariant="bold">V</mml:mi><mml:mi mathvariant="normal">⊤</mml:mi></mml:msup><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>22</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>Y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mo>Δ</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi mathvariant="bold">F</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi mathvariant="bold">U</mml:mi><mml:mi mathvariant="bold">S</mml:mi><mml:msup><mml:mi mathvariant="bold">U</mml:mi><mml:mi mathvariant="normal">⊤</mml:mi></mml:msup><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>Y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mo>Δ</mml:mo><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <inline-formula id="IE29"><mml:math id="IM29"><mml:mrow><mml:mi mathvariant="bold">U</mml:mi><mml:mi mathvariant="bold">S</mml:mi><mml:msup><mml:mi mathvariant="bold">V</mml:mi><mml:mi mathvariant="normal">⊤</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">K</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>C</mml:mi><mml:mi>T</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the singular value decomposition (SVD) of the kernel matrix <bold>K</bold><sub><italic>DCTW</italic></sub>. By employing this equation as the subgradient, we can optimize the parameters <italic>θ<sub>i</sub></italic> in each neural network via back-propagation.</p>
        <p>Since the electrical current signal of a 5-mer could be influenced by the surrounding sequences, we extend the feature function <inline-formula id="IE30"><mml:math id="IM30"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mo>θ</mml:mo><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:math></inline-formula> in the original DCTW with bi-directional long short-term memory (Bi-LSTM) (<xref rid="bty223-B5" ref-type="bibr">Boža <italic>et al.</italic>, 2017</xref>) to incorporate the contextual information. Section S1 gives a brief introduction to Bi-LSTM. The DNN architecture in <xref ref-type="fig" rid="bty223-F3">Figure 3</xref> is further elucidated in <xref ref-type="fig" rid="bty223-F4">Figure 4</xref>, which is introduced in details in Sections 2.3.3 and 2.3.4.
</p>
        <fig id="bty223-F4" orientation="portrait" position="float">
          <label>Fig. 4.</label>
          <caption>
            <p>Detailed architecture of the deep neural network in deep canonical time warping for feature mapping of the input nucleotide sequence. Here we apply Bi-LSTM with three feature matrices (described in Section 2.3.3): Seq<sub><italic>k</italic></sub> represents the feature matrix by one-hot vector encoding of <italic>k</italic>-mers where <italic>k</italic> = {1, 3, 5}, respectively. After training, this model becomes the context-dependent pore model</p>
          </caption>
          <graphic xlink:href="bty223f4"/>
        </fig>
      </sec>
      <sec>
        <title><italic>2.3.3</italic> Feature representation</title>
        <p>To preserve the original sequence information, we use one-hot encoding as the representation of the nucleotide sequence <italic>X</italic>. When a nucleotide sequence passes through the nanopore, each 5-mer inside the pore will cause a change in the magnitude of the electrical current. Thus, instead of just considering one nucleotide (4<sup>1</sup> = 4 combinations) at position <italic>t</italic>, we encode the 3-mer (4<sup>3</sup> = 64 combinations) and the 5-mer (4<sup>5</sup> = 1024 combinations) centered at <italic>t</italic> as well. Specifically, we use one 1 and (4<sup>k</sup> – 1) 0’s to represent each <italic>k</italic>-mer (<inline-formula id="IE31"><mml:math id="IM31"><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>). Then for each nucleotide sequence <italic>X</italic> with length <italic>T</italic><sub>1</sub>, the one-hot encoding would produce three feature matrices with dimensions <italic>T</italic><sub>1</sub> × 4, <italic>T</italic><sub>1</sub> × 64 and <italic>T</italic><sub>1</sub> × 1024, respectively. Each row in the feature matrix represents a specific position and each column represents the appearance of a certain <italic>k</italic>-mer.</p>
      </sec>
      <sec>
        <title><italic>2.3.4</italic> Neural network architecture</title>
        <p>To simplify our model architecture, we use an identical transformation as the feature mapping to deal with the raw signal data. That is, we set <inline-formula id="IE32"><mml:math id="IM32"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mo>θ</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>. For the other feature mapping function <italic>F</italic><sub>1</sub>(<italic>X</italic><sub>1</sub>; <italic>θ</italic><sub>1</sub>) for the nucleotide sequence, we use the Bi-LSTM architecture. Specifically, as shown in <xref ref-type="fig" rid="bty223-F4">Figure 4</xref>, for each feature matrix, we use a Bi-LSTM block to obtain the hidden representation, with 50 forward LSTM cells and 50 backward LSTM cells. After concatenating the obtained hidden representations of different feature matrices, we feed it into a fully-connected layer with 200 nodes, which is followed by a regression layer. All the weights are initialized using the Xavier method. To avoid overfitting, we utilize weight decay with the coefficient as 1e<sup>–</sup><sup>4</sup>. We choose Adam (<xref rid="bty223-B20" ref-type="bibr">Kingma and Ba, 2014</xref>) as the optimizer with the learning rate 1e<sup>–</sup><sup>4</sup>. Deploying batch normalization (<xref rid="bty223-B17" ref-type="bibr">Ioffe and Szegedy, 2015</xref>) to accelerate training, we set the batch size as 64 during training. The deep neural network model is implemented using Tensorflow (<xref rid="bty223-B1" ref-type="bibr">Abadi, 2016</xref>) and can converge within 6 h with the help of two Pascal Titan X cards.</p>
      </sec>
      <sec>
        <title><italic>2.3.5</italic> Context-dependent pore model</title>
        <p>The deep neural network in deep canonical time warping for feature mapping of the input nucleotide sequence (<xref ref-type="fig" rid="bty223-F4">Fig. 4</xref>) becomes the context-dependent pore model after training. To use it, the pore model first uses one-hot vector encoding of <italic>k</italic>-mers, where <italic>k </italic>=<italic> </italic>1, 3, 5, to encode the input sequence. The encodings then go through BiLSTM layers, fully-connected layers as well as the final regression layer to generate the expected electrical signals. The training process of the model is illustrated in <xref ref-type="fig" rid="bty223-F5">Figure 5</xref>, which shows the loss value change with respect to the training iteration steps.
</p>
        <fig id="bty223-F5" orientation="portrait" position="float">
          <label>Fig. 5.</label>
          <caption>
            <p>The loss value change with respect to the training iteration steps. Since we use the stochastic optimizer during training, which only evaluates the loss function of a small batch of data points, the original loss value curve is very noisy. Thus, we apply a Hanning filter with the window size 10 to the original loss curve to smooth it</p>
          </caption>
          <graphic xlink:href="bty223f5"/>
        </fig>
      </sec>
    </sec>
    <sec>
      <title>2.4 Signal simulation</title>
      <p>After obtaining the expected current signals of a given nucleotide sequence, the second step of simulating its corresponding electrical current signals is to repeat the signal at each position and add random noise. It is well-known that during sequencing, the raw signal acquisition speed is much faster than the DNA or RNA moving speed, causing a certain 5-mer being measured multiple times. Thus, to convert the expected signals produced by the pore model to the electrical current signals which can be put into a basecaller, we need to repeat a certain position on the expected signal several times. Similar to the read length, we manage to model the repeat time using a mixture alpha distribution. When running the simulator, the repeat time would be drawn from the distribution for each position on the expected signal, generating the simulated current signal by repeating that position for a certain number of times. The details of the distribution and the parameters could be referred to Section S3. It should also be noted that the raw signals are extremely noisy due to the complicated sequencing environment (<xref rid="bty223-B9" ref-type="bibr">David <italic>et al.</italic>, 2017</xref>). Therefore, we add Gaussian noise with the user-defined variance parameter to each position of the simulated signals.</p>
      <p>The main difficulty of this step is to get the statistics of the repeat time, as shown in <xref ref-type="fig" rid="bty223-F6">Figure 6</xref>. Currently, it is almost impossible to get the precise repeat time of a certain 5-mer, but it is possible to obtain the approximate repeat time statistics. Here we show the four basic steps for obtaining the statistics. (i) Taking as input the reference genome, raw signals produced by the MinION, and the basecalled reads from Albacore, we first map the reads on to the reference genome by Minimap (<xref rid="bty223-B24" ref-type="bibr">Li, 2016</xref>), which would mark out the ground truth (at least approximate) sequence that corresponds to the raw signal. (ii) With the ground truth sequence, we can get the expected signal of each 5-mer in the sequence using the context-independent pore model. (iii) We then apply dynamic time warping (DTW) (<xref rid="bty223-B33" ref-type="bibr">Salvador and Chan, 2007</xref>) to map the raw signal and the expected signal, which is based on the fact that those two signals should have similar shapes. (iv) Based on the mapping, we can find out the repeat time from the raw signal positions that correspond to each expected signal position. Performing the above procedure on a large dataset, we can get a stable statistic of the repeat time. We then fit the distribution as a mixture model (Section S3).
</p>
      <fig id="bty223-F6" orientation="portrait" position="float">
        <label>Fig. 6.</label>
        <caption>
          <p>The distribution of the signal repeat times of 5-mer nucleotides</p>
        </caption>
        <graphic xlink:href="bty223f6"/>
      </fig>
    </sec>
    <sec>
      <title>2.5 Datasets</title>
      <p>Four Nanopore sequencing datasets from different species are used in this paper: ranging from the in-house datasets lambda phage, <italic>E.coli</italic> K-12 sub-strain MG1655, <italic>Pandoraea pnomenusa</italic> strain 6399, to the public available human data. The three in-house datasets were prepared and sequenced by Prof. Lachlan Coin’s lab at University of Queensland. In particular, all the samples were sequenced on the MinION device with 1D ligation kits on R9.4 flow cells (SQK-LSK108 protocol). The publicly available human dataset is the human chromosome 21 from the Nanopore WGS Consortium (<xref rid="bty223-B19" ref-type="bibr">Jain <italic>et al.</italic>, 2018</xref>). The samples in this dataset were sequenced from the NA12878 human genome reference on the Oxford Nanopore MinION using 1D ligation kits (450 bp/s) with R9.4 flow cells. The Nanopore raw signal datasets in the FAST5 format were downloaded from nanopore-wgs-consortium (<ext-link ext-link-type="uri" xlink:href="http://s3.amazonaws.com/nanopore-human-wgs/rel3-fast5-chr21.part03.tar">http://s3.amazonaws.com/nanopore-human-wgs/rel3-fast5-chr21.part03.tar</ext-link>). The reference genomes of the four datasets were downloaded from NCBI (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/nuccore/J02459">https://www.ncbi.nlm.nih.gov/nuccore/J02459</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/nuccore/U00096">https://www.ncbi.nlm.nih.gov/nuccore/U00096</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/nuccore/JTCR01000000">https://www.ncbi.nlm.nih.gov/nuccore/JTCR01000000</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/nuccore/NC_000021">https://www.ncbi.nlm.nih.gov/nuccore/NC_000021</ext-link>).</p>
      <p>The context-dependent pore model of the second module in DeepSimulator was trained on the <italic>Pandoraea pnomenusa</italic> dataset. To construct the dataset used in Section 3.2, which is used to check the performance of the pore models, we randomly sampled 700 reads from each of remaining three species to form a dataset containing 2100 reads.</p>
      <p>In addition to the four species for which we have both the reference genome and the empirical experimental data, we also include another extremely small genome, mitochondria, for which we only have the reference genome (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/nuccore/AY172335">https://www.ncbi.nlm.nih.gov/nuccore/AY172335</ext-link>). We used the <italic>E.coli</italic> K-12 genome, the lambda phage genome and the mitochondrial genome to perform the assembly experiments in Section 3.4. Finally, the mitochondrial genome and lambda phage genome were used for the single nucleotide polymorphisms (SNP) calling experiments in Section 3.5.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <p>We comprehensively evaluated each of the three modules in DeepSimulator. In summary, the results in this section show that (i) the length distribution of the simulated reads satisfies the empirical read length distribution; (ii) the signals generated by our context-dependent pore model are more similar to the experimental signals than the signals generated by the official context-independent pore model; and (iii) the final reads generated by DeepSimulator with the default parameter have almost the same profile as the experimental data. We finally show that DeepSimulator can benefit the development of tools or methods in <italic>de novo</italic> assembly and low coverage SNP detection. All the parameter setting related to the experiments can be found in <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S4</xref> and all the parameter definitions can be found in Section S4.</p>
    <sec>
      <title>3.1 Read length distribution</title>
      <p>As mentioned in Section 2.2, for an input genome sequence, DeepSimulator generates reads whose length distribution satisfies the empirical length distribution. In order to find the distributions of the Nanopore sequencing reads, we applied the DBSCAN clustering algorithm with histogram intersection as the distance metric to the datasets, which found three distinguished patterns from the data. We used three distributions, beta distribution, exponential distribution and the mixed gamma distribution to fit the three patterns. The three distributions are thus provided as options in DeepSimulator. The parameters of these distributions are given in Section S2. In general, the mixed gamma distribution is often the most suitable length distribution. As a result, we set it as the default length distribution pattern. In addition to that, considering the property of different sequencing tasks, some biological experiments may be designed on purpose so that the read length distribution would satisfy a predefined distribution. In order to simulate this case, we also provide the interface for the user-defined read length distributions. The distributions of the length of the simulated reads by DeepSimulator on human, <italic>E.coli</italic> K-12 sub-strain MG1655 and lambda phage are very similar to that of the experimental reads (Section S5). SiLiCO and Nanosim also investigated the read length distribution fitting problem. More detailed discussion of their methods could be found in (<xref rid="bty223-B4" ref-type="bibr">Baker <italic>et al.</italic>, 2016</xref>; <xref rid="bty223-B45" ref-type="bibr">Yang <italic>et al.</italic>, 2017</xref>).</p>
    </sec>
    <sec>
      <title>3.2 Simulated signals</title>
      <p>To check the signal-level similarity between the simulated signals generated by DeepSimulator and the experimental ones produced by the MinION (i.e. the raw signals), we employed dynamic time warping (DTW) (<xref rid="bty223-B33" ref-type="bibr">Salvador and Chan, 2007</xref>) which is the standard way of checking the difference between two signals (see Section S6 for details). We test the performance on the randomly selected 2100 reads from lambda phage, <italic>E.coli</italic> K-12 sub-strain MG1655 and human (as described in Section 2.5). The average deviation between the simulated signals and the raw signals is 0.175. We also performed the same analysis using the official content-independent pore model followed by the same signal repeat component used in DeepSimulator to obtain the context-independent simulated signals. Using the same set of reads, the average deviation of the context-independent signals to the raw ones is 0.185, which is about 5.7% higher than that of DeepSimulator. Furthermore, we performed another experiment on the reads generated by NanoSim (<xref rid="bty223-B45" ref-type="bibr">Yang <italic>et al.</italic>, 2017</xref>) to derive the simulated signals by the context-independent pore model. The average deviation of the NanoSim signals to the raw ones is 0.210, which is 20% higher than that of DeepSimulator. <xref ref-type="fig" rid="bty223-F7">Figure 7</xref> shows the comparison of the deviation scores of the DeepSimulator signals and that of the context independent signals as well as that of the NanoSim signals for the 2100 reads. Notice that DeepSimulator was trained solely on <italic>Pandoraea pnomenusa</italic> and tested on the three other species, which demonstrates the generality of our model.
</p>
      <fig id="bty223-F7" orientation="portrait" position="float">
        <label>Fig. 7.</label>
        <caption>
          <p>Comparison of the context-dependent pore model component of DeepSimulator with the context-independent pore model on the signal-level. Each point represents an input read. The x-axis represents the DTW deviation of the DeepSimulator signals of the input read from the real raw signals. The y-axis represents the DTW deviation of the signals generated from context-independent pore model from the real raw signals (context-independent pore model with our signal repeat component in blue, and context-independent pore model with NanoSim in cyan). The red line is the diagonal line. Any point above the red line means our simulation is better, whereas any point below means the existing method is better</p>
        </caption>
        <graphic xlink:href="bty223f7"/>
      </fig>
    </sec>
    <sec>
      <title>3.3 Simulated reads</title>
      <p>The read-level outputs are also of significant importance for sequence level analysis. This section further investigates whether DeepSimulator can simulate reads with the same profile as the real reads from the Nanopore sequencing. For the read-level outputs, we provided a parameter interface in DeepSimulator, which can be adjusted continuously so that the user could control the final read basecalling accuracy as well as the indel ratio. Internally, the parameters change the noise and the signal repeat time distribution, which are the two factors that affect the read profile greatly. To check the read profile of the simulated reads, for a given input ground truth sequence, we ran DeepSimulator to obtain the simulated read. Performing BLAST (<xref rid="bty223-B3" ref-type="bibr">Altschul <italic>et al.</italic>, 1997</xref>) between the simulated read and the ground truth read, we can calculate the profiles such as the accuracy, mismatch number and gap numbers. According to our experiment, the output reads of DeepSimulator can have a basecalling accuracy ranging from 83 to 97%. <xref rid="bty223-T1" ref-type="table">Table 1</xref> shows the profile of the real reads and the profiles of DeepSimulator reads using four typical parameter settings. In addition, we also checked the profile of the reads generated from the official context-independent pore model, whose output is extended using the noise-free repeat time distribution and further basecalled using Albacore, which is shown in the third column of <xref rid="bty223-T1" ref-type="table">Table 1</xref>. Due to the modularization of DeepSimulator, we know the ground truth of each read from the Sequence Generator module. As a result, we can run BLAST and obtain the exact profile. As for the reads from other baseline methods, of which it is difficult to determine the ground truth, we performed a global mapping of the reads to first find the regions of the reference genome that are the most similar to the reads, followed by a BLAST analysis to approximate the true profile.
<table-wrap id="bty223-T1" orientation="portrait" position="float"><label>Table 1.</label><caption><p>The profiles of different types of reads, tested on the dataset described in Section 3.2, which are basecalled using Albacore</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1">Criteria</th><th rowspan="1" colspan="1">Real data</th><th rowspan="1" colspan="1">OPM</th><th rowspan="1" colspan="1">DS (noise free)</th><th rowspan="1" colspan="1">DS (high acc)</th><th rowspan="1" colspan="1">DS (med acc)</th><th rowspan="1" colspan="1">DS (low acc)</th><th rowspan="1" colspan="1">NanoSim</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Accuracy</td><td rowspan="1" colspan="1">88.49%</td><td rowspan="1" colspan="1">95.99%</td><td rowspan="1" colspan="1">97.01%</td><td rowspan="1" colspan="1">92.96%</td><td rowspan="1" colspan="1">88.78%</td><td rowspan="1" colspan="1">83.45%</td><td rowspan="1" colspan="1">83.80%</td></tr><tr><td rowspan="1" colspan="1">Mismatch</td><td rowspan="1" colspan="1">2.88%</td><td rowspan="1" colspan="1">1.24%</td><td rowspan="1" colspan="1">0.94%</td><td rowspan="1" colspan="1">1.87%</td><td rowspan="1" colspan="1">2.74%</td><td rowspan="1" colspan="1">4.36%</td><td rowspan="1" colspan="1">4.51%</td></tr><tr><td rowspan="1" colspan="1">Gap open</td><td rowspan="1" colspan="1">5.38%</td><td rowspan="1" colspan="1">2.21%</td><td rowspan="1" colspan="1">1.69%</td><td rowspan="1" colspan="1">3.63%</td><td rowspan="1" colspan="1">5.28%</td><td rowspan="1" colspan="1">7.08%</td><td rowspan="1" colspan="1">7.31%</td></tr><tr><td rowspan="1" colspan="1">Gap total</td><td rowspan="1" colspan="1">8.62%</td><td rowspan="1" colspan="1">2.77%</td><td rowspan="1" colspan="1">2.04%</td><td rowspan="1" colspan="1">5.17%</td><td rowspan="1" colspan="1">8.48%</td><td rowspan="1" colspan="1">12.19%</td><td rowspan="1" colspan="1">11.69%</td></tr></tbody></table><table-wrap-foot><fn id="tblfn1"><p><italic>Note</italic>: DS represents the reads generated from DeepSimulator. Here we show the profiles of four typical settings (the parameter can be adjusted continuously, not just four choices) of DeepSimulator, noise free, high accuracy, middle accuracy (aimed at simulating the empirical data profile) and low accuracy. OPM (official pore model) shows the read profile generated by the official context-independent pore model, whose output is extended using the noise-free repeat time distribution and further basecalled using Albacore, given an input ground truth sequence. We also provide the profile of reads generated by NanoSim, with the pre-trained <italic>E.coli</italic> R9 profile from the NanoSim official website, on the test dataset. In this table, ‘Gap open’ represents the total number of gaps in the alignment between the simulated reads and the reference genome divided by the length of alignment, excluding the head and tail gaps. ‘Gap total’ represents the total number of bases included in the gaps divided by the length of alignment, excluding the head and tail gaps. The parameter manual of DeepSimulator can be referred to Section S4. Note that since NanoSim and DeepSimulator tackle the simulation problem from different angles, this comparison is not completely fair, although we tried to make it as fair as possible. The detailed description of how we ran NanoSim could be referred to Section S9.</p></fn></table-wrap-foot></table-wrap></p>
    </sec>
    <sec>
      <title>3.4 <italic>De novo</italic> assembly</title>
      <p>Because of long reads, Nanopore sequencing has higher potential in genome assembly than the other short-reads sequencing technologies (<xref rid="bty223-B7" ref-type="bibr">Cao <italic>et al.</italic>, 2017</xref>). Thus, one of the main applications for Nanopore sequencing is <italic>de novo</italic> assembly. We used two widely recognized <italic>de novo</italic> assembly pipelines, Canu (<xref rid="bty223-B21" ref-type="bibr">Koren <italic>et al.</italic>, 2017</xref>) and Miniasm (<xref rid="bty223-B24" ref-type="bibr">Li, 2016</xref>) with Racon (<xref rid="bty223-B42" ref-type="bibr">Vaser <italic>et al.</italic>, 2017</xref>), to perform such a task on two different sets of simulated reads generated by DeepSimulator from the <italic>E.coli</italic> K-12 genome and the lambda phage genome, respectively. Both experiments succeeded in assembling the simulated reads into one contig. The comparison between the assemblies and the reference genome is plotted using MUMmer (<xref rid="bty223-B11" ref-type="bibr">Delcher <italic>et al.</italic>, 1999</xref>), as shown in <xref ref-type="fig" rid="bty223-F8">Figure 8A and C</xref>. As a comparison, we also show the assembly results of <italic>E.coli</italic> K-12 and lambda phage using the empirical data (<xref ref-type="fig" rid="bty223-F8">Fig. 8B and D</xref>). It is clear that the results of the empirical data show similar patterns as the results of the simulated data. In addition to the relatively large genome, <italic>E.coli</italic> K-12, which is 4.6 Mbp, and a small genome, lambda phage, which is 48 Kbp, we also performed another experiment on an extremely small genome, the mitochondrial genome (16 Kbp). Miniasm with Racon also succeeded in assembling the simulated reads into one contig (Section S7).
</p>
      <fig id="bty223-F8" orientation="portrait" position="float">
        <label>Fig. 8.</label>
        <caption>
          <p>Mummer plots comparing the reference genome on the x-axis with the assembled genome on the y-axis. (<bold>A</bold>) The assembly result of the <italic>E.coli</italic> K-12 genome by Canu, using simulated reads from DeepSimulator. (<bold>B</bold>) The assembly result of the <italic>E.coli</italic> K-12 genome by Canu, using the experimental MinION sequence data (i.e. empirical data). (<bold>C</bold>) The assembly result of the lambda phage genome by Miniasm with Racon, using simulated reads from DeepSimulator. (<bold>D</bold>) The assembly result of the lambda phage genome by Miniasm with Racon, using the empirical data</p>
        </caption>
        <graphic xlink:href="bty223f8"/>
      </fig>
    </sec>
    <sec>
      <title>3.5 Low coverage SNP detection</title>
      <p>Single nucleotide polymorphisms (SNPs) are found to be involved in the etiology of many human diseases. For example, hundreds of SNPs in the mitochondrial DNA (mtDNA) have been linked to aging-related diseases (<xref rid="bty223-B31" ref-type="bibr">Ocampo <italic>et al.</italic>, 2016</xref>; <xref rid="bty223-B37" ref-type="bibr">Stewart and Chinnery, 2015</xref>). Despite the importance of the complete haplotyping of the mitochondrial genome, the current methods, which are designed for detecting mitochondrial mutations from a population of cells, would perform massively parallel sequencing of short DNA fragments, having difficulty in performing the complete haplotyping. On the other hand, the Nanopore sequencing, which has the potential of performing the long-read single-molecular sequencing of mtDNA, may overcome the hurdle. Under this circumstance, mimicking the ideal single molecular Nanopore sequencing scenarios, we conducted experiments on the success rate of SNPs detection with respect to sequencing coverage, using the simulated reads from DeepSimulator.</p>
      <p>Considering the basecalling accuracy of the Nanopore sequencing, although the current basecalling accuracy is not high enough (around 86–88%), theoretically, we can consider those errors as random errors instead of systematic errors, and the consensus analysis could help us get rid of such random noise and detect the systematic variants which are caused by SNPs.</p>
      <p>The results are shown in <xref ref-type="fig" rid="bty223-F9">Figure 9</xref>. On the simulated data of mitochondrial genome, we could detect SNPs when the coverage is above 6× using the standard pipeline of samtools (<xref rid="bty223-B26" ref-type="bibr">Li <italic>et al.</italic>, 2009</xref>) and bcftools (<xref rid="bty223-B23" ref-type="bibr">Li, 2011</xref>) (<xref ref-type="fig" rid="bty223-F9">Fig. 9A</xref>), which is consistent with the conclusion in (<xref rid="bty223-B46" ref-type="bibr">Zeng <italic>et al.</italic>, 2013</xref>). As the number of the implanted SNPs increases, the coverage should increase to ensure all the SNPs to be successfully called. <xref ref-type="fig" rid="bty223-F9">Figure 9B</xref> shows the same analysis on the lambda phage genome, which shares the similar pattern as the mitochondrial experiment. In summary, the detection of the SNPs would become more difficult as the number of SNPs increases. Our experiments demonstrate that in general, 6× coverage would be enough to detect a small number of SNPs.
</p>
      <fig id="bty223-F9" orientation="portrait" position="float">
        <label>Fig. 9.</label>
        <caption>
          <p>(A) The relationship between the SNP detection performance and the coverage as well as the number of introduced SNPs on the simulated reads from the mitochondrial genome. (B) The relationship between the SNP detection performance and the coverage as well as the number of introduced SNPs on the simulated reads from the lambda phage genome</p>
        </caption>
        <graphic xlink:href="bty223f9"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion and conclusion</title>
    <p>In this paper, we proposed DeepSimulator, the first Nanopore simulator that aims at mimicking the entire procedure of Nanopore sequencing. Unlike the previous simulators which only simulate the reads from the statistical patterns of the real data, DeepSimulator simulates both the raw electrical current signals and nucleotide reads.</p>
    <p>There are three advantages of DeepSimulator. First of all, our pipeline is highly modularized, which is easier to be customized by users. For example, the users can use another basecaller, to replace Albacore, to obtain the reads with the profile of that basecaller. Secondly, because of the modularization, compared with other simulators, it is more likely for our simulator to keep up with the rapid development of the Nanopore sequencing technology. If one step of the Nanopore sequencing pipeline is updated, we can also update the corresponding module without changing the entire pipeline completely. We further provide an interface of using a customized dataset to train a customized pore model, which enables DeepSimulator to keep up with the developing pace of the Nanopore sequencing. Thirdly, in addition to the final simulated reads, we are also able to obtain the simulated electrical current signals, which are very useful for the development of basecallers and for the benchmarking of signal-level read mappers.</p>
    <p>There are two potential applications of DeepSimulator. On one hand, DeepSimulator can generate benchmark datasets to evaluate the newly developed methods for Nanopore sequencing data analysis. Unlike the empirical datasets whose ground truth is difficult to obtain, DeepSimulator can be fully controlled, which makes it a practical complement to the empirical data. On the other hand, as shown in the SNP detection experiments, it can act as a guidance to the empirical experiment by simulating the ideal situation.</p>
    <p>Despite the novelty of DeepSimulator, it can still be improved from various aspects. Since it contains a module based on deep learning, which is computationally intensive, it is inevitable that DeepSimulator would require more computational resources and longer running time than some of the other simulators, such as NanoSim, as shown in Section S8. The recent development of deep learning for mobile devices (<xref rid="bty223-B47" ref-type="bibr">Zhang <italic>et al.</italic>, 2017</xref>) may be useful for overcoming this bottleneck. In terms of the selection of the deep learning architecture, several recent works, such as generative adversarial networks (GANs) for sequence data (<xref rid="bty223-B32" ref-type="bibr">Rajeswar <italic>et al.</italic>, 2017</xref>), attention networks (<xref rid="bty223-B43" ref-type="bibr">Vaswani <italic>et al.</italic>, 2017</xref>) and convolutional sequence to sequence models (<xref rid="bty223-B14" ref-type="bibr">Gehring <italic>et al.</italic>, 2017</xref>), are promising directions which may lead to better context-dependent pore models.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>Supplementary Data</label>
      <media xlink:href="bty223_supplemental_materials.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank Lachlan J.M. Coin, Louise Roddam and Tania Duarte from University of Queensland for providing the nanopore sequencing data for the lambda phage, <italic>E. coli</italic> and <italic>Pandoraea pnomenusa</italic> samples.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by the King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research (OSR) under Awards No. FCC/1/1976-04, URF/1/2602-01, URF/1/3007-01, URF/1/3412-01 and URF/1/3450-01.</p>
      <p><italic>Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="bty223-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Abadi</surname><given-names>M.</given-names></name></person-group> (<year>2016</year>) 
<article-title>Tensorflow: learning functions at scale</article-title>. <source>ACM Sigplan Notices</source>, <volume>51</volume>, <fpage>1</fpage>–<lpage>1</lpage>.</mixed-citation>
    </ref>
    <ref id="bty223-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Akaike</surname><given-names>H.</given-names></name></person-group> (<year>1976</year>) 
<article-title>Canonical correlation analysis of time series and the use of an information criterion</article-title>. <source>Math. Sci. Eng</source>., <volume>126</volume>, <fpage>27</fpage>–<lpage>96</lpage>.</mixed-citation>
    </ref>
    <ref id="bty223-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Altschul</surname><given-names>S.F.</given-names></name></person-group><etal>et al</etal> (<year>1997</year>) 
<article-title>Gapped blast and psi-blast: a new generation of protein database search programs</article-title>. <source>Nucleic Acids Res</source>., <volume>25</volume>, <fpage>3389</fpage>–<lpage>3402</lpage>.<pub-id pub-id-type="pmid">9254694</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B4">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Baker</surname><given-names>E.A.G.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) Silico: a simulator of long read sequencing in pacbio and oxford nanopore. <italic>bioRxiv</italic>, 76901.</mixed-citation>
    </ref>
    <ref id="bty223-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Boža</surname><given-names>V.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Deepnano: deep recurrent neural networks for base calling in minion nanopore reads</article-title>. <source>PloS One</source>, <volume>12</volume>, <fpage>e0178751.</fpage><pub-id pub-id-type="pmid">28582401</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Byrne</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) Nanopore long-read rnaseq reveals widespread transcriptional variation among the surface receptors of individual b cells. <italic>Nat. Commun.</italic>, <volume>8</volume>, <fpage>16027</fpage>.</mixed-citation>
    </ref>
    <ref id="bty223-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cao</surname><given-names>M.D.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Scaffolding and completing genome assemblies in real-time with nanopore sequencing</article-title>. <source>Nat. Commun</source>., <volume>8</volume>, <fpage>14515.</fpage><pub-id pub-id-type="pmid">28218240</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dai</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Sequence2vec: a novel embedding approach for modeling transcription factor binding affinity landscape</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>3575</fpage>–<lpage>3583</lpage>.<pub-id pub-id-type="pmid">28961686</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>David</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Nanocall: an open source basecaller for oxford nanopore sequencing data</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>49</fpage>–<lpage>55</lpage>.<pub-id pub-id-type="pmid">27614348</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Deamer</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Three decades of nanopore sequencing</article-title>. <source>Nat. Biotechnol</source>., <volume>34</volume>, <fpage>518</fpage>–<lpage>525</lpage>.<pub-id pub-id-type="pmid">27153285</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Delcher</surname><given-names>A.L.</given-names></name></person-group><etal>et al</etal> (<year>1999</year>) 
<article-title>Alignment of whole genomes</article-title>. <source>Nucleic Acids Res</source>., <volume>27</volume>, <fpage>2369</fpage>–<lpage>2376</lpage>.<pub-id pub-id-type="pmid">10325427</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Escalona</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>A comparison of tools for the simulation of genomic next-generation sequencing data</article-title>. <source>Nat. Rev. Genet</source>., <volume>17</volume>, <fpage>459</fpage>–<lpage>469</lpage>.<pub-id pub-id-type="pmid">27320129</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Ester</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>1996</year>) A density-based algorithm for discovering clusters a density-based algorithm for discovering clusters in large spatial databases with noise. In: <italic>Proceedings of the Second International Conference on Knowledge Discovery and Data Mining</italic>, KDD’96. AAAI Press, pp. 226–231.</mixed-citation>
    </ref>
    <ref id="bty223-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Gehring</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) Convolutional sequence to sequence learning. <italic>arXiv preprint arXiv:1705.03122</italic>.</mixed-citation>
    </ref>
    <ref id="bty223-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Graves</surname><given-names>A.</given-names></name></person-group> (<year>2013</year>) Generating sequences with recurrent neural networks. <italic>arXiv preprint arXiv: 1308.0850.</italic></mixed-citation>
    </ref>
    <ref id="bty223-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Graves</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Schmidhuber</surname><given-names>J.</given-names></name></person-group> (<year>2005</year>) 
<article-title>Framewise phoneme classification with bidirectional lstm and other neural network architectures</article-title>. <source>Neural Netw</source>., <volume>18</volume>, <fpage>602</fpage>–<lpage>610</lpage>.<pub-id pub-id-type="pmid">16112549</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B17">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Ioffe</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Szegedy</surname><given-names>C.</given-names></name></person-group> (<year>2015</year>) Batch normalization: Accelerating deep network training by reducing internal covariate shift. <italic>arXiv: 1502.03167</italic>.</mixed-citation>
    </ref>
    <ref id="bty223-B18">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Jain</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) A fast approximate algorithm for mapping long reads to large reference databases. In: <person-group person-group-type="editor"><name name-style="western"><surname>Sahinalp</surname><given-names>S.C.</given-names></name></person-group> (ed.) <source>Research in Computational Molecular Biology</source>, 
<publisher-name>Springer International Publishing</publisher-name>, Cham, pp. <fpage>66</fpage>–<lpage>81</lpage>.</mixed-citation>
    </ref>
    <ref id="bty223-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jain</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) Nanopore sequencing and assembly of a human genome with ultra-long reads. <italic>Nat. Biotechnol.</italic>, <volume>36</volume>, <fpage>338</fpage>.</mixed-citation>
    </ref>
    <ref id="bty223-B20">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Kingma</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Ba</surname><given-names>J.</given-names></name></person-group> (<year>2014</year>) Adam: a method for stochastic optimization. <italic>arXiv preprint arXiv: 1412.6980</italic>.</mixed-citation>
    </ref>
    <ref id="bty223-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Koren</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Canu: scalable and accurate long-read assembly via adaptive k-mer weighting and repeat separation</article-title>. <source>Genome Res</source>., <volume>27</volume>, <fpage>722</fpage>–<lpage>736</lpage>.<pub-id pub-id-type="pmid">28298431</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B22">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Lee</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) Error correction and assembly complexity of single molecule sequencing reads. <italic>BioRxiv</italic>, <fpage>6395</fpage>.</mixed-citation>
    </ref>
    <ref id="bty223-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>H.</given-names></name></person-group> (<year>2011</year>) 
<article-title>A statistical framework for snp calling, mutation discovery, association mapping and population genetical parameter estimation from sequencing data</article-title>. <source>Bioinformatics</source>, <volume>27</volume>, <fpage>2987</fpage>–<lpage>2993</lpage>.<pub-id pub-id-type="pmid">21903627</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>H.</given-names></name></person-group> (<year>2016</year>) 
<article-title>Minimap and miniasm: fast mapping and de novo assembly for noisy long sequences</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>2103</fpage>–<lpage>2110</lpage>.<pub-id pub-id-type="pmid">27153593</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>H.</given-names></name></person-group> (<year>2017</year>) Minimap2: versatile pairwise alignment for nucleotide sequences. <italic>arXiv</italic>1708.</mixed-citation>
    </ref>
    <ref id="bty223-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> and (<year>2009</year>) 
<article-title>The sequence alignment/map format and samtools</article-title>. <source>Bioinformatics</source>, <volume>25</volume>, <fpage>2078</fpage>–<lpage>2079</lpage>.<pub-id pub-id-type="pmid">19505943</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Deepre: sequence-based enzyme ec number prediction by deep learning</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>760</fpage>–<lpage>769</lpage>.<pub-id pub-id-type="pmid">29069344</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lu</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Oxford nanopore minion sequencing and genome assembly</article-title>. <source>Genomics Proteomics Bioinf</source>., <volume>14</volume>, <fpage>265</fpage>–<lpage>279</lpage>.</mixed-citation>
    </ref>
    <ref id="bty223-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>MacLean</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Application of ’next-generation’ sequencing technologies to microbial genetics</article-title>. <source>Nat. Rev. Microbiol</source>., <volume>7</volume>, <fpage>287</fpage>–<lpage>296</lpage>.<pub-id pub-id-type="pmid">19287448</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Metzker</surname><given-names>M.L.</given-names></name></person-group> (<year>2010</year>) 
<article-title>Sequencing technologies–the next generation</article-title>. <source>Nat. Rev. Genet</source>., <volume>11</volume>, <fpage>31.</fpage><pub-id pub-id-type="pmid">19997069</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ocampo</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>In vivo amelioration of age-associated hallmarks by partial reprogramming</article-title>. <source>Cell</source>, <volume>167</volume>, <fpage>1719.</fpage><pub-id pub-id-type="pmid">27984723</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B32">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Rajeswar</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) Adversarial generation of natural language. <italic>arXiv preprint arXiv:1705.10929</italic>.</mixed-citation>
    </ref>
    <ref id="bty223-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Salvador</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Chan</surname><given-names>P.</given-names></name></person-group> (<year>2007</year>) 
<article-title>Toward accurate dynamic time warping in linear time and space</article-title>. <source>Intell. Data Anal</source>., <volume>11</volume>, <fpage>561</fpage>–<lpage>580</lpage>.</mixed-citation>
    </ref>
    <ref id="bty223-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shi</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Long-read sequencing and de novo assembly of a chinese genome</article-title>. <source>Nat. Commun</source>., <volume>7</volume>, <fpage>12065</fpage>.<pub-id pub-id-type="pmid">27356984</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Simpson</surname><given-names>J.T.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Detecting dna cytosine methylation using nanopore sequencing</article-title>. <source>Nat. Methods</source>, <volume>14</volume>, <fpage>407</fpage>–<lpage>410</lpage>.<pub-id pub-id-type="pmid">28218898</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sović</surname><given-names>I.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Fast and sensitive mapping of nanopore sequencing reads with graphmap</article-title>. <source>Nat. Commun</source>., <volume>7</volume>, <fpage>11307.</fpage><pub-id pub-id-type="pmid">27079541</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stewart</surname><given-names>J.B.</given-names></name>, <name name-style="western"><surname>Chinnery</surname><given-names>P.F.</given-names></name></person-group> (<year>2015</year>) 
<article-title>The dynamics of mitochondrial dna heteroplasmy: implications for human health and disease</article-title>. <source>Nat. Rev. Genet</source>., <volume>16</volume>, <fpage>530</fpage>–<lpage>542</lpage>.<pub-id pub-id-type="pmid">26281784</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B38">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Stoiber</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Brown</surname><given-names>J.</given-names></name></person-group> (<year>2017</year>) BasecRAWller: streaming nanopore basecalling directly from raw signal. <italic>bioRxiv</italic>, 133058.</mixed-citation>
    </ref>
    <ref id="bty223-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Swain</surname><given-names>M.J.</given-names></name>, <name name-style="western"><surname>Ballard</surname><given-names>D.H.</given-names></name></person-group> (<year>1991</year>) 
<article-title>Color indexing</article-title>. <source>Int. J. Comput. Vis</source>., <volume>7</volume>, <fpage>11</fpage>–<lpage>32</lpage>.</mixed-citation>
    </ref>
    <ref id="bty223-B40">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Teng</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) Chiron: translating nanopore raw signal directly into nucleotide sequence using deep learning. <italic>GigaScience</italic>, doi.org/10.1101/179531.</mixed-citation>
    </ref>
    <ref id="bty223-B41">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Trigeorgis</surname><given-names>G.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) Deep canonical time warping. In: <italic>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic>, pp. 5110–5118.</mixed-citation>
    </ref>
    <ref id="bty223-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vaser</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Fast and accurate de novo genome assembly from long uncorrected reads</article-title>. <source>Genome Res</source>., <volume>27</volume>, <fpage>737</fpage>–<lpage>746</lpage>.<pub-id pub-id-type="pmid">28100585</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B43">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Vaswani</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) Attention is all you need. In: <italic>Advances in Neural Information Processing Systems</italic> pp. <fpage>6000</fpage>–<lpage>6010</lpage>.</mixed-citation>
    </ref>
    <ref id="bty223-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wu</surname><given-names>A.R.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Single-cell transcriptional analysis</article-title>. <source>Annu. Rev. Anal. Chem</source>., <volume>10</volume>, <fpage>439</fpage>–<lpage>462</lpage>.</mixed-citation>
    </ref>
    <ref id="bty223-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yang</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Nanosim: nanopore sequence read simulator based on statistical characterization</article-title>. <source>GigaScience</source>, <volume>6</volume>, <fpage>1</fpage>–<lpage>6</lpage>.</mixed-citation>
    </ref>
    <ref id="bty223-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zeng</surname><given-names>F.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Pyrohmmvar: a sensitive and accurate method to call short indels and snps for ion torrent and 454 data</article-title>. <source>Bioinformatics</source>, <volume>29</volume>, <fpage>2859</fpage>–<lpage>2868</lpage>.<pub-id pub-id-type="pmid">23995392</pub-id></mixed-citation>
    </ref>
    <ref id="bty223-B47">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) Deep mutual learning. <italic>arXiv preprint arXiv:1706.00384</italic>.</mixed-citation>
    </ref>
  </ref-list>
</back>
