<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Am Med Inform Assoc</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Am Med Inform Assoc</journal-id>
    <journal-id journal-id-type="publisher-id">jamia</journal-id>
    <journal-title-group>
      <journal-title>Journal of the American Medical Informatics Association : JAMIA</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1067-5027</issn>
    <issn pub-type="epub">1527-974X</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8363782</article-id>
    <article-id pub-id-type="pmid">34157094</article-id>
    <article-id pub-id-type="doi">10.1093/jamia/ocab090</article-id>
    <article-id pub-id-type="publisher-id">ocab090</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research and Applications</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/MED00580</subject>
        <subject>AcademicSubjects/SCI01060</subject>
        <subject>AcademicSubjects/SCI01530</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Biomedical and clinical English model packages for the Stanza Python NLP library</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Yuhao</given-names>
        </name>
        <xref rid="ocab090-cor1" ref-type="corresp"/>
        <xref rid="ocab090-aff1" ref-type="aff">1</xref>
        <!--yuhao.zhang@stanford.edu-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Yuhui</given-names>
        </name>
        <xref rid="ocab090-aff2" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Qi</surname>
          <given-names>Peng</given-names>
        </name>
        <xref rid="ocab090-aff2" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Manning</surname>
          <given-names>Christopher D</given-names>
        </name>
        <xref rid="ocab090-aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Langlotz</surname>
          <given-names>Curtis P</given-names>
        </name>
        <xref rid="ocab090-aff4" ref-type="aff">4</xref>
      </contrib>
    </contrib-group>
    <aff id="ocab090-aff1"><label>1</label><institution>Biomedical Informatics Training Program, Stanford University</institution>, Stanford, California, <country country="US">USA</country></aff>
    <aff id="ocab090-aff2"><label>2</label><institution>Computer Science Department, Stanford University</institution>, Stanford, California, <country country="US">USA</country></aff>
    <aff id="ocab090-aff3"><label>3</label><institution>Computer Science and Linguistics Departments, Stanford University</institution>, Stanford, California, <country country="US">USA</country></aff>
    <aff id="ocab090-aff4"><label>4</label><institution>Department of Radiology, Stanford University</institution>, Stanford, California, <country country="US">USA</country></aff>
    <author-notes>
      <corresp id="ocab090-cor1">Corresponding Author: Yuhao Zhang, PhD, Biomedical Informatics Training Program, Stanford University, Stanford, CA 94305, USA; <email>yuhao.zhang@stanford.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>9</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-06-22">
      <day>22</day>
      <month>6</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>22</day>
      <month>6</month>
      <year>2021</year>
    </pub-date>
    <volume>28</volume>
    <issue>9</issue>
    <fpage>1892</fpage>
    <lpage>1899</lpage>
    <history>
      <date date-type="received">
        <day>05</day>
        <month>1</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>05</day>
        <month>4</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>03</day>
        <month>5</month>
        <year>2021</year>
      </date>
      <date date-type="corrected-typeset">
        <day>10</day>
        <month>8</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021. Published by Oxford University Press on behalf of the American Medical Informatics Association.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ocab090.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Objective</title>
        <p>The study sought to develop and evaluate neural natural language processing (NLP) packages for the syntactic analysis and named entity recognition of biomedical and clinical English text.</p>
      </sec>
      <sec id="s2">
        <title>Materials and Methods</title>
        <p>We implement and train biomedical and clinical English NLP pipelines by extending the widely used Stanza library originally designed for general NLP tasks. Our models are trained with a mix of public datasets such as the CRAFT treebank as well as with a private corpus of radiology reports annotated with 5 radiology-domain entities. The resulting pipelines are fully based on neural networks, and are able to perform tokenization, part-of-speech tagging, lemmatization, dependency parsing, and named entity recognition for both biomedical and clinical text. We compare our systems against popular open-source NLP libraries such as CoreNLP and scispaCy, state-of-the-art models such as the BioBERT models, and winning systems from the BioNLP CRAFT shared task.</p>
      </sec>
      <sec id="s3">
        <title>Results</title>
        <p>For syntactic analysis, our systems achieve much better performance compared with the released scispaCy models and CoreNLP models retrained on the same treebanks, and are on par with the winning system from the CRAFT shared task. For NER, our systems substantially outperform scispaCy, and are better or on par with the state-of-the-art performance from BioBERT, while being much more computationally efficient.</p>
      </sec>
      <sec id="s4">
        <title>Conclusions</title>
        <p>We introduce biomedical and clinical NLP packages built for the Stanza library. These packages offer performance that is similar to the state of the art, and are also optimized for ease of use. To facilitate research, we make all our models publicly available. We also provide an online demonstration (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://stanza.run/bio" ext-link-type="uri">http://stanza.run/bio</ext-link>).</p>
      </sec>
    </abstract>
    <kwd-group>
      <kwd>natural language processing</kwd>
      <kwd>machine learning</kwd>
      <kwd>syntactic analysis</kwd>
      <kwd>dependency parsing</kwd>
      <kwd>named entity recognition</kwd>
    </kwd-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro">
    <title>INTRODUCTION</title>
    <p>A large portion of biomedical knowledge and clinical communication is encoded in free-text biomedical literature or clinical notes.<xref rid="ocab090-B1" ref-type="bibr"><sup>1</sup></xref><sup>,</sup><xref rid="ocab090-B2" ref-type="bibr"><sup>2</sup></xref> The biomedical and clinical natural language processing (NLP) communities have made substantial efforts to unlock this knowledge, by building systems that are able to extract information,<xref rid="ocab090-B3" ref-type="bibr"><sup>3</sup></xref><sup>,</sup><xref rid="ocab090-B4" ref-type="bibr"><sup>4</sup></xref> answer questions,<xref rid="ocab090-B5" ref-type="bibr"><sup>5</sup></xref><sup>,</sup><xref rid="ocab090-B6" ref-type="bibr"><sup>6</sup></xref> or understand conversations<xref rid="ocab090-B7" ref-type="bibr"><sup>7</sup></xref> from biomedical and clinical text.</p>
    <p>NLP toolkits that are able to understand the linguistic structure of biomedical and clinical textand extract information from it are often used as the first step of building such systems.<xref rid="ocab090-B8" ref-type="bibr"><sup>8</sup></xref><sup>,</sup><xref rid="ocab090-B9" ref-type="bibr"><sup>9</sup></xref> Existing general-purpose NLP toolkits are optimized for high performance and ease of use but are not easily adapted to the biomedical domain with state-of-the-art performance. For example, the Stanford CoreNLP library<xref rid="ocab090-B10" ref-type="bibr"><sup>10</sup></xref> and the spaCy library (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://spacy.io/" ext-link-type="uri">https://spacy.io/</ext-link>), despite being widely used by the NLP community, do not provide customized models for biomedical language processing. The recent scispaCy toolkit<xref rid="ocab090-B11" ref-type="bibr"><sup>11</sup></xref> extends spaCy’s coverage to the biomedical domain, yet it does not provide state-of-the-art performance on syntactic analysis or entity recognition tasks, and does not offer models customized to clinical text processing.</p>
    <p>In addition to general-purpose NLP toolkits, several NLP toolkits specialized for processing biomedical or clinical text are available. For example, Mayo Clinic’s cTAKES (Clinical Text Analysis and Knowledge Extraction System) provides a dictionary-based named-entity recognizer to find Uniﬁed Medical Language System Metathesaurus terms<xref rid="ocab090-B12" ref-type="bibr"><sup>12</sup></xref> in text, in addition to other NLP functionalities, such as tokenization, part of speech tagging, and parsing.<xref rid="ocab090-B13" ref-type="bibr"><sup>13</sup></xref> Other similar packages include the Health Information Text Extraction (HITEx) library,<xref rid="ocab090-B14" ref-type="bibr"><sup>14</sup></xref> the MetaMap toolkit,<xref rid="ocab090-B15" ref-type="bibr"><sup>15</sup></xref> and the CLAMP clinical NLP toolkit.<xref rid="ocab090-B16" ref-type="bibr"><sup>16</sup></xref> These packages often integrate sophisticated domain-specific features crafted by experts, yet they fall short of integrating modern deep learning–based models that offer much more accurate performance than traditional rule-based or machine learning methods. Moreover, as Python becomes a common language of choice in the biomedical data science community,<xref rid="ocab090-B17" ref-type="bibr"><sup>17</sup></xref> the lack of native Python support has significantly limited users’ ability to adopt these toolkits and integrate them with modern computational libraries such as the deep learning libraries.</p>
    <p>The recently introduced Stanza NLP library<xref rid="ocab090-B18" ref-type="bibr"><sup>18</sup></xref> offers state-of-the-art syntactic analysis and NER functionality with native Python support. Its fully neural pipeline design enables extension of its language processing capabilities to the biomedical and clinical domain. In this study, we present biomedical and clinical English model packages for the Stanza library (<xref rid="ocab090-F1" ref-type="fig">Figure 1</xref>). These packages are built on top of Stanza’s neural system, and offer syntactic analysis support for biomedical and clinical text, including tokenization, lemmatization, part-of-speech (POS) tagging, and dependency parsing, based on the Universal Dependencies v2 (UDv2) formalism,<xref rid="ocab090-B19" ref-type="bibr"><sup>19</sup></xref> and highly accurate named entity recognition (NER) capabilities covering a wide variety of domains.</p>
    <fig position="float" id="ocab090-F1">
      <label>Figure 1.</label>
      <caption>
        <p>Overview of the biomedical and clinical English model packages in the Stanza NLP library. For syntactic analysis, an example output from the CRAFT biomedical pipeline is shown; for named entity recognition, an example output from the i2b2 clinical model is shown.</p>
      </caption>
      <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ocab090f1" position="float"/>
    </fig>
    <p>These packages include 2 UD-compatible biomedical syntactic analysis pipelines trained on the publicly available CRAFT<xref rid="ocab090-B20" ref-type="bibr"><sup>20</sup></xref> and GENIA<xref rid="ocab090-B8" ref-type="bibr"><sup>8</sup></xref> treebanks, respectively; a UD-compatible clinical syntactic analysis pipeline, trained with a silver-standard treebank created from clinical notes in the MIMIC-III (Medical Information Mart for Intensive Care-III) database<xref rid="ocab090-B21" ref-type="bibr"><sup>21</sup></xref>; 8 accurate biomedical NER models augmented with contextualized representations, achieving near state-of-the-art performance; and 2 clinical NER models, including a newly introduced model specialized in recognizing entities in clinical radiology reports.</p>
    <p>We show through a variety of experiments that these packages achieve performance that meets or surpasses state-of-the-art results. We further show via examples and benchmarking that these packages are easy to use and do not compromise speed, especially when GPU acceleration is available. We hope that our packages will facilitate future research to analyze and understand biomedical and clinical text.</p>
  </sec>
  <sec>
    <title>MATERIALS AND METHODS</title>
    <sec>
      <title>Syntactic analysis modules and implementations</title>
      <p>Stanza’s syntactic analysis pipeline consists of modules for tokenization, sentence segmentation, POS tagging, lemmatization, and dependency parsing. All modules are implemented as neural network models. We briefly introduce each component in turn and refer readers to the Stanza system paper<xref rid="ocab090-B18" ref-type="bibr"><sup>18</sup></xref> for details.</p>
      <sec>
        <title>Tokenization and sentence splitting</title>
        <p>The first step of text analysis is usually tokenization and sentence segmentation. In Stanza, these 2 tasks are jointly modeled as a tagging problem over character sequences, in which the model predicts whether a given character is the end of a token, a sentence, or neither. This joint task is realized with a lightweight recurrent neural network. We choose to combine these tasks because they are usually context-sensitive and can benefit from joint inference to reduce ambiguity.</p>
      </sec>
      <sec>
        <title>POS tagging</title>
        <p>Once the text is tokenized, Stanza predicts the POS tags for each word in each sentence.</p>
        <p>We adopt a bidirectional long short-term memory network (BiLSTM) as the basic architecture to predict both the language-specific POS (XPOS) tags and the universal POS (UPOS) tags.</p>
        <p>We further adapt the biaffine scoring mechanism from the biaffine neural parser<xref rid="ocab090-B22" ref-type="bibr"><sup>22</sup></xref> to condition XPOS prediction on that of UPOS, which improves the prediction consistency between XPOS and UPOS tags.<xref rid="ocab090-B23" ref-type="bibr"><sup>23</sup></xref></p>
      </sec>
      <sec>
        <title>Lemmatization</title>
        <p>In many practical downstream applications, it is useful to recover the canonical form of a word by lemmatizing it (eg, recovering the lemma form <italic toggle="yes">do</italic> from the word <italic toggle="yes">did</italic>) for better pattern matching. Stanza’s lemmatizer is implemented as an ensemble of a dictionary-based lemmatizer and a neural sequence-to-sequence lemmatizer that operate on character sequences. An additional classifier is built on the encoder output of the seq2seq model, to predict <italic toggle="yes">shortcut operations</italic> such as lowercasing the input word or using an exact copy of the input word as lemma. These shortcut operations improve the robustness of the neural lemmatizer on long input character sequences such as URLs by avoiding the unnecessary generation of very long sequences.</p>
      </sec>
      <sec>
        <title>Dependency parsing</title>
        <p>To analyze the syntactic structure of each sentence, Stanza parses it into the UD format,<xref rid="ocab090-B19" ref-type="bibr"><sup>19</sup></xref> in which each word in a sentence is assigned a syntactic head that is either another word in the sentence, or in the case of the root word, an artificial <italic toggle="yes">root</italic> symbol. The dependency parser in Stanza is a variant of the BiLSTM-based deep biaffine neural dependency parser<xref rid="ocab090-B22" ref-type="bibr"><sup>22</sup></xref> that Qi et al<xref rid="ocab090-B23" ref-type="bibr"><sup>23</sup></xref> have modified for improved accuracy.</p>
      </sec>
    </sec>
    <sec>
      <title>Biomedical syntactic analysis pipeline</title>
      <p>We provide 2 separate syntactic analysis pipelines for biomedical text by training Stanza’s neural syntactic pipeline on 2 publicly available biomedical treebanks: the CRAFT treebank<xref rid="ocab090-B20" ref-type="bibr"><sup>20</sup></xref> and the GENIA treebank.<xref rid="ocab090-B8" ref-type="bibr"><sup>8</sup></xref><sup>,</sup><xref rid="ocab090-B24" ref-type="bibr"><sup>24</sup></xref> The 2 treebanks differ in 2 main ways. First, while GENIA is collected from PubMed abstracts related to “human,” “blood cells,” and “transcription factors,” CRAFT is collected from full-text articles related to the Mouse Genome Informatics database. Second, while the CRAFT treebank tokenizes segments of hyphenated words separately (eg, <italic toggle="yes">up-regulation</italic> tokenized into <italic toggle="yes">up—regulation</italic>), the GENIA treebank treats hyphenated words as single tokens.</p>
      <p>Because both treebanks provide only Penn Treebank annotations in their original releases, to train our neural pipeline, we first convert both of them into UDv2<xref rid="ocab090-B19" ref-type="bibr"><sup>19</sup></xref> format annotations, using the UD converter<xref rid="ocab090-B25" ref-type="bibr"><sup>25</sup></xref> in the Stanford CoreNLP library.<xref rid="ocab090-B10" ref-type="bibr"><sup>10</sup></xref> To facilitate future research we have made the converted files publicly available (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://nlp.stanford.edu/projects/stanza/bio/" ext-link-type="uri">https://nlp.stanford.edu/projects/stanza/bio/</ext-link>).</p>
      <sec>
        <title>Treebank combination</title>
        <p>Because the tokenization in the CRAFT treebank is fully compatible with that in the general UD English treebanks, in practice we found it beneficial to combine the English Web Treebank (EWT)<xref rid="ocab090-B26" ref-type="bibr"><sup>26</sup></xref> with the CRAFT treebank for training the CRAFT syntactic analysis pipeline. We show later via experiments that this treebank combination improves the robustness of the resulting pipeline on both general and in-domain text.</p>
      </sec>
    </sec>
    <sec>
      <title>Clinical syntactic analysis pipeline</title>
      <p>Unlike the biomedical domain, no large annotated treebanks for clinical text are publicly available.</p>
      <p>Therefore, to build a syntactic analysis pipeline that generalizes well to the clinical domain, we created a silver-standard treebank by making use of the publicly available clinical notes in the MIMIC-III database.<xref rid="ocab090-B21" ref-type="bibr"><sup>21</sup></xref> The creation of this treebank is based on 2 main observations made via qualitative analysis over sampled clinical notes from the MIMIC-III database. First, we find that Stanza’s neural syntactic analysis pipeline trained on general English treebanks generalizes reasonably well to well-formatted text in the clinical domain. Second, the highly optimized rule-based tokenizer in the Stanford CoreNLP library produces more accurate and consistent tokenization and sentence segmentation on clinical text than the neural tokenizer in Stanza trained on a single treebank. For example, while the neural tokenizer trained on a general English treebank tends to produce inconsistent sentence segmentations in the presence of consecutive punctuation marks or spaces in a sentence, the CoreNLP tokenizer handles these cases in a much more consistent and accurate manner.</p>
      <p>Based on these observations, we create a silver-standard MIMIC treebank with the following procedure. First, we randomly sample 800 clinical notes of all types from the MIMIC-III database, and stratify the notes into training/dev/test splits with 600/100/100 clinical notes, respectively. These numbers are chosen to create a treebank of similar size to the general English EWT treebank. Second, we tokenize and sentence-segment the sampled notes with the default CoreNLP tokenizer. Third, we pretrain Stanza’s general English syntactic analysis pipeline on the EWT treebank, then run it on the pretokenized notes, and produce syntactic annotations following the UDv2 format. Fourth, to improve the robustness of the resulting models trained on this treebank, similar to the CRAFT pipeline, we concatenate the training split of the original EWT treebank with this silver-standard MIMIC treebank. We show later via experiments that this treebank combination again improves the robustness of the resulting pipeline on syntactic analysis tasks. A diagram that illustrates this whole training procedure is shown in <xref rid="ocab090-F2" ref-type="fig">Figure 2</xref>.</p>
      <fig position="float" id="ocab090-F2">
        <label>Figure 2.</label>
        <caption>
          <p>Training diagram of the Stanza MIMIC clinical syntactic analysis models. Sampled MIMIC-III (Medical Information Mart for Intensive Care-III) clinical notes are first tokenized and sentence-segmented with the CoreNLP tokenizer, and then syntactically annotated with the pretrained Stanza general English syntactic models. The derived silver-standard treebank is then concatenated with the original English Web Treebank (EWT) treebank and used for training the Stanza clinical syntactic models.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ocab090f2" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>NER models</title>
      <p>Stanza’s NER component adopts the architecture of the contextualized string representation-based sequence tagger.<xref rid="ocab090-B27" ref-type="bibr"><sup>27</sup></xref> For each domain, we train a forward and a backward LSTM character-level language model (CharLM) to supplement the word representation in each sentence. At tagging time, we concatenate the representations from these CharLMs at each word position with a word embedding, and feed the result into a standard 1-layer BiLSTM sequence tagger with a conditional random field–based decoder. The pretrained CharLMs provide rich domain-specific representations that notably improve the accuracy of the NER models.</p>
      <sec>
        <title>Biomedical NER models</title>
        <p>For the biomedical domain, we provide 8 individual NER models trained on 8 publicly available biomedical NER datasets: AnatEM,<xref rid="ocab090-B28" ref-type="bibr"><sup>28</sup></xref> BC5CDR,<xref rid="ocab090-B29" ref-type="bibr"><sup>29</sup></xref> BC4CHEMD,<xref rid="ocab090-B30" ref-type="bibr"><sup>30</sup></xref> BioNLP13CG,<xref rid="ocab090-B31" ref-type="bibr"><sup>31</sup></xref> JNLPBA,<xref rid="ocab090-B32" ref-type="bibr"><sup>32</sup></xref> Linnaeus,<xref rid="ocab090-B33" ref-type="bibr"><sup>33</sup></xref> NCBI-Disease,<xref rid="ocab090-B34" ref-type="bibr"><sup>34</sup></xref> and S800.<xref rid="ocab090-B35" ref-type="bibr"><sup>35</sup></xref> These models cover a wide variety of entity types in domains ranging from anatomical analysis to genetics and cellular biology. For training, we use preprocessed versions of these datasets provided by Wang et al.<xref rid="ocab090-B36" ref-type="bibr"><sup>36</sup></xref></p>
      </sec>
      <sec>
        <title>Clinical NER models</title>
        <p>Our clinical-domain NER system contains 2 individually trained models. First, we provide a general-purpose NER model trained on the 2010 i2b2/VA dataset<xref rid="ocab090-B37" ref-type="bibr"><sup>37</sup></xref> that extracts problem, test, and treatment entities from various types of clinical notes. Second, we also provide a new radiology NER model, which extracts 5 types of entities from radiology reports: <italic toggle="yes">anatomy</italic>, <italic toggle="yes">observation</italic>, <italic toggle="yes">anatomy modifier</italic>, <italic toggle="yes">observation modifier</italic>, and <italic toggle="yes">uncertainty</italic>. The training dataset of this NER model consists of 150 chest computed tomography radiology reports collected from 3 individual hospitals.<xref rid="ocab090-B38" ref-type="bibr"><sup>38</sup></xref> Two radiologists were trained to annotate the reports with 5 entity types with an estimated Cohen's kappa interannotator agreement of 0.75. For full details of the entity types and corpora used in this dataset, we refer the readers to Hassanpour and Langlotz.<xref rid="ocab090-B38" ref-type="bibr"><sup>38</sup></xref></p>
        <p>For all biomedical and clinical NER datasets used in our study, we provide a detailed description of their supported entity types and their statistics in <xref rid="sup1" ref-type="supplementary-material">Supplementary Appendix</xref> B.</p>
      </sec>
      <sec>
        <title>CharLM training corpora</title>
        <p>For the biomedical NER models, we pretrain both the forward and backward CharLMs on the publicly available PubMed abstracts. For computational efficiency, we sampled about half of the 2020 PubMed Baseline dump (<underline>ftp://ftp.ncbi.nlm.nih.gov/pubmed/baseline</underline>) as our training corpus, which includes about 2.1 billion tokens. For the clinical NER models, we pretrain the CharLMs on all types of the MIMIC-III<xref rid="ocab090-B21" ref-type="bibr"><sup>21</sup></xref> clinical notes. During preprocessing of these notes, we exclude sentences in which at least 1 anonymization mask is applied (eg, <italic toggle="yes">[**First Name8 (NamePattern2)**]</italic>), to prevent the prevalence of such masks from polluting the representations learned by the CharLMs. The final corpus for training the clinical CharLMs includes about 0.4 billion tokens.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="results">
    <title>RESULTS</title>
    <sec>
      <title>Syntactic analysis performance</title>
      <p>We compare Stanza’s syntactic analysis performance mainly with CoreNLP and scispaCy, and present the results in <xref rid="ocab090-T1" ref-type="table">Table 1</xref>. We focus on evaluating the end-to-end performance of all toolkits starting from raw text. In this evaluation setup, a system takes raw text as input, and each module makes predictions by taking outputs from its previous modules. This setup is more challenging than using gold tokenized text and other annotations as input to downstream modules, as used in a lot of previous evaluations. For quantitative evaluation of the syntactic pipeline, we adopt the official evaluation metrics used in the CoNLL 2018 Universal Dependencies Shared Task. We include detailed descriptions of our metrics in <xref rid="sup1" ref-type="supplementary-material">Supplementary Appendix</xref> A, and refer the readers to the shared task official website for in-depth introductions (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://universaldependencies.org/conll18/evaluation.html" ext-link-type="uri">https://universaldependencies.org/conll18/evaluation.html</ext-link>).</p>
      <table-wrap position="float" id="ocab090-T1">
        <label>Table 1.</label>
        <caption>
          <p>Neural syntactic analysis pipeline performance</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Treebank</th>
              <th rowspan="1" colspan="1">System</th>
              <th rowspan="1" colspan="1">Tokens</th>
              <th rowspan="1" colspan="1">Sents.</th>
              <th rowspan="1" colspan="1">UPOS</th>
              <th rowspan="1" colspan="1">XPOS</th>
              <th rowspan="1" colspan="1">Lemmas</th>
              <th rowspan="1" colspan="1">UAS</th>
              <th rowspan="1" colspan="1">LAS</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="3" colspan="1">CRAFT</td>
              <td rowspan="1" colspan="1">Stanza</td>
              <td rowspan="1" colspan="1">99.66</td>
              <td rowspan="1" colspan="1">99.16</td>
              <td rowspan="1" colspan="1">98.18</td>
              <td rowspan="1" colspan="1">97.95</td>
              <td rowspan="1" colspan="1">98.92</td>
              <td rowspan="1" colspan="1">91.09</td>
              <td rowspan="1" colspan="1">89.67</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CoreNLP</td>
              <td rowspan="1" colspan="1">98.80</td>
              <td rowspan="1" colspan="1">98.45</td>
              <td rowspan="1" colspan="1">93.65</td>
              <td rowspan="1" colspan="1">96.56</td>
              <td rowspan="1" colspan="1">97.99</td>
              <td rowspan="1" colspan="1">83.59</td>
              <td rowspan="1" colspan="1">81.81</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">scispaCy</td>
              <td rowspan="1" colspan="1">91.49</td>
              <td rowspan="1" colspan="1">97.47</td>
              <td rowspan="1" colspan="1">83.81</td>
              <td rowspan="1" colspan="1">89.67</td>
              <td rowspan="1" colspan="1">89.39</td>
              <td rowspan="1" colspan="1">79.08</td>
              <td rowspan="1" colspan="1">77.74</td>
            </tr>
            <tr>
              <td rowspan="3" colspan="1">GENIA</td>
              <td rowspan="1" colspan="1">Stanza</td>
              <td rowspan="1" colspan="1">99.81</td>
              <td rowspan="1" colspan="1">99.78</td>
              <td rowspan="1" colspan="1">98.81</td>
              <td rowspan="1" colspan="1">98.76</td>
              <td rowspan="1" colspan="1">99.58</td>
              <td rowspan="1" colspan="1">91.01</td>
              <td rowspan="1" colspan="1">89.48</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CoreNLP</td>
              <td rowspan="1" colspan="1">98.22</td>
              <td rowspan="1" colspan="1">97.20</td>
              <td rowspan="1" colspan="1">93.40</td>
              <td rowspan="1" colspan="1">96.98</td>
              <td rowspan="1" colspan="1">97.97</td>
              <td rowspan="1" colspan="1">84.75</td>
              <td rowspan="1" colspan="1">83.16</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">scispaCy</td>
              <td rowspan="1" colspan="1">98.88</td>
              <td rowspan="1" colspan="1">97.18</td>
              <td rowspan="1" colspan="1">89.84</td>
              <td rowspan="1" colspan="1">97.55</td>
              <td rowspan="1" colspan="1">97.02</td>
              <td rowspan="1" colspan="1">88.15</td>
              <td rowspan="1" colspan="1">86.57</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">MIMIC</td>
              <td rowspan="1" colspan="1">Stanza</td>
              <td rowspan="1" colspan="1">99.18</td>
              <td rowspan="1" colspan="1">97.11</td>
              <td rowspan="1" colspan="1">95.64</td>
              <td rowspan="1" colspan="1">95.25</td>
              <td rowspan="1" colspan="1">97.37</td>
              <td rowspan="1" colspan="1">85.44</td>
              <td rowspan="1" colspan="1">82.81</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CoreNLP</td>
              <td rowspan="1" colspan="1">100.00</td>
              <td rowspan="1" colspan="1">100.00</td>
              <td rowspan="1" colspan="1">94.08</td>
              <td rowspan="1" colspan="1">94.53</td>
              <td rowspan="1" colspan="1">95.84</td>
              <td rowspan="1" colspan="1">78.92</td>
              <td rowspan="1" colspan="1">74.94</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p>All results are F<sub>1</sub> scores produced by the 2018 UD Shared Task official evaluation script. All CoreNLP (v4.0.0) and scispaCy (v0.2.5) results are from models retrained on the corresponding treebanks. UPOS results for scispaCy are generated by manually converting XPOS predictions to UPOS tags with the conversion script provided by spaCy. For scispaCy results, the <italic toggle="yes">scispacy-large</italic> models are used. Note that the MIMIC results are based on silver-standard training and evaluation data as described previously.</p>
          </fn>
          <fn id="tblfn2">
            <p>LAS: labeled attachment score; MIMIC: Medical Information Mart for Intensive Care; UAS: unlabeled attachment score; UPOS: universal part of speech; XPOS: language part of speech.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>For fair comparisons, for both CoreNLP and scispaCy, we present their results by retraining their pipelines on the corresponding treebanks using the official training scripts. scispaCy results are generated by retraining the <italic toggle="yes">scispacy-large</italic> models. For the MIMIC treebank, we do not include a comparison with scispaCy, mainly because we observed a severely degraded performance when applying it to tokenizing and sentence-segmenting clinical notes.</p>
      <p>Notably, we find that Stanza’s neural pipeline generalizes well to all treebanks we evaluate on, and achieves the best results for all components on all treebanks.</p>
      <sec>
        <title>POS and parsing with gold input</title>
        <p>The much lower tokenization performance of scispaCy on the CRAFT treebank is due to different tokenization rules adopted: the tokenizer in scispaCy is originally developed for the GENIA treebank and therefore segments hyphenated words differently from the CRAFT treebank annotations (see Biomedical Pipeline), leading to lower tokenization performance. To understand the underlying syntactic analysis performance without this tokenization difference, we run an individual evaluation on the CRAFT treebank with gold tokenization results provided to the POS tagger and parser at test time. We find that under this gold tokenization setup, Stanza is able to achieve an XPOS F<sub>1</sub> score of 98.40 and a parsing labeled attachment score (LAS) score of 92.10, while CoreNLP achieves 97.67 and 86.17, and scispaCy achieves 97.85 and 87.52 for XPOS and parsing LAS, respectively. Therefore, even with gold tokenization input (and gold POS tags for the parser), Stanza’s neural pipeline still leads to substantially better performance for both POS tagging and UD parsing, with a notable gain of 5.93 and 4.58 LAS compared with CoreNLP and scispaCy, respectively. Our findings are in line with previous observations that a neural biaffine architecture outperforms other models on biomedical syntactic analysis tasks.<xref rid="ocab090-B39" ref-type="bibr"><sup>39</sup></xref></p>
      </sec>
      <sec>
        <title>Comparisons with CRAFT shared tasks 2019 systems</title>
        <p>We further compare our end-to-end syntactic analysis results with the state-of-the-art system in the CRAFT Shared Tasks 2019,<xref rid="ocab090-B9" ref-type="bibr"><sup>9</sup></xref> for which CRAFT is also used as the evaluation treebank. For all systems, we also report results for the official morphology-aware LAS (MLAS) and bi-lexical dependency score (BLEX) metrics, which, apart from dependency predictions, also take POS tags and lemma outputs into account.</p>
        <p>Under this setting, we find that the CRAFT shared task 2019 baseline system, which uses a combination of the NLTK tokenizer<xref rid="ocab090-B40" ref-type="bibr"><sup>40</sup></xref> and the SyntaxNet neural parser<xref rid="ocab090-B41" ref-type="bibr"><sup>41</sup></xref> retrained with the CRAFT treebank, achieves limited performance with LAS = 56.68 and MLAS = 44.22 (no BLEX score due to missing lemma outputs), while our syntactic pipeline trained on the CRAFT dataset achieves a much better performance: LAS = 89.67, MLAS = 86.06, and BLEX = 86.47. For comparisons, the shared task winning system<xref rid="ocab090-B42" ref-type="bibr"><sup>42</sup></xref> reports similar performance, with LAS = 89.70, MLAS = 85.55, and BLEX = 86.63. We note that the results from our system are not directly comparable to those from the shared task, owing to the different dependency parsing formalisms used (i.e., while we use UDv2 parse trees, the shared task used a parsing formalism similar to the older Stanford Dependencies formalism). Nevertheless, these results suggest that the accuracy of our pipeline is on par with that of the CRAFT shared task 2019 winning system, and substantially outperforms the shared task baseline system.</p>
      </sec>
      <sec>
        <title>Effects of using combined treebanks</title>
        <p>To evaluate the effect of using combined treebanks, we train Stanza’s biomedical and clinical syntactic analysis pipeline on each individual treebank as well as the combined treebanks and evaluate their performance on the test set of each individual treebank. We present the results in <xref rid="ocab090-T2" ref-type="table">Table 2</xref>. We find that by combining the biomedical or clinical treebanks with the general English EWT treebank, the resulting model not only is able to preserve its high performance on processing general-domain text, but also achieves marginally better in-domain performance compared with using the biomedical and clinical treebanks alone. For example, while the pipeline trained on the EWT treebank alone is only able to achieve an LAS scoreof 68.99 on the CRAFT test set, the pipeline trained on the combined dataset achieves the overall best LAS score of 89.57 on the CRAFT test set, with only a drop in LAS of 1.2 on the EWT test set. These results suggest that compared with using the in-domain treebank alone, using the combined treebanks improves the robustness of Stanza’s pipeline on both in-domain and general English text.</p>
        <table-wrap position="float" id="ocab090-T2">
          <label>Table 2.</label>
          <caption>
            <p>Comparisons of using combined treebanks vs single treebanks for the biomedical and clinical syntactic analysis pipelines</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th colspan="5" rowspan="1">Biomedical Syntactic Analysis Pipelines</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td colspan="2" rowspan="1">
                  <bold>EWT Test</bold>
                </td>
                <td colspan="2" rowspan="1">
                  <bold>CRAFT Test</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>Training Corpus</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>Token F<sub>1</sub></bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>LAS</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>Token F<sub>1</sub></bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>LAS</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">EWT</td>
                <td rowspan="1" colspan="1">99.01</td>
                <td rowspan="1" colspan="1">83.59</td>
                <td rowspan="1" colspan="1">96.09</td>
                <td rowspan="1" colspan="1">68.99</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CRAFT</td>
                <td rowspan="1" colspan="1">93.67</td>
                <td rowspan="1" colspan="1">60.42</td>
                <td rowspan="1" colspan="1">99.66</td>
                <td rowspan="1" colspan="1">89.58</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Combined</td>
                <td rowspan="1" colspan="1">98.99</td>
                <td rowspan="1" colspan="1">82.37</td>
                <td rowspan="1" colspan="1">99.66</td>
                <td rowspan="1" colspan="1">89.67</td>
              </tr>
              <tr>
                <td colspan="5" rowspan="1">Clinical Syntactic Analysis Pipelines</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td colspan="2" rowspan="1">
                  <bold>EWT Test</bold>
                </td>
                <td colspan="2" rowspan="1">
                  <bold>MIMIC Test</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>Training Corpus</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>Token F<sub>1</sub></bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>LAS</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>Token F<sub>1</sub></bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>LAS</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">EWT</td>
                <td rowspan="1" colspan="1">99.01</td>
                <td rowspan="1" colspan="1">83.59</td>
                <td rowspan="1" colspan="1">92.97</td>
                <td rowspan="1" colspan="1">75.97</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">MIMIC</td>
                <td rowspan="1" colspan="1">94.39</td>
                <td rowspan="1" colspan="1">66.63</td>
                <td rowspan="1" colspan="1">98.70</td>
                <td rowspan="1" colspan="1">81.46</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Combined</td>
                <td rowspan="1" colspan="1">98.84</td>
                <td rowspan="1" colspan="1">82.57</td>
                <td rowspan="1" colspan="1">99.18</td>
                <td rowspan="1" colspan="1">82.81</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn3">
              <p>For the biomedical pipeline we show results for the English EWT treebank and the CRAFT treebank; for the clinical pipeline we show results for the English EWT treebank and a silver-standard MIMIC treebank. For each test set, tokenization F<sub>1</sub> and LAS scores are shown for models trained with each treebank alone and a combined treebank.</p>
            </fn>
            <fn id="tblfn4">
              <p>EWT: English Web Treebank; LAS: labeled attachment score; MIMIC: Medical Information Mart for Intensive Care.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
    </sec>
    <sec>
      <title>NER performance</title>
      <p>We mainly compare Stanza’s NER performance to BioBERT, which achieves state-of-the-art performance on most of the datasets tested, and scispaCy in <xref rid="ocab090-T3" ref-type="table">Table 3</xref>. For both toolkits, we compare with their official reported results.<xref rid="ocab090-B4" ref-type="bibr"><sup>4</sup></xref><sup>,</sup><xref rid="ocab090-B11" ref-type="bibr"><sup>11</sup></xref> We find that on most datasets tested, Stanza’s NER performance is on par with or superior to the strong performance achieved by BioBERT, despite using considerably more compact models. A substantial difference is observed on the BC4CHEMD and NCBI-Disease datasets, where BioBERT leads by 2.71 and 2.22 in F<sub>1</sub>, respectively, and on the S800 dataset, in which Stanza leads by 2.29 in F<sub>1</sub> score. Compared with scispaCy, Stanza achieves substantially higher performance on all datasets tested. On the newly introduced Radiology dataset, Stanza achieves an overall F<sub>1</sub> score of 84.80 micro-averaged over 5 entity types.</p>
      <table-wrap position="float" id="ocab090-T3">
        <label>Table 3.</label>
        <caption>
          <p>Named entity recognition performance across different datasets in the biomedical and clinical domains</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Category</th>
              <th rowspan="1" colspan="1">Dataset</th>
              <th rowspan="1" colspan="1">Domain (# of Entities)</th>
              <th rowspan="1" colspan="1">Stanza</th>
              <th rowspan="1" colspan="1">BioBERT</th>
              <th rowspan="1" colspan="1">scispaCy</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="8" colspan="1">Bio</td>
              <td rowspan="1" colspan="1">AnatEM</td>
              <td rowspan="1" colspan="1">Anatomy (1)</td>
              <td rowspan="1" colspan="1">88.18</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">84.14</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BC5CDR</td>
              <td rowspan="1" colspan="1">Chemical, Disease (2)</td>
              <td rowspan="1" colspan="1">88.08</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">83.92</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BC4CHEMD</td>
              <td rowspan="1" colspan="1">Chemical (1)</td>
              <td rowspan="1" colspan="1">89.65</td>
              <td rowspan="1" colspan="1">92.36</td>
              <td rowspan="1" colspan="1">84.55</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioNLP13CG</td>
              <td rowspan="1" colspan="1">Cancer Genetics (16)</td>
              <td rowspan="1" colspan="1">84.34</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">77.60</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">JNLPBA</td>
              <td rowspan="1" colspan="1">Protein, DNA, RNA, Cell line, Cell type (5)</td>
              <td rowspan="1" colspan="1">76.09</td>
              <td rowspan="1" colspan="1">77.49</td>
              <td rowspan="1" colspan="1">73.21</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Linnaeus</td>
              <td rowspan="1" colspan="1">Species (1)</td>
              <td rowspan="1" colspan="1">88.27</td>
              <td rowspan="1" colspan="1">88.24</td>
              <td rowspan="1" colspan="1">81.74</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">NCBI-Disease</td>
              <td rowspan="1" colspan="1">Disease (1)</td>
              <td rowspan="1" colspan="1">87.49</td>
              <td rowspan="1" colspan="1">89.71</td>
              <td rowspan="1" colspan="1">81.65</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">S800</td>
              <td rowspan="1" colspan="1">Species (1)</td>
              <td rowspan="1" colspan="1">76.35</td>
              <td rowspan="1" colspan="1">74.06</td>
              <td rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">Clinical</td>
              <td rowspan="1" colspan="1">i2b2</td>
              <td rowspan="1" colspan="1">Problem, Test, Treatment (3)</td>
              <td rowspan="1" colspan="1">88.13</td>
              <td rowspan="1" colspan="1">86.73</td>
              <td rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Radiology</td>
              <td rowspan="1" colspan="1">Radiology Report (5)</td>
              <td rowspan="1" colspan="1">84.80</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">–</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn5">
            <p>All scores reported are entity micro-averaged test F<sub>1</sub>. For each dataset, we also list the domain and number of its entity types. BioBERT results are from the v1.1 models reported by Lee et al<xref rid="ocab090-B4" ref-type="bibr"><sup>4</sup></xref>; scispaCy results are from the <italic toggle="yes">scispacy-medium</italic> models reported by Neumann et al.<xref rid="ocab090-B11" ref-type="bibr"><sup>11</sup></xref></p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>In addition to BioBERT, we also compare Stanza’s performance with SciBERT,<xref rid="ocab090-B43" ref-type="bibr"><sup>43</sup></xref> which achieves F<sub>1</sub> scores of 90.01, 77.28, and 88.57 on the BC5CDR, JNLPBA, and NCBI-Disease datasets, respectively, and ClinicalBERT,<xref rid="ocab090-B44" ref-type="bibr"><sup>44</sup></xref> which achieves an F<sub>1</sub> score of 86.4 on the i2b2 dataset. We find that Stanza’s performance is on par with or better than the strong performance offered by SciBERT and ClinicalBERT, too.</p>
      <sec>
        <title>Effects of pretrained character LMs</title>
        <p>To understand the effect of using the domain-specific pretrained CharLMs in NER models, on each dataset we also trained a baseline NER model in which the pretrained LM is replaced by a randomly initialized character-level BiLSTM, which is fine-tuned with other components during training. We compare Stanza’s full NER performance with this baseline model in <xref rid="ocab090-T4" ref-type="table">Table 4</xref>. We find that by pretraining Stanza’s CharLMs on large corpora, we are able to achieve an average gain of in F<sub>1</sub> score of 2.91 and 1.94 on the biomedical and clinical NER datasets, respectively.</p>
        <table-wrap position="float" id="ocab090-T4">
          <label>Table 4.</label>
          <caption>
            <p>Named entity recognition performance comparison between Stanza and a baseline BiLSTM-CRF model without character language models pretrained on large corpora</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Category</th>
                <th rowspan="1" colspan="1">Dataset</th>
                <th rowspan="1" colspan="1">Baseline</th>
                <th rowspan="1" colspan="1">Stanza</th>
                <th rowspan="1" colspan="1">Δ</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="9" colspan="1">Bio</td>
                <td rowspan="1" colspan="1">AnatEM</td>
                <td rowspan="1" colspan="1">85.14</td>
                <td rowspan="1" colspan="1">88.18</td>
                <td rowspan="1" colspan="1">+3.04</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">BC5CDR</td>
                <td rowspan="1" colspan="1">86.14</td>
                <td rowspan="1" colspan="1">88.08</td>
                <td rowspan="1" colspan="1">+1.94</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">BC4CHEMD</td>
                <td rowspan="1" colspan="1">87.45</td>
                <td rowspan="1" colspan="1">89.65</td>
                <td rowspan="1" colspan="1">+2.20</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">BioNLP13CG</td>
                <td rowspan="1" colspan="1">82.09</td>
                <td rowspan="1" colspan="1">84.34</td>
                <td rowspan="1" colspan="1">+2.25</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">JNLPBA</td>
                <td rowspan="1" colspan="1">75.29</td>
                <td rowspan="1" colspan="1">76.09</td>
                <td rowspan="1" colspan="1">+0.80</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Linnaeus</td>
                <td rowspan="1" colspan="1">83.74</td>
                <td rowspan="1" colspan="1">88.27</td>
                <td rowspan="1" colspan="1">+4.53</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">NCBI-Disease</td>
                <td rowspan="1" colspan="1">84.04</td>
                <td rowspan="1" colspan="1">87.49</td>
                <td rowspan="1" colspan="1">+3.45</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">S800</td>
                <td rowspan="1" colspan="1">71.30</td>
                <td rowspan="1" colspan="1">76.35</td>
                <td rowspan="1" colspan="1">+5.05</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Average (8 datasets)</td>
                <td rowspan="1" colspan="1">81.90</td>
                <td rowspan="1" colspan="1">84.81</td>
                <td rowspan="1" colspan="1">+2.91</td>
              </tr>
              <tr>
                <td rowspan="3" colspan="1">Clinical</td>
                <td rowspan="1" colspan="1">i2b2</td>
                <td rowspan="1" colspan="1">86.04</td>
                <td rowspan="1" colspan="1">88.08</td>
                <td rowspan="1" colspan="1">+2.04</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Radiology</td>
                <td rowspan="1" colspan="1">83.01</td>
                <td rowspan="1" colspan="1">84.80</td>
                <td rowspan="1" colspan="1">+1.79</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Average (2 datasets)</td>
                <td rowspan="1" colspan="1">84.53</td>
                <td rowspan="1" colspan="1">86.47</td>
                <td rowspan="1" colspan="1">+1.94</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn6">
              <p>For both the biomedical and clinical models, an average difference over 8 models and 2 models are shown in the last column, respectively.</p>
            </fn>
            <fn id="tblfn7">
              <p>BiLSTM-CRF: bidirectional long short-term memory network conditional random field.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
    </sec>
    <sec>
      <title>Speed comparisons</title>
      <p>We compare the speed of Stanza with CoreNLP and scispaCy on syntactic analysis tasks, and with scispaCy and BioBERT on the NER task (for BioBERT, we implemented our own code to run inference on the test data, as an inference API is not provided in the BioBERT official repository). We use the CRAFT test set, which contains about 1.2 million raw characters, for benchmarking the syntactic analysis pipeline, and the test split of the JNLPBA NER dataset, which contains about 101k tokens, for benchmarking the NER task. Apart from CPU speed, we also benchmark a toolkit’s speed on GPU whenever GPU acceleration is available. Experiments are run on a machine with 2 Intel Xeon Gold 5222 CPUs (14 cores each). For GPU tests, we use a single NVIDIA Titan RTX card.</p>
      <p>For each of the tasks, we focus on comparing the runtime of each toolkit relative to scispaCy. We find that for syntactic analysis, Stanza’s speed is on par with scispaCy when a GPU is used (1.42× runtime), although it is much slower when only a CPU is available (6.83× runtime vs scispaCy). Even in the CPU setting, Stanza’s biomedical syntactic analysis pipeline is still slightly faster than CoreNLP, which uses 7.23× runtime compared with scispaCy. For NER with GPU acceleration, Stanza’s biomedical models are marginally faster than scispaCy (0.95× runtime vs scispaCy) and are considerably faster than BioBERT (4.59× runtime vs scispaCy). When only CPU is available, Stanza’s biomedical models take much longer time to process text than scispaCy (14.8× runtime) but remain much faster than BioBERT which uses 121× runtime compared with scispaCy.</p>
    </sec>
  </sec>
  <sec sec-type="discussion">
    <title>DISCUSSION</title>
    <sec>
      <title>System usage</title>
      <p>We provide a fully unified Python interface for using Stanza’s biomedical/clinical models and general NLP models. The biomedical and clinical syntactic analysis pipelines can be specified with a <italic toggle="yes">package</italic> keyword. We demonstrate how to download the CRAFT biomedical package and run syntactic analysis for an example sentence in <xref rid="ocab090-F3" ref-type="fig">Figure 3</xref>. For NER, Stanza’s biomedical and clinical models can be specified with a <italic toggle="yes">processors</italic> keyword. We demonstrate how to download the i2b2 clinical NER model along with the MIMIC clinical pipeline, and run NER annotation over an example clinical text in <xref rid="ocab090-F3" ref-type="fig">Figure 3</xref>. To easily integrate with external tokenization libraries, Stanza’s biomedical and clinical pipelines also support annotating text that is pretokenized and sentence-segmented. This can be easily specified with a <italic toggle="yes">tokenize_pretokenized</italic> keyword when initializing the pipelines.</p>
      <fig position="float" id="ocab090-F3">
        <label>Figure 3.</label>
        <caption>
          <p>Example code for using the biomedical syntactic analysis and named entity recognition pipelines in Stanza.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ocab090f3" position="float"/>
      </fig>
      <p>We provide full details on how to use the biomedical and clinical models via online documentation (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://stanfordnlp.github.io/stanza/" ext-link-type="uri">https://stanfordnlp.github.io/stanza/</ext-link>).</p>
    </sec>
  </sec>
  <sec sec-type="conclusion">
    <title>CONCLUSION</title>
    <p>We present the biomedical and clinical model packages in the Stanza Python NLP toolkit. We show that Stanza’s biomedical and clinical packages offer highly accurate syntactic analysis and named entity recognition capabilities, while maintaining competitive speed with existing toolkits, especially when GPU acceleration is available. These packages are highly integrated with Stanza’s existing Python NLP interface, and require no additional effort to use. We hope to continuously maintain and expand these packages as new resources become available.</p>
  </sec>
  <sec>
    <title>FUNDING</title>
    <p>This research received no specific grant from any funding agency in the public, commercial or not-for-profit sectors.</p>
  </sec>
  <sec>
    <title>AUTHOR CONTRIBUTIONS</title>
    <p>YuhaZ, YuhuZ, and PQ implemented the models used in this article. YuhaZ and YuhuZ performed the data collection, data processing and experiments. YuhaZ created the figures and tables, and drafted the manuscript. All authors conceived of the idea for the article. All authors were involved in the design of the methodologies and experiments, and in the preparation of the final manuscript.</p>
  </sec>
  <sec>
    <title>SUPPLEMENTARY MATERIAL</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary material</xref> is available at <italic toggle="yes">Journal of the American Medical Informatics Association</italic> online.</p>
  </sec>
  <sec>
    <title>CONFLICT OF INTEREST STATEMENT</title>
    <p>Curtis P. Langlotzis in the board of directors and a shareholder of BunkerHill Health and is an advisor and option holder of whiterabbit.ai, Nines, GalileoCDS, and Sirona Medical.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>DATA AVAILABILITY STATEMENT</title>
    <p>The source code used in this paper is available at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/stanfordnlp/stanza" ext-link-type="uri">https://github.com/stanfordnlp/stanza</ext-link>. All pretrained models used in this paper can be downloaded by following the instructions at: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://stanfordnlp.github.io/stanza/biomed.html" ext-link-type="uri">https://stanfordnlp.github.io/stanza/biomed.html</ext-link>. An online demo of the models is available at: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://stanza.ru" ext-link-type="uri">http://stanza.ru</ext-link>n/bio. The preprocessed biomedical treebanks used in this paper are available at: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://nlp.stanford.edu/projects/" ext-link-type="uri">https://nlp.stanford.edu/projects/</ext-link>.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>ocab090_Supplementary_Data</label>
      <media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ocab090_supplementary_data.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="ocab090-B1">
      <label>1</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hunter</surname><given-names>L</given-names></string-name>, <string-name><surname>Bretonnel Cohen</surname><given-names>K.</given-names></string-name></person-group><article-title>Biomedical language processing: what’s beyond PubMed?</article-title><source>Mol Cell</source><year>2006</year>; <volume>21</volume> (<issue>5</issue>): <fpage>589</fpage>–<lpage>94</lpage>.<pub-id pub-id-type="pmid">16507357</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B2">
      <label>2</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jha</surname><given-names>AK</given-names></string-name>, <string-name><surname>DesRoches</surname><given-names>CM</given-names></string-name>, <string-name><surname>Campbell</surname><given-names>EG</given-names></string-name></person-group>, <etal>et al</etal><article-title>Use of electronic health records in U.S. hospitals</article-title>. <source>N Engl J Med</source><year>2009</year>; <volume>360</volume> (<issue>16</issue>): <fpage>1628</fpage>–<lpage>38</lpage>.<pub-id pub-id-type="pmid">19321858</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B3">
      <label>3</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Poon</surname><given-names>H</given-names></string-name>, <string-name><surname>Quirk</surname><given-names>C</given-names></string-name>, <string-name><surname>DeZiel</surname><given-names>C</given-names></string-name></person-group>, <etal>et al</etal><article-title>Literome: PubMed-scale genomic knowledge base in the cloud</article-title>. <source>Bioinformatics</source><year>2014</year>; <volume>30</volume> (<issue>19</issue>): <fpage>2840</fpage>–<lpage>2</lpage>.<pub-id pub-id-type="pmid">24939151</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B4">
      <label>4</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>J</given-names></string-name>, <string-name><surname>Yoon</surname><given-names>W</given-names></string-name>, <string-name><surname>Kim</surname><given-names>S</given-names></string-name></person-group>, <etal>et al</etal><article-title>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</article-title>. <source>Bioinformatics</source><year>2020</year>; <volume>36</volume> (<issue>4</issue>): <fpage>1234</fpage>–<lpage>40</lpage>.<pub-id pub-id-type="pmid">31501885</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B5">
      <label>5</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Liu</surname><given-names>F</given-names></string-name>, <string-name><surname>Simpson</surname><given-names>P</given-names></string-name></person-group>, <etal>et al</etal><article-title>AskHERMES: An online question answering system for complex clinical questions</article-title>. <source>J Biomed Inform</source><year>2011</year>; <volume>44</volume> (<issue>2</issue>): <fpage>277</fpage>–<lpage>88</lpage>.<pub-id pub-id-type="pmid">21256977</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B6">
      <label>6</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Jin</surname><given-names>Q</given-names></string-name>, <string-name><surname>Dhingra</surname><given-names>B</given-names></string-name>, <string-name><surname>Liu</surname><given-names>Z</given-names></string-name></person-group>, <etal>et al</etal> PubMedQA: a dataset for biomedical research question answering. In: <italic toggle="yes">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</italic>; <year>2019</year>: 2567–77. doi:10.18653/v1/d19-1259.</mixed-citation>
    </ref>
    <ref id="ocab090-B7">
      <label>7</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Du</surname><given-names>N</given-names></string-name>, <string-name><surname>Chen</surname><given-names>K</given-names></string-name>, <string-name><surname>Kannan</surname><given-names>A</given-names></string-name></person-group>, <etal>et al</etal> Extracting symptoms and their status from clinical conversations. In: <italic toggle="yes">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</italic>; <year>2019</year>; 915–25. doi:10.18653/v1/p19-1087.</mixed-citation>
    </ref>
    <ref id="ocab090-B8">
      <label>8</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>McClosky</surname><given-names>D</given-names></string-name>, <string-name><surname>Charniak</surname><given-names>E.</given-names></string-name></person-group> Self-training for biomedical parsing. In: <italic toggle="yes">Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies Short Papers - HLT ’08</italic>; <year>2008</year>: 101–4. doi:10.3115/1557690.1557717.</mixed-citation>
    </ref>
    <ref id="ocab090-B9">
      <label>9</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Baumgartner</surname><given-names>W</given-names></string-name>, <string-name><surname>Bada</surname><given-names>M</given-names></string-name>, <string-name><surname>Pyysalo</surname><given-names>S</given-names></string-name></person-group>, <etal>et al</etal> CRAFT shared tasks 2019 overview – integrated structure, semantics, and coreference. In: <italic toggle="yes">Proceedings of the 5th Workshop on BioNLP Open Shared Tasks</italic>; <year>2019</year>; 174–84. doi:10.18653/v1/d19-5725.</mixed-citation>
    </ref>
    <ref id="ocab090-B10">
      <label>10</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Manning</surname><given-names>C</given-names></string-name>, <string-name><surname>Surdeanu</surname><given-names>M</given-names></string-name>, <string-name><surname>Bauer</surname><given-names>J</given-names></string-name></person-group>, <etal>et al</etal> The Stanford CoreNLP natural language processing toolkit. In: <italic toggle="yes">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</italic>; <year>2014</year>: 55–60. doi:10.3115/v1/p14-5010.</mixed-citation>
    </ref>
    <ref id="ocab090-B11">
      <label>11</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Neumann</surname><given-names>M</given-names></string-name>, <string-name><surname>King</surname><given-names>D</given-names></string-name>, <string-name><surname>Beltagy</surname><given-names>I</given-names></string-name></person-group>, <etal>et al</etal> ScispaCy: fast and robust models for biomedical natural language processing. In: <italic toggle="yes">Proceedings of the 18th BioNLP Workshop and Shared Task</italic>; <year>2019</year>; 319–27. doi:10.18653/v1/w19-5034.</mixed-citation>
    </ref>
    <ref id="ocab090-B12">
      <label>12</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bodenreider</surname><given-names>O.</given-names></string-name></person-group><article-title>The Unified Medical Language System (UMLS): integrating biomedical terminology</article-title>. <source>Nucleic Acids Res</source><year>2004</year>; <volume>32</volume>: <fpage>D267</fpage>–<lpage>70</lpage>.<pub-id pub-id-type="pmid">14681409</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B13">
      <label>13</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Savova</surname><given-names>GK</given-names></string-name>, <string-name><surname>Masanz</surname><given-names>JJ</given-names></string-name>, <string-name><surname>Ogren</surname><given-names>PV</given-names></string-name></person-group>, <etal>et al</etal><article-title>Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications</article-title>. <source>J Am Med Inform Assoc</source><year>2010</year>; <volume>17</volume> (<issue>5</issue>): <fpage>507</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">20819853</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B14">
      <label>14</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zeng</surname><given-names>QT</given-names></string-name>, <string-name><surname>Goryachev</surname><given-names>S</given-names></string-name>, <string-name><surname>Weiss</surname><given-names>S</given-names></string-name></person-group>, <etal>et al</etal><article-title>Extracting principal diagnosis, co-morbidity and smoking status for asthma research: evaluation of a natural language processing system</article-title>. <source>BMC Med Inform Decis Mak</source><year>2006</year>; <volume>6</volume>: <fpage>30</fpage>.<pub-id pub-id-type="pmid">16872495</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B15">
      <label>15</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Aronson</surname><given-names>AR</given-names></string-name>, <string-name><surname>Lang</surname><given-names>F-M.</given-names></string-name></person-group><article-title>An overview of MetaMap: historical perspective and recent advances</article-title>. <source>J Am Med Inform Assoc</source><year>2010</year>; <volume>17</volume> (<issue>3</issue>): <fpage>229</fpage>–<lpage>36</lpage>.<pub-id pub-id-type="pmid">20442139</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B16">
      <label>16</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Soysal</surname><given-names>E</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>M</given-names></string-name></person-group>, <etal>et al</etal><article-title>CLAMP—a toolkit for efficiently building customized clinical natural language processing pipelines</article-title>. <source>J Am Med Inform Assoc</source><year>2018</year>; <volume>25</volume> (<issue>3</issue>): <fpage>331</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">29186491</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B17">
      <label>17</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deardorff</surname><given-names>A.</given-names></string-name></person-group><article-title>Why do biomedical researchers learn to program? An exploratory investigation</article-title>. <source>J Med Libr Assoc</source><year>2020</year>; <volume>108</volume> (<issue>1</issue>): <fpage>29</fpage>–<lpage>35</lpage>.<pub-id pub-id-type="pmid">31897049</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B18">
      <label>18</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Qi</surname><given-names>P</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Y</given-names></string-name></person-group>, <etal>et al</etal> Stanza: A Python Natural Language Processing Toolkit for Many Human Languages. In: <italic toggle="yes">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</italic>; <year>2020</year>: 101–8. doi:10.18653/v1/2020.acl-demos.14.</mixed-citation>
    </ref>
    <ref id="ocab090-B19">
      <label>19</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Nivre</surname><given-names>J</given-names></string-name>, <string-name><surname>de Marneffe</surname><given-names>M-C</given-names></string-name>, <string-name><surname>Ginter</surname><given-names>F</given-names></string-name></person-group>, <etal>et al</etal> Universal dependencies v2: an evergrowing multilingual treebank collection. In: <italic toggle="yes">Proceedings of the Twelfth International Conference on Language Resources and Evaluation (LREC’20)</italic>; <year>2020</year>: <fpage>4034</fpage>–<lpage>43</lpage>.</mixed-citation>
    </ref>
    <ref id="ocab090-B20">
      <label>20</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Verspoor</surname><given-names>K</given-names></string-name>, <string-name><surname>Cohen</surname><given-names>KB</given-names></string-name>, <string-name><surname>Lanfranchi</surname><given-names>A</given-names></string-name></person-group>, <etal>et al</etal><article-title>A corpus of full-text journal articles is a robust evaluation tool for revealing differences in performance of biomedical natural language processing tools</article-title>. <source>BMC Bioinform</source><year>2012</year>; <volume>13</volume>: <fpage>207</fpage>.</mixed-citation>
    </ref>
    <ref id="ocab090-B21">
      <label>21</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname><given-names>AEW</given-names></string-name>, <string-name><surname>Pollard</surname><given-names>TJ</given-names></string-name>, <string-name><surname>Shen</surname><given-names>L</given-names></string-name></person-group>, <etal>et al</etal><article-title>MIMIC-III, a freely accessible critical care database</article-title>. <source>Sci Data</source><year>2016</year>; <volume>3</volume>: <fpage>160035</fpage>.<pub-id pub-id-type="pmid">27219127</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B22">
      <label>22</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Dozat</surname><given-names>T</given-names></string-name>, <string-name><surname>Manning</surname><given-names>CD.</given-names></string-name></person-group> Deep Biaffine attention for neural dependency parsing. In: <italic toggle="yes">International Conference on Learning Representations (ICLR)</italic>; <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="ocab090-B23">
      <label>23</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Qi</surname><given-names>P</given-names></string-name>, <string-name><surname>Dozat</surname><given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Y</given-names></string-name></person-group>, <etal>et al</etal> Universal dependency parsing from scratch. In: <italic toggle="yes">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</italic>; <year>2018</year>: <fpage>160</fpage>–<lpage>70</lpage>.</mixed-citation>
    </ref>
    <ref id="ocab090-B24">
      <label>24</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname><given-names>J-D</given-names></string-name>, <string-name><surname>Ohta</surname><given-names>T</given-names></string-name>, <string-name><surname>Tateisi</surname><given-names>Y</given-names></string-name></person-group>, <etal>et al</etal><article-title>GENIA corpus—a semantically annotated corpus for bio-textmining</article-title>. <source>Bioinformatics</source><year>2003</year>; <volume>19</volume> (<issue>Suppl 1</issue>): <fpage>i180</fpage>–<lpage>2</lpage>.<pub-id pub-id-type="pmid">12855455</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B25">
      <label>25</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Schuster</surname><given-names>S</given-names></string-name>, <string-name><surname>Manning</surname><given-names>CD.</given-names></string-name></person-group> Enhanced English universal dependencies: An improved representation for natural language understanding tasks. <italic toggle="yes">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC’16)</italic>; <year>2016</year>. <fpage>2371</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="ocab090-B26">
      <label>26</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Silveira</surname><given-names>N</given-names></string-name>, <string-name><surname>Dozat</surname><given-names>T</given-names></string-name>, <string-name><surname>de Marneffe</surname><given-names>M-C</given-names></string-name></person-group>, <etal>et al</etal> A gold standard dependency corpus for English. In: <italic toggle="yes">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014)</italic>; <year>2014</year>: <fpage>2897</fpage>–<lpage>904</lpage>.</mixed-citation>
    </ref>
    <ref id="ocab090-B27">
      <label>27</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Akbik</surname><given-names>A</given-names></string-name>, <string-name><surname>Blythe</surname><given-names>D</given-names></string-name>, <string-name><surname>Vollgraf</surname><given-names>R.</given-names></string-name></person-group> Contextual string embeddings for sequence labeling. In: <italic toggle="yes">Proceedings of the 27th International Conference on Computational Linguistics</italic>; <year>2018</year>: <fpage>1638</fpage>–<lpage>49</lpage>.</mixed-citation>
    </ref>
    <ref id="ocab090-B28">
      <label>28</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pyysalo</surname><given-names>S</given-names></string-name>, <string-name><surname>Ananiadou</surname><given-names>S.</given-names></string-name></person-group><article-title>Anatomical entity mention recognition at literature scale</article-title>. <source>Bioinformatics</source><year>2014</year>; <volume>30</volume> (<issue>6</issue>): <fpage>868</fpage>–<lpage>75</lpage>.<pub-id pub-id-type="pmid">24162468</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B29">
      <label>29</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>J</given-names></string-name>, <string-name><surname>Sun</surname><given-names>Y</given-names></string-name>, <string-name><surname>Johnson</surname><given-names>RJ</given-names></string-name></person-group>, <etal>et al</etal><article-title>BioCreative V CDR task corpus: a resource for chemical disease relation extraction</article-title>. <source>Database (Oxford)</source><year>2016</year>; <volume>2016</volume>: <fpage>baw068</fpage>.<pub-id pub-id-type="pmid">27161011</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B30">
      <label>30</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krallinger</surname><given-names>M</given-names></string-name>, <string-name><surname>Rabal</surname><given-names>O</given-names></string-name>, <string-name><surname>Leitner</surname><given-names>F</given-names></string-name></person-group>, <etal>et al</etal><article-title>The CHEMDNER corpus of chemicals and drugs and its annotation principles</article-title>. <source>J Cheminform</source><year>2015</year>; <volume>7</volume> (<issue>Suppl 1</issue>): <fpage>S2</fpage>.<pub-id pub-id-type="pmid">25810773</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B31">
      <label>31</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pyysalo</surname><given-names>S</given-names></string-name>, <string-name><surname>Ohta</surname><given-names>T</given-names></string-name>, <string-name><surname>Rak</surname><given-names>R</given-names></string-name></person-group>, <etal>et al</etal><article-title>Overview of the cancer genetics and pathway curation tasks of BioNLP shared task 2013</article-title>. <source>BMC Bioinform</source><year>2015</year>; <volume>16</volume> (<issue>S10</issue>): <fpage>S2</fpage>.</mixed-citation>
    </ref>
    <ref id="ocab090-B32">
      <label>32</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kim</surname><given-names>J-D</given-names></string-name>, <string-name><surname>Ohta</surname><given-names>T</given-names></string-name>, <string-name><surname>Tsuruoka</surname><given-names>Y</given-names></string-name></person-group>, <etal>et al</etal> Introduction to the bio-entity recognition task at JNLPBA. In: <italic toggle="yes">Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications</italic>; <year>2004</year>: <fpage>73</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="ocab090-B33">
      <label>33</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gerner</surname><given-names>M</given-names></string-name>, <string-name><surname>Nenadic</surname><given-names>G</given-names></string-name>, <string-name><surname>Bergman</surname><given-names>CM.</given-names></string-name></person-group><article-title>LINNAEUS: a species name identification system for biomedical literature</article-title>. <source>BMC Bioinform</source><year>2010</year>; <volume>11</volume>: <fpage>85</fpage>.</mixed-citation>
    </ref>
    <ref id="ocab090-B34">
      <label>34</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Doğan</surname><given-names>RI</given-names></string-name>, <string-name><surname>Leaman</surname><given-names>R</given-names></string-name>, <string-name><surname>Lu</surname><given-names>Z.</given-names></string-name></person-group><article-title>NCBI disease corpus: a resource for disease name recognition and concept normalization</article-title>. <source>J Biomed Inform</source><year>2014</year>; <volume>47</volume>: <fpage>1</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">24393765</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B35">
      <label>35</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pafilis</surname><given-names>E</given-names></string-name>, <string-name><surname>Frankild</surname><given-names>SP</given-names></string-name>, <string-name><surname>Fanini</surname><given-names>L</given-names></string-name></person-group>, <etal>et al</etal><article-title>The SPECIES and ORGANISMS resources for fast and accurate identification of taxonomic names in text</article-title>. <source>PLoS One</source><year>2013</year>; <volume>8</volume> (<issue>6</issue>): <fpage>e65390</fpage>.<pub-id pub-id-type="pmid">23823062</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B36">
      <label>36</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Ren</surname><given-names>X</given-names></string-name></person-group>, <etal>et al</etal><article-title>Cross-type biomedical named entity recognition with deep multi-task learning</article-title>. <source>Bioinformatics</source><year>2019</year>; <volume>35</volume> (<issue>10</issue>): <fpage>1745</fpage>–<lpage>52</lpage>.<pub-id pub-id-type="pmid">30307536</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B37">
      <label>37</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Uzuner</surname><given-names>Ö</given-names></string-name>, <string-name><surname>South</surname><given-names>BR</given-names></string-name>, <string-name><surname>Shen</surname><given-names>S</given-names></string-name></person-group>, <etal>et al</etal><article-title>2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text</article-title>. <source>J Am Med Inform Assoc</source><year>2011</year>; <volume>18</volume> (<issue>5</issue>): <fpage>552</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">21685143</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B38">
      <label>38</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hassanpour</surname><given-names>S</given-names></string-name>, <string-name><surname>Langlotz</surname><given-names>CP.</given-names></string-name></person-group><article-title>Information extraction from multi-institutional radiology reports</article-title>. <source>Artif Intell Med</source><year>2016</year>; <volume>66</volume>: <fpage>29</fpage>–<lpage>39</lpage>.<pub-id pub-id-type="pmid">26481140</pub-id></mixed-citation>
    </ref>
    <ref id="ocab090-B39">
      <label>39</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nguyen</surname><given-names>DQ</given-names></string-name>, <string-name><surname>Verspoor</surname><given-names>K.</given-names></string-name></person-group><article-title>From POS tagging to dependency parsing for biomedical event extraction</article-title>. <source>BMC Bioinform</source><year>2019</year>; <volume>20</volume> (<issue>1</issue>): <fpage>72</fpage>.</mixed-citation>
    </ref>
    <ref id="ocab090-B40">
      <label>40</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bird</surname><given-names>S</given-names></string-name>, <string-name><surname>Klein</surname><given-names>E</given-names></string-name>, <string-name><surname>Loper</surname><given-names>E.</given-names></string-name></person-group><source>Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit</source>. Newton, MA: <publisher-name>O’Reilly Media</publisher-name>; <year>2009</year>.</mixed-citation>
    </ref>
    <ref id="ocab090-B41">
      <label>41</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Andor</surname><given-names>D</given-names></string-name>, <string-name><surname>Alberti</surname><given-names>C</given-names></string-name>, <string-name><surname>Weiss</surname><given-names>D</given-names></string-name></person-group>, <etal>et al</etal> Globally normalized transition-based neural networks. In: <italic toggle="yes">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</italic>; <year>2016</year>: <fpage>2442</fpage>–<lpage>52</lpage>.</mixed-citation>
    </ref>
    <ref id="ocab090-B42">
      <label>42</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ngo</surname><given-names>TM</given-names></string-name>, <string-name><surname>Kanerva</surname><given-names>J</given-names></string-name>, <string-name><surname>Ginter</surname><given-names>F</given-names></string-name></person-group>, <etal>et al</etal> Neural dependency parsing of biomedical text: TurkuNLP entry in the CRAFT structural annotation task. In: <italic toggle="yes">Proceedings of the 5th Workshop on BioNLP Open Shared Tasks</italic>; <year>2019</year>: <fpage>206</fpage>–<lpage>15</lpage>.</mixed-citation>
    </ref>
    <ref id="ocab090-B43">
      <label>43</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Beltagy</surname><given-names>I</given-names></string-name>, <string-name><surname>Lo</surname><given-names>K</given-names></string-name>, <string-name><surname>Cohan</surname><given-names>A.</given-names></string-name></person-group> SciBERT: a pretrained language model for scientific text. In: <italic toggle="yes">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</italic>; <year>2019</year>: <fpage>3615</fpage>–<lpage>20</lpage>.</mixed-citation>
    </ref>
    <ref id="ocab090-B44">
      <label>44</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Alsentzer</surname><given-names>E</given-names></string-name>, <string-name><surname>Murphy</surname><given-names>J</given-names></string-name>, <string-name><surname>Boag</surname><given-names>W</given-names></string-name></person-group>, <etal>et al</etal> Publicly available clinical BERT embeddings. In: <italic toggle="yes">Proceedings of the 2nd Clinical Natural Language Processing Workshop</italic>; <year>2019</year>: <fpage>72</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="ocab090-B45">
      <label>45</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Moen</surname><given-names>SP</given-names></string-name>, <string-name><surname>Ananiadou</surname><given-names>TS.</given-names></string-name></person-group> Distributional semantics resources for biomedical text processing. In: <italic toggle="yes">Proceedings of Languages in Biology and Medicine</italic>; <year>2013</year>.</mixed-citation>
    </ref>
    <ref id="ocab090-B46">
      <label>46</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Chen</surname><given-names>Q</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Z</given-names></string-name></person-group>, <etal>el al</etal>. <article-title>BioWordVec, improving biomedical word embeddings with subword information and MeSH</article-title>. <source>Sci Data</source><year>2019</year>; <volume>6</volume> (<issue>1</issue>): <fpage>52</fpage>.<pub-id pub-id-type="pmid">31076572</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
