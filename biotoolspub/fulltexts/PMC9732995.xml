<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9732995</article-id>
    <article-id pub-id-type="pmid">36482307</article-id>
    <article-id pub-id-type="publisher-id">5071</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-022-05071-5</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>ReCSAI: recursive compressed sensing artificial intelligence for confocal lifetime localization microscopy</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Reinhard</surname>
          <given-names>Sebastian</given-names>
        </name>
        <address>
          <email>sebastian.reinhard@uni-wuerzburg.de</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Helmerich</surname>
          <given-names>Dominic A.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Boras</surname>
          <given-names>Dominik</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sauer</surname>
          <given-names>Markus</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Kollmannsberger</surname>
          <given-names>Philip</given-names>
        </name>
        <address>
          <email>Philip.Kollmannsberger@uni-wuerzburg.de</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.8379.5</institution-id><institution-id institution-id-type="ISNI">0000 0001 1958 8658</institution-id><institution>Department of Biotechnology and Biophysics, </institution><institution>University of Wuerzburg, </institution></institution-wrap>Am Hubland, 97074 Wuerzburg, Germany </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.8379.5</institution-id><institution-id institution-id-type="ISNI">0000 0001 1958 8658</institution-id><institution>Center for Computational and Theoretical Biology, </institution><institution>University of Wuerzburg, </institution></institution-wrap>Klara-Oppenheimer-Weg 32, 97074 Wuerzburg, Germany </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>8</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>8</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <elocation-id>530</elocation-id>
    <history>
      <date date-type="received">
        <day>16</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>21</day>
        <month>11</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Localization-based super-resolution microscopy resolves macromolecular structures down to a few nanometers by computationally reconstructing fluorescent emitter coordinates from diffraction-limited spots. The most commonly used algorithms are based on fitting parametric models of the point spread function (PSF) to a measured photon distribution. These algorithms make assumptions about the symmetry of the PSF and thus, do not work well with irregular, non-linear PSFs that occur for example in confocal lifetime imaging, where a laser is scanned across the sample. An alternative method for reconstructing sparse emitter sets from noisy, diffraction-limited images is compressed sensing, but due to its high computational cost it has not yet been widely adopted. Deep neural network fitters have recently emerged as a new competitive method for localization microscopy. They can learn to fit arbitrary PSFs, but require extensive simulated training data and do not generalize well. A method to efficiently fit the irregular PSFs from confocal lifetime localization microscopy combining the advantages of deep learning and compressed sensing would greatly improve the acquisition speed and throughput of this method.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Here we introduce <italic>ReCSAI</italic>, a compressed sensing neural network to reconstruct localizations for confocal <italic>d</italic>STORM, together with a simulation tool to generate training data. We implemented and compared different artificial network architectures, aiming to combine the advantages of compressed sensing and deep learning. We found that a U-Net with a recursive structure inspired by iterative compressed sensing showed the best results on realistic simulated datasets with noise, as well as on real experimentally measured confocal lifetime scanning data. Adding a trainable wavelet denoising layer as prior step further improved the reconstruction quality.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">Our deep learning approach can reach a similar reconstruction accuracy for confocal <italic>d</italic>STORM as frame binning with traditional fitting without requiring the acquisition of multiple frames. In addition, our work offers generic insights on the reconstruction of sparse measurements from noisy experimental data by combining compressed sensing and deep learning. We provide the trained networks, the code for network training and inference as well as the simulation tool as python code and Jupyter notebooks for easy reproducibility.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12859-022-05071-5.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Compressed sensing</kwd>
      <kwd>AI</kwd>
      <kwd>SMLM</kwd>
      <kwd>FLIMbee</kwd>
      <kwd>
        <italic>dSTORM</italic>
      </kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id>
            <institution>Deutsche Forschungsgemeinschaft</institution>
          </institution-wrap>
        </funding-source>
        <award-id>SA829/19-1</award-id>
        <award-id>KO3715/5-1</award-id>
        <principal-award-recipient>
          <name>
            <surname>Sauer</surname>
            <given-names>Markus</given-names>
          </name>
          <name>
            <surname>Kollmannsberger</surname>
            <given-names>Philip</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id>
            <institution>European Research Council</institution>
          </institution-wrap>
        </funding-source>
        <award-id>835102</award-id>
        <principal-award-recipient>
          <name>
            <surname>Sauer</surname>
            <given-names>Markus</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Julius-Maximilians-Universität Würzburg (3088)</institution>
        </funding-source>
      </award-group>
      <open-access>
        <p>Open Access funding enabled and organized by Projekt DEAL.</p>
      </open-access>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par4">The resolution of classical fluorescence microscopy is limited by the Abbe criterion [<xref ref-type="bibr" rid="CR1">1</xref>]. In the past decades, several super-resolution techniques to surpass this limit have been developed. One of them is single molecule localization microscopy (SMLM), which is based on localizing the position of individual fluorescent dyes. By fitting a model of the theoretical photon distribution, the point spread function (PSF), to the measured signal, the emitter position can be precisely determined [<xref ref-type="bibr" rid="CR2">2</xref>]. While this problem was quickly solved for perfect samples, reality is often more difficult. Overlapping or varying photon distributions as well as low signal-to-noise ratio still pose a challenge. Various approaches are used to reconstruct super-resolved positions of individual emitters, such as intensity centroids, fitting Gaussian or more complex (e.g. Zernike polynomial) functions [<xref ref-type="bibr" rid="CR3">3</xref>], compressed sensing [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR5">5</xref>], and deep neural networks [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>].</p>
    <p id="Par5">An interesting application of SMLM is the simultaneous imaging of different targets using multiple colors however, suitable fluorescent dyes are very limited, and chromatic aberrations are unavoidable for different emission wavelength [<xref ref-type="bibr" rid="CR8">8</xref>]. A promising workaround is to distinguish dyes with similar emission wavelength by their different lifetime [<xref ref-type="bibr" rid="CR9">9</xref>]. This detection method is based on confocal scanning, where a laser scans the sample with a sampling rate similar to the switching rate of fluorescent dyes. This introduces distorted and disrupted PSFs that cannot be properly localized by fitting a parametric PSF model. To solve this problem, Thiele et al. [<xref ref-type="bibr" rid="CR9">9</xref>] acquired multiple frames, projected them onto each other to obtain complete PSFs, and applied conventional fitting. An efficient method to fit the irregular, chopped PSFs in individual frames would greatly improve the acquisition speed and throughput of confocal lifetime localization microscopy.</p>
    <p id="Par6">The nonlinearities of irregular, chopped PSFs require a large degree of flexibility in the fitting function while maintaining high precision. Most classical algorithms are based on fitting a Gaussian or similar function to the measured photon distribution for each individual emitter. While these methods approach the theoretical lower bound for individual emitters, they fail when emitters overlap or the PSF is irregular. For overlapping emitters at high density, compressed sensing (CS) is superior to conventional fitting [<xref ref-type="bibr" rid="CR10">10</xref>]. CS works by solving the inverse problem of recovering a super-resolved image of the emitters from a noisy, low-resolution measurement using sparsity in the spatial [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR5">5</xref>] or correlation [<xref ref-type="bibr" rid="CR11">11</xref>] domain as constraint. Due to its high computational demands, CS has so far not found widespread use. Artificial Neural Networks (ANN) are well suited for fitting complex PSFs, as they are essentially high-dimensional function approximators. Recently, ANN-based fitters such as DeepSTORM [<xref ref-type="bibr" rid="CR6">6</xref>] or DECODE [<xref ref-type="bibr" rid="CR7">7</xref>] achieved outstanding results in a SMLM reconstruction benchmark [<xref ref-type="bibr" rid="CR10">10</xref>], beating CS at high emitter density.</p>
    <p id="Par7">One drawback of NN-based methods is their lack of interpretability compared to deterministic algorithms. Various attempts have been made to tackle this problem, since especially in a clinical imaging context, it is important to have an explanation for the predictions of a deep learning model. For example, Corizzo et al. [<xref ref-type="bibr" rid="CR12">12</xref>] presented a new method combining clustering, dimensionality reduction and class activation mapping to identify the rationale behind the model output. The deterministic nature of CS algorithms offers another possible route towards adding explainability to deep neural networks.</p>
    <p id="Par8">Since the iterative process of compressed sensing can be expressed as a differentiable operation, it should be possible to integrate it into a neural network to combine the advantages of both approaches.</p>
    <p id="Par9">Here, we present a novel trainable fitting algorithm that combines wavelet denoising, compressed sensing, and deep learning to recover emitter locations from confocal <italic>d</italic>STORM data with chopped, irregular PSFs. We developed a simulator producing accurate ground truth for training, including various distortions and noise as well as temporal context over multiple frames. We then trained different neural networks combining existing approaches with a novel trainable CS layer and wavelet filters, and evaluated and compared their performance on simulated and experimental data using common accuracy metrics as well as Fourier Ring Correlation [<xref ref-type="bibr" rid="CR13">13</xref>] and LineProfiler [<xref ref-type="bibr" rid="CR14">14</xref>].</p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <sec id="Sec3">
      <title>Experimental validation</title>
      <p id="Par10">We acquired confocal lifetime localization microscopy images of fluorescently stained microtubules to evaluate our method. Microtubules are well-characterized cytoskeletal filaments in cells and are often used as a reference structure in localization microscopy to evaluate the quality of an imaging modality or reconstruction algorithm [<xref ref-type="bibr" rid="CR15">15</xref>]. The details of the experimental methods are described in the following sections.</p>
    </sec>
    <sec id="Sec4">
      <title>Antibody labeling</title>
      <p id="Par11">For antibody labeling, an excess of Cy5-NHS (GE-Healthcare, PA15101) was used. Goat anti-rabbit IgG (Invitrogen, 31212) was used as secondary antibody for microtubules in FLIM experiments. Antibody labeling was performed at room temperature for 4h in labeling buffer [100 mM sodium tetraborate (Fulka, 71999), pH 9.5] following the manufacturers standard protocol. Briefly, 100 g antibody were reconstituted in labeling buffer using 0.5 ml spin-desalting columns (40K MWCO, ThermoFisher, 87766). An 5x excess of Cy5-NHS (GE-Healthcare, PA15101) was used. Antibody conjugates were purified and washed up to three times using spin-desalting columns (40K MWCO) in PBS (Sigma-Aldrich, D8537-500ML) to remove excess dyes. Finally, antibody concentration and DOL were determined by UV-vis absorption spectrometry (Jasco V-650).</p>
    </sec>
    <sec id="Sec5">
      <title>Cell culture</title>
      <p id="Par12">African green monkey kidney fibroblast-like cells (COS7, Cell Lines Service GmbH, Eppelheim, #605470) were cultured in DMEM (Sigma, #D8062) containing 10 % FCS (Sigma-Aldrich, #F7524), 100 U/ml penicillin and 0.1 mg/ml streptomycin (Sigma-Aldrich, #P4333) at 37 C and 5 % CO<inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_2$$\end{document}</tex-math><mml:math id="M2"><mml:msub><mml:mrow/><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq1.gif"/></alternatives></inline-formula>. Cells were grown in standard T25-culture flasks (Greiner Bio-One).</p>
    </sec>
    <sec id="Sec6">
      <title>Immunostaining</title>
      <p id="Par13">For immunostaining, cells were seeded at a concentration of 2.5 10<inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^4$$\end{document}</tex-math><mml:math id="M4"><mml:msup><mml:mrow/><mml:mn>4</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq2.gif"/></alternatives></inline-formula> cells/well into 8 chambered cover glass systems with high performance cover glass (Cellvis, C8-1.5H-N) and stained after 3 hours of incubation at 37 C and 5 % CO<inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_2$$\end{document}</tex-math><mml:math id="M6"><mml:msub><mml:mrow/><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq3.gif"/></alternatives></inline-formula>. For microtubule immunostaining, cells were washed with pre-warmed (37 C) PBS (Sigma-Aldrich, D8537-500ML) and permeabilized for 2 min with 0.3 % glutaraldehyde (GA) + 0.25 % Triton X-100 (EMS, 16220 and ThermoFisher, 28314) in pre-warmed (37 C) cytoskeleton buffer (CB), consisting of 10 mM MES [(Sigma-Aldrich, M8250), pH 6.1], 150 mM NaCl (Sigma-Aldrich, 55886), 5 mM EGTA (Sigma-Aldrich, 03777), 5 mM glucose (Sigma-Aldrich, G7021) and 5 mM MgCl<inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_2$$\end{document}</tex-math><mml:math id="M8"><mml:msub><mml:mrow/><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq4.gif"/></alternatives></inline-formula> (Sigma-Aldrich, M9272). After permeabilization, cells were fixed with a pre-warmed (37 C) solution of 2 % GA for 10 min. After fixation, cells were washed twice with PBS (Sigma-Aldrich, D8537-500ML) and reduced with 0.1 % sodium borohydride (Sigma-Aldrich, 71320) in PBS for 7 min. Cells were washed three times with PBS (Sigma-Aldrich, D8537-500ML) before blocking with 5 % BSA (Roth, #3737.3) for 30 min. Subsequently, microtubule samples were incubated with 2 ng/l rabbit anti-<inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}</tex-math><mml:math id="M10"><mml:mi>α</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq5.gif"/></alternatives></inline-formula>-tubulin primary antibody (Abcam, #ab18251) in blocking buffer for 1 hour. After primary antibody incubation, cells were rinsed with PBS (Sigma-Aldrich, D8537-500ML) and washed twice with 0.1 % Tween20 (ThermoFisher, 28320) in PBS (Sigma-Aldrich, D8537-500ML) for 5 min. After washing, cells were incubated in blocking buffer with 4 ng/l of dye-labeled goat anti-rabbit IgG secondary antibodies (Invitrogen, 31212) for 45 min. After secondary antibody incubation, cells were rinsed with PBS (Sigma-Aldrich, D8537-500ML) and washed twice with 0.1 % Tween20 (ThermoFisher, 28320) in PBS (Sigma-Aldrich, D8537-500ML) for 5 min. After washing, cells were fixed with 4% formaldehyde (Sigma-Aldrich, F8775) for 10 min and washed three times in PBS (Sigma-Aldrich, D8537-500ML) prior to imaging.</p>
    </sec>
    <sec id="Sec7">
      <title>Fluorescence lifetime imaging microscopy (FLIM)</title>
      <p id="Par14">All single molecule fluorescence lifetime measurements were performed on a MicroTime200 (PicoQuant, Berlin, Germany) time-resolved confocal fluorescence microscope setup (Fig. <xref rid="Fig1" ref-type="fig">1</xref>a) consisting of a FLIMbee galvo scanner (PicoQuant, Berlin, Germany), an Olympus IX83 microscope including an oil-immersion objective (60×, NA 1.45; Olympus), 2 single photon avalanche photodiodes (SPAD) (Excelitas Technologies, 75154 K3, 75154 L6) and a TimeHarp300 dual channel board. Pulsed excitation was performed using a white-light laser (NKT photonics, superK extreme) which was coupled into the MicroTime200 system via a glass fiber (NKT photonics, SuperK FD PM, A502-010-110). A 100 µm pinhole was used for all measurements. The emission light was split onto the SPADs using a 50:50 beamsplitter (PicoQuant, Berlin, Germany). To filter out afterglow effects of the SPADs as well as scattered and reflected light, two identical bandpass filters (ET700/75 M, Semrock, 294808) were installed in front of the SPADs. The measurements were performed and analyzed with the SymPhoTime64 software (PicoQuant, Berlin, Germany). The microtubule measurements were performed with an irradiation intensity of 5 kW cm<inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{-2}$$\end{document}</tex-math><mml:math id="M12"><mml:msup><mml:mrow/><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq6.gif"/></alternatives></inline-formula> in T3 mode with 25 ps time-resolution. The pixel dwell time was 100 s and a monodirectional line frequency of 108.7 Hz was used. The corresponding frame frequency was 2.4 Hz. Measurements were performed in PBS-based photoswitching buffer containing 100 mM <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\beta$$\end{document}</tex-math><mml:math id="M14"><mml:mi>β</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq7.gif"/></alternatives></inline-formula>-mercaptoethylamine (MEA, Sigma-Aldrich) adjusted to pH 7.6.<fig id="Fig1"><label>Fig. 1</label><caption><p>Confocal <italic>d</italic>STORM data acquisition process and data simulation. <bold>a</bold> The pulsed 640 nm excitation light is converted to radial polarisation with a quarter wave plate (QWP) after passing through a single mode fibre (SMF), reflected by a beam splitter (BS) into a galvanometric laser scanner and focused by an oil immersion objective. The collected fluorescent emission from the sample is descanned, passed through the BS, reflected by mirrors (M) and focused onto the pinhole (PH), then onto the single-photon avalanche photodiodes (SPAD) using lenses (L1, L2, L3 and L4). Band pass filters (BP) block scattered excitation light and prevent afterglow effects of the detectors. <bold>b</bold> The galvo scanner is a one-pixel scanner rastering the image line by line. At time <italic>t</italic>, only the blue marked part of <italic>S</italic> is active, representing the horizontal acquisition line of the FLIMbee detector. The acquisition speed in x-direction is sufficiently fast to be neglected during simulations. Only active fluorophores overlapping into the active part of <italic>S</italic> are rendered (green)</p></caption><graphic xlink:href="12859_2022_5071_Fig1_HTML" id="MO1"/></fig><fig id="Fig2"><label>Fig. 2</label><caption><p>Network models. Image data containing the temporal context of the previous and subsequent frame are processed in different network models. <bold>a</bold> CS CNN uses compressed sensing as a prior and applies several convolutional layers. <bold>b</bold> CS Inception integrates the CS component deeper into the neural network. <bold>c</bold> CS U-Net uses compressed sensing as a prior and computes the feature space with a U-Net architecture <bold>d</bold> Rec U-Net aims to unroll the CS algorithm with iterative encoding and decoding from image to feature space and vice versa. For all network models the feature space is processed with sigmoid and tanh activations and fed into a Gaussian mixture model to compute the loss</p></caption><graphic xlink:href="12859_2022_5071_Fig2_HTML" id="MO2"/></fig><fig id="Fig3"><label>Fig. 3</label><caption><p>Comparison of different network architectures. <bold>a</bold> Validation loss over training steps. <bold>b</bold> Jaccard Index and RMSE of the tested models, and comparison to fitting the same data with ThunderSTORM as baseline. Error bars denote standard deviation of the mean for N=25 different validation datasets</p></caption><graphic xlink:href="12859_2022_5071_Fig3_HTML" id="MO3"/></fig><fig id="Fig4"><label>Fig. 4</label><caption><p>Reconstruction of FLIMbee <italic>d</italic> STORM microtubuli. <bold>a</bold> Fitting of disrupted PSFs with artificial intelligence. Red crosses denote the estimated location of a fluorophore. <bold>b</bold> Reconstructed super-resolution image. Scale bar = <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$10\,$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:mn>10</mml:mn><mml:mspace width="0.166667em"/></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq8.gif"/></alternatives></inline-formula>m <bold>c</bold> Line profile of the microtubule marked blue in <bold>b</bold></p></caption><graphic xlink:href="12859_2022_5071_Fig4_HTML" id="MO4"/></fig><fig id="Fig5"><label>Fig. 5</label><caption><p>Comparison of FLIM data evaluated with Thunderstorm and our method. Reconstructed images of AI (left) and Thunderstorm (right). Comparing the first and the second half of the localisation data, we obtain a Fourier Ring Correlation Coefficient [<xref ref-type="bibr" rid="CR13">13</xref>] of 0.310; 0.187; 0.265 (left) and 0.179; 0.187; 0.167 (right) respectively. Scale bar = <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$10\,$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:mn>10</mml:mn><mml:mspace width="0.166667em"/></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq9.gif"/></alternatives></inline-formula>m</p></caption><graphic xlink:href="12859_2022_5071_Fig5_HTML" id="MO5"/></fig><table-wrap id="Tab1"><label>Table 1</label><caption><p>Training and inference time of different network architectures on a Nvidia GTX 1080 TI</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Network architecture</th><th align="left">Training time [s]</th><th align="left">Inference time [s]</th></tr></thead><tbody><tr><td align="left">CS-CNN</td><td align="left">1102.0</td><td align="left">440.8</td></tr><tr><td align="left">CS-Inception</td><td align="left">2091.3</td><td align="left">502.5</td></tr><tr><td align="left">CS-U</td><td align="left">596.4</td><td align="left">72.5</td></tr><tr><td align="left">CS-Res-U</td><td align="left">64.1</td><td align="left">88.8</td></tr></tbody></table><table-wrap-foot><p>Training times are measured per epoch. For the evaluation of inference time, a FLIMbee dataset with 4500 frames of 45 <inline-formula id="IEq17"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M20"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq17.gif"/></alternatives></inline-formula> 45 px is used</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec8">
      <title>Data format and fitting</title>
      <p id="Par15">Each localization microscopy experiment results in a movie of several thousand raw camera frames containing images of blinking single molecule emitters, i.e., sparsely distributed and separated PSFs. To obtain the final super-resolved image, the positions of the individual emitters are reconstructed from the raw frames, usually by fitting a Gaussian to each PSF. In the case of confocal lifetime localization microscopy, however, the PSFs are disrupted: while the sample is scanned line by line, individual emitters can switch to the non-fluorescent OFF state while being scanned before their entire PSF is captured and rasterized. Thus, the symmetry assumptions underlying the Gaussian approach do not hold, and traditional fitting approaches fail.</p>
    </sec>
    <sec id="Sec9">
      <title>Simulation</title>
      <p id="Par16">The core of our simulation is an artificial space <inline-formula id="IEq18"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S^{N,N}$$\end{document}</tex-math><mml:math id="M22"><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq18.gif"/></alternatives></inline-formula>, with dimension <inline-formula id="IEq19"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N = s_{\text {px}} *s_{\text {im}}$$\end{document}</tex-math><mml:math id="M24"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mtext>px</mml:mtext></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mtext>im</mml:mtext></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq19.gif"/></alternatives></inline-formula>. Here, <inline-formula id="IEq20"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$s_{\text {px}}$$\end{document}</tex-math><mml:math id="M26"><mml:msub><mml:mi>s</mml:mi><mml:mtext>px</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq20.gif"/></alternatives></inline-formula> is the pixel size in nanometers, corresponding to the number of discrete coordinate points in the simulation that are afterwards binned into one value to emulate the pixel grid of the camera, while <inline-formula id="IEq21"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$s_{\text {im}}$$\end{document}</tex-math><mml:math id="M28"><mml:msub><mml:mi>s</mml:mi><mml:mtext>im</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq21.gif"/></alternatives></inline-formula> is the size of the resulting simulated image in pixels. We used a pixel size of 100 nm, same as in the experimental data. <italic>S</italic> is thus a sub-lattice of the image <italic>I</italic> with nanometer resolution. It represents one frame with only a small amount of emitters in the fluorescent ON state. These emitters are simulated with the following properties: A spatial position in x- and y-direction <inline-formula id="IEq22"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{x},L_{y} \in [0,N]$$\end{document}</tex-math><mml:math id="M30"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq22.gif"/></alternatives></inline-formula>, a lifetime distribution (Poisson, <inline-formula id="IEq23"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t = 90$$\end{document}</tex-math><mml:math id="M32"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>90</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq23.gif"/></alternatives></inline-formula>), a switch-ON countdown (Poisson, <inline-formula id="IEq24"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t = 90$$\end{document}</tex-math><mml:math id="M34"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>90</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq24.gif"/></alternatives></inline-formula>) and a photon count (ph = randint(800,1500), Gaussian distribution <inline-formula id="IEq25"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma = 0.2\,$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn><mml:mspace width="0.166667em"/></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq25.gif"/></alternatives></inline-formula>ph). We define an empty subset of <inline-formula id="IEq26"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{\text {ON}}$$\end{document}</tex-math><mml:math id="M38"><mml:msub><mml:mi>L</mml:mi><mml:mtext>ON</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq26.gif"/></alternatives></inline-formula> describing points in a fluorescent ON state.  <inline-formula id="IEq27"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{\text {ON}}$$\end{document}</tex-math><mml:math id="M40"><mml:msub><mml:mi>L</mml:mi><mml:mtext>ON</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq27.gif"/></alternatives></inline-formula> is recalculated each line, adding emitters based on a Poisson distribution <inline-formula id="IEq28"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_\lambda (k) = \frac{\lambda ^k}{k!}e^{-\lambda }$$\end{document}</tex-math><mml:math id="M42"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>λ</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>λ</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mrow><mml:mi>k</mml:mi><mml:mo>!</mml:mo></mml:mrow></mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq28.gif"/></alternatives></inline-formula> and deleting those which returned to a dark state. We further divide <italic>S</italic> into horizontal lines of size <inline-formula id="IEq29"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$s_{\text {px}}$$\end{document}</tex-math><mml:math id="M44"><mml:msub><mml:mi>s</mml:mi><mml:mtext>px</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq29.gif"/></alternatives></inline-formula>, representing the rasterization process of the detector (blue line in Fig. <xref rid="Fig1" ref-type="fig">1</xref>b). A time variable <italic>t</italic> is increased with each horizontal line by <inline-formula id="IEq30"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta t = 6$$\end{document}</tex-math><mml:math id="M46"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq30.gif"/></alternatives></inline-formula> ms. The timestep of column-wise movements is neglected in our simulations since it is one order of magnitude faster.</p>
      <p id="Par17">The simulated localizations are included in the image by adding values from a predefined array containing an approximation of the PSF, centered on the coordinates of the simulated emitter. We refer to this as rendering process. If the switch-ON countdown of a localisation is larger than zero, it is decreased by <inline-formula id="IEq31"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta t$$\end{document}</tex-math><mml:math id="M48"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq31.gif"/></alternatives></inline-formula> and the localisation is not rendered in the current line. If the variable drops below zero, the localisation is rendered and <inline-formula id="IEq32"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta t$$\end{document}</tex-math><mml:math id="M50"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq32.gif"/></alternatives></inline-formula> is subtracted from the remaining lifetime. Localisations surpassing their lifetime are not rendered in the subsequent lines and are deleted from <inline-formula id="IEq33"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{\text {ON}}$$\end{document}</tex-math><mml:math id="M52"><mml:msub><mml:mi>L</mml:mi><mml:mtext>ON</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq33.gif"/></alternatives></inline-formula>. The rendering process described above adds a clipped version of the PSF at the localization’s relative x- and y-position to <italic>S</italic>, multiplied by the photon count of the localization. Thus, for each time point, the currently scanned image line contains the overlapping part of all currently active PSFs. Next, the time the detector needs to scan the next line is added to the simulation time. In this step, localizations can switch between a non-fluorescent OFF state or the fluorescent ON state. A localisation has to be rendered for at least 40% of its ON-time to be accepted as a true positive. For the PSF shape, we use an airy disc model from astropy [<xref ref-type="bibr" rid="CR16">16</xref>] with a varying radius <inline-formula id="IEq34"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$r \in [525,555]$$\end{document}</tex-math><mml:math id="M54"><mml:mrow><mml:mi>r</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>525</mml:mn><mml:mo>,</mml:mo><mml:mn>555</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq34.gif"/></alternatives></inline-formula>. However, this kernel can be easily replaced by a measured PSF for further applications. The simulated emitters are incomplete at the top or bottom. This depicts the switching process into the fluorescent ON/OFF state during the acquisition and is a typical feature of FLIMbee measurements. Subsequently, the image is resized by opencv’s [<xref ref-type="bibr" rid="CR17">17</xref>] InterArea interpolation to <inline-formula id="IEq35"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$s_{im}$$\end{document}</tex-math><mml:math id="M56"><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="italic">im</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq35.gif"/></alternatives></inline-formula>. Noise is added corresponding to [<xref ref-type="bibr" rid="CR18">18</xref>]. For our training we simulated <inline-formula id="IEq36"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$9\times 9\times 3$$\end{document}</tex-math><mml:math id="M58"><mml:mrow><mml:mn>9</mml:mn><mml:mo>×</mml:mo><mml:mn>9</mml:mn><mml:mo>×</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq36.gif"/></alternatives></inline-formula> crops of SMLM data. Each crop contains <inline-formula id="IEq37"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n \in [0,10]$$\end{document}</tex-math><mml:math id="M60"><mml:mrow><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>10</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq37.gif"/></alternatives></inline-formula> localisations.</p>
    </sec>
    <sec id="Sec10">
      <title>Reconstruction</title>
      <p id="Par18">Our reconstruction pipeline is composed of several steps. First, regions of interest are detected by a trainable wavelet based peak detection layer and cropped to a <inline-formula id="IEq38"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$9\times 9\times 3$$\end{document}</tex-math><mml:math id="M62"><mml:mrow><mml:mn>9</mml:mn><mml:mo>×</mml:mo><mml:mn>9</mml:mn><mml:mo>×</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq38.gif"/></alternatives></inline-formula> patch around the detected maximum, taking the temporal context of the previous and subsequent frame into account. The selected crops are further processed in one of the network architectures described in the following sections, ultimately creating a feature space describing the predicted emitters. This feature space equals the original crop data in size and contains a stack estimating the positions <inline-formula id="IEq39"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta x$$\end{document}</tex-math><mml:math id="M64"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq39.gif"/></alternatives></inline-formula> and <inline-formula id="IEq40"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta y$$\end{document}</tex-math><mml:math id="M66"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq40.gif"/></alternatives></inline-formula> relative to the pixel center, the emitter intensity <italic>N</italic>, the corresponding uncertainties <inline-formula id="IEq41"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _x, \sigma _y$$\end{document}</tex-math><mml:math id="M68"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq41.gif"/></alternatives></inline-formula>, <inline-formula id="IEq42"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _N$$\end{document}</tex-math><mml:math id="M70"><mml:msub><mml:mi>σ</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq42.gif"/></alternatives></inline-formula>, the probability <italic>p</italic> for a pixel to contain an emitter, and an estimation <italic>B</italic> of the local background. This output format as well as the loss function were adapted from DECODE [<xref ref-type="bibr" rid="CR7">7</xref>]. If an emitter is close to the edge of a pixel, i.e. <inline-formula id="IEq43"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta x / \Delta y$$\end{document}</tex-math><mml:math id="M72"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq43.gif"/></alternatives></inline-formula> are close to 0.5, the corresponding probability is often distributed over two adjacent pixels. Therefore, we defined the following conditions to retrieve a localisation: If a classifier pixel value exceeds the given threshold, a cross shaped filter <italic>F</italic> is applied:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} F = \left[ {\begin{array}{ccc} 0 &amp;{} 1 &amp;{} 0\\ 1 &amp;{} 1 &amp;{} 1\\ 0 &amp;{} 1 &amp;{} 0\\ \end{array} } \right] \end{aligned}$$\end{document}</tex-math><mml:math id="M74" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mn>1</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mn>1</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mn>1</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mn>1</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5071_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>If the convolved pixel exceeds a threshold <inline-formula id="IEq44"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t_{re}=0.7$$\end{document}</tex-math><mml:math id="M76"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="italic">re</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq44.gif"/></alternatives></inline-formula>, the pixel with the highest value of that formation is accepted as localisation. We determined that value by plotting the Jaccard index of our validation data in dependency of <inline-formula id="IEq45"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t_{re}$$\end{document}</tex-math><mml:math id="M78"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="italic">re</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq45.gif"/></alternatives></inline-formula> (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S1). The plot yields a maximum for <inline-formula id="IEq46"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t_{re}=0.7$$\end{document}</tex-math><mml:math id="M80"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="italic">re</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq46.gif"/></alternatives></inline-formula>. If <inline-formula id="IEq47"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t_{re}$$\end{document}</tex-math><mml:math id="M82"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="italic">re</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq47.gif"/></alternatives></inline-formula> exceeds 1.4, the pixel with the second highest value is also accepted.</p>
      <p id="Par19">The output of a simulated or real experiment consists of individual camera frames with noisy, clipped images of the emitter PSFs. The final result after SMLM fitting is a list of reconstructed emitter coordinates, together with their intensity, localization uncertainty, and sometimes other parameters. A super-resolved image can then be obtained by rendering a 2D histogram of these coordinates. Our reconstruction pipeline also generates a list of emitter coordinates, intensities and localization uncertainties in the usual SMLM format, but without requiring Gaussian-like PSFs.</p>
    </sec>
    <sec id="Sec11">
      <title>Trainable wavelet layer</title>
      <p id="Par20">To reduce the dimensionality of the reconstruction problem, we developed a binning that crops localizations to a ROI of <inline-formula id="IEq48"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$9\times 9$$\end{document}</tex-math><mml:math id="M84"><mml:mrow><mml:mn>9</mml:mn><mml:mo>×</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq48.gif"/></alternatives></inline-formula> pixels. These ROIs are identified with a trainable wavelet filter bank. To ensure perfect reconstruction, deconstruction and reconstruction filters share the same weights. Orthogonality of the filter bank is provided by coupling the learning process of low pass <italic>lp</italic> and high pass <italic>hp</italic> filter banks with a Gram-Schmidt process:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} hp_{n}= &amp; {} hp \end{aligned}$$\end{document}</tex-math><mml:math id="M86" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>h</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mi>h</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5071_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} lp_{n}= &amp; {} \frac{\langle hp_{n}, lp\rangle }{\langle hp_{n},hp_{n}\rangle } hp_{n} \end{aligned}$$\end{document}</tex-math><mml:math id="M88" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>l</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mfrac><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mi>h</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mi>h</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mfrac><mml:mi>h</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5071_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>A bias followed by a ReLU activation is applied to the decomposed frequency images. A filtered image can then be reconstructed using the decomposed frequency images and the inverted filter bank. Given the noise and disruption-free ground truth as training data, the algorithm is able to filter spatial frequency components that are ”PSF-like”. Potential localisations can then be identified by a local maximum detection. The denoised data can be of additional use for difficult reconstructions, e.g., when PSFs are shifted or disrupted as in FLIMbee measurements.</p>
    </sec>
    <sec id="Sec12">
      <title>Trainable CS layer</title>
      <p id="Par21">A major challenge of CS algorithms is the choice of suitable hyperparameters. We implemented the fast iterative shrinkage-thresholding algorithm (FISTA) [<xref ref-type="bibr" rid="CR19">19</xref>], where the thresholding parameter <inline-formula id="IEq49"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M90"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq49.gif"/></alternatives></inline-formula> significantly affects the number of iterations needed for convergence. Higher <inline-formula id="IEq50"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M92"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq50.gif"/></alternatives></inline-formula> implies more background information to be filtered and leads to a faster convergence but can on the other hand lead to undetected localisations. Smaller <inline-formula id="IEq51"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M94"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq51.gif"/></alternatives></inline-formula> implies less background and can lead to the detection of false positives. In classical approaches, <inline-formula id="IEq52"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M96"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq52.gif"/></alternatives></inline-formula> is set globally in dependency of the noise level. Since our method works with ROIs, an appropriate <inline-formula id="IEq53"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M98"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq53.gif"/></alternatives></inline-formula> depending on the local noise level can be estimated. We implemented a classical CNN (Convolutional Neural Network) consisting of three convolutional layers followed by three dense layers, predicting a specific <inline-formula id="IEq54"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M100"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq54.gif"/></alternatives></inline-formula> parameter for each crop (Additional file <xref rid="MOESM2" ref-type="media">2</xref>: Fig. S2). Constraining this part of the network is challenging, as the network easily loses its gradient either by converging to a high <inline-formula id="IEq55"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M102"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq55.gif"/></alternatives></inline-formula>, resulting in a zero output, or by converging to zero, resulting in no benefit of the compressed sensing operation. Therefore, it is crucial to regularize this step and to use suitable layer initialization. The <inline-formula id="IEq56"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M104"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq56.gif"/></alternatives></inline-formula> estimation part of our network is followed by a sigmoid activation, multiplied by 0.025 corresponding to the maximal <inline-formula id="IEq57"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M106"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq57.gif"/></alternatives></inline-formula> for a noiseless image that does not result in zero as output. Dense layers are initialized with a random normal distribution of mean <inline-formula id="IEq58"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu = 0.5$$\end{document}</tex-math><mml:math id="M108"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq58.gif"/></alternatives></inline-formula>, standard deviation <inline-formula id="IEq59"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma = 0.3$$\end{document}</tex-math><mml:math id="M110"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq59.gif"/></alternatives></inline-formula> and truncated normal bias. We further implemented a functional test displaying the output of the first inception layer together with the estimated <inline-formula id="IEq60"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M112"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq60.gif"/></alternatives></inline-formula> and the CS-reconstructed sub-lattice image to monitor the <inline-formula id="IEq61"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M114"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq61.gif"/></alternatives></inline-formula> estimation process.</p>
    </sec>
    <sec id="Sec13">
      <title>Network architecture</title>
      <p id="Par22">To combine CS and artificial intelligence we implemented and evaluated the following network architectures</p>
      <sec id="Sec14">
        <title>CS CNN</title>
        <p id="Par23">Our first approach for a network design was to use a simple CNN as shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>a. We used the aforementioned FISTA layer as a prior, downsampled the sub-lattice back to the input dimensions, concatenated the original input image, and applied a set of convolutions to generate the eight described feature space maps.</p>
      </sec>
      <sec id="Sec15">
        <title>CS Inception</title>
        <p id="Par24">In a more sophisticated approach (Fig. <xref rid="Fig2" ref-type="fig">2</xref>b), we integrated the concept of CS deeper into machine learning rather than using it only as a prior for computation. We built an architecture (Additional file <xref rid="MOESM2" ref-type="media">2</xref>: Fig. S2) similar to Inception [<xref ref-type="bibr" rid="CR20">20</xref>]. The aim is to run a first inception layer with a very low CS iteration count as a prior for a second inception layer with a higher iteration count. While inception layer 1 can focus on improving the image quality, inception layer 2 can reconstruct coordinates with a lower error rate, i.e. compute a higher <inline-formula id="IEq62"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M116"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq62.gif"/></alternatives></inline-formula>, resulting in faster convergence. The output of inception layer 2 is processed in a convolutional path similar to the first approach, reconstructing to eight feature layers in the original image dimensions.</p>
      </sec>
      <sec id="Sec16">
        <title>CS U-Net</title>
        <p id="Par25">The U-Net [<xref ref-type="bibr" rid="CR21">21</xref>] is a widely used neural network architecture for image-to-image tasks and was for example used in DECODE [<xref ref-type="bibr" rid="CR7">7</xref>]. The dimension of the input is step by step reduced in a down-sampling path, ultimately resulting in a dense feature space. In the subsequent up-sampling path, the dense information is combined with the corresponding layers of the down-sampling path containing spatial information (Fig. <xref rid="Fig2" ref-type="fig">2</xref>c).</p>
      </sec>
      <sec id="Sec17">
        <title>Recursive U-Net</title>
        <p id="Par26">The concept of stacked or residual U-Nets for reconstruction has previously been described in the context of medical imaging: Mizusawa et al. [<xref ref-type="bibr" rid="CR22">22</xref>] used stacks of independent U-Nets to enhance the reconstruction of CT images. Their approach achieved results comparable with the computationally much more costly iterative approach. Le et al. [<xref ref-type="bibr" rid="CR23">23</xref>] used two independent U-Nets combined with residual learning [<xref ref-type="bibr" rid="CR24">24</xref>] to achieve a 200-fold acceleration in the reconstruction of simultaneous multislice datasets. Lu et al. [<xref ref-type="bibr" rid="CR25">25</xref>] used a residual convolutional network to replace a compressed sensing algorithm, reconstructing high resolution images from low resolution measurements. The feature space is connected to the sub-lattice via downsampling layers and is updated with additional details in each iteration. Therefore, the current estimation <inline-formula id="IEq63"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x(t+1)$$\end{document}</tex-math><mml:math id="M118"><mml:mrow><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq63.gif"/></alternatives></inline-formula> is generated as <inline-formula id="IEq64"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$BN(x(t)+x(0)+update)$$\end{document}</tex-math><mml:math id="M120"><mml:mrow><mml:mi>B</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq64.gif"/></alternatives></inline-formula>, where <italic>BN</italic> describes a batch normalization. Taking these prior works into account, we replaced the matrix multiplications of compressed sensing with a U-Net, but retained the original concept of iteratively optimizing the feature space. The Recursive U-Net model is shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>d. In an initial step, we compute a first estimation for the feature space <italic>F</italic>(0). This estimation is updated <inline-formula id="IEq65"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F(N+1)=F(N)+F_{\text {update}}$$\end{document}</tex-math><mml:math id="M122"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mtext>update</mml:mtext></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq65.gif"/></alternatives></inline-formula> by encoding the feature space to image space, adding the noise estimation <inline-formula id="IEq66"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F_{\text {bg}}$$\end{document}</tex-math><mml:math id="M124"><mml:msub><mml:mi>F</mml:mi><mml:mtext>bg</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq66.gif"/></alternatives></inline-formula>. There, we calculate the difference to the original image, aiming for a feature space representation that is capable of completely describing the original image. The difference is subsequently encoded back to feature space and element-wise added to the previous estimation.</p>
      </sec>
    </sec>
    <sec id="Sec18">
      <title>Activation</title>
      <p id="Par27">A detailed visualization of the activations is shown in Additional file <xref rid="MOESM3" ref-type="media">3</xref>: Fig. S3. We used a sigmoid function on the output slice of the classifier image, to map each output pixel to a probability <inline-formula id="IEq67"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p \in [0,1]$$\end{document}</tex-math><mml:math id="M126"><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq67.gif"/></alternatives></inline-formula>. We constrained <inline-formula id="IEq68"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _x$$\end{document}</tex-math><mml:math id="M128"><mml:msub><mml:mi>σ</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq68.gif"/></alternatives></inline-formula>, <inline-formula id="IEq69"><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _y$$\end{document}</tex-math><mml:math id="M130"><mml:msub><mml:mi>σ</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq69.gif"/></alternatives></inline-formula> and <inline-formula id="IEq70"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _N$$\end{document}</tex-math><mml:math id="M132"><mml:msub><mml:mi>σ</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq70.gif"/></alternatives></inline-formula> to <inline-formula id="IEq71"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\in [0, 3]$$\end{document}</tex-math><mml:math id="M134"><mml:mrow><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq71.gif"/></alternatives></inline-formula> with a sigmoid activation multiplied by three to limit the standard deviation to a reasonable interval. A tangens hyperbolicus activation was applied to the subpixel coordinates <inline-formula id="IEq72"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta x$$\end{document}</tex-math><mml:math id="M136"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq72.gif"/></alternatives></inline-formula> and <inline-formula id="IEq73"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta y$$\end{document}</tex-math><mml:math id="M138"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq73.gif"/></alternatives></inline-formula> to clip these values into the range of <inline-formula id="IEq74"><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[-1,1]$$\end{document}</tex-math><mml:math id="M140"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq74.gif"/></alternatives></inline-formula>. This is important to maintain the advantages of local reconstruction while neglecting localisations beyond the local context.</p>
      <p id="Par28">We also considered softmax as activation function for the classifier image. Despite a higher learning rate, this approach has major drawbacks. Outputs always cover the full range <inline-formula id="IEq75"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p \in [0,1]$$\end{document}</tex-math><mml:math id="M142"><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq75.gif"/></alternatives></inline-formula>. This gives rise to false positives if there is no localisation within the observed region, or false negatives if more than one active localisation is present.</p>
    </sec>
    <sec id="Sec19">
      <title>Loss function</title>
      <p id="Par29">The loss function of our network is composed of several components and was adapted from DECODE [<xref ref-type="bibr" rid="CR7">7</xref>]. We implemented a localisation loss for predicted emitters, a count loss for an accurate number of localisations, a prediction probability close to one or zero, and a background loss predicting the noise level. The localisation loss represents a Gaussian mixture model of the probability <inline-formula id="IEq76"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_i$$\end{document}</tex-math><mml:math id="M144"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq76.gif"/></alternatives></inline-formula> for every pixel to contain a localisation, the position of said localisation <inline-formula id="IEq77"><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_i = x_{\text {px}} + \Delta x$$\end{document}</tex-math><mml:math id="M146"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mtext>px</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq77.gif"/></alternatives></inline-formula>, <inline-formula id="IEq78"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_i = y_{\text {px}} + \Delta y$$\end{document}</tex-math><mml:math id="M148"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mtext>px</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq78.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq79"><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_{\text {px}}, x_{\text {px}}$$\end{document}</tex-math><mml:math id="M150"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mtext>px</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mtext>px</mml:mtext></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq79.gif"/></alternatives></inline-formula> denote the coordinates of the current pixel and <inline-formula id="IEq80"><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta x, \Delta y$$\end{document}</tex-math><mml:math id="M152"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq80.gif"/></alternatives></inline-formula> its value, the estimated intensity <italic>N</italic> as well as the estimated error <inline-formula id="IEq81"><alternatives><tex-math id="M153">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M154"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq81.gif"/></alternatives></inline-formula> for each variable:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} P= &amp; {} \sum _{i}p_i e^{-\left( \frac{(x_i-x_t)^2}{\sigma _{ix}^2}+\frac{(y_i-y_t)^2}{\sigma _{iy}^2}+\frac{(N_i-N_t)^2}{\sigma _{iN}^2}\right) } \end{aligned}$$\end{document}</tex-math><mml:math id="M156" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mfenced close=")" open="("><mml:mfrac><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi mathvariant="italic">ix</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi mathvariant="italic">iy</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi mathvariant="italic">iN</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5071_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M157">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L_{\text {loc}}= &amp; {} \sum _{t} \frac{P}{\sqrt{(2\pi )^3\sigma _x\sigma _y\sigma _N}\sum _{m}p_m}, \end{aligned}$$\end{document}</tex-math><mml:math id="M158" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mtext>loc</mml:mtext></mml:msub><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:mfrac><mml:mi>P</mml:mi><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:msub><mml:mi>σ</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:msub><mml:mi>σ</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:msub><mml:mi>σ</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:mrow></mml:msqrt><mml:msub><mml:mo>∑</mml:mo><mml:mi>m</mml:mi></mml:msub><mml:msub><mml:mi>p</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5071_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq82"><alternatives><tex-math id="M159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_t$$\end{document}</tex-math><mml:math id="M160"><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq82.gif"/></alternatives></inline-formula> and <inline-formula id="IEq83"><alternatives><tex-math id="M161">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_t$$\end{document}</tex-math><mml:math id="M162"><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq83.gif"/></alternatives></inline-formula> denote the ground truth coordinates and <inline-formula id="IEq84"><alternatives><tex-math id="M163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N_t$$\end{document}</tex-math><mml:math id="M164"><mml:msub><mml:mi>N</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq84.gif"/></alternatives></inline-formula> the ground truth intensity. The count loss is<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M165">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L_{\text {count}} = \frac{(\sum _{i}p_i-c_t)^2}{2\sigma _c}-\ln (\sqrt{2\pi \sigma _c}), \end{aligned}$$\end{document}</tex-math><mml:math id="M166" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mtext>count</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>σ</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>-</mml:mo><mml:mo>ln</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mi>σ</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:msqrt><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5071_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq85"><alternatives><tex-math id="M167">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _c = \sum _{i}p_i(1-p_i)$$\end{document}</tex-math><mml:math id="M168"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq85.gif"/></alternatives></inline-formula> encourages results close to 0 and 1 and therefore, reduces uncertainty. The background loss is<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M169">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L_{\text {bg}} = \sqrt{(B_i-N_i)^2}, \end{aligned}$$\end{document}</tex-math><mml:math id="M170" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mtext>bg</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:msqrt><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5071_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq86"><alternatives><tex-math id="M171">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$B_i$$\end{document}</tex-math><mml:math id="M172"><mml:msub><mml:mi>B</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq86.gif"/></alternatives></inline-formula> denotes the predicted background and <inline-formula id="IEq87"><alternatives><tex-math id="M173">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N_i$$\end{document}</tex-math><mml:math id="M174"><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq87.gif"/></alternatives></inline-formula> the noiseless ground truth. The total loss is the sum of the individual loss functions:<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M175">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L = L_{\text {loc}} + L_{\text {count}} + L_{\text {bg}} \end{aligned}$$\end{document}</tex-math><mml:math id="M176" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mtext>loc</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mtext>count</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mtext>bg</mml:mtext></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5071_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec20">
      <title>Model evaluation</title>
      <p id="Par30">To evaluate the performance of our approach, we use the RMSE (Root Mean Squared Error) and the Jaccard-Index <italic>JI</italic>:<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M177">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} JI = \frac{TP}{TP+FP+FN}, \end{aligned}$$\end{document}</tex-math><mml:math id="M178" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>J</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5071_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>where <italic>TP</italic> are the true positives, <italic>FP</italic> the false positives and <italic>FN</italic> the false negatives. For real datasets with unknown ground truth, we used the Fourier Ring Correlation (FRC) as proposed in [<xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR26">26</xref>]<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M179">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} FRC(I_1,I_2) = \frac{\sum _{i\in R} FFT(I_1)(r_i)\cdot FFT(I_2)(r_i)^*}{\sqrt{(\sum _{i\in R}|FFT(I_1)(r_i)|^2)\cdot (\sum _{i\in R}|FFT(I_2)(r_i)|^2)}} \end{aligned}$$\end{document}</tex-math><mml:math id="M180" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi><mml:mi>R</mml:mi><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mi>F</mml:mi><mml:mi>F</mml:mi><mml:mi>T</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>·</mml:mo><mml:mi>F</mml:mi><mml:mi>F</mml:mi><mml:mi>T</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>F</mml:mi><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">(</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>F</mml:mi><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mo stretchy="false">|</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5071_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec21">
      <title>Training procedure</title>
      <p id="Par31">Using our simulation, we created a dataset consisting of 40 batches each containing 4<inline-formula id="IEq88"><alternatives><tex-math id="M181">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M182"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq88.gif"/></alternatives></inline-formula>1000 crops. Three of these sub-batches are used for training and one for evaluation. While the noise simulations are completely random for each crop, sigma is different for each batch and in the range of <inline-formula id="IEq89"><alternatives><tex-math id="M183">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma \in [175, 185]$$\end{document}</tex-math><mml:math id="M184"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>175</mml:mn><mml:mo>,</mml:mo><mml:mn>185</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq89.gif"/></alternatives></inline-formula>. The network is trained for 150 iterations followed by one evaluation circle, where we compute the JI, the RMSE and a validation loss. We used an Adam optimizer with a learning rate of <inline-formula id="IEq90"><alternatives><tex-math id="M185">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$10^{-4}$$\end{document}</tex-math><mml:math id="M186"><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq90.gif"/></alternatives></inline-formula>. Neural networks were implemented in Tensorflow 2 and trained on a Nvidia GTX 1080 TI GPU.</p>
    </sec>
  </sec>
  <sec id="Sec22">
    <title>Results</title>
    <sec id="Sec23">
      <title>Ground truth from simulated FLIMbee experiments</title>
      <p id="Par32">The first step before training a deep neural network is to obtain suitable ground truth. Training data can either be obtained from experiments and labeled by hand or by existing algorithms, or it can be generated using simulations. Since <italic>d</italic>STORM FLIMbee experimental data are difficult to measure and the performance of classical reconstruction algorithms is limited, we used the latter and developed a computer simulation of the FLIMbee measurement process. Using this tool, we simulated a dataset consisting of 40 batches, each containing 4<inline-formula id="IEq91"><alternatives><tex-math id="M187">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M188"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq91.gif"/></alternatives></inline-formula>1000 crops. Three of these sub-batches were used for training and one for evaluation.</p>
    </sec>
    <sec id="Sec24">
      <title>Trainable wavelet filter to find regions of interest</title>
      <p id="Par33">Reconstructing SMLM data requires a lot of computational power, as each super-resolved image is composed of millions of localisations retrieved from thousands of frames. On top of that, compressed sensing algorithms are computationally expensive: The size of the reconstruction matrix and therefore the speed of the reconstruction scale with the fourth power of image size, <inline-formula id="IEq92"><alternatives><tex-math id="M189">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m^4$$\end{document}</tex-math><mml:math id="M190"><mml:msup><mml:mi>m</mml:mi><mml:mn>4</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq92.gif"/></alternatives></inline-formula>. We reduce the dimension of the reconstruction problem by implementing a differentiable wavelet filter bank, trained to search for frequencies that resemble a PSF. ROIs are then cropped in a <inline-formula id="IEq93"><alternatives><tex-math id="M191">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$9\times 9\times 3$$\end{document}</tex-math><mml:math id="M192"><mml:mrow><mml:mn>9</mml:mn><mml:mo>×</mml:mo><mml:mn>9</mml:mn><mml:mo>×</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq93.gif"/></alternatives></inline-formula> area around the detected maximum, taking the temporal context of the previous and subsequent frame into account (Additional file <xref rid="MOESM4" ref-type="media">4</xref>: Fig. S4).</p>
    </sec>
    <sec id="Sec25">
      <title>Deep neural networks with CS</title>
      <p id="Par34">To combine the advantages of CS with the benefits of artificial intelligence, we implemented and trained four different network architectures. The first approach was a simple CNN using the CS layer as a prior (Fig. <xref rid="Fig2" ref-type="fig">2</xref>a). In the second approach, we used an Inception-like architecture [<xref ref-type="bibr" rid="CR20">20</xref>] combined with CS. This network has two steps with different iteration counts and values of <inline-formula id="IEq94"><alternatives><tex-math id="M193">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M194"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq94.gif"/></alternatives></inline-formula> (Fig. <xref rid="Fig2" ref-type="fig">2</xref>b). The third approach combines a classical U-Net architecture with CS, and the fourth network is a recursive U-Net-like architecture mimicking the iterative structure of CS. In all cases, the first layer has a size of <inline-formula id="IEq95"><alternatives><tex-math id="M195">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$9\times 9\times 3$$\end{document}</tex-math><mml:math id="M196"><mml:mrow><mml:mn>9</mml:mn><mml:mo>×</mml:mo><mml:mn>9</mml:mn><mml:mo>×</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq95.gif"/></alternatives></inline-formula> pixels, using the ROIs identified by the trainable wavelet transform as input.</p>
      <p id="Par35">To further constrain the compressed sensing part of our network we tried to implement an additional loss term for the CS layer to encourage a sparse reconstruction. For this term, we track the normalized compressed sensing output <italic>b</italic> of the inception layers and penalize entries differing from zero using the L<inline-formula id="IEq96"><alternatives><tex-math id="M197">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_1$$\end{document}</tex-math><mml:math id="M198"><mml:msub><mml:mrow/><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq96.gif"/></alternatives></inline-formula> loss. To prevent the compressed sensing part form diverging to zero, we apply the convolution matrix <italic>A</italic> to the CS output: <inline-formula id="IEq97"><alternatives><tex-math id="M199">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$s=Ab$$\end{document}</tex-math><mml:math id="M200"><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq97.gif"/></alternatives></inline-formula>. In case of an optimal reconstruction, this operation convolves a sparse sub-lattice with the measurement function while downsampling to the original image size. The result <italic>s</italic> is a denoised version of the original image. The loss can then be computed as squared difference to the noiseless training data:<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M201">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L_{\text {cs}} = \sum _{i} |b_i| + (s_i-n_i)^2 \end{aligned}$$\end{document}</tex-math><mml:math id="M202" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mtext>cs</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5071_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>Since this did not improve the results significantly we discarded the loss term in our final network versions.</p>
    </sec>
    <sec id="Sec26">
      <title>Comparison of network architectures</title>
      <p id="Par36">We computed the RMSE, JI and validation loss every 150 steps on an independent test batch during training (Fig. <xref rid="Fig3" ref-type="fig">3</xref>a). After training, we compared the average performance of the four different network architectures on 25 different simulated validation datasets (Fig. <xref rid="Fig3" ref-type="fig">3</xref>b). As additional baseline, we also include the results of fitting the same datasets with ThunderSTORM, a widely used conventional SMLM fitter. The recursive U-Net achieved the best results compared to the other methods. It can be observed that CS in the form of FISTA is a solid prior for the Inception-like network, leading to an early increase in metrics. For higher iterations, however, the network metrics converge. The training time per epoch for the Inception architecture (<inline-formula id="IEq98"><alternatives><tex-math id="M203">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$2091.3\,$$\end{document}</tex-math><mml:math id="M204"><mml:mrow><mml:mn>2091.3</mml:mn><mml:mspace width="0.166667em"/></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq98.gif"/></alternatives></inline-formula>s) is 32.6 times higher than the training time per epoch of the CS-Res-U Net (<inline-formula id="IEq99"><alternatives><tex-math id="M205">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$64.1\,$$\end{document}</tex-math><mml:math id="M206"><mml:mrow><mml:mn>64.1</mml:mn><mml:mspace width="0.166667em"/></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq99.gif"/></alternatives></inline-formula>s). For the evaluation of an example dataset, the Rec U-Net still introduces a 5.6 fold acceleration in comparison to the Inception architecture. A detailed evaluation of the training and evaluation performances is shown in Table <xref rid="Tab1" ref-type="table">1</xref>.</p>
    </sec>
    <sec id="Sec27">
      <title>Application to experimental data</title>
      <p id="Par37">We performed experiments with a FLIMbee galvanometric scanner as described in the methods (Fig. <xref rid="Fig4" ref-type="fig">4</xref>) and tested the trained networks on these real data. The raw data shows the typical interrupted PSF as well as a varying intensity between lines. Trained for these non-linearities, our network is able to precisely predict the center of these localisations. To assess the quality of prediction on experimental data, we used FRC and LineProfiler, as objective ground truth was not available in this case. The results (CSInception: 0.211 Rec U-Net: 0.265) indicate an improved reconstruction quality compared to classical fitters like ThunderSTORM (0.167) (Fig. <xref rid="Fig5" ref-type="fig">5</xref>). Note that an additional drift correction improves the quality of the reconstruction significantly. For the image in Fig. <xref rid="Fig4" ref-type="fig">4</xref> we applied a linear drift. For the images in Fig. <xref rid="Fig5" ref-type="fig">5</xref>, we used the ThunderSTORM RCC drift correction.</p>
    </sec>
  </sec>
  <sec id="Sec28">
    <title>Discussion</title>
    <p id="Par38">We developed a robust data simulator for FLIMbee SMLM measurements, combining the method-specific disrupted PSFs with accurate noise simulations. We furthermore introduce a learnable wavelet filter that can be trained to accurately detect emitters and crop them to enhance the speed of the evaluation pipeline. Finally, we implemented and evaluated different approaches to integrate compressed sensing operations into deep neural networks for the reconstruction of super-resolution images from nonlinear disrupted PSFs.</p>
    <p id="Par39">The Recursive U-Net architecture achieved the best JI and RMSE performance on simulated data as well as the best FRC score on real data, while architectures with CS-like sparse representations did not perform as well. This indicates that sparse representations might not be optimal for the learning process of neural networks. A possible reason may be the large amount of zero values in the sparse representation, leading to a vanishing gradient for large fractions of the feature space. Neural networks might be better suited to create a parameterized representation of the sparse sub-domain, like compressed sparse row [<xref ref-type="bibr" rid="CR27">27</xref>], or to directly compute the feature space representation as proposed in the Recursive U-Net.</p>
    <p id="Par40">The trainable wavelet filter is an efficient way to identify regions of interest in SMLM data. Trained on realistic simulated data, it is able to filter background frequencies and to accurately determine regions of interest. Fitting the center of sparsely activated emitters is a redundant problem, so preselecting regions of interest has several advantages over reconstructing a whole image. The subsequent reconstruction network is scalable, since the reconstructed regions of interest always have identical size. On top of that, training duration and network depth can be reduced drastically. However, there are cases where prefiltering has its limits or even introduces disadvantages. High density samples pose a problem since emitters overlap and have less resemblance with the original PSF. Data that diverges too much from the original training data can also lead to loss of localisations. For the given problem of low density emitters with disrupted PSFs, however, it is an efficient way to identify regions of interest.</p>
    <p id="Par41">As stated in [<xref ref-type="bibr" rid="CR7">7</xref>], inaccurately estimated localisations tend to be reconstructed towards the center of a feature space pixel. This can be overcome by adjusting the precision threshold and/or the reconstruction method (local maxima). Interestingly, this feature was also observed for classical compressed sensing methods like [<xref ref-type="bibr" rid="CR28">28</xref>] and seems to be a general problem of discrete feature spaces.</p>
    <p id="Par42">The fact that metrics converge at high iterations may be caused by the linear convergence of L1 minimization algorithms, as the available information before full convergence is limited. Another possible explanation is that the training process is able to extract the necessary information even with low iteration counts. Interestingly, the best results in terms of JI and RMSE do not coincide with the best validation loss. Possible explanations of this behavior include overfitting, or local minima with very low underestimated localisation uncertainty.</p>
    <p id="Par43">As can bee seen from Table <xref rid="Tab1" ref-type="table">1</xref>, the initial FISTA layer introduces a large computational cost, making the Recursive U-Net approach much faster than the CS-like implementations. This architecture resembles the unfolding of CS interations in a deep neural network, as proposed by Gregor and LeCun [<xref ref-type="bibr" rid="CR29">29</xref>]. This approach has already been applied to SOFI super-resolution imaging using sparsity in the correlation domain [<xref ref-type="bibr" rid="CR30">30</xref>] by unrolling the iterative FISTA compressed sensing algorithm into a deep neural network. Our results confirm that algorithm unfolding is an efficient method to combine the advantages of iterative compressed sensing methods with deep learning for reconstruction of high-resolution microscopy data and will likely see many other applications in the future.</p>
    <p id="Par44">The biggest limitation of current AI-based image reconstruction and interpretation is the amount of training data required, since neural networks easily overfit to the training set and most architectures do not generalize well to data outside of the training distribution. Simulated ground truth, as used here, can alleviate this problem as it is easier to obtain than experimental measurements and makes manual annotation obsolete. It does however require a detailed understanding of the measurement process and a precise noise model. In addition, each simulated dataset can only represent a small subset of possible experimental conditions, as defined by the parameters of the simulation such as the optical properties of the microscope or the noise distribution and intensity. As soon as a different microscope or sample type is used, the neural network needs to be retrained. Traditional fitting algorithms do not suffer from this limitation as they already incorporate a highly constrained model of possible outcomes, such as the Gaussian-like PSF in classical SMLM. The solution could be to introduce similar constraints to neural network architectures to lower the dimensionality of their search space during training. In the context of medical imaging, a similar concept has been proposed as known operator learning [<xref ref-type="bibr" rid="CR31">31</xref>]. Compressed sensing reduces the search space by adding sparsity as a constraint. This makes it a highly suitable choice of algorithm for SMLM reconstruction. Since most image-based measurements are sparse in one or several domains, an efficient combination of CS and neural networks could solve the training data problem of deep learning in this domain. A particularly interesting direction, besides algorithm unrolling already discussed in the previous paragraph, is to add the existing knowledge of the measurement process to the model by making the simulation part (data generator) trainable, as discussed for example by Lillicrap et al. [<xref ref-type="bibr" rid="CR32">32</xref>]</p>
    <p id="Par45">The current state-of-the-art for fitting classical localization data according to the SMLM challenge [<xref ref-type="bibr" rid="CR10">10</xref>] is DECODE [<xref ref-type="bibr" rid="CR7">7</xref>]. In this work, three independent U-Nets were applied to three consecutive frames to detect localizations. It was not possible to perform a direct comparison of our approach to DECODE, since its training process is tightly coupled to a simulation of frames with a spline-parameterized PSF that is not compatible with our confocal <italic>d</italic>STORM data. If the training process could be adapted to incorporate our simulator, it would be interesting to see if it performs as well as our CS U-Net-based approach, since we adapted our loss function and output format from DECODE.</p>
  </sec>
  <sec id="Sec29">
    <title>Conclusions</title>
    <p id="Par46">We developed a data generator for nonlinear PSFs in the context of super-resolved confocal lifetime imaging and were able to reconstruct localisations with improved accuracy compared to classical fitters by developing and training an artificial neural network. Next to an improvement in computation time, we demonstrate the adaptation of compressed sensing to deep neural networks for reconstructing non-linearly varying PSFs. Our results indicate that using a deep architecture like inception is beneficial to the models performance. Including local context by reconstructing to the original crop size as well as including the temporal context of the previous and subsequent frame improves the reconstruction quality significantly. Implementing compressed sensing into artificial neural networks is a promising concept, but further work has to be done to improve the implementation details. For an optimal solution, the CS part should fully converge. This is, however, computationally demanding since every iteration contains a nontrivial derivation used by the network for back-propagation. In comparison, algorithm unfolding appears to be a more efficient way to integrate compressed sensing and deep learning.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec170">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2022_5071_MOESM1_ESM.png">
            <caption>
              <p><bold>Additional file 1.</bold><bold>Fig. S1.</bold> Reconstruction threshold. To identify the optimal threshold to reconstruct localisations from feature space, we tested the influence of the parameter on our validation data. It can be seen that the Jaccard Index peaks for a value of 0.7.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="12859_2022_5071_MOESM2_ESM.jpg">
            <caption>
              <p><bold>Additional file 2.</bold><bold>Fig. S2.</bold> Inception building block. This building block is derived from the inception network [<xref ref-type="bibr" rid="CR20">20</xref>]. The input is processed in 4 different paths (from left to right). We estimate the compressed sensing parameter <inline-formula id="IEq16"><alternatives><tex-math id="M207">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M208"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq16.gif"/></alternatives></inline-formula> with a conventional CNN. The input is processed by a bottleneck layer, followed by the compressed sensing layer. Several convolutional layers restore the original image size. A feature detector applies asymmetric filters from different directions. A pass-through only applies an activation function, passing forward the original image.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="12859_2022_5071_MOESM3_ESM.jpg">
            <caption>
              <p><bold>Additional file 3.</bold><bold>Fig. S3.</bold> Activations of the output layer. The relative positions <inline-formula id="IEq10"><alternatives><tex-math id="M209">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta x$$\end{document}</tex-math><mml:math id="M210"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq10.gif"/></alternatives></inline-formula> and <inline-formula id="IEq11"><alternatives><tex-math id="M211">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta y$$\end{document}</tex-math><mml:math id="M212"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq11.gif"/></alternatives></inline-formula> are fed into a Gaussian mixture model with the local probability <italic>p</italic> and the positional uncertainties <inline-formula id="IEq12"><alternatives><tex-math id="M213">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _x$$\end{document}</tex-math><mml:math id="M214"><mml:msub><mml:mi>σ</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq12.gif"/></alternatives></inline-formula> and <inline-formula id="IEq13"><alternatives><tex-math id="M215">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _y$$\end{document}</tex-math><mml:math id="M216"><mml:msub><mml:mi>σ</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq13.gif"/></alternatives></inline-formula>. The estimated intensity <italic>N</italic> is included into the localisation loss. While <inline-formula id="IEq14"><alternatives><tex-math id="M217">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta x$$\end{document}</tex-math><mml:math id="M218"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq14.gif"/></alternatives></inline-formula> and <inline-formula id="IEq15"><alternatives><tex-math id="M219">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta y$$\end{document}</tex-math><mml:math id="M220"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5071_Article_IEq15.gif"/></alternatives></inline-formula> are <italic>tanh</italic> activated, all other components are sigmoid activated.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM4">
          <media xlink:href="12859_2022_5071_MOESM4_ESM.jpg">
            <caption>
              <p><bold>Additional file 4.</bold><bold>Fig. S4.</bold> Wavelet filter bank peak detection on an example frame of a FLIMbee measurement. The input image <bold>a</bold> is deconstructed with a wavelet filter bank, trained to extract frequencies resembling a PSF. A threshold is applied before reconstructing to generate a denoised image <bold>b</bold>. Potential emitters are identified with a local maximum detection. The detected peaks are marked with red rectangles.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>PK, MS and SR designed the project. SR wrote the code and performed the evaluations. DAH and DB performed the FLIMBee measurements. PK, SR and DAH wrote the manuscript. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>Open Access funding enabled and organized by Projekt DEAL. MS has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (Grant agreement No 835102) and the Deutsche Forschungsgemeinschaft (DFG SA829/19-1). PK has received funding from Deutsche Forschungsgemeinschaft (DFG KO3715/5-1).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The described software is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/super-resolution/ReCSAI">https://github.com/super-resolution/ReCSAI</ext-link>. The dataset supporting the conclusions of this article is available at <ext-link ext-link-type="uri" xlink:href="https://drive.google.com/drive/folders/1gMRARPgdH9GwV4wiO03SVG-qPNDXgwzi">https://drive.google.com/drive/folders/1gMRARPgdH9GwV4wiO03SVG-qPNDXgwzi</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par47">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par48">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par49">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Abbe</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Beiträge zur Theorie des Mikroskops und der mikroskopischen Wahrnehmung</article-title>
        <source>Archiv für Mikroskopische Anatomie.</source>
        <year>1873</year>
        <volume>9</volume>
        <fpage>413</fpage>
        <lpage>68</lpage>
        <pub-id pub-id-type="doi">10.1007/BF02956173</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Heilemann</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>van de Linde</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schüttpelz</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kasper</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Seefeldt</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Mukherjee</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Subdiffraction-resolution fluorescence imaging with conventional fluorescent probes</article-title>
        <source>Angew Chem Int Ed</source>
        <year>2008</year>
        <volume>47</volume>
        <issue>33</issue>
        <fpage>6172</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="doi">10.1002/anie.200802376</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Siemons</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hulleman</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Thorsen</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Stallinga</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>High precision wavefront control in point spread function engineering for single emitter localization</article-title>
        <source>Opt Express</source>
        <year>2018</year>
        <volume>26</volume>
        <issue>7</issue>
        <fpage>8397</fpage>
        <pub-id pub-id-type="doi">10.1364/OE.26.008397</pub-id>
        <pub-id pub-id-type="pmid">29715807</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Elnatan</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Faster STORM using compressed sensing</article-title>
        <source>Nat Methods.</source>
        <year>2012</year>
        <volume>9</volume>
        <issue>7</issue>
        <fpage>721</fpage>
        <lpage>3</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.1978</pub-id>
        <pub-id pub-id-type="pmid">22522657</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Babcock</surname>
            <given-names>HP</given-names>
          </name>
          <name>
            <surname>Moffitt</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhuang</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Fast compressed sensing analysis for super-resolution imaging using L1-homotopy</article-title>
        <source>Opt Express.</source>
        <year>2013</year>
        <volume>21</volume>
        <issue>23</issue>
        <fpage>28583</fpage>
        <lpage>96</lpage>
        <pub-id pub-id-type="doi">10.1364/OE.21.028583</pub-id>
        <pub-id pub-id-type="pmid">24514370</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nehme</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Weiss</surname>
            <given-names>LE</given-names>
          </name>
          <name>
            <surname>Michaeli</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Shechtman</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Deep-STORM: super-resolution single-molecule microscopy by deep learning</article-title>
        <source>Optica.</source>
        <year>2018</year>
        <volume>5</volume>
        <issue>4</issue>
        <fpage>458</fpage>
        <lpage>64</lpage>
        <pub-id pub-id-type="doi">10.1364/OPTICA.5.000458</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Speiser</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Müller</surname>
            <given-names>LR</given-names>
          </name>
          <name>
            <surname>Hoess</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Matti</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Obara</surname>
            <given-names>CJ</given-names>
          </name>
          <name>
            <surname>Legant</surname>
            <given-names>WR</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep learning enables fast and dense single-molecule localization with high accuracy</article-title>
        <source>Nat Methods.</source>
        <year>2021</year>
        <volume>18</volume>
        <issue>9</issue>
        <fpage>1082</fpage>
        <lpage>90</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-021-01236-x</pub-id>
        <pub-id pub-id-type="pmid">34480155</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Reinhard</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Aufmkolk</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sauer</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Doose</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Registration and visualization of correlative super-resolution microscopy data</article-title>
        <source>Biophys J</source>
        <year>2019</year>
        <volume>116</volume>
        <issue>11</issue>
        <fpage>2073</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1016/j.bpj.2019.04.029</pub-id>
        <pub-id pub-id-type="pmid">31103233</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thiele</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Helmerich</surname>
            <given-names>DA</given-names>
          </name>
          <name>
            <surname>Oleksiievets</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Tsukanov</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Butkevich</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Sauer</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Confocal fluorescence-lifetime single-molecule localization microscopy</article-title>
        <source>ACS Nano.</source>
        <year>2020</year>
        <volume>14</volume>
        <issue>10</issue>
        <fpage>14190</fpage>
        <lpage>200</lpage>
        <pub-id pub-id-type="doi">10.1021/acsnano.0c07322</pub-id>
        <pub-id pub-id-type="pmid">33035050</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sage</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Pham</surname>
            <given-names>TA</given-names>
          </name>
          <name>
            <surname>Babcock</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Lukes</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Pengo</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Chao</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Super-resolution fight club: assessment of 2D and 3D single-molecule localization microscopy software</article-title>
        <source>Nat Methods.</source>
        <year>2019</year>
        <volume>16</volume>
        <issue>5</issue>
        <fpage>387</fpage>
        <lpage>95</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-019-0364-4</pub-id>
        <pub-id pub-id-type="pmid">30962624</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Solomon</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Mutzafi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Segev</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Eldar</surname>
            <given-names>YC</given-names>
          </name>
        </person-group>
        <article-title>Sparsity-based super-resolution microscopy from correlation information</article-title>
        <source>Opt Express.</source>
        <year>2018</year>
        <volume>26</volume>
        <issue>14</issue>
        <fpage>18238</fpage>
        <lpage>69</lpage>
        <pub-id pub-id-type="doi">10.1364/OE.26.018238</pub-id>
        <pub-id pub-id-type="pmid">30114104</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Corizzo R, Dauphin Y, Bellinger C, Zdravevski E, Japkowicz N. Explainable image analysis for decision support in medical healthcare. In: 2021 IEEE international conference on big data (big data); 2021. p. 4667–74.</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Berberich</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kurz</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Reinhard</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Paul</surname>
            <given-names>TJ</given-names>
          </name>
          <name>
            <surname>Burd</surname>
            <given-names>PR</given-names>
          </name>
          <name>
            <surname>Sauer</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Fourier ring correlation and anisotropic kernel density estimation improve deep learning based smlm reconstruction of microtubules</article-title>
        <source>Front Bioinf</source>
        <year>2021</year>
        <volume>1</volume>
        <fpage>55</fpage>
        <pub-id pub-id-type="doi">10.3389/fbinf.2021.752788</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zwettler</surname>
            <given-names>FU</given-names>
          </name>
          <name>
            <surname>Reinhard</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sauer</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Ex-dSTORM and automated quantitative image analysis of expanded filamentous structures</article-title>
        <source>Methods Cell Biol</source>
        <year>2021</year>
        <volume>161</volume>
        <fpage>317</fpage>
        <lpage>40</lpage>
        <pub-id pub-id-type="doi">10.1016/bs.mcb.2020.05.004</pub-id>
        <pub-id pub-id-type="pmid">33478695</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Lelek M, Gyparaki MT, Beliu G, Schueder F, Griffié J, Manley S, et al. Single-molecule localization microscopy. Nature Reviews Methods Primers. 2021 Jun;1(1):1–27. Number: 1 Publisher: Nature Publishing Group. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s43586-021-00038-x">https://www.nature.com/articles/s43586-021-00038-x</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Astropy</surname>
            <given-names>Collaboration</given-names>
          </name>
          <name>
            <surname>Price-Whelan</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>SipHocz</surname>
            <given-names>BM</given-names>
          </name>
          <name>
            <surname>Günther</surname>
            <given-names>HM</given-names>
          </name>
          <name>
            <surname>Lim</surname>
            <given-names>PL</given-names>
          </name>
          <name>
            <surname>Crawford</surname>
            <given-names>SM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The astropy project: building an open-science project and status of the v2.0 core package</article-title>
        <source>aj</source>
        <year>2018</year>
        <volume>156</volume>
        <issue>3</issue>
        <fpage>123</fpage>
        <pub-id pub-id-type="doi">10.3847/1538-3881/aabc4f</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Bradski G. The OpenCV Library. Dr Dobb’s Journal of Software Tools. 2000;.</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Douglass KM. Modeling noise for image simulations; 2017. Available from: <ext-link ext-link-type="uri" xlink:href="http://kmdouglass.github.io/posts/modeling-noise-for-image-simulations/">http://kmdouglass.github.io/posts/modeling-noise-for-image-simulations/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Beck</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Teboulle</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>A fast iterative shrinkage-thresholding algorithm for linear inverse problems</article-title>
        <source>SIAM J Imaging Sci</source>
        <year>2009</year>
        <volume>2</volume>
        <issue>1</issue>
        <fpage>183</fpage>
        <lpage>202</lpage>
        <pub-id pub-id-type="doi">10.1137/080716542</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z. Rethinking the inception architecture for computer vision. In: 2016 IEEE conference on computer vision and pattern recognition (CVPR); 2016. p. 2818–26.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Ronneberger</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Fischer</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Brox</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Navab</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hornegger</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wells</surname>
            <given-names>WM</given-names>
          </name>
          <name>
            <surname>Frangi</surname>
            <given-names>AF</given-names>
          </name>
        </person-group>
        <article-title>U-Net: convolutional networks for biomedical image segmentation</article-title>
        <source>Medical image computing and computer-assisted intervention - MICCAI 2015. Lecture notes in computer science</source>
        <year>2015</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer International Publishing</publisher-name>
        <fpage>234</fpage>
        <lpage>41</lpage>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mizusawa</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sei</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Orihara</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Ohsuga</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Computed tomography image reconstruction using stacked U-Net</article-title>
        <source>Comput Med Imag Graph</source>
        <year>2021</year>
        <volume>90</volume>
        <fpage>101920</fpage>
        <pub-id pub-id-type="doi">10.1016/j.compmedimag.2021.101920</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Le</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Mendes</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wilson</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Ibrahim</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>DiBella</surname>
            <given-names>E</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep learning for radial SMS myocardial perfusion reconstruction using the 3D residual booster U-net</article-title>
        <source>Magn Reson Imag</source>
        <year>2021</year>
        <volume>83</volume>
        <fpage>178</fpage>
        <lpage>88</lpage>
        <pub-id pub-id-type="doi">10.1016/j.mri.2021.08.007</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. In: 2016 IEEE conference on computer vision and pattern recognition (CVPR). Las Vegas, NV, USA: IEEE; 2016. p. 770–8.</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Lu X, Dong W, Wang P, Shi G, Xie X. ConvCSNet: a convolutional compressive sensing framework based on deep learning. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1801.10342">arXiv:1801.10342</ext-link> [cs]. 2018.</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Banterle</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Bui</surname>
            <given-names>KH</given-names>
          </name>
          <name>
            <surname>Lemke</surname>
            <given-names>EA</given-names>
          </name>
          <name>
            <surname>Beck</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Fourier ring correlation as a resolution criterion for super-resolution microscopy</article-title>
        <source>J Struct Biol</source>
        <year>2013</year>
        <volume>183</volume>
        <issue>3</issue>
        <fpage>363</fpage>
        <lpage>7</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jsb.2013.05.004</pub-id>
        <pub-id pub-id-type="pmid">23684965</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Bell N, Garland M. E?cient Sparse Matrix-Vector Multiplication on CUDA. Nvidia Technical Report NVR-2008-004, Nvidia Corporation. 2008;2(5):32.</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Min</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Vonesch</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Kirshner</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Carlini</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Olivier</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Holden</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>FALCON: fast and unbiased reconstruction of high-density super-resolution microscopy data</article-title>
        <source>Sci Rep</source>
        <year>2015</year>
        <volume>4</volume>
        <issue>1</issue>
        <fpage>4577</fpage>
        <pub-id pub-id-type="doi">10.1038/srep04577</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Gregor K, LeCun Y. Learning fast approximations of sparse coding. In: Proceedings of the 27th international conference on international conference on machine learning. ICML’10. Madison, WI, USA: Omnipress; 2010. p. 399–406.</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dardikman-Yoffe</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Eldar</surname>
            <given-names>YC</given-names>
          </name>
        </person-group>
        <article-title>Learned SPARCOM: unfolded deep super-resolution microscopy</article-title>
        <source>Opt Express</source>
        <year>2020</year>
        <volume>28</volume>
        <issue>19</issue>
        <fpage>27736</fpage>
        <lpage>63</lpage>
        <pub-id pub-id-type="doi">10.1364/OE.401925</pub-id>
        <pub-id pub-id-type="pmid">32988061</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Maier AK, Syben C, Stimpel B, Würfl T, Hoffmann M, Schebesch F, et al. Learning with known operators reduces maximum error bounds. Nat Mach Intell. 2019;1(8):373–80. Number: 8 Publisher: Nature Publishing Group. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s42256-019-0077-5">https://www.nature.com/articles/s42256-019-0077-5</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <mixed-citation publication-type="other">Wu Y, Rosca M, Lillicrap T. Deep compressed sensing. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1905.06723">arXiv:1905.06723</ext-link> [cs, eess, stat]. 2019 May;ArXiv: 1905.06723. Available from: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1905.06723">http://arxiv.org/abs/1905.06723</ext-link>.</mixed-citation>
    </ref>
  </ref-list>
</back>
