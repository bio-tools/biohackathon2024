<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Mol Cancer Res</journal-id>
    <journal-id journal-id-type="iso-abbrev">Mol Cancer Res</journal-id>
    <journal-title-group>
      <journal-title>Molecular Cancer Research</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1541-7786</issn>
    <issn pub-type="epub">1557-3125</issn>
    <publisher>
      <publisher-name>American Association for Cancer Research</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9127877</article-id>
    <article-id pub-id-type="pmid">34880124</article-id>
    <article-id pub-id-type="publisher-id">MCR-21-0665</article-id>
    <article-id pub-id-type="doi">10.1158/1541-7786.MCR-21-0665</article-id>
    <article-version id="ver1" article-version-type="VoR">Version of Record</article-version>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Perspective</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Building Tools for Machine Learning and Artificial Intelligence in Cancer Research: Best Practices and a Case Study with the PathML Toolkit for Computational Pathology</article-title>
      <alt-title alt-title-type="short">Building Tools for AI in Cancer Research: Landscape &amp; PathML</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-1767-1826</contrib-id>
        <name>
          <surname>Rosenthal</surname>
          <given-names>Jacob</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="aff2" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Carelli</surname>
          <given-names>Ryan</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="aff2" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-8068-1920</contrib-id>
        <name>
          <surname>Omar</surname>
          <given-names>Mohamed</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Brundage</surname>
          <given-names>David</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="aff2" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Halbert</surname>
          <given-names>Ella</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Nyman</surname>
          <given-names>Jackson</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7970-4307</contrib-id>
        <name>
          <surname>Hari</surname>
          <given-names>Surya N.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Van Allen</surname>
          <given-names>Eliezer M.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="aff4" ref-type="aff">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-7336-8071</contrib-id>
        <name>
          <surname>Marchionni</surname>
          <given-names>Luigi</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-5561-6932</contrib-id>
        <name>
          <surname>Umeton</surname>
          <given-names>Renato</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="aff2" ref-type="aff">2</xref>
        <xref rid="aff5" ref-type="aff">5</xref>
        <xref rid="aff6" ref-type="aff">6</xref>
        <xref rid="cor1" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-9674-8379</contrib-id>
        <name>
          <surname>Loda</surname>
          <given-names>Massimo</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="aff2" ref-type="aff">2</xref>
        <xref rid="cor1" ref-type="corresp">*</xref>
      </contrib>
    </contrib-group>
    <aff id="aff1"><label>1</label>Dana-Farber Cancer Institute, Boston, Massachusetts.</aff>
    <aff id="aff2"><label>2</label>Weill Cornell Medicine, New York, New York.</aff>
    <aff id="aff3"><label>3</label>Oberlin College, Oberlin, Ohio.</aff>
    <aff id="aff4"><label>4</label>Broad Institute of MIT and Harvard, Cambridge, Massachusetts.</aff>
    <aff id="aff5"><label>5</label>Harvard T.H. Chan School of Public Health, Boston, Massachusetts.</aff>
    <aff id="aff6"><label>6</label>Massachusetts Institute of Technology, Cambridge, Massachusetts.</aff>
    <author-notes>
      <corresp id="cor1"><label>*</label><bold>Corresponding Authors:</bold> Renato Umeton, Department of Informatics and Analytics, Dana-Farber Cancer Institute, Boston, MA 02215. Phone: 617-632-3000; E-mail: <email>renato_umeton@dfci.harvard.edu</email>; and Massimo Loda, New York Presbyterian-Weill Cornell Campus, 1300 York Avenue, Room C-302 New York, NY 10065. E-mail: <email>mloda@med.cornell.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub" iso-8601-date="2022-02-01">
      <day>01</day>
      <month>2</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-12-08">
      <day>08</day>
      <month>12</month>
      <year>2021</year>
    </pub-date>
    <volume>20</volume>
    <issue>2</issue>
    <fpage>202</fpage>
    <lpage>206</lpage>
    <history>
      <date date-type="received" iso-8601-date="2021-08-13">
        <day>13</day>
        <month>8</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd" iso-8601-date="2021-10-25">
        <day>25</day>
        <month>10</month>
        <year>2021</year>
      </date>
      <date date-type="accepted" iso-8601-date="2021-12-01">
        <day>01</day>
        <month>12</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>©2021 The Authors; Published by the American Association for Cancer Research</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>American Association for Cancer Research</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This open access article is distributed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="202.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>Imaging datasets in cancer research are growing exponentially in both quantity and information density. These massive datasets may enable derivation of insights for cancer research and clinical care, but only if researchers are equipped with the tools to leverage advanced computational analysis approaches such as machine learning and artificial intelligence. In this work, we highlight three themes to guide development of such computational tools: scalability, standardization, and ease of use. We then apply these principles to develop PathML, a general-purpose research toolkit for computational pathology. We describe the design of the PathML framework and demonstrate applications in diverse use cases. PathML is publicly available at <ext-link xlink:href="http://www.pathml.com" ext-link-type="uri" xlink:show="new">www.pathml.com</ext-link>.</p>
    </abstract>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution>NIH</institution>
            <institution-id institution-id-type="DOI">http://dx.doi.org/10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>F31CA250136</award-id>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution>NCI</institution>
            <institution-id institution-id-type="DOI">https://doi.org/10.13039/100000054</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>P50CA211024</award-id>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution>DoD</institution>
            <institution-id institution-id-type="DOI">http://dx.doi.org/10.13039/100000005</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>PC160357</award-id>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution>DoD</institution>
            <institution-id institution-id-type="DOI">http://dx.doi.org/10.13039/100000005</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>PC180582</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="5"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="sec1">
    <title>Big Data, Image Analysis, and Machine Learning in Cancer Research</title>
    <p>Imaging has long been a cornerstone of cancer research and clinical care, providing insight into tissue morphology and spatial intercellular dynamics. Technological advances in recent years have enabled microscopy at a larger scale than ever before, leading to exponential growth in the size of commonly available datasets—a trend that is likely to continue to accelerate in coming years.</p>
    <p>“Big Data” in biomedical imaging can be conceptualized along two orthogonal axes: sample size and data dimensionality (<xref rid="fig1" ref-type="fig">Fig. 1</xref>). The first axis (<italic toggle="yes">n</italic>) can be measured by simply counting the number of cases in a dataset. Scaling in this dimension has been chiefly driven by advances in high-throughput imaging technologies. A notable example can be seen in the field of pathology, where increasing adoption of digital workflows results in slide scanning being routinely incorporated into pathologists' workflows, consequently creating large databases of whole slide images (WSI). Early adopters of digital pathology workflows are scanning more than 1 million slides per year (<xref rid="bib1" ref-type="bibr">1</xref>)—several orders of magnitude larger than current benchmark datasets such as The Cancer Genome Atlas, and an indication of the potential volume of data that large academic tertiary care hospitals can expect to routinely generate as workflows are increasingly digitized.</p>
    <fig position="float" id="fig1">
      <label>Figure 1.</label>
      <caption>
        <p>"Big Data" in biomedical imaging scales along two orthogonal axes: dataset size (<italic toggle="yes">n</italic>), which captures the number of data points (i.e., cases) in each dataset, and data dimensionality (<italic toggle="yes">d</italic>), which refers to the amount of data captured in each data point.</p>
      </caption>
      <alt-text>Figure 1. "Big Data" in biomedical imaging scales along two orthogonal axes: dataset size (n), which captures the number of data points (i.e., cases) in each dataset, and data dimensionality (d), which refers to the amount of data captured in each data point.</alt-text>
      <graphic xlink:href="202fig1" position="float"/>
    </fig>
    <p>At the same time, data are also growing in the amount of information captured in each image, which we refer to as data dimensionality (<italic toggle="yes">d</italic>). This is chiefly driven by emerging technologies in spatial omics (i.e., spatial quantification of molecular markers such as proteins or RNA) and highly multiplexed imaging (reviewed in ref. <xref rid="bib2" ref-type="bibr">2</xref>). In contrast to brightfield images with three channels (red, green, and blue), each of these high-dimensional images may have upward of 10,000 channels, each representing a specific target. Volumetric imaging further increases information content in each specimen by adding a depth dimension, enabling the capture of three-dimensional tissue morphology. Thus, dataset sizes can grow even while the number of cases remains constant.</p>
    <p>This rapid proliferation of imaging data has significant implications for cancer research, especially in conjunction with accompanying metadata such as genomics and outcomes. Large sample sizes provide sufficient power for discovery and quantification of histologic patterns associated with clinically and biologically relevant features, with recent work demonstrating the potential of these methods to improve clinical and diagnostic workflows (<xref rid="bib3" ref-type="bibr">3–5</xref>) and discover image-based biomarkers that recapitulate molecular features (<xref rid="bib6" ref-type="bibr">6, 7</xref>). Similarly, the rich contextual information captured in high-dimensional imaging data lays the groundwork for interrogation of tumor microenvironment at unprecedented resolution (<xref rid="bib8" ref-type="bibr">8, 9</xref>). The ubiquity of brightfield microscopy makes it an especially attractive candidate for image-based biomarker development, as digital workflows are increasingly deployed in a wider variety of clinical contexts.</p>
    <p>However, while increasing scale of imaging datasets presents new opportunities and avenues of investigation, it also presents major challenges. Namely, these advances are only possible by leveraging computational image analysis methods, particularly deep learning. Deep learning models are flexible and powerful and have demonstrated remarkable success at identifying patterns in large datasets. As cancer research enters the age of “Big Data,” machine learning and is therefore poised to become an increasingly essential tool in the researcher's toolkit, necessary for making use of massive datasets to study impactful questions in cancer biology and clinical care.</p>
    <p>To enable this transition, software tools must lower the barrier to entry for computational image analysis, providing a bridge between the worlds of cancer research and machine learning. In this work, we discuss general features necessary for successful software tools, and present PathML: an open-source toolkit for computational pathology which we have built to address this outstanding need.</p>
  </sec>
  <sec id="sec2">
    <title>Guiding Principles for Building Software Tools to Accelerate Research</title>
    <p>To effectively leverage the wealth of imaging data, researchers must be equipped with the tools to easily incorporate powerful computational image analysis methods into their research. We identified three key elements that should guide design and development of software tools in this domain: scalability, standardization, and ease of use.</p>
    <sec id="sec2-1">
      <title>Scalability</title>
      <p>As datasets grow, analysis tools must be carefully designed to meet the technical challenges presented by scaling up in both <italic toggle="yes">n</italic> and <italic toggle="yes">d</italic>. Algorithms should be parallelized wherever possible, reducing computation time by running tasks concurrently. To enable efficient computation at the massive scale of tomorrow's datasets, tools should embrace distributed processing and provide easy integration with commonly used open source big data solutions for on-premise, cloud, and hybrid infrastructures (e.g., Kubernetes, Hadoop YARN, Slurm, etc.). Support for hardware accelerators such as graphics processing units and tensor processing units is a requirement for computationally intensive tasks such as training machine learning models. Finally, tools should enable users to work with data that are larger than available memory—an important feature for accommodating larger data and supporting exploratory research on consumer-grade computers.</p>
    </sec>
    <sec id="sec2-2">
      <title>Standardization</title>
      <p>Another crucial consideration is standardization. No single tool can or should do everything; rather, by embracing standardized file formats, data structures, and application programming interfaces (API), individual tools can focus on specialized tasks while still providing cross-compatibility with other tools. For example, researchers may need to implement domain-specific algorithms for working with specific data types of interest [e.g., stain deconvolution for hematoxylin and eosin (H&amp;E) images], but should interface with industry-standard machine learning frameworks [e.g., PyTorch (<xref rid="bib10" ref-type="bibr">10</xref>) and TensorFlow (<xref rid="bib11" ref-type="bibr">11</xref>)] rather than implementing basic machine learning functionalities from scratch. In addition to providing consistency for users, this approach also promotes emergence of a cohesive ecosystem of tools, such as those built around the AnnData (<xref rid="bib12" ref-type="bibr">12</xref>) standard in single-cell omics.</p>
    </sec>
    <sec id="sec2-3">
      <title>Ease of use</title>
      <p>A tool may be scalable and standardized, but it can only have an impact on accelerating research if users adopt it into their workflows. Therefore, software should be designed from the ground up with the intended audience in mind, and tools should be accessible with only minimal prior training in programming. This can be facilitated by building applications around well-defined APIs, which reduce the learning curve by providing consistency and by abstracting away some technical details from end users. All source code should be fully documented, with reproducible worked examples and detailed reference materials for all APIs. On the flip side of the coin, researchers will stand to benefit the most from advances in computational approaches if they are comfortable with the basics of coding in commonly used languages such as Python or R.</p>
    </sec>
  </sec>
  <sec id="sec3">
    <title>PathML: A Toolkit for Computational Pathology</title>
    <p>We applied these guiding principles to development of PathML, an open-source toolkit designed for digital pathology research.</p>
    <p>There are several existing tools that serve various needs in computational pathology. Some tools provide implementations of specific workflows or workflow components but are not designed as fully customizable, general-purpose libraries (<xref rid="bib13" ref-type="bibr">13–17</xref>). HistomicsTK (<xref rid="bib18" ref-type="bibr">18</xref>) offers a Python API for running aspects of analysis workflows, but is built around a specific data management platform (Girder) rather than being platform agnostic. QuPath (<xref rid="bib19" ref-type="bibr">19</xref>) is an open-source tool for viewing and analyzing WSIs which has a scripting language for programmatic analysis but does not natively support Python. SquidPy (<xref rid="bib20" ref-type="bibr">20</xref>) is primarily focused on spatial omics rather than general-purpose image analysis. There are also commercial tools available for digital pathology, some with support for machine learning analysis; however, these proprietary tools are not always ideal for researchers due to their cost and reduced flexibility in development relative to open source tools which enable full transparency into the underlying source code. Notably, there are no currently available open source tools which support the following requirements: the ability to load images from a wide array of file formats, including proprietary formats and standard formats such as TIFF and DICOM, under a common API; a standardized API for building custom preprocessing pipelines from modular components; support for running preprocessing at scale on commonly used high-performance computing solutions; integration with industry-standard machine learning frameworks in Python; and uniting analysis of brightfield and fluorescence images under a common framework.</p>
    <p>To fill this unmet need, we developed PathML as a general-purpose toolkit for computational pathology, designed to be both highly performant and easy to use for researchers without requiring extensive training in programming or data science. PathML provides a general framework for creating and running preprocessing pipelines, unifying analysis of varying file formats (e.g., TIFF, DICOM, proprietary file formats from vendors, etc.), imaging modalities (e.g., H&amp;E, IHC, Vectra Opal, CODEX, etc.), and dataset scales (from individual images to millions of images) under a single object-oriented API, with data structures and design choices specifically tailored to digital pathology (<xref rid="fig2" ref-type="fig">Fig. 2</xref>). The PathML library is written in Python 3 to promote ease of use and integration with the broader ecosystem of standard tools for data science and machine learning; however, we leverage libraries such as NumPy (<xref rid="bib21" ref-type="bibr">21</xref>) and PyTorch which are written in low-level languages such as C, C++, and CUDA to handle computationally intensive operations more efficiently. An extensive suite of unit testing and integration testing helps minimize bugs and ensure that all code in PathML is working as expected. By developing PathML as an open source tool, we hope to build a community of users and collaborators to collectively accelerate the pace of innovation in digital pathology research.</p>
    <fig position="float" id="fig2">
      <label>Figure 2.</label>
      <caption>
        <p>Overview of the PathML preprocessing framework. <bold>A,</bold> A wide range of imaging platforms and modalities are supported via <bold>B,</bold> support for loading a comprehensive set of more than 165 file formats, including proprietary formats from vendors (see full list of supported file formats in Supplementary Table S1). <bold>C,</bold> Raw image files are loaded into SlideData objects, which encapsulate the image as well as associated metadata. <bold>D,</bold> To enable efficient processing of gigapixel-scale scans, images are divided into tiles and preprocessing pipelines are applied independently to each tile. Tiles can thus be processed in parallel, using the Dask scheduler to orchestrate distributed computation on large clusters, with support for both cloud and on-premise computing. Smaller images are processed in this framework as a single tile containing the entire image. <bold>E,</bold> A preprocessing pipeline is defined as a set of transformations applied sequentially. Transformations are modular, so can be mix-and-matched to rapidly build custom pipelines. <bold>F,</bold> Processed tiles are aggregated into an h5path file on disk, along with associated metadata such as labels, masks, and counts matrix. HDF5 is used to enable efficient slicing and indexing of the resulting file without needing to load the entire file into memory. <bold>G,</bold> DataLoaders from frameworks such as PyTorch then interact with the h5path file to efficiently feed images from the processed image into downstream machine learning models.</p>
      </caption>
      <alt-text>Figure 2. Overview of the PathML preprocessing framework. A, A wide range of imaging platforms and modalities are supported via B, support for loading a comprehensive set of more than 165 file formats, including proprietary formats from vendors (see full list of supported file formats in Supplementary Table S1). C, Raw image files are loaded into SlideData objects, which encapsulate the image as well as associated metadata. D, To enable efficient processing of gigapixel-scale scans, images are divided into tiles and preprocessing pipelines are applied independently to each tile. Tiles can thus be processed in parallel, using the Dask scheduler to orchestrate distributed computation on large clusters, with support for both cloud and on-premise computing. Smaller images are processed in this framework as a single tile containing the entire image. E, A preprocessing pipeline is defined as a set of transformations applied sequentially. Transformations are modular, so can be mix-and-matched to rapidly build custom pipelines. F, Processed tiles are aggregated into an h5path file on disk, along with associated metadata such as labels, masks, and counts matrix. HDF5 is used to enable efficient slicing and indexing of the resulting file without needing to load the entire file into memory. G, DataLoaders from frameworks such as PyTorch then interact with the h5path file to efficiently feed images from the processed image into downstream machine learning models.</alt-text>
      <graphic xlink:href="202fig2" position="float"/>
    </fig>
    <p>The first step in a PathML workflow is loading the raw image file to create a SlideData object, which is the central data class representing an image and associated metadata. To accommodate the wide array of file formats commonly used in digital pathology, we provide three separate backends for reading image files, each supporting a complementary set of file formats (Supplementary Table S1). Each backend adheres to a standardized API, enabling users to manipulate images with a consistent interface regardless of file format or imaging modality (Supplementary Vignette S1).</p>
    <p>The next step is to create a preprocessing pipeline, which we define as the sequential application of independent building blocks, or transformations. Each transformation applies a specific operation which may include modifying an input image, creating or modifying pixel-level metadata (i.e., masks), or creating or modifying image-level metadata (e.g., image quality metrics or an AnnData counts matrix). Transformations are general and flexible, providing a standardized interface to compose preprocessing pipelines. We provide in PathML a set of commonly used transformations, both domain-specific (e.g., H&amp;E stain deconvolution, tissue detection, WSI artifact detection) and general-purpose (e.g., blurring, binary thresholding; Supplementary Fig. S1). Users may also implement custom transformations, and we provide an API to enable integration of custom transformations alongside prebuilt transformations. Multiple transformations can be composed into a single compound transformation. Transformations therefore provide the building blocks for formalizing the design and implementation of arbitrary preprocessing pipelines. This API allows researchers to write scalable, end-to-end preprocessing pipelines in only a few lines of code, using the same syntax and building blocks across different file formats and imaging modalities (Supplementary Vignettes S2 and S3).</p>
    <p>One of the most common technical challenges in computational pathology is presented by extremely large file sizes, with high-resolution WSIs routinely exceeding the capacity of available memory. We therefore designed PathML based on a paradigm of independent processing of tiles. To run a preprocessing pipeline, subregions of the image (i.e., tiles) are extracted and passed to the preprocessing pipeline independently. Smaller images are processed in this framework as a single tile containing the entire image. All processed tiles are then aggregated together into an on-disk array optimized for storing and manipulating large imaging datasets. This design allows for efficient preprocessing of large datasets of gigapixel images, as the data parallelism approach can efficiently scale up to make use of additional computational resources (e.g., cores in a multi-core computing unit, computing nodes in a cluster, etc.). We use the dask.distributed (<xref rid="bib22" ref-type="bibr">22</xref>) scheduler on the backend, which allows for distributed preprocessing on many common high-performance computing platforms, including support for both on-premise and cloud computing environments. Importantly, tile extraction and distributed processing are handled automatically by PathML, enabling users to leverage these features to run analyses at scale with no change to the rest of their code. One limitation of this tile-centric approach is that artifacts may arise when tiles are aggregated back together, such as discontinuities at tile edges or “patchwork” effects. However, processing is inherently limited by the number of pixels that can be stored and manipulated in memory at once, so there is always a tradeoff between processing few low-resolution tiles and many high-resolution tiles. Users have complete control over tile extraction parameters, including the ability to use overlapping tiles which, in conjunction with stitching algorithms such as (<xref rid="bib23" ref-type="bibr">23</xref>) can mitigate such artifacts.</p>
    <p>As tiles are processed, they are aggregated together and written to disk. We define a file specification (h5path) which leverages the Hierarchical Data Format (HDF5) to enable efficient read/write access to regions of the processed image without loading the entire image into memory. Along with the processed images and masks, each h5path file contains associated slide-level and tile-level metadata. Each SlideData object is backed by a corresponding h5path file on disk, allowing for intuitive object-oriented workflows scalable to larger-than-memory images.</p>
    <p>After a preprocessing pipeline has been run, we provide utilities to load the processed images into machine learning frameworks for downstream tasks (e.g., PyTorch DataLoaders). Preprocessing pipelines may themselves include transformations which encapsulate machine learning algorithms, for example using a model to perform nucleus detection and/or classification on each tile. PathML further provides PyTorch implementations of commonly used models such as U-Net (<xref rid="bib24" ref-type="bibr">24</xref>) and HoVer-Net (<xref rid="bib25" ref-type="bibr">25</xref>). Finally, we provide streamlined access to domain-specific datasets including PanNuke (<xref rid="bib26" ref-type="bibr">26</xref>), PESO (<xref rid="bib27" ref-type="bibr">27</xref>), and DeepFocus (<xref rid="bib28" ref-type="bibr">28</xref>) for use in model training and benchmarking for various tasks. With support from open-source contributors, we hope that the inventory of available datasets and machine learning models will continue to expand.</p>
    <p>In sum, PathML provides comprehensive support for each step in the computational pathology research workflow. We define a framework for preprocessing images and metadata which is streamlined and flexible for a wide variety of file formats and imaging modalities, implemented in an efficient, open source, fully tested and thoroughly documented Python package. We have already applied PathML to enable published (<xref rid="bib29" ref-type="bibr">29</xref>) and currently ongoing computational pathology research at our institutions; by releasing it as an open source standard toolkit to bridge the gap between digital pathology and the broader machine learning and artificial intelligence (AI) ecosystem, we aim to lower the barrier to entry and accelerate progress in digital pathology research, thus benefiting the entire research community and moving one step closer to implementation of computational methods in the clinic.</p>
  </sec>
  <sec id="sec4">
    <title>Conclusion</title>
    <p>With biomedical imaging datasets growing exponentially in both number of samples and dimensionality (i.e., data within each sample), machine learning is emerging as an increasingly essential tool for cancer researchers. To support these efforts, software tools must be designed with emphasis on scalability, standardization, and ease of use. Here we introduce PathML, a framework built with these best practices in mind that aims at lowering the barrier of entry to digital pathology, and show how a number of heterogeneous computational pathology use cases can be readily implemented in very few lines of code. With comprehensive support for all aspects of computational pathology research, from loading a wide variety of imaging modalities and file formats, to building modular and completely customizable preprocessing pipelines, to parallel-computing provisions, and integrations with other tools in the machine learning, AI, and single-cell analysis ecosystems, PathML can be employed to tackle a variety of biologically relevant problems. We anticipate that the real impactful part of this work will be around the applications of this technology, which we made open source and therefore available to all researchers. PathML is publicly available at <ext-link xlink:href="http://www.pathml.com" ext-link-type="uri" xlink:show="new">www.pathml.com</ext-link>.</p>
  </sec>
  <sec id="sec5">
    <title>Authors' Disclosures</title>
    <p>E.M. Van Allen reports personal fees from Tango Therapeutics, Genome Medical, Invitae, Monte Rosa Therapeutics, Manifold Bio, Illumina, Enara Bio, and Janssen; grants from Novartis and BMS outside the submitted work; in addition, E.M. Van Allen has a patent for institutional patents filed on Chromatin Mutations and Immunotherapy Response, and Methods for Clinical Interpretation pending and issued. The Editor-in-Chief of <italic toggle="yes">Molecular Cancer Research</italic> is an author on this article. In keeping with AACR editorial policy, a senior member of the <italic toggle="yes">Molecular Cancer Research</italic> editorial team managed the consideration process for this submission and independently rendered the final decision concerning acceptability. No disclosures were reported by the other authors.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material position="float" content-type="local-data">
      <label>Supplementary Figure 1</label>
      <caption>
        <p>Supplementary Figure 1 shows some examples of the transformations which form the building blocks of preprocessing pipelines.</p>
      </caption>
      <media xlink:href="mcr-21-0665_supplementary_figure_1_supp1.png">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material position="float" content-type="local-data">
      <label>Supplementary Table 1</label>
      <caption>
        <p>Table S1 lists the file formats supported by each of PathML's three backends</p>
      </caption>
      <media xlink:href="mcr-21-0665_supplementary_table_1_supp1.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material position="float" content-type="local-data">
      <label>Supplementary Vignette 1</label>
      <caption>
        <p>In this vignette, we use 15 publicly available images of a wide range of imaging modalities and file formats to demonstrate how PathML supports loading all of them under a simple, standardized syntax.</p>
      </caption>
      <media xlink:href="mcr-21-0665_supplementary_vignette_1_supp1.html">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material position="float" content-type="local-data">
      <label>Supplementary Vignette 2</label>
      <caption>
        <p>In this vignette, we demonstrate a practical example of a complete PathML workflow for analyzing brightfield H&amp;E images.</p>
      </caption>
      <media xlink:href="mcr-21-0665_supplementary_vignette_2_supp2.html">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material position="float" content-type="local-data">
      <label>Supplementary Vignette 3</label>
      <caption>
        <p>In this vignette, we demonstrate a practical example of a complete PathML workflow for analyzing immunofluorescence images</p>
      </caption>
      <media xlink:href="mcr-21-0665_supplementary_vignette_3_supp3.html">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>The authors would like to thank Jason Johnson, Jerri Zhang, the Artificial Intelligence Operations and Data Science Services group, and many collaborators in the Department of Informatics and Analytics at Dana-Farber Cancer Institute and in the Department of Pathology and Laboratory Medicine at Weill Cornell Medicine for their continuous support and critical feedback that improved this work. We thank Angeles Duran, Jorge Moscat, and Maria T. Diaz-Meco for providing the images used in Supplementary Fig. S1, panels F and G. J. Nyman's work is supported by NIH F31 Predoctoral Individual National Research Service Award F31CA250136. M. Loda's work is supported by NCI P50CA211024, DoD PC160357, DoD PC180582, and the Prostate Cancer Foundation.</p>
  </ack>
  <fn-group>
    <fn fn-type="supplementary-material">
      <p><bold>Note:</bold> Supplementary data for this article are available at Molecular Cancer Research Online (http://mcr.aacrjournals.org/).</p>
    </fn>
  </fn-group>
  <ref-list>
    <title>References</title>
    <ref id="bib1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schüffler</surname><given-names>PJ</given-names></string-name>, <string-name><surname>Geneslaw</surname><given-names>L</given-names></string-name>, <string-name><surname>Yarlagadda</surname><given-names>DVK</given-names></string-name>, <string-name><surname>Hanna</surname><given-names>MG</given-names></string-name>, <string-name><surname>Samboy</surname><given-names>J</given-names></string-name>, <string-name><surname>Stamelos</surname><given-names>E</given-names></string-name>, <etal/></person-group>. <article-title>Integrated digital pathology at scale: a solution for clinical diagnostics and cancer research at a large academic medical center</article-title>.
<source>J Am Med Inform Assoc</source><year>2021</year>;<volume>28</volume>:<fpage>1874</fpage>–<lpage>84</lpage>.<pub-id pub-id-type="pmid">34260720</pub-id></mixed-citation>
    </ref>
    <ref id="bib2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lewis</surname><given-names>SM</given-names></string-name>, <string-name><surname>Asselin-Labat</surname><given-names>ML</given-names></string-name>, <string-name><surname>Nguyen</surname><given-names>Q</given-names></string-name>, <string-name><surname>Berthelet</surname><given-names>J</given-names></string-name>, <string-name><surname>Tan</surname><given-names>X</given-names></string-name>, <string-name><surname>Wimmer</surname><given-names>VC</given-names></string-name>, <etal/></person-group>. <article-title>Spatial omics and multiplexed imaging to explore cancer biology</article-title>.
<source>Nat Methods</source><year>2021</year>;<volume>18</volume>:<fpage>997</fpage>–<lpage>1012</lpage>.<pub-id pub-id-type="pmid">34341583</pub-id></mixed-citation>
    </ref>
    <ref id="bib3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Campanella</surname><given-names>G</given-names></string-name>, <string-name><surname>Hanna</surname><given-names>MG</given-names></string-name>, <string-name><surname>Geneslaw</surname><given-names>L</given-names></string-name>, <string-name><surname>Miraflor</surname><given-names>A</given-names></string-name>, <string-name><surname>Werneck Krauss Silva</surname><given-names>V</given-names></string-name>, <string-name><surname>Busam</surname><given-names>KJ</given-names></string-name>, <etal/></person-group>. <article-title>Clinical-grade computational pathology using weakly supervised deep learning on whole slide images</article-title>.
<source>Nat Med</source><year>2019</year>;<volume>25</volume>:<fpage>1301</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">31308507</pub-id></mixed-citation>
    </ref>
    <ref id="bib4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chatrian</surname><given-names>A</given-names></string-name>, <string-name><surname>Colling</surname><given-names>RT</given-names></string-name>, <string-name><surname>Browning</surname><given-names>L</given-names></string-name>, <string-name><surname>Alham</surname><given-names>NK</given-names></string-name>, <string-name><surname>Sirinukunwattana</surname><given-names>K</given-names></string-name>, <string-name><surname>Malacrino</surname><given-names>S</given-names></string-name>, <etal/></person-group>. <article-title>Artificial intelligence for advance requesting of immunohistochemistry in diagnostically uncertain prostate biopsies</article-title>.
<source>Mod Pathol</source><year>2021</year>;<volume>34</volume>:<fpage>1780</fpage>–<lpage>94</lpage>.<pub-id pub-id-type="pmid">34017063</pub-id></mixed-citation>
    </ref>
    <ref id="bib5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lu</surname><given-names>MY</given-names></string-name>, <string-name><surname>Chen</surname><given-names>TY</given-names></string-name>, <string-name><surname>Williamson</surname><given-names>DFK</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>M</given-names></string-name>, <string-name><surname>Shady</surname><given-names>M</given-names></string-name>, <string-name><surname>Lipkova</surname><given-names>J</given-names></string-name>, <etal/></person-group>. <article-title>AI-based pathology predicts origins for cancers of unknown primary</article-title>.
<source>Nature</source><year>2021</year>;<volume>594</volume>:<fpage>106</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">33953404</pub-id></mixed-citation>
    </ref>
    <ref id="bib6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kather</surname><given-names>JN</given-names></string-name>, <string-name><surname>Heij</surname><given-names>LR</given-names></string-name>, <string-name><surname>Grabsch</surname><given-names>HI</given-names></string-name>, <string-name><surname>Loeffler</surname><given-names>C</given-names></string-name>, <string-name><surname>Echle</surname><given-names>A</given-names></string-name>, <string-name><surname>Muti</surname><given-names>HS</given-names></string-name>, <etal/></person-group>. <article-title>Pan-cancer image-based detection of clinically actionable genetic alterations</article-title>.
<source>Nat Cancer</source><year>2020</year>;<volume>1</volume>:<fpage>789</fpage>–<lpage>99</lpage>.<pub-id pub-id-type="pmid">33763651</pub-id></mixed-citation>
    </ref>
    <ref id="bib7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kather</surname><given-names>JN</given-names></string-name>, <string-name><surname>Pearson</surname><given-names>AT</given-names></string-name>, <string-name><surname>Halama</surname><given-names>N</given-names></string-name>, <string-name><surname>Jäger</surname><given-names>D</given-names></string-name>, <string-name><surname>Krause</surname><given-names>J</given-names></string-name>, <string-name><surname>Loosen</surname><given-names>SH</given-names></string-name>, <etal/></person-group>. <article-title>Deep learning can predict microsatellite instability directly from histology in gastrointestinal cancer</article-title>.
<source>Nat Med</source><year>2019</year>;<volume>25</volume>:<fpage>1054</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">31160815</pub-id></mixed-citation>
    </ref>
    <ref id="bib8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berry</surname><given-names>S</given-names></string-name>, <string-name><surname>Giraldo</surname><given-names>NA</given-names></string-name>, <string-name><surname>Green</surname><given-names>BF</given-names></string-name>, <string-name><surname>Cottrell</surname><given-names>TR</given-names></string-name>, <string-name><surname>Stein</surname><given-names>JE</given-names></string-name>, <string-name><surname>Engle</surname><given-names>EL</given-names></string-name>, <etal/></person-group>. <article-title>Analysis of multispectral imaging with the AstroPath platform informs efficacy of PD-1 blockade</article-title>.
<source>Science</source><year>2021</year>;<volume>372</volume>:<fpage>eaba2609</fpage>.<pub-id pub-id-type="pmid">34112666</pub-id></mixed-citation>
    </ref>
    <ref id="bib9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schürch</surname><given-names>CM</given-names></string-name>, <string-name><surname>Bhate</surname><given-names>SS</given-names></string-name>, <string-name><surname>Barlow</surname><given-names>GL</given-names></string-name>, <string-name><surname>Phillips</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Noti</surname><given-names>L</given-names></string-name>, <string-name><surname>Zlobec</surname><given-names>I</given-names></string-name>, <etal/></person-group>. <article-title>Coordinated cellular neighborhoods orchestrate antitumoral immunity at the colorectal cancer invasive front</article-title>.
<source>Cell</source><year>2020</year>;<volume>183</volume>:<fpage>838</fpage>.<pub-id pub-id-type="pmid">33125896</pub-id></mixed-citation>
    </ref>
    <ref id="bib10">
      <label>10.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Paszke</surname><given-names>A</given-names></string-name>, <etal/></person-group>. <article-title>PyTorch: an imperative style, high-performance deep learning library</article-title>;
<year>2019</year>.</mixed-citation>
    </ref>
    <ref id="bib11">
      <label>11.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Abadi</surname><given-names>M</given-names></string-name>, <etal/></person-group>. <article-title>Tensorflow: a system for large-scale machine learning</article-title>. In: <comment>Proceedings of 12th USENIX symposium on operating systems design and implementation (OSDI 16)</comment>;
<year>2016</year>.</mixed-citation>
    </ref>
    <ref id="bib12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wolf</surname><given-names>FA</given-names></string-name>, <string-name><surname>Angerer</surname><given-names>P</given-names></string-name>, <string-name><surname>Theis</surname><given-names>FJ</given-names></string-name></person-group>. <article-title>SCANPY: large-scale single-cell gene expression data analysis</article-title>.
<source>Genome Biol</source><year>2018</year>;<volume>19</volume>:<fpage>15</fpage>.<pub-id pub-id-type="pmid">29409532</pub-id></mixed-citation>
    </ref>
    <ref id="bib13">
      <label>13.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>S</given-names></string-name>, <etal/></person-group>. <article-title>HistomicsML2. 0: fast interactive machine learning for whole slide imaging data</article-title>;
<year>2020</year>.</mixed-citation>
    </ref>
    <ref id="bib14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Janowczyk</surname><given-names>A</given-names></string-name>, <string-name><surname>Zuo</surname><given-names>R</given-names></string-name>, <string-name><surname>Gilmore</surname><given-names>H</given-names></string-name>, <string-name><surname>Feldman</surname><given-names>M</given-names></string-name>, <string-name><surname>Madabhushi</surname><given-names>A</given-names></string-name></person-group>. <article-title>HistoQC: an open-source quality control tool for digital pathology slides</article-title>.
<source>JCO Clin Cancer Inform</source><year>2019</year>;<volume>3</volume>:<fpage>1</fpage>–<lpage>7</lpage>.</mixed-citation>
    </ref>
    <ref id="bib15">
      <label>15.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Byfield</surname><given-names>P</given-names></string-name></person-group>. <article-title>Peter554/StainTools</article-title>, <comment>Zenodo</comment>;
<year>2019</year>.</mixed-citation>
    </ref>
    <ref id="bib16">
      <label>16.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Berman</surname><given-names>AG</given-names></string-name>, <etal/></person-group>. <article-title>PathML: a unified framework for whole-slide image analysis with deep learning</article-title>. <comment>medRxiv</comment>;
<year>2021</year>.</mixed-citation>
    </ref>
    <ref id="bib17">
      <label>17.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Jaume</surname><given-names>G</given-names></string-name>, <etal/></person-group>. <article-title>HistoCartography: A toolkit for graph analytics in digital pathology</article-title>. In: <comment>Proceedings of the MICCAI Workshop on Computational Pathology</comment>;
<year>2021</year>; <comment>PMLR</comment>.</mixed-citation>
    </ref>
    <ref id="bib18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gutman</surname><given-names>DA</given-names></string-name>, <string-name><surname>Khalilia</surname><given-names>M</given-names></string-name>, <string-name><surname>Lee</surname><given-names>S</given-names></string-name>, <string-name><surname>Nalisnik</surname><given-names>M</given-names></string-name>, <string-name><surname>Mullen</surname><given-names>Z</given-names></string-name>, <string-name><surname>Beezley</surname><given-names>J</given-names></string-name>, <etal/></person-group>. <article-title>The digital slide archive: a software platform for management, integration, and analysis of histology for cancer research</article-title>.
<source>Cancer Res</source><year>2017</year>;<volume>77</volume>:<fpage>e75</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">29092945</pub-id></mixed-citation>
    </ref>
    <ref id="bib19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bankhead</surname><given-names>P</given-names></string-name>, <string-name><surname>Loughrey</surname><given-names>MB</given-names></string-name>, <string-name><surname>Fernández</surname><given-names>JA</given-names></string-name>, <string-name><surname>Dombrowski</surname><given-names>Y</given-names></string-name>, <string-name><surname>McArt</surname><given-names>DG</given-names></string-name>, <string-name><surname>Dunne</surname><given-names>PD</given-names></string-name>, <etal/></person-group>. <article-title>QuPath: open source software for digital pathology image analysis</article-title>.
<source>Sci Rep</source><year>2017</year>;<volume>7</volume>:<fpage>16878</fpage>.<pub-id pub-id-type="pmid">29203879</pub-id></mixed-citation>
    </ref>
    <ref id="bib20">
      <label>20.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Palla</surname><given-names>G</given-names></string-name>, <etal/></person-group>. <article-title>Squidpy: a scalable framework for spatial single cell analysis</article-title>. <comment>bioRxiv</comment>;
<year>2021</year>.</mixed-citation>
    </ref>
    <ref id="bib21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harris</surname><given-names>CR</given-names></string-name>, <string-name><surname>Millman</surname><given-names>KJ</given-names></string-name>, <string-name><surname>van der Walt</surname><given-names>SJ</given-names></string-name>, <string-name><surname>Gommers</surname><given-names>R</given-names></string-name>, <string-name><surname>Virtanen</surname><given-names>P</given-names></string-name>, <string-name><surname>Cournapeau</surname><given-names>D</given-names></string-name>, <etal/></person-group>. <article-title>Array programming with NumPy</article-title>.
<source>Nature</source><year>2020</year>;<volume>585</volume>:<fpage>357</fpage>–<lpage>62</lpage>.<pub-id pub-id-type="pmid">32939066</pub-id></mixed-citation>
    </ref>
    <ref id="bib22">
      <label>22.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Rocklin</surname><given-names>M</given-names></string-name></person-group>. <article-title>Dask: parallel computation with blocked algorithms and task scheduling</article-title>. In: <comment>Proceedings of the 14th python in science conference</comment>;
<year>2015</year>; <comment>Citeseer</comment>.</mixed-citation>
    </ref>
    <ref id="bib23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Preibisch</surname><given-names>S</given-names></string-name>, <string-name><surname>Saalfeld</surname><given-names>S</given-names></string-name>, <string-name><surname>Tomancak</surname><given-names>P</given-names></string-name></person-group>. <article-title>Globally optimal stitching of tiled 3D microscopic image acquisitions</article-title>.
<source>Bioinformatics</source><year>2009</year>;<volume>25</volume>:<fpage>1463</fpage>–<lpage>5</lpage>.<pub-id pub-id-type="pmid">19346324</pub-id></mixed-citation>
    </ref>
    <ref id="bib24">
      <label>24.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Ronneberger</surname><given-names>O</given-names></string-name>, <string-name><surname>Fischer</surname><given-names>P</given-names></string-name>, <string-name><surname>Brox</surname><given-names>T</given-names></string-name></person-group>. <article-title>U-net: convolutional networks for biomedical image segmentation</article-title>. In:
<source>International Conference on Medical image computing and computer-assisted intervention</source>.
<publisher-name>Springer</publisher-name>;
<year>2015</year>.</mixed-citation>
    </ref>
    <ref id="bib25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Graham</surname><given-names>S</given-names></string-name>, <string-name><surname>Vu</surname><given-names>QD</given-names></string-name>, <string-name><surname>Raza</surname><given-names>SEA</given-names></string-name>, <string-name><surname>Azam</surname><given-names>A</given-names></string-name>, <string-name><surname>Tsang</surname><given-names>YW</given-names></string-name>, <string-name><surname>Kwak</surname><given-names>JT</given-names></string-name>, <etal/></person-group>. <article-title>Hover-net: simultaneous segmentation and classification of nuclei in multi-tissue histology images</article-title>.
<source>Med Image Anal</source><year>2019</year>;<volume>58</volume>:<fpage>101563</fpage>.<pub-id pub-id-type="pmid">31561183</pub-id></mixed-citation>
    </ref>
    <ref id="bib26">
      <label>26.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Gamper</surname><given-names>J</given-names></string-name>, <etal/></person-group><source>Pannuke: an open pan-cancer histology dataset for nuclei instance segmentation and classification</source>. In:
<source>European Congress on Digital Pathology</source>.
<publisher-name>Springer</publisher-name>;
<year>2019</year>.</mixed-citation>
    </ref>
    <ref id="bib27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bulten</surname><given-names>W</given-names></string-name>, <string-name><surname>Bándi</surname><given-names>P</given-names></string-name>, <string-name><surname>Hoven</surname><given-names>J</given-names></string-name>, <string-name><surname>van de Loo</surname><given-names>R</given-names></string-name>, <string-name><surname>Lotz</surname><given-names>J</given-names></string-name>, <string-name><surname>Weiss</surname><given-names>N</given-names></string-name>, <etal/></person-group>. <article-title>Epithelium segmentation using deep learning in H&amp;E-stained prostate specimens with immunohistochemistry as reference standard</article-title>.
<source>Sci Rep</source><year>2019</year>;<volume>9</volume>:<fpage>864</fpage>.<pub-id pub-id-type="pmid">30696866</pub-id></mixed-citation>
    </ref>
    <ref id="bib28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Senaras</surname><given-names>C</given-names></string-name>, <string-name><surname>Niazi</surname><given-names>MKK</given-names></string-name>, <string-name><surname>Lozanski</surname><given-names>G</given-names></string-name>, <string-name><surname>Gurcan</surname><given-names>MN</given-names></string-name></person-group>. <article-title>DeepFocus: detection of out-of-focus regions in whole slide digital images using deep learning</article-title>.
<source>PLoS One</source><year>2018</year>;<volume>13</volume>:<fpage>e0205387</fpage>.<pub-id pub-id-type="pmid">30359393</pub-id></mixed-citation>
    </ref>
    <ref id="bib29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Linares</surname><given-names>JF</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>X</given-names></string-name>, <string-name><surname>Martinez-Ordoñez</surname><given-names>A</given-names></string-name>, <string-name><surname>Duran</surname><given-names>A</given-names></string-name>, <string-name><surname>Kinoshita</surname><given-names>H</given-names></string-name>, <string-name><surname>Kasashima</surname><given-names>H</given-names></string-name>, <etal/></person-group>. <article-title>PKCλ/ι inhibition activates an ULK2-mediated interferon response to repress tumorigenesis</article-title>.
<source>Mol Cell</source><year>2021</year>;<volume>81</volume>:<fpage>4509</fpage>–<lpage>26</lpage>.<pub-id pub-id-type="pmid">34560002</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
