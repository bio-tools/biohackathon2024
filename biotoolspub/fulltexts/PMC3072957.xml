<?properties open_access?>
<?DTDIdentifier.IdentifierValue article.dtd?>
<?DTDIdentifier.IdentifierType system?>
<?SourceDTD.DTDName article.dtd?>
<?SourceDTD.Version 1.0?>
<?ConverterInfo.XSLTName bmc2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">3072957</article-id>
    <article-id pub-id-type="publisher-id">1471-2105-12-85</article-id>
    <article-id pub-id-type="pmid">21447171</article-id>
    <article-id pub-id-type="doi">10.1186/1471-2105-12-85</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DecGPU: distributed error correction on massively parallel graphics processing units using CUDA and MPI</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes" id="A1">
        <name>
          <surname>Liu</surname>
          <given-names>Yongchao</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <email>liuy0039@ntu.edu.sg</email>
      </contrib>
      <contrib contrib-type="author" id="A2">
        <name>
          <surname>Schmidt</surname>
          <given-names>Bertil</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <email>asbschmidt@ntu.edu.sg</email>
      </contrib>
      <contrib contrib-type="author" id="A3">
        <name>
          <surname>Maskell</surname>
          <given-names>Douglas L</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <email>asdouglas@ntu.edu.sg</email>
      </contrib>
    </contrib-group>
    <aff id="I1"><label>1</label>School of Computer Engineering, Nanyang Technological University, 639798, Singapore</aff>
    <pub-date pub-type="collection">
      <year>2011</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>29</day>
      <month>3</month>
      <year>2011</year>
    </pub-date>
    <volume>12</volume>
    <fpage>85</fpage>
    <lpage>85</lpage>
    <history>
      <date date-type="received">
        <day>9</day>
        <month>7</month>
        <year>2010</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>3</month>
        <year>2011</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2011 Liu et al; licensee BioMed Central Ltd.</copyright-statement>
      <copyright-year>2011</copyright-year>
      <copyright-holder>Liu et al; licensee BioMed Central Ltd.</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/2.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/2.0/">http://creativecommons.org/licenses/by/2.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="http://www.biomedcentral.com/1471-2105/12/85"/>
    <abstract>
      <sec>
        <title>Background</title>
        <p>Next-generation sequencing technologies have led to the high-throughput production of sequence data (reads) at low cost. However, these reads are significantly shorter and more error-prone than conventional Sanger shotgun reads. This poses a challenge for the <italic>de novo </italic>assembly in terms of assembly quality and scalability for large-scale short read datasets.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>We present DecGPU, the first parallel and distributed error correction algorithm for high-throughput short reads (HTSRs) using a hybrid combination of CUDA and MPI parallel programming models. DecGPU provides CPU-based and GPU-based versions, where the CPU-based version employs coarse-grained and fine-grained parallelism using the MPI and OpenMP parallel programming models, and the GPU-based version takes advantage of the CUDA and MPI parallel programming models and employs a hybrid CPU+GPU computing model to maximize the performance by overlapping the CPU and GPU computation. The distributed feature of our algorithm makes it feasible and flexible for the error correction of large-scale HTSR datasets. Using simulated and real datasets, our algorithm demonstrates superior performance, in terms of error correction quality and execution speed, to the existing error correction algorithms. Furthermore, when combined with Velvet and ABySS, the resulting DecGPU-Velvet and DecGPU-ABySS assemblers demonstrate the potential of our algorithm to improve <italic>de novo </italic>assembly quality for <italic>de</italic>-<italic>Bruijn</italic>-graph-based assemblers.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p>DecGPU is publicly available open-source software, written in CUDA C++ and MPI. The experimental results suggest that DecGPU is an effective and feasible error correction algorithm to tackle the flood of short reads produced by next-generation sequencing technologies.</p>
      </sec>
    </abstract>
  </article-meta>
</front>
<body>
  <sec>
    <title>Background</title>
    <sec>
      <title>Introduction</title>
      <p>The ongoing revolution of next-generation sequencing (NGS) technologies has led to the production of high-throughput short read (HTSR) data (i.e. DNA sequences) at dramatically lower cost compared to conventional Sanger shotgun sequencing. However, the produced reads are significantly shorter and more error-prone. Additionally, <italic>de novo </italic>whole-genome shotgun fragment assemblers that have been optimized for Sanger reads, such as Altas [<xref ref-type="bibr" rid="B1">1</xref>], ARACHNE [<xref ref-type="bibr" rid="B2">2</xref>], Celera [<xref ref-type="bibr" rid="B3">3</xref>] and PCAP [<xref ref-type="bibr" rid="B4">4</xref>], do not scale well for HTSR data. Therefore, a new generation of <italic>de novo </italic>assemblers is required.</p>
      <p>Several greedy short read assemblers, such as SSAKE [<xref ref-type="bibr" rid="B5">5</xref>], SHARCGS [<xref ref-type="bibr" rid="B6">6</xref>], VCAKE [<xref ref-type="bibr" rid="B7">7</xref>] and Taipan [<xref ref-type="bibr" rid="B8">8</xref>], have been developed based on <italic>contig </italic>extensions. However, these assemblers have difficulties in assembling repeat regions. The introduction of de Bruijn graphs for fragment assembly [<xref ref-type="bibr" rid="B9">9</xref>] has sparked new interests in using the de Bruijn graph approach for short read assembly. In the context of short read assembly, nodes of a de Bruijn graph represent all possible <italic>k</italic>-mers (a <italic>k</italic>-mer is a substring of length <italic>k</italic>), and edges represent suffix-prefix perfect overlaps of length <italic>k</italic>-1. Short read assemblers based on the de Bruijn graph approach include EULER-SR [<xref ref-type="bibr" rid="B10">10</xref>], Velvet [<xref ref-type="bibr" rid="B11">11</xref>], ALLPATHS [<xref ref-type="bibr" rid="B12">12</xref>], ABySS [<xref ref-type="bibr" rid="B13">13</xref>], and SOAPdenovo [<xref ref-type="bibr" rid="B14">14</xref>]. In a de Bruijn graph, each single-base error in a read induces up to <italic>k </italic>false nodes, and since each false node has a chance of linking to some other node, it is likely to induce false path convergence. Therefore, assembly quality of <italic>de</italic>-<italic>Bruijn</italic>-graph-based assemblers is expected to improve by detecting and fixing base errors in reads prior to assembly.</p>
      <p>In addition to the error correction algorithms based on the spectral alignment problem (SAP) in [<xref ref-type="bibr" rid="B9">9</xref>] and [<xref ref-type="bibr" rid="B10">10</xref>], a new error correction algorithm called SHREC [<xref ref-type="bibr" rid="B15">15</xref>] has been proposed using a generalized suffix trie. Hybrid SHREC (hSHREC) [<xref ref-type="bibr" rid="B16">16</xref>] extends the work of SHREC by enabling the correction of substitutions, insertions, and deletions in a mixed set of short reads produced from different sequencing platforms. Unfortunately, due to the large size of NGS datasets, the error correction procedure before assembly is both time and memory consuming. Many-core GPU computing architectures have evolved rapidly and have already demonstrated their powerful compute capability to reduce the execution time of a range of demanding bioinformatics applications, such as protein sequence database search [<xref ref-type="bibr" rid="B17">17</xref>,<xref ref-type="bibr" rid="B18">18</xref>], multiple sequence alignment [<xref ref-type="bibr" rid="B19">19</xref>], and motif finding [<xref ref-type="bibr" rid="B20">20</xref>]. As a first step, Shi et al. [<xref ref-type="bibr" rid="B21">21</xref>] implemented CUDA-EC, a parallel error correction algorithm using NVIDIA's compute unified device architecture (CUDA), based on the SAP approach [<xref ref-type="bibr" rid="B9">9</xref>], where a Bloom filter data structure [<xref ref-type="bibr" rid="B22">22</xref>] is used to gain memory space efficiency. This algorithm has been further optimized by incorporating quality scores and filtration approach in [<xref ref-type="bibr" rid="B23">23</xref>]. However, the drawback of this approach is the assumption that the device memory of a single GPU is sufficient to store the genome information of the SAP, i.e. the spectrum <italic>T</italic>(<italic>G</italic>) (see Spectral alignment problem subsection). Thus, a distributed error correction approach is a good choice to further reduce execution time and to overcome memory constraints.</p>
      <p>In this paper, we present DecGPU, the first parallel and distributed error correction algorithm for large-scale HTSR datasets using a hybrid combination of CUDA and message passing interface (MPI) [<xref ref-type="bibr" rid="B24">24</xref>] parallel programming models. DecGPU provides two versions: a CPU-based version and a GPU-based version. The CPU-based version employs coarse-grained and fine-grained parallelism using the MPI and Open Multi-Processing (OpenMP) [<xref ref-type="bibr" rid="B25">25</xref>] parallel programming models. The GPU-based version takes advantage of the CUDA and MPI parallel programming models and employs a hybrid CPU+GPU computing model to maximize the performance by overlapping the CPU and GPU computation. The distributed feature of our algorithm makes it a feasible and flexible solution to the error correction of large-scale HTSR datasets. Our algorithm is designed based on the SAP approach and uses a counting Bloom filter data structure [<xref ref-type="bibr" rid="B26">26</xref>] for memory space efficiency. Even though our algorithm also uses the filtration approach to reduce execution time like CUDA-EC, it has intrinsic differences from CUDA-EC, such as distributed <italic>k</italic>-mer spectrums, hybrid combination of different parallel programming models, and CUDA kernel implementations. Compared to the hSHREC algorithm, DecGPU shows superior error correction quality for both simulated and real datasets. As for the execution speed, on a workstation with two quad-core CPUs, our CPU-based version runs up to 22× faster than hSHREC. Furthermore, on a single GPU, the GPU-based version runs up to 2.8× faster than CUDA-EC (version 1.0.1). When combined with Velvet (version 1.0.17) and ABySS (version 1.2.1), the resulting DecGPU-Velvet and DecGPU-ABySS assemblers demonstrate the potential of our algorithm to improve <italic>de novo </italic>assembly quality for <italic>de</italic>-<italic>Bruijn</italic>-graph-based assemblers by correcting sequencing errors prior to assembly.</p>
    </sec>
    <sec>
      <title>Spectral alignment problem</title>
      <p>The SAP approach detects and fixes base errors in a read based on the <italic>k</italic>-mer set <italic>G</italic><sub><italic>k </italic></sub>of a genome <italic>G</italic>. Since the genome <italic>G </italic>is not known beforehand in a <italic>de novo </italic>sequencing project, SAP approximates <italic>G</italic><sub><italic>k </italic></sub>using a <italic>k</italic>-mer spectrum <italic>T</italic>(<italic>G</italic>). <italic>T</italic>(<italic>G</italic>) is the set of all solid <italic>k</italic>-mers throughout all reads. A <italic>k</italic>-mer is called <italic>solid </italic>if its multiplicity throughout all reads is not less than a user-specified threshold <italic>M</italic>, and <italic>weak </italic>otherwise. If every <italic>k</italic>-mer in a read has an exact match in <italic>T</italic>(<italic>G</italic>), the read is called a <italic>T-string</italic>. Given an erroneous read <italic>R</italic>, SAP is defined to find a <italic>T-string R</italic><sup><italic>* </italic></sup>with minimal Hamming distance to <italic>R</italic>.</p>
      <p>Two heuristics of SAP have been suggested: the iterative approach [<xref ref-type="bibr" rid="B9">9</xref>] and the dynamic programming approach [<xref ref-type="bibr" rid="B10">10</xref>]. The iterative approach attempts to transform weak <italic>k</italic>-mers in a read to solid ones by substituting some possibly erroneous bases through a voting algorithm. The dynamic programming approach attempts to find the shortest path that corresponds to a <italic>T-string </italic>with minimal edit distance. The underlying algorithm model of DecGPU is inspired by the iterative approach.</p>
    </sec>
    <sec>
      <title>Bloom filter data structure</title>
      <p>The spectrum <italic>T</italic>(<italic>G</italic>) is the fundamental data structure for SAP-based error correction. For large-scale short read error correction, the major challenges posed by <italic>T</italic>(<italic>G</italic>) are the computational overhead for <italic>k</italic>-mer membership lookup and the memory constraint for <italic>k</italic>-mer storage. Hash tables are advantageous in execution time for membership lookup, but consume too much memory. Thus, we choose a Bloom filter, a very compact hash-based data structure, to achieve efficiency in terms of both lookup time and memory space. However, the space efficiency of a Bloom filter is gained by allowing false positive querying. The more elements inserted to the Bloom filter, the higher the probability of false positive querying. As such, a Bloom filter is more suitable for the cases where space resources are at a premium and a small number of false positives can be tolerated. Both conditions are met by our error correction algorithm, since false positives might only result in some unidentified sequencing errors.</p>
      <p>A classical Bloom filter uses a bit array with <italic>h </italic>associated independent hash functions, supporting insertion and membership querying of elements. Initially, all buckets (1 bit per bucket) in a classical Bloom filter are set to zero. When inserting or querying an element, the <italic>h </italic>hash values of the element are first calculated using the <italic>h </italic>hash functions. When inserting an element, the corresponding buckets indexed by the hash values are set to 1. When querying an element, it returns the corresponding buckets. The element is likely to exist if all buckets are 1; and definitely does not exist, otherwise. The time for insertion and querying, of an element, is of constant time complexity, <italic>O</italic>(<italic>h</italic>), and is also independent of the number of inserted elements. The false positive probability (FPP) of a classical Bloom filter is calculated as<disp-formula id="bmcM1"><label>(1)</label><graphic xlink:href="1471-2105-12-85-i1.gif"/></disp-formula></p>
      <p>where <italic>N</italic><sub><italic>B </italic></sub>is the total number of buckets, <italic>N</italic><sub><italic>E </italic></sub>is the number of elements, and <italic>α </italic>= <italic>hN</italic><sub><italic>E</italic></sub>/<italic>N</italic><sub><italic>B</italic></sub>.</p>
      <p>To construct <italic>T</italic>(<italic>G</italic>), we need to record the multiplicity of each <italic>k</italic>-mer. However, because the classical Bloom filter does not store the number of <italic>k</italic>-mer occurrences, DecGPU instead chooses a counting Bloom filter to represent <italic>T</italic>(<italic>G</italic>). A counting Bloom filter extends a bucket of the classical Bloom filter from 1 bit to several bits. DecGPU uses 4 bits per bucket, supporting a maximum multiplicity of 15. When inserting an element, it increases (using saturation addition) the counter values of the corresponding buckets indexed by the hash values. When querying an element, it returns the minimum counter value of all the corresponding buckets, which is most likely to be the real multiplicity of the element. A counting Bloom filter has the same FPP as the corresponding classical Bloom filter.</p>
    </sec>
    <sec>
      <title>CUDA and MPI programming models</title>
      <p>More than a software and hardware co-processing architecture, CUDA is also a parallel programming language extending general programming languages, such as C, C++ and Fortran with a minimalist set of abstractions for expressing parallelism. CUDA enables users to write parallel scalable programs for CUDA-enabled processors with familiar languages [<xref ref-type="bibr" rid="B27">27</xref>]. A CUDA program is comprised of two parts: a host program running one or more sequential threads on a host CPU, and one or more parallel <italic>kernels </italic>able to execute on Tesla [<xref ref-type="bibr" rid="B28">28</xref>] and Fermi [<xref ref-type="bibr" rid="B29">29</xref>] unified graphics and computing architectures.</p>
      <p>A kernel is a sequential program launched on a set of lightweight concurrent threads. The parallel threads are organized into a grid of thread blocks, where all threads in a thread block can synchronize through barriers and communicate via a high-speed, per block shared memory (PBSM). This hierarchical organization of threads enables thread blocks to implement coarse-grained task and data parallelism and lightweight threads comprising a thread block to provide fine-grained thread-level parallelism. Threads from different thread blocks in the same grid are able to cooperate through atomic operations on global memory shared by all threads. To write efficient CUDA programs, it is important to understand the features of the different memory spaces, including non-cached global and local memory, cached texture and constant memory as well as on-chip PBSM and registers.</p>
      <p>The CUDA-enabled processors are built around a fully programmable scalable processor array, organized into a number of streaming multiprocessors (SMs). For the Tesla architecture, each SM contains 8 scalar processors (SPs) and shares a fixed 16 KB of PBSM. For the Tesla series, the number of SMs per device varies from generation to generation. For the Fermi architecture, it contains 16 SMs with each SM having 32 SPs. Each SM in the Fermi architecture has a configurable PBSM size from the 64 KB on-chip memory. This on-chip memory can be configured as 48 KB of PBSM with 16 KB of L1 cache or as 16 KB of PBSM with 48 KB of L1 cache. When executing a thread block, both architectures split all the threads in the thread block into small groups of 32 parallel threads, called <italic>warps</italic>, which are scheduled in a single instruction, multiple thread (SIMT) fashion. Divergence of execution paths is allowed for threads in a warp, but SMs realize full efficiency and performance when all threads of a warp take the same execution path.</p>
      <p>MPI is a <italic>de facto </italic>standard for developing portable parallel applications using the message passing mechanism. MPI works on both shared and distributed memory machines, offering a highly portable solution to parallel programming on a variety of machines and hardware topologies. In MPI, it defines each worker as a process and enables the processes to execute different programs. This multiple program, multiple data model offers more flexibility for data-shared or data-distributed parallel program design. Within a computation, processes communicate data by calling runtime library routines, specified for the C/C++ and Fortran programming languages, including point-to-point and collective communication routines. Point-to-point communication is used to send and receive messages between two named processes, suitable for local and unstructured communications. Collective (global) communication is used to perform commonly used global operations (e.g. reduction and broadcast operations).</p>
    </sec>
  </sec>
  <sec>
    <title>Implementation</title>
    <sec>
      <title>DecGPU error correction algorithm</title>
      <p>DecGPU consists of four major stages: (1) constructing the distributed <italic>k</italic>-mer spectrum, (2) filtering out error-free reads, (3) fixing erroneous reads using a voting algorithm, (4) trimming (or discarding entirely) the fixed reads that remain erroneous, and (5) an optional iterative policy between the filtering and fixing stages with intention to correct more than one base error in a single read. The second stage filters out error-free reads and passes down the remaining erroneous reads to the third stage. After the erroneous reads have been fixed, the fixed reads are either passed up to another filtering stage or down to the trimming stage, depending on whether the optional iterative policy is used. For a fixed read that remains erroneous, the trimming stage attempts to find the user-satisfied longest substring of the read, in which all <italic>k</italic>-mers are solid (the workflow and data dependence between stages are shown in Figure <xref ref-type="fig" rid="F1">1</xref>).</p>
      <fig id="F1" position="float">
        <label>Figure 1</label>
        <caption>
          <p><bold>Program workflow and data dependence between different stages</bold>.</p>
        </caption>
        <graphic xlink:href="1471-2105-12-85-1"/>
      </fig>
      <p>For DecGPU, a processing element (PE) <italic>P</italic><sub><italic>i </italic></sub>refers to the <italic>i</italic><sup>th </sup>MPI process. Each MPI process has a one-to-one correspondence with a GPU device. Each <italic>P</italic><sub><italic>i </italic></sub>therefore consists of two threads: a CPU thread and a GPU thread. This hybrid CPU+GPU computing model provides the potential to achieve performance maximization through the overlapping of CPU and GPU computation. The input reads of each stage are organized into batches to facilitate the overlapping. In the MPI runtime environment, DecGPU ensures the one-to-one correspondence between an MPI process and one GPU device by automatically assigning GPU devices to processes using a registration management approach. First, each process registers its hostname and the number of qualified GPU devices in its host to a specified master process. Secondly, the master process verifies the registrations by checking that, for a specific host, the number of GPU devices reported by all processes running on it must be the same and must not be less than the number of the processes. Finally, the master process enumerates each host and assigns a unique GPU device identifier to each process running on the host.</p>
    </sec>
    <sec>
      <title>Distributed spectrum construction</title>
      <p>DecGPU distributes the <italic>k</italic>-mer spectrum that uses a counting Bloom filter. For the distributed spectrum, each <italic>P</italic><sub><italic>i </italic></sub>holds a local spectrum <italic>T</italic>(<italic>G</italic>, <italic>P</italic><sub><italic>i</italic></sub>) that is a subset of <italic>T</italic>(<italic>G</italic>). The set of all local spectrums {<italic>T</italic>(<italic>G</italic>, <italic>P</italic><sub><italic>i</italic></sub>)} forms a partition of <italic>T</italic>(<italic>G</italic>); i.e. it holds:.<disp-formula id="bmcM2"><label>(2)</label><graphic xlink:href="1471-2105-12-85-i2.gif"/></disp-formula></p>
      <p>where <italic>N</italic><sub><italic>PE </italic></sub>is the number of PEs. DecGPU constructs the distributed spectrum by (nearly) evenly distributing the set of all possible <italic>k</italic>-mers (including their reverse complements) over all PEs. The location of a <italic>k</italic>-mer is determined using modular hashing. A <italic>k</italic>-mer is packed into an integer <italic>I</italic><sub><italic>k </italic></sub>by mapping the bases {A, C, G, T} to the numerical values {0, 1, 2, 3}. The index of the PE that owns this <italic>k</italic>-mer is computed as <italic>I</italic><sub><italic>k </italic></sub>% <italic>N</italic><sub><italic>PE</italic></sub>. This distributed spectrum reduces the number of <italic>k</italic>-mers in a single spectrum by a factor of the number of PEs. Thus, we are able to keep an acceptable probability of false positives of <italic>T</italic>(<italic>G</italic>) with no need for a vast amount of device memory in a single GPU. Using this distributed spectrum, for the membership lookup of a <italic>k</italic>-mer, all PEs must simultaneously conduct the membership lookup of the <italic>k</italic>-mer in their local spectrums, and then perform collective operations to gain the final result.</p>
      <p>For the distributed spectrum construction, intuitively, the most effective approach is to allow each PE to build its local spectrum on its GPU device, where thousands of threads on the GPU device simultaneously calculate hash values of <italic>k</italic>-mers and determine their destinations. However, this approach requires the support for device-level global memory consistency or atomic functions, since different threads in the device might update the counter value at the same address in the counting Bloom filter. CUDA-enabled GPUs do not provide a mechanism to ensure device-level global memory consistency for all threads in a kernel when the kernel is running. CUDA does provide the support for atomic functions, but they are not byte-addressable. If using an integer for a bucket of a counting Bloom filter, the memory space efficiency of the Bloom filter will be significantly lost. In this case, we choose the CPU + GPU hybrid computing for the local spectrum construction of each <italic>P</italic><sub><italic>i </italic></sub>(as shown in Figure <xref ref-type="fig" rid="F2">2</xref>). Since all input reads are organized into batches, each <italic>P</italic><sub><italic>i </italic></sub>runs multiple iterations to complete the spectrum construction with each iteration processing a read batch. In each iteration, the CPU thread awaits the hash values of a read batch. When the hash values of a read batch are available, the CPU thread inserts <italic>k</italic>-mers, which are distributed to itself, into its local spectrum using the corresponding hash values. In the meantime, the GPU thread reads in another batch of reads, calculates the hash values for this batch, and then transfers the hash values as well as the read batch to the CPU thread.</p>
      <fig id="F2" position="float">
        <label>Figure 2</label>
        <caption>
          <p><bold>Workflow of each PE for distributed spectrum construction</bold>.</p>
        </caption>
        <graphic xlink:href="1471-2105-12-85-2"/>
      </fig>
      <p>Using CUDA, one read is mapped to one thread, where the thread computes the hash values of all <italic>k</italic>-mers and their reverse complements and determines their destination PEs in the read. All reads of a batch are stored in texture memory bound to linear memory. Because a <italic>k</italic>-mer is frequently accessed while calculating the hash values, the <italic>k</italic>-mer is loaded from texture memory to shared memory for improving performance. All the following stages store and access reads and <italic>k</italic>-mers in the same manner. A conversion table in constant memory is used for the conversion of a nucleotide base to its complement. The hash value arrays are allocated in global memory using the coalesced global memory allocation pattern [<xref ref-type="bibr" rid="B15">15</xref>].</p>
    </sec>
    <sec>
      <title>Filtering out error-free reads</title>
      <p>The core of our distributed filtering algorithm is described as follows. For a specific read, each <italic>P</italic><sub><italic>i </italic></sub>simultaneously checks in its local spectrum <italic>T</italic>(<italic>G</italic>, <italic>P</italic><sub><italic>i</italic></sub>) the solidity of each <italic>k</italic>-mer of the read. Since each <italic>k</italic>-mer corresponds to a position in a read, <italic>P</italic><sub><italic>i </italic></sub>uses a local solidity vector <italic>SV</italic>(<italic>P</italic><sub><italic>i</italic></sub>) to record the <italic>k</italic>-mer existence for the read. If a <italic>k</italic>-mer belongs to <italic>T</italic>(<italic>G</italic>, <italic>P</italic><sub><italic>i</italic></sub>), the corresponding position in <italic>SV</italic>(<italic>P</italic><sub><italic>i</italic></sub>) is set to 0 and to 1 otherwise. After completing the solidity check of all <italic>k</italic>-mers, all PEs perform a logical AND reduction operation on the solidity vectors {<italic>SV</italic>(<italic>P</italic><sub><italic>i</italic></sub>)} to gain the final global solidity vector <italic>SV</italic>. The read is error-free if all the positions in <italic>SV </italic>are 0 and erroneous otherwise. For each erroneous read, the values of <italic>SV </italic>are stored into a file, along with the read, for the future use of the fixing stage.</p>
      <p>Figure <xref ref-type="fig" rid="F3">3</xref> shows the workflow of each PE for filtering out error-free reads. For each <italic>P</italic><sub><italic>i</italic></sub>, the CPU thread receives the set {<italic>SV</italic>(<italic>P</italic><sub><italic>i</italic></sub>)} of a read batch from the GPU thread, performs logical AND reduction operations on {<italic>SV</italic>(<italic>P</italic><sub><italic>i</italic></sub>)} in parallel with the other PEs, and then processes the read batch in parallel with the other PEs to filter out error-free reads. Meanwhile, the GPU thread reads in a batch of reads, calculates {<italic>SV</italic>(<italic>P</italic><sub><italic>i</italic></sub>)} of the batch using its local spectrum <italic>T</italic>(<italic>G</italic>, <italic>P</italic><sub><italic>i</italic></sub>), and then transfers {<italic>SV</italic>(<italic>P</italic><sub><italic>i</italic></sub>)} to the CPU thread. From this workflow, the calculation time of the solidity vectors on the GPUs does not scale with the number of PEs, but the execution time of the reduction operations and the error-free reads determination scales well with the number of PEs. Using CUDA, one read is mapped to one thread which builds the solidity vector of the read using <italic>T</italic>(<italic>G</italic>, <italic>P</italic><sub><italic>i</italic></sub>). The solidity vectors are allocated in global memory in a coalesced pattern.</p>
      <fig id="F3" position="float">
        <label>Figure 3</label>
        <caption>
          <p><bold>Workflow of each PE for distributed error-free read filtering</bold>.</p>
        </caption>
        <graphic xlink:href="1471-2105-12-85-3"/>
      </fig>
    </sec>
    <sec>
      <title>Fixing erroneous reads</title>
      <p>If a mutation error occurs at position <italic>j </italic>of a read of length <italic>l</italic>, this mutation creates up to <italic>min</italic>{<italic>k</italic>, <italic>j</italic>, <italic>l</italic>-<italic>j</italic>} erroneous <italic>k</italic>-mers that point to the same sequencing error. The aim of our fixing algorithm is to transform the <italic>min</italic>{<italic>k</italic>, <italic>j</italic>, <italic>l</italic>-<italic>j</italic>} weak <italic>k</italic>-mers to solid ones. In this case, a voting algorithm is applied to correct the most likely erroneous bases that result in these weak <italic>k</italic>-mers. The voting algorithm attempts to find the correct base by replacing all possible bases at each position of the <italic>k</italic>-mer and checking the solidities of the resulting <italic>k</italic>-mers.</p>
      <p>The core of our distributed fixing algorithm is described as follows. For an erroneous read, each <italic>P</italic><sub><italic>i </italic></sub>checks in <italic>T</italic>(<italic>G</italic>) the existence of all <italic>k</italic>-mers of the read from left to right. Because each <italic>P</italic><sub><italic>i </italic></sub>does not hold a copy of <italic>T</italic>(<italic>G</italic>), the existence check in <italic>T</italic>(<italic>G</italic>) is conducted using the solidity vectors {<italic>SV</italic>} produced and saved by the filtering stage. If a <italic>k</italic>-mer does not belong to <italic>T</italic>(<italic>G</italic>), each <italic>P</italic><sub><italic>i </italic></sub>invokes the voting algorithm to compute its local voting matrix <italic>VM</italic>(<italic>P</italic><sub><italic>i</italic></sub>) using its local spectrum <italic>T</italic>(<italic>G</italic>, <italic>P</italic><sub><italic>i</italic></sub>). After completing the voting matrix computation, all PEs perform an ADDITION reduction operation on the voting matrices {<italic>VM</italic>(<italic>P</italic><sub><italic>i</italic></sub>)} to gain the final global voting matrix <italic>VM </italic>of the read. Then, a fixing procedure is performed using <italic>VM </italic>to correct the erroneous read. When enabling the optional iterative policy, for an erroneous read, a starting position <italic>SPOS </italic>is saved after completing the previous fixing iteration, which indicates that each <italic>k</italic>-mer starting before <italic>SPOS </italic>is solid in the read. In the current fixing iteration, the voting matrix computation starts from <italic>SPOS</italic>. Actually, after substituting an erroneous base with the voted (likely) correct base, we might introduce new errors even if there is really only one base error in a read. Hence, it is not necessarily the case that the more fixing iterations used, the more base errors that are corrected. Figure <xref ref-type="fig" rid="F4">4</xref> shows the pseudocode of the CUDA kernel of the voting algorithm.</p>
      <fig id="F4" position="float">
        <label>Figure 4</label>
        <caption>
          <p><bold>Pseudocode of the CUDA kernel of the voting algorithm</bold>.</p>
        </caption>
        <graphic xlink:href="1471-2105-12-85-4"/>
      </fig>
      <p>Figure <xref ref-type="fig" rid="F5">5</xref> shows the workflow of each PE for fixing erroneous reads. For each <italic>P</italic><sub><italic>i</italic></sub>, the CPU thread receives the voting matrices {<italic>VM</italic>(<italic>P</italic><sub><italic>i</italic></sub>)} of a read batch from the GPU thread, performs ADDITION reduction operations on {<italic>VM</italic>(<italic>P</italic><sub><italic>i</italic></sub>)} in parallel with the other PEs, and then fixes the erroneous reads in parallel with the other PEs. The GPU thread computes its local voting matrices {<italic>VM</italic>(<italic>P</italic><sub><italic>i</italic></sub>)} of a read batch using <italic>T</italic>(<italic>G</italic>, <italic>P</italic><sub><italic>i</italic></sub>), and then transfers the voting matrices to the CPU thread.</p>
      <fig id="F5" position="float">
        <label>Figure 5</label>
        <caption>
          <p><bold>Workflow of each PE for fixing erroneous reads</bold>.</p>
        </caption>
        <graphic xlink:href="1471-2105-12-85-5"/>
      </fig>
      <p>Using CUDA, one read is mapped to a thread which performs the voting algorithm on the read to gain the voting matrix. From Figure <xref ref-type="fig" rid="F4">4</xref>, the execution speed of the voting algorithm on GPUs highly depends on how frequently the threads in a warp diverge. The solidity vectors of the reads, used for checking <italic>k</italic>-mer existence in <italic>T</italic>(<italic>G</italic>), are stored in texture memory bound to linear memory. The voting matrices are allocated in global memory in a coalesced pattern.</p>
    </sec>
    <sec>
      <title>Trimming erroneous reads</title>
      <p>After fixing errors in erroneous reads, some reads are still not <italic>T-strings</italic>. In this case, a trimming procedure is performed on the fixed reads that remain erroneous. For an erroneous read, all PEs cooperate to compute the solidity vector <italic>SV </italic>of the read using the same algorithm as in the filtering stage. After gaining <italic>SV</italic>, the algorithm attempts to find the user-satisfied longest substring of the read, in which all <italic>k</italic>-mers are solid. The read is trimmed if such a substring is found and discarded entirely, otherwise. Each <italic>P</italic><sub><italic>i </italic></sub>runs the same workflow as in the filtering stage, except that after gaining the solidity vectors {<italic>SV</italic>} of a read batch, the CPU thread performs the trimming procedure in parallel with the other PEs, instead.</p>
    </sec>
  </sec>
  <sec>
    <title>Results</title>
    <p>We have evaluated the performance of DecGPU from three perspectives: (1) the error correction quality both on simulated and real short read datasets; (2) <italic>de novo </italic>assembly quality improvement after combining our algorithm with Velvet (version 1.0.17) and ABySS (version 1.2.1); and (3) the scalability with respect to different number of compute resources for the CPU-based and GPU-based versions respectively. Six simulated short read datasets (the first six datasets in Table <xref ref-type="table" rid="T1">1</xref>) and three real Illumina GA short read datasets (the last three datasets in Table <xref ref-type="table" rid="T1">1</xref>, named after their accession numbers in NCBI Sequence Read Archive [<xref ref-type="bibr" rid="B30">30</xref>]) are used to measure the accuracy of correction and the <italic>de novo </italic>assembly quality. For the six simulated datasets, they are simulated from the E. coli K12 MG1665 reference genome (NC_000913) with different read lengths, coverage and error rates. For the three real datasets, the SRR001665 dataset is a paired-end dataset and the other two are single-end. The SRR001665 dataset consists of about 20.8 million paired-end 36-basepair (bp) reads generated from a 200-bp insert size of an E. coli library (SRX000429), and has been used in [<xref ref-type="bibr" rid="B13">13</xref>] and [<xref ref-type="bibr" rid="B14">14</xref>] to assess the assembly qualities of various assemblers.</p>
    <table-wrap id="T1" position="float">
      <label>Table 1</label>
      <caption>
        <p>Simulated and real short read datasets</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">Datasets</th>
            <th align="left">Read length</th>
            <th align="left">Coverage</th>
            <th align="left">Error rate</th>
            <th align="left">No. of Reads</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">D30X1.5</td>
            <td align="left">36</td>
            <td align="left">30</td>
            <td align="left">1.5%</td>
            <td align="left">3866000</td>
          </tr>
          <tr>
            <td colspan="5">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D30X3.0</td>
            <td align="left">36</td>
            <td align="left">30</td>
            <td align="left">3.0%</td>
            <td align="left">3860000</td>
          </tr>
          <tr>
            <td colspan="5">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D75X1.5</td>
            <td align="left">36</td>
            <td align="left">75</td>
            <td align="left">1.5%</td>
            <td align="left">9666000</td>
          </tr>
          <tr>
            <td colspan="5">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D75X3.0</td>
            <td align="left">36</td>
            <td align="left">75</td>
            <td align="left">3.0%</td>
            <td align="left">9666000</td>
          </tr>
          <tr>
            <td colspan="5">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D150X1.5</td>
            <td align="left">72</td>
            <td align="left">150</td>
            <td align="left">1.5%</td>
            <td align="left">9666000</td>
          </tr>
          <tr>
            <td colspan="5">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D150X3.0</td>
            <td align="left">72</td>
            <td align="left">150</td>
            <td align="left">3.0%</td>
            <td align="left">9666000</td>
          </tr>
          <tr>
            <td colspan="5">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">SRR006331</td>
            <td align="left">36</td>
            <td align="left">69</td>
            <td align="left">-</td>
            <td align="left">1693848</td>
          </tr>
          <tr>
            <td colspan="5">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">SRR016146</td>
            <td align="left">51</td>
            <td align="left">81</td>
            <td align="left">-</td>
            <td align="left">4438066</td>
          </tr>
          <tr>
            <td colspan="5">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">SRR001665</td>
            <td align="left">36</td>
            <td align="left">162</td>
            <td align="left">-</td>
            <td align="left">20816448</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>All the following tests are conducted on a workstation computer and a computing cluster with eight compute nodes that are connected by a high-speed Infiniband switch. The workstation computer has two quad-core Intel Xeon E5506 2.13 GHz processors and 16 GB RAM running the Linux operating system (OS). For the computing cluster, each compute node consists of an AMD Opteron 2378 quad-core 2.4 GHz processor and 8 GB RAM running the Linux OS with the MVAPICH2 library [<xref ref-type="bibr" rid="B31">31</xref>]. Furthermore, two Tesla S1070 quad-GPU computing systems are installed and connected to four nodes of the cluster. A single Tesla T10 GPU of a Tesla S1070 system consists of 30 SMs comprising 240 SPs and 4 GB RAM. If not specified, for all the following tests, DecGPU uses the default parameters (i.e. the <italic>k</italic>-mer length is set to 21, the multiplicity threshold <italic>M </italic>to 6, the maximum allowable number of bases to be trimmed to 4, and one fixing iteration), and hSHREC sets the strictness value to 5 for the first four simulated datasets and 6 for the last two simulated datasets, using eight threads.</p>
    <p>We have evaluated the performance of our algorithm using the simulated datasets in terms of: (1) the ability to detect reads as error-free or erroneous, and (2) the ability to correct erroneous reads. The detection of erroneous reads is a binary classification test, where an input read is classified into either the error-free group or the erroneous group. Table <xref ref-type="table" rid="T2">2</xref> shows the corresponding definitions of true positive (TP), false positive (FP), true negative (TN) and false negative (FN). The sensitivity and specificity measures are defined as<disp-formula id="bmcM3"><label>(3)</label><graphic xlink:href="1471-2105-12-85-i3.gif"/></disp-formula><disp-formula id="bmcM4"><label>(4)</label><graphic xlink:href="1471-2105-12-85-i4.gif"/></disp-formula></p>
    <table-wrap id="T2" position="float">
      <label>Table 2</label>
      <caption>
        <p>Definitions for the read binary classification test</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">Classification</th>
            <th align="left" colspan="2">Read Condition</th>
          </tr>
          <tr>
            <th/>
            <th colspan="2">
              <hr/>
            </th>
          </tr>
          <tr>
            <th/>
            <th align="left">Erroneous</th>
            <th align="left">Error-free</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">Detected as erroneous</td>
            <td align="left">TP</td>
            <td align="left">FP</td>
          </tr>
          <tr>
            <td colspan="3">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">Detected as error-free</td>
            <td align="left">FN</td>
            <td align="left">TN</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>The results of the classification test are shown in Table <xref ref-type="table" rid="T3">3</xref> for the six simulated datasets, where the sensitivity and specificity values have been multiplied by 100. From the sensitivity measure, DecGPU and hSHREC achieve comparable performance for all datasets, where the sensitivity is &gt; 99.80% for each dataset, meaning that only very few erroneous reads remain undetected. However, as for the specificity measure, the performance of hSHREC degrades very fast with the increase of dataset size and coverage. For each of the last four simulated datasets, the specificity of DecGPU is &gt; 99.80%, clearly outperforming hSHREC. For the two low-coverage D30X1.5 and D30X3.0 datasets, DecGPU gives poorer specificity than hSHREC. However, after setting the multiplicity threshold <italic>M </italic>to 3 and 2, instead of the default 6, DecGPU yields a specificity of 99.52% and 99.32% for the two datasets respectively, better than hSHREC.</p>
    <table-wrap id="T3" position="float">
      <label>Table 3</label>
      <caption>
        <p>Summary of the classification test for simulated datasets</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">Datasets</th>
            <th align="left">Algorithm</th>
            <th align="left">TP</th>
            <th align="left">FP</th>
            <th align="left">FN</th>
            <th align="left">TN</th>
            <th align="left">Sensitivity</th>
            <th align="left">Specificity</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">D30X1.5</td>
            <td align="left">DecGPU</td>
            <td align="left">1620660</td>
            <td align="left">349908</td>
            <td align="left">253</td>
            <td align="left">1895179</td>
            <td align="left">99.98</td>
            <td align="left">84.41</td>
          </tr>
          <tr>
            <td/>
            <td colspan="7">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">hSHREC</td>
            <td align="left">1617685</td>
            <td align="left">13998</td>
            <td align="left">3228</td>
            <td align="left">2231089</td>
            <td align="left">99.80</td>
            <td align="left">99.38</td>
          </tr>
          <tr>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D30X3.0</td>
            <td align="left">DecGPU</td>
            <td align="left">2575411</td>
            <td align="left">660533</td>
            <td align="left">306</td>
            <td align="left">629750</td>
            <td align="left">99.99</td>
            <td align="left">48.81</td>
          </tr>
          <tr>
            <td/>
            <td colspan="7">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">hSHREC</td>
            <td align="left">2571520</td>
            <td align="left">31367</td>
            <td align="left">4197</td>
            <td align="left">1258916</td>
            <td align="left">99.84</td>
            <td align="left">97.57</td>
          </tr>
          <tr>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D75X1.5</td>
            <td align="left">DecGPU</td>
            <td align="left">4053688</td>
            <td align="left">23</td>
            <td align="left">1024</td>
            <td align="left">5611265</td>
            <td align="left">99.97</td>
            <td align="left">100.00</td>
          </tr>
          <tr>
            <td/>
            <td colspan="7">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">hSHREC</td>
            <td align="left">4053827</td>
            <td align="left">4990124</td>
            <td align="left">885</td>
            <td align="left">621164</td>
            <td align="left">99.98</td>
            <td align="left">11.07</td>
          </tr>
          <tr>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D75X3.0</td>
            <td align="left">DecGPU</td>
            <td align="left">6435328</td>
            <td align="left">3481</td>
            <td align="left">1621</td>
            <td align="left">3225570</td>
            <td align="left">99.97</td>
            <td align="left">99.89</td>
          </tr>
          <tr>
            <td/>
            <td colspan="7">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">hSHREC</td>
            <td align="left">6436305</td>
            <td align="left">3129803</td>
            <td align="left">644</td>
            <td align="left">99248</td>
            <td align="left">99.99</td>
            <td align="left">3.07</td>
          </tr>
          <tr>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D150X1.5</td>
            <td align="left">DecGPU</td>
            <td align="left">6406078</td>
            <td align="left">2</td>
            <td align="left">5395</td>
            <td align="left">3254525</td>
            <td align="left">99.92</td>
            <td align="left">100.00</td>
          </tr>
          <tr>
            <td/>
            <td colspan="7">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">hSHREC</td>
            <td align="left">6411346</td>
            <td align="left">3185858</td>
            <td align="left">127</td>
            <td align="left">68669</td>
            <td align="left">100.00</td>
            <td align="left">2.11</td>
          </tr>
          <tr>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D150X3.0</td>
            <td align="left">DecGPU</td>
            <td align="left">8578176</td>
            <td align="left">1</td>
            <td align="left">8651</td>
            <td align="left">1079172</td>
            <td align="left">99.90</td>
            <td align="left">100.00</td>
          </tr>
          <tr>
            <td/>
            <td colspan="7">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">hSHREC</td>
            <td align="left">8586743</td>
            <td align="left">1056392</td>
            <td align="left">84</td>
            <td align="left">22781</td>
            <td align="left">100.00</td>
            <td align="left">2.11</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>The performance of correcting erroneous reads is evaluated using the simulated datasets from two aspects. The first aspect is to compare the error rates before and after error correction. The error rates are calculated by doing a base-by-base comparison with their respective original reads (without errors). It is possible that a corrected read does not have the same length with its original read. In this case, the shorter read is mapped with no gaps to the longer one by iteratively changing the starting positions. We choose the mapping with the minimal number of base errors, and then add the number of bases in the shorter one to the total number of bases for the future calculation of error rates. For DecGPU, we vary the number of fixing iterations with the intention to find and correct more than one erroneous base in a single read. We have compared the accuracy and execution time of DecGPU to hSHREC (see Table <xref ref-type="table" rid="T4">4</xref>) on the above workstation with eight CPU cores. Table <xref ref-type="table" rid="T4">4</xref> shows that DecGPU significantly reduces the error rates of all datasets (particularly reducing the error rate of D75X1.5 from 1.500% to 0.248% and the error rate of D75X3.0 from 3.000% to 0.988%), clearly outperforming hSHREC. Furthermore, on the dual quad-core workstation, the CPU-based DecGPU version runs up to 22× faster when performing one fixing iteration and up to 19× faster when performing two fixing iterations compared to hSHREC. For DecGPU, the error rates are further reduced for all datasets when using two fixing iterations instead of only one. However, we found that a further increase of iterations does not significantly reduce the error rates further. As for the execution time, the second fixing iteration does not result in a large execution time increase, since it only corrects the remaining erroneous reads.</p>
    <table-wrap id="T4" position="float">
      <label>Table 4</label>
      <caption>
        <p>The error rates and execution time comparison for DecGPU and Hybrid SHREC</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">Datasets</th>
            <th align="left">Original Error Rate (%)</th>
            <th align="left" colspan="3">Corrected Error Rate (%)</th>
            <th align="left" colspan="3">Time (seconds)</th>
          </tr>
          <tr>
            <th/>
            <th/>
            <th colspan="6">
              <hr/>
            </th>
          </tr>
          <tr>
            <th/>
            <th/>
            <th align="left" colspan="2">DecGPU</th>
            <th align="left">hSHREC</th>
            <th align="left" colspan="2">DecGPU</th>
            <th align="left">hSHREC</th>
          </tr>
          <tr>
            <th/>
            <th/>
            <th colspan="2">
              <hr/>
            </th>
            <th/>
            <th colspan="2">
              <hr/>
            </th>
            <th/>
          </tr>
          <tr>
            <th/>
            <th/>
            <th align="left">one fixing</th>
            <th align="left">two fixing</th>
            <th/>
            <th align="left">one fixing</th>
            <th align="left">two fixing</th>
            <th/>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">D30X1.5</td>
            <td align="left">1.498</td>
            <td align="left">0.426</td>
            <td align="left">0.341</td>
            <td align="left">0.713</td>
            <td align="left">125</td>
            <td align="left">145</td>
            <td align="left">2721</td>
          </tr>
          <tr>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D30X3.0</td>
            <td align="left">3.003</td>
            <td align="left">1.773</td>
            <td align="left">1.625</td>
            <td align="left">2.014</td>
            <td align="left">164</td>
            <td align="left">217</td>
            <td align="left">2882</td>
          </tr>
          <tr>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D75X1.5</td>
            <td align="left">1.500</td>
            <td align="left">0.347</td>
            <td align="left">0.248</td>
            <td align="left">3.936</td>
            <td align="left">288</td>
            <td align="left">348</td>
            <td align="left">4380</td>
          </tr>
          <tr>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D75X3.0</td>
            <td align="left">3.000</td>
            <td align="left">1.262</td>
            <td align="left">0.988</td>
            <td align="left">4.058</td>
            <td align="left">375</td>
            <td align="left">473</td>
            <td align="left">5079</td>
          </tr>
          <tr>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D150X1.5</td>
            <td align="left">1.500</td>
            <td align="left">0.579</td>
            <td align="left">0.348</td>
            <td align="left">3.233</td>
            <td align="left">981</td>
            <td align="left">1118</td>
            <td align="left">11047</td>
          </tr>
          <tr>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D150X3.0</td>
            <td align="left">3.001</td>
            <td align="left">1.781</td>
            <td align="left">1.241</td>
            <td align="left">4.082</td>
            <td align="left">1254</td>
            <td align="left">1489</td>
            <td align="left">12951</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>The second aspect is to evaluate the correct correction rate, incorrect correction rate, and the rate of newly introduced errors, relative to the total number of original base errors. When performing error correction, correction operations will result in the following four cases:</p>
    <p>• <italic>Correct Corrections </italic>(<italic>CC</italic>): meaning that original erroneous bases have been changed to the correct ones;</p>
    <p>• <italic>Incorrect Corrections </italic>(<italic>IC</italic>): meaning that original erroneous bases have been changed to other wrong ones;</p>
    <p>• <italic>Errors Unchanged </italic>(<italic>EU</italic>): meaning that original erroneous bases remain the same;</p>
    <p>• <italic>Errors Introduced </italic>(<italic>EI</italic>): meaning that original correct bases have been changed to be incorrect, thus introducing new base errors.</p>
    <p>In this paper, we define three measures relative to the total number of original base errors: correct correction rate <italic>R</italic><sub><italic>CC</italic></sub>, incorrect correction rate <italic>R</italic><sub><italic>IC</italic></sub>, and correction error rate <italic>R</italic><sub><italic>EI</italic></sub>, to facilitate the error correction accuracy comparison. <italic>R</italic><sub><italic>CC </italic></sub>indicates the proportion of the original erroneous bases that have been corrected, <italic>R</italic><sub><italic>EI </italic></sub>indicates the proportion of the original erroneous bases that have been changed to other wrong bases, and <italic>R</italic><sub><italic>EI </italic></sub>indicates the ratio of the original correct bases that have been changed to be incorrect. For <italic>R</italic><sub><italic>CC</italic></sub>, the larger value means the better performance, and for <italic>R</italic><sub><italic>IC </italic></sub>and <italic>R</italic><sub><italic>EI</italic></sub>, the smaller value the better performance. The <italic>R</italic><sub><italic>CC</italic></sub>, <italic>R</italic><sub><italic>IC </italic></sub>and <italic>R</italic><sub><italic>EI </italic></sub>measures are calculated as<disp-formula id="bmcM5"><label>(5)</label><graphic xlink:href="1471-2105-12-85-i5.gif"/></disp-formula><disp-formula id="bmcM6"><label>(6)</label><graphic xlink:href="1471-2105-12-85-i6.gif"/></disp-formula><disp-formula id="bmcM7"><label>(7)</label><graphic xlink:href="1471-2105-12-85-i7.gif"/></disp-formula></p>
    <p>In this test, for DecGPU, we do not trim the fixed reads that remain erroneous, and use two fixing iterations. For hSHREC, we only use the reads that have the same lengths with their original reads after correction, because the correspondence relationship between bases is difficult to be determined for two reads of different lengths. Table <xref ref-type="table" rid="T5">5</xref> shows the performance comparison in terms of the three measures between DecGPU and hSHREC, where the value of <italic>R</italic><sub><italic>CC</italic></sub>, <italic>R</italic><sub><italic>IC </italic></sub>and <italic>R</italic><sub><italic>EI </italic></sub>has been multiplied by 100. For <italic>R</italic><sub><italic>CC</italic></sub>, hSHREC yields better performance for the first three datasets and DecGPU performs better for the last three datasets. However, hSHREC degrades very rapidly (down to 5.73%) with the increase of coverage and original error rate, while DecGPU remains relatively consistent. For <italic>R</italic><sub><italic>IC </italic></sub>and <italic>R</italic><sub><italic>EI</italic></sub>, DecGPU clearly outperforms hSHREC for each dataset, where DecGPU miscorrected ≤ 0.04% bases and introduced ≤ 0.08% new base errors, but hSHREC miscorrected ≥ 0.30% (up to 0.73%) bases, and introduced ≥ 6.95% (up to 47.67%) new base errors.</p>
    <table-wrap id="T5" position="float">
      <label>Table 5</label>
      <caption>
        <p>Performance comparison with respect to <italic>R<sub>C</sub><sub>C</sub></italic>, <italic>R<sub>I</sub><sub>C </sub></italic>and <italic>R<sub>E</sub><sub>I </sub></italic>measures</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">Datasets</th>
            <th align="left">Algorithms</th>
            <th align="left">CC</th>
            <th align="left">IC</th>
            <th align="left">EU</th>
            <th align="left">EI</th>
            <th align="left">
              <bold>R</bold>
              <sub>
                <bold>CC</bold>
              </sub>
            </th>
            <th align="left">
              <bold>R</bold>
              <sub>
                <bold>IC</bold>
              </sub>
            </th>
            <th align="left">
              <bold>R</bold>
              <sub>
                <bold>EI</bold>
              </sub>
            </th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">D30X1.5</td>
            <td align="left">DecGPU</td>
            <td align="left">1275967</td>
            <td align="left">191</td>
            <td align="left">809207</td>
            <td align="left">893</td>
            <td align="left">61.19</td>
            <td align="left">0.01</td>
            <td align="left">0.05</td>
          </tr>
          <tr>
            <td/>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">hSHREC</td>
            <td align="left">1736112</td>
            <td align="left">10960</td>
            <td align="left">214851</td>
            <td align="left">125381</td>
            <td align="left">88.49</td>
            <td align="left">0.56</td>
            <td align="left">6.95</td>
          </tr>
          <tr>
            <td colspan="9">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D30X3.0</td>
            <td align="left">DecGPU</td>
            <td align="left">1611459</td>
            <td align="left">344</td>
            <td align="left">2567906</td>
            <td align="left">2932</td>
            <td align="left">38.55</td>
            <td align="left">0.01</td>
            <td align="left">0.08</td>
          </tr>
          <tr>
            <td/>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">hSHREC</td>
            <td align="left">2983112</td>
            <td align="left">27448</td>
            <td align="left">764097</td>
            <td align="left">326466</td>
            <td align="left">79.03</td>
            <td align="left">0.73</td>
            <td align="left">9.38</td>
          </tr>
          <tr>
            <td colspan="9">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D75X1.5</td>
            <td align="left">DecGPU</td>
            <td align="left">3373714</td>
            <td align="left">388</td>
            <td align="left">1844213</td>
            <td align="left">530</td>
            <td align="left">64.65</td>
            <td align="left">0.01</td>
            <td align="left">0.02</td>
          </tr>
          <tr>
            <td/>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">hSHREC</td>
            <td align="left">1431267</td>
            <td align="left">27988</td>
            <td align="left">3256061</td>
            <td align="left">2219648</td>
            <td align="left">30.35</td>
            <td align="left">0.59</td>
            <td align="left">47.67</td>
          </tr>
          <tr>
            <td colspan="9">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D75X3.0</td>
            <td align="left">DecGPU</td>
            <td align="left">5425615</td>
            <td align="left">746</td>
            <td align="left">5013497</td>
            <td align="left">1122</td>
            <td align="left">51.97</td>
            <td align="left">0.01</td>
            <td align="left">0.02</td>
          </tr>
          <tr>
            <td/>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">hSHREC</td>
            <td align="left">757454</td>
            <td align="left">29924</td>
            <td align="left">9248234</td>
            <td align="left">1250738</td>
            <td align="left">7.55</td>
            <td align="left">0.30</td>
            <td align="left">12.76</td>
          </tr>
          <tr>
            <td colspan="9">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D150X1.5</td>
            <td align="left">DecGPU</td>
            <td align="left">7242425</td>
            <td align="left">2913</td>
            <td align="left">3196883</td>
            <td align="left">1004</td>
            <td align="left">69.36</td>
            <td align="left">0.03</td>
            <td align="left">0.04</td>
          </tr>
          <tr>
            <td/>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">hSHREC</td>
            <td align="left">741722</td>
            <td align="left">37618</td>
            <td align="left">9034830</td>
            <td align="left">3345778</td>
            <td align="left">7.56</td>
            <td align="left">0.38</td>
            <td align="left">34.47</td>
          </tr>
          <tr>
            <td colspan="9">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">D150X3.0</td>
            <td align="left">DecGPU</td>
            <td align="left">11221669</td>
            <td align="left">7593</td>
            <td align="left">9655700</td>
            <td align="left">2121</td>
            <td align="left">53.73</td>
            <td align="left">0.04</td>
            <td align="left">0.05</td>
          </tr>
          <tr>
            <td/>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">hSHREC</td>
            <td align="left">1152718</td>
            <td align="left">71504</td>
            <td align="left">18896523</td>
            <td align="left">3136637</td>
            <td align="left">5.73</td>
            <td align="left">0.36</td>
            <td align="left">15.94</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>Furthermore, we have measured the error correction quality of DecGPU in terms of mapped reads after aligning the reads to their reference genome. We vary the maximum allowable number of mismatches in a single read (or seed) to see the proportion changes. The SRR001665 dataset and Bowtie (version 0.12.7) [<xref ref-type="bibr" rid="B32">32</xref>] short read alignment algorithm are used for the evaluation. For Bowtie, the default parameters are used except for the maximum allowable number of mismatches, and for hSHREC, we have set the strictness value to 7. The proportion of mapped reads is calculated in three cases: exact match, ≤ one mismatch, and ≤ two mismatches (see Figure <xref ref-type="fig" rid="F6">6</xref>). After error correction with DecGPU, the proportion of mapped reads is higher than the original reads in each case. However, after error correction with hSHREC, the proportion for each dataset goes down in each case. This might be caused by the fact that some reads become very short after error correction with hSHREC.</p>
    <fig id="F6" position="float">
      <label>Figure 6</label>
      <caption>
        <p><bold>Percentage of mapped reads as a function of maximum number of mismatches</bold>.</p>
      </caption>
      <graphic xlink:href="1471-2105-12-85-6"/>
    </fig>
    <p>Error correction prior to assembly is important for short read assemblers based on the <italic>de Brujin </italic>graph approach. To demonstrate how our algorithm affects <italic>de novo </italic>assembly quality, we have assessed the assembly quality before and after using our algorithm to correct errors for two popular assemblers: Velvet (version 1.0.17) and ABySS (version 1.2.1). Both assemblers do not internally incorporate error correction prior to assembly. We have carefully tuned the parameters with the intention to gain the highest assembly quality for the stand-alone Velvet and ABySS assemblers. We compared the assemblers in terms of N50, N90 and maximum <italic>contig </italic>or <italic>scaffold </italic>sizes using the three real datasets. The N50 (N90) <italic>contig </italic>or <italic>scaffold </italic>size is calculated by ordering all assembled sequences by length, and then adding the lengths from the largest to the smallest until the summed length exceeds 50% (90%) of the reference genome size. For these calculations, we use the reference genome sizes of 877438, 2801838, and 4639675 for the datasets SRR006331, SRR016146 and SRR001665 respectively. For the calculation of <italic>scaffold </italic>sizes, the intra-scaffold gaps are included. To see the difference in assembly quality before and after error correction, we use the same set of parameters with the stand-alone assemblers for our resulting DecGPU-Velvet (D-Velvet) and DecGPU-ABySS (D-ABySS) assemblers to conduct the assembly work (assembly results are shown in Table <xref ref-type="table" rid="T6">6</xref>), where DecGPU uses two fixing iterations. From Table <xref ref-type="table" rid="T6">6</xref>, D-Velvet yields superior N50 <italic>contig </italic>sizes to Velvet, with not always higher N90 and maximum <italic>contig </italic>sizes, for all datasets. D-ABySS gives comparable N50, N90 and maximum <italic>contig </italic>sizes with ABySS for all datasets. When scaffolding the paired-end SRR001665, D-ABySS produces larger N50 <italic>scaffold </italic>size than ABySS, but D-Velvet failed to outperform Velvet. However, after further tuning the assembly parameters, D-Velvet yields superior N50 <italic>scaffold </italic>size to Velvet for SRR001665 (see Table <xref ref-type="table" rid="T7">7</xref>). Moreover, larger N50 <italic>contig </italic>sizes are produced by D-ABySS on SRR006331 and SRR016146 respectively, which are better than the outcome of ABySS. All these results suggest that our algorithm has the potential to improve the <italic>de novo </italic>assembly quality for <italic>de</italic>-<italic>Bruijn</italic>-graph-based assemblers. The number of assembled sequences ("#Seq" column in Tables <xref ref-type="table" rid="T6">6</xref> and <xref ref-type="table" rid="T7">7</xref>) only counts in the sequences of lengths ≥ 100 bps, and the assembly output can be obtained from Additional file <xref ref-type="supplementary-material" rid="S1">1</xref>.</p>
    <table-wrap id="T6" position="float">
      <label>Table 6</label>
      <caption>
        <p>Assembly quality and parameters for different assemblers</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">Datasets</th>
            <th align="left">Type</th>
            <th align="left">Assembler</th>
            <th align="left">N50</th>
            <th align="left">N90</th>
            <th align="left">MAX</th>
            <th align="left">#Seq</th>
            <th align="left">Parameters</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">SRR006331</td>
            <td align="left">
              <italic>Contig</italic>
            </td>
            <td align="left">Velvet</td>
            <td align="left">6229</td>
            <td align="left">1830</td>
            <td align="left">21166</td>
            <td align="left">288</td>
            <td align="left">k = 23, cov_cutoff = auto</td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="5">
              <hr/>
            </td>
            <td/>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">D-Velvet</td>
            <td align="left">7411</td>
            <td align="left">1549</td>
            <td align="left">17986</td>
            <td align="left">282</td>
            <td/>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="6">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">ABySS</td>
            <td align="left">5644</td>
            <td align="left">1505</td>
            <td align="left">15951</td>
            <td align="left">334</td>
            <td align="left">k = 24</td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="5">
              <hr/>
            </td>
            <td/>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">D-ABySS</td>
            <td align="left">4789</td>
            <td align="left">1216</td>
            <td align="left">12090</td>
            <td align="left">371</td>
            <td/>
          </tr>
          <tr>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">SRR016146</td>
            <td align="left">
              <italic>Contig</italic>
            </td>
            <td align="left">Velvet</td>
            <td align="left">34052</td>
            <td align="left">7754</td>
            <td align="left">112041</td>
            <td align="left">301</td>
            <td align="left">k = 31, cov_cutoff = auto</td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="5">
              <hr/>
            </td>
            <td/>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">D-Velvet</td>
            <td align="left">34898</td>
            <td align="left">7754</td>
            <td align="left">134258</td>
            <td align="left">292</td>
            <td/>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="6">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">ABySS</td>
            <td align="left">34124</td>
            <td align="left">7758</td>
            <td align="left">112038</td>
            <td align="left">297</td>
            <td align="left">k = 33</td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="5">
              <hr/>
            </td>
            <td/>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">D-ABySS</td>
            <td align="left">34889</td>
            <td align="left">7916</td>
            <td align="left">134314</td>
            <td align="left">297</td>
            <td/>
          </tr>
          <tr>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">SRR001665</td>
            <td align="left">
              <italic>Contig</italic>
            </td>
            <td align="left">Velvet</td>
            <td align="left">17900</td>
            <td align="left">4362</td>
            <td align="left">73058</td>
            <td align="left">601</td>
            <td align="left">k = 29, cov_cutoff = auto</td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="5">
              <hr/>
            </td>
            <td/>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">D-Velvet</td>
            <td align="left">18484</td>
            <td align="left">4687</td>
            <td align="left">73058</td>
            <td align="left">586</td>
            <td/>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="6">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">ABySS</td>
            <td align="left">18161</td>
            <td align="left">4364</td>
            <td align="left">71243</td>
            <td align="left">603</td>
            <td align="left">k = 30</td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="5">
              <hr/>
            </td>
            <td/>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">D-ABySS</td>
            <td align="left">18161</td>
            <td align="left">4604</td>
            <td align="left">73060</td>
            <td align="left">595</td>
            <td/>
          </tr>
          <tr>
            <td/>
            <td colspan="7">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">
              <italic>Scaffold</italic>
            </td>
            <td align="left">Velvet</td>
            <td align="left">95486</td>
            <td align="left">26570</td>
            <td align="left">268283</td>
            <td align="left">179</td>
            <td align="left">k = 31,exp_cov = auto, cov_cutoff = auto</td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="5">
              <hr/>
            </td>
            <td/>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">D-Velvet</td>
            <td align="left">95429</td>
            <td align="left">26570</td>
            <td align="left">268084</td>
            <td align="left">175</td>
            <td/>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="6">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">ABySS</td>
            <td align="left">96308</td>
            <td align="left">25780</td>
            <td align="left">268372</td>
            <td align="left">124</td>
            <td align="left">k = 33, n = 10</td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="5">
              <hr/>
            </td>
            <td/>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">D-ABySS</td>
            <td align="left">96904</td>
            <td align="left">27002</td>
            <td align="left">210775</td>
            <td align="left">122</td>
            <td/>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap id="T7" position="float">
      <label>Table 7</label>
      <caption>
        <p>Assembly quality and parameters after further tuning parameters for some datasets</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">Datasets</th>
            <th align="left">Type</th>
            <th align="left">Assembler</th>
            <th align="left">N50</th>
            <th align="left">N90</th>
            <th align="left">MAX</th>
            <th align="left">#Seq</th>
            <th align="left">Parameters</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">SRR006331</td>
            <td align="left">
              <italic>Contig</italic>
            </td>
            <td align="left">D-ABySS</td>
            <td align="left">6130</td>
            <td align="left">1513</td>
            <td align="left">16397</td>
            <td align="left">311</td>
            <td align="left">k = 24, c = 7</td>
          </tr>
          <tr>
            <td colspan="8">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">SRR001665</td>
            <td align="left">
              <italic>Contig</italic>
            </td>
            <td align="left">D-ABySS</td>
            <td align="left">20068</td>
            <td align="left">5147</td>
            <td align="left">73062</td>
            <td align="left">565</td>
            <td align="left">k = 31, c = 12</td>
          </tr>
          <tr>
            <td/>
            <td colspan="7">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">
              <italic>Scaffold</italic>
            </td>
            <td align="left">D-Velvet</td>
            <td align="left">101245</td>
            <td align="left">30793</td>
            <td align="left">269944</td>
            <td align="left">146</td>
            <td align="left">k = 31, exp_cov = 36, cov_cutoff = 13</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>The execution speed of DecGPU is evaluated using the three real datasets in terms of: (1) scalability of the CPU-based and GPU-based versions with respect to different number of compute resources, and (2) execution time of the GPU-based version compared to that of CUDA-EC (version 1.0.1) on a single GPU. Both of the assessments are conducted on the already described computing cluster. In addition to the absolute execution time, we use another measure, called Million Bases Processed per Second (MBPS), to indicate execution speed and make the evaluation more independent of datasets. Table <xref ref-type="table" rid="T8">8</xref> gives the execution time (in seconds) and MBPS of the two versions on different number of CPU cores and different number of GPUs respectively. On a quad-core CPU, DecGPU achieves a performance of up to 1.7 MBPS for the spectrum construction ("Spectrum" row in the table) and up to 2.8 MBPS for the error correction part ("EC" row in the table). On a single GPU, our algorithm produces a performance of up to 2.9 MBPS for the spectrum construction and up to 8.0 MBPS for the error correction part. However, it can also be seen that our algorithm does not show good runtime scalability with respect to the number of compute resources for either version. This is because our algorithm intends to solve the memory constraint problem for large-scale HTSR datasets, i.e. it requires the combination of results from distributed spectrums through collective reduction operations on all reads, limiting its runtime scalability. Subsequently, we compared the execution speed of our algorithm with that of CUDA-EC on a single Tesla T10 GPU (see Figure <xref ref-type="fig" rid="F7">7</xref>), where CUDA-EC sets <italic>k</italic>-mer length to 21 and the minimum multiplicity to 5. DecGPU runs on average about 2.4× faster than CUDA-EC, with a highest of about 2.8 ×.</p>
    <table-wrap id="T8" position="float">
      <label>Table 8</label>
      <caption>
        <p>Execution time and MBPS of DecGPU on different number of compute resources</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left" colspan="3">Datasets</th>
            <th align="left" colspan="4">No. of CPU cores</th>
            <th align="left" colspan="4">No. of GPUs</th>
          </tr>
          <tr>
            <th/>
            <th/>
            <th/>
            <th colspan="8">
              <hr/>
            </th>
          </tr>
          <tr>
            <th/>
            <th/>
            <th/>
            <th align="left">4</th>
            <th align="left">8</th>
            <th align="left">16</th>
            <th align="left">32</th>
            <th align="left">1</th>
            <th align="left">2</th>
            <th align="left">4</th>
            <th align="left">8</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">SRR006331</td>
            <td align="left">Spectrum</td>
            <td align="left">Time(s)</td>
            <td align="left">36</td>
            <td align="left">19</td>
            <td align="left">11</td>
            <td align="left">7</td>
            <td align="left">21</td>
            <td align="left">15</td>
            <td align="left">9</td>
            <td align="left">9</td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="9">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">MBPS</td>
            <td align="left">1.7</td>
            <td align="left">3.2</td>
            <td align="left">5.5</td>
            <td align="left">8.7</td>
            <td align="left">2.9</td>
            <td align="left">4.1</td>
            <td align="left">6.8</td>
            <td align="left">6.8</td>
          </tr>
          <tr>
            <td/>
            <td colspan="10">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">EC</td>
            <td align="left">Time(s)</td>
            <td align="left">35</td>
            <td align="left">38</td>
            <td align="left">41</td>
            <td align="left">42</td>
            <td align="left">9</td>
            <td align="left">11</td>
            <td align="left">18</td>
            <td align="left">23</td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="9">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">MBPS</td>
            <td align="left">1.7</td>
            <td align="left">1.6</td>
            <td align="left">1.5</td>
            <td align="left">1.5</td>
            <td align="left">6.8</td>
            <td align="left">5.5</td>
            <td align="left">3.4</td>
            <td align="left">2.7</td>
          </tr>
          <tr>
            <td colspan="11">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">SRR016146</td>
            <td align="left">Spectrum</td>
            <td align="left">Time(s)</td>
            <td align="left">194</td>
            <td align="left">96</td>
            <td align="left">51</td>
            <td align="left">30</td>
            <td align="left">121</td>
            <td align="left">86</td>
            <td align="left">46</td>
            <td align="left">48</td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="9">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">MBPS</td>
            <td align="left">1.2</td>
            <td align="left">2.4</td>
            <td align="left">4.4</td>
            <td align="left">7.5</td>
            <td align="left">1.9</td>
            <td align="left">2.6</td>
            <td align="left">4.9</td>
            <td align="left">4.7</td>
          </tr>
          <tr>
            <td/>
            <td colspan="10">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">EC</td>
            <td align="left">Time(s)</td>
            <td align="left">194</td>
            <td align="left">168</td>
            <td align="left">175</td>
            <td align="left">206</td>
            <td align="left">63</td>
            <td align="left">53</td>
            <td align="left">43</td>
            <td align="left">45</td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="9">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">MBPS</td>
            <td align="left">1.2</td>
            <td align="left">1.3</td>
            <td align="left">1.3</td>
            <td align="left">1.1</td>
            <td align="left">3.6</td>
            <td align="left">4.3</td>
            <td align="left">5.3</td>
            <td align="left">5.0</td>
          </tr>
          <tr>
            <td colspan="11">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">SRR001665</td>
            <td align="left">Spectrum</td>
            <td align="left">Time(s)</td>
            <td align="left">473</td>
            <td align="left">247</td>
            <td align="left">136</td>
            <td align="left">86</td>
            <td align="left">297</td>
            <td align="left">231</td>
            <td align="left">133</td>
            <td align="left">137</td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="9">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">MBPS</td>
            <td align="left">1.6</td>
            <td align="left">3.0</td>
            <td align="left">5.5</td>
            <td align="left">8.7</td>
            <td align="left">2.5</td>
            <td align="left">3.2</td>
            <td align="left">5.6</td>
            <td align="left">5.5</td>
          </tr>
          <tr>
            <td/>
            <td colspan="10">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">EC</td>
            <td align="left">Time(s)</td>
            <td align="left">266</td>
            <td align="left">223</td>
            <td align="left">251</td>
            <td align="left">306</td>
            <td align="left">94</td>
            <td align="left">85</td>
            <td align="left">85</td>
            <td align="left">99</td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td colspan="9">
              <hr/>
            </td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td align="left">MBPS</td>
            <td align="left">2.8</td>
            <td align="left">3.4</td>
            <td align="left">3.0</td>
            <td align="left">2.4</td>
            <td align="left">8.0</td>
            <td align="left">8.8</td>
            <td align="left">8.8</td>
            <td align="left">7.6</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <fig id="F7" position="float">
      <label>Figure 7</label>
      <caption>
        <p><bold>Execution time comparison between DecGPU and CUDA-EC</bold>.</p>
      </caption>
      <graphic xlink:href="1471-2105-12-85-7"/>
    </fig>
    <p>As mentioned above, DecGPU achieves memory efficiency through the use of a counting Bloom filter. From Equation 1, the FPP of a counting Bloom filter depends on the values <italic>h </italic>and <italic>α</italic>. DecGPU uses eight hash functions (i.e. <italic>h </italic>= 8) and has a maximal <italic>N</italic><sub><italic>B </italic></sub>of 2<sup>32</sup>. Thus, for specific values of <italic>α </italic>and FPP, we can calculate the maximal value of <italic>N</italic><sub><italic>E</italic></sub>. Table <xref ref-type="table" rid="T9">9</xref> shows the FPP and the maximal <italic>N</italic><sub><italic>E </italic></sub>for a counting Bloom filter for some representative values of <italic>α</italic>. In the following, we will discuss how to estimate the maximal size of a short read dataset that can be processed with a fixed FPP by <italic>N</italic><sub><italic>PE </italic></sub>MPI processes (i.e. we are using <italic>N</italic><sub><italic>PE </italic></sub>counting Bloom filters on <italic>N</italic><sub><italic>PE </italic></sub>compute nodes). Following [<xref ref-type="bibr" rid="B11">11</xref>], the expected number of times a unique <italic>k</italic>-mer in a genome is observed in a short read dataset with coverage <italic>C </italic>and read length <italic>L </italic>can be estimated as<disp-formula id="bmcM8"><label>(8)</label><graphic xlink:href="1471-2105-12-85-i8.gif"/></disp-formula></p>
    <table-wrap id="T9" position="float">
      <label>Table 9</label>
      <caption>
        <p>FPP and maximal <italic>N</italic><sub><italic>E </italic></sub>for representative <italic>α </italic>value</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">
              <italic>α</italic>
            </th>
            <th align="left">FPP</th>
            <th align="left">
              <bold>Maximal <italic>N</italic></bold>
              <sub>
                <bold>
                  <italic>E</italic>
                </bold>
              </sub>
            </th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">1</td>
            <td align="left">2.5 × 10<sup>-2</sup></td>
            <td align="left">536870912</td>
          </tr>
          <tr>
            <td colspan="3">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">0.5</td>
            <td align="left">5.7 × 10<sup>-4</sup></td>
            <td align="left">268435456</td>
          </tr>
          <tr>
            <td colspan="3">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">0.25</td>
            <td align="left">5.7 × 10<sup>-6</sup></td>
            <td align="left">134217728</td>
          </tr>
          <tr>
            <td colspan="3">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="left">0.125</td>
            <td align="left">3.6 × 10<sup>-8</sup></td>
            <td align="left">67108864</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>Thus, the number of reads <italic>N</italic><sub><italic>R </italic></sub>in the dataset, which can be processed with a fixed FPP by <italic>N</italic><sub><italic>PE </italic></sub>MPI processes, can be estimated as<disp-formula id="bmcM9"><label>(9)</label><graphic xlink:href="1471-2105-12-85-i9.gif"/></disp-formula></p>
    <p>From Equation 9, we can see that <italic>N</italic><sub><italic>R </italic></sub>is directly proportional to <italic>N</italic><sub><italic>PE</italic></sub>; i.e. the maximal number of reads scales linearly with the number of compute nodes. Next, we use an example to illustrate how the memory consumption of our algorithm scales with the number of reads. For an example dataset with <italic>C </italic>= 75 and <italic>L </italic>= 36, when <italic>N</italic><sub><italic>PE </italic></sub>= 8, the maximal <italic>N</italic><sub><italic>R </italic></sub>is estimated as 2.24 billion (80.5 billion bases) for <italic>α </italic>= 0.25 and as 4.47 billion (161.1 billion bases) for <italic>α </italic>= 0.5. Because each bucket takes 4 bits and the maximal <italic>N</italic><sub><italic>B </italic></sub>is 2<sup>32</sup>, the peak memory consumption of a counting Bloom filter is 2 GB. Hence, the maximal total memory consumption is only 2 GB × <italic>N</italic><sub><italic>PE </italic></sub>= 16 GB for such large a dataset. DecGPU uses <italic>α </italic>= 0.25 by default.</p>
    <p>The above observations and discussions demonstrate that DecGPU has superior capabilities in both error correction quality and execution speed compared to existing error correction algorithms. Even though our algorithm does not show good parallel scalability with respect to different number of computing resources, the distributed feature of our algorithm does provide a feasible and flexible solution to the error correction of large-scale HTSR datasets.</p>
  </sec>
  <sec>
    <title>Conclusions</title>
    <p>In this paper, we have presented DecGPU, the first parallel and distributed error correction algorithm for large-scale HTSR using a hybrid combination of CUDA and MPI parallel programming models. Our algorithm is designed based on the SAP approach and uses a counting Bloom filter data structure to gain space efficiency. DecGPU provides two versions: a CPU-based version and a GPU-based version. The CPU-based version employs coarse-grained and fine-grained parallelism using MPI and OpenMP parallel programming models. The GPU-based version takes advantage of the CUDA and MPI programming models, and employs a hybrid CPU+GPU computing model to maximize the performance by overlapping the CPU and GPU computation. Compared to hSHREC, our algorithm shows superior error correction quality for both simulated and real datasets. On a workstation with two quad-core CPUs, our CPU-based version runs up to 22× faster than hSHREC. On a single GPU, the GPU-based version runs up to 2.8× faster than CUDA-EC. Furthermore, the resultant D-Velvet and D-ABySS assemblers demonstrate that our algorithm has the potential to improve <italic>de novo </italic>assembly quality, through prior-assembly error correction, for <italic>de</italic>-<italic>Bruijn</italic>-graph-based assemblers. Although our algorithm does not show good parallel runtime scalability with respect to the number of computing resources, the distributed characteristic of DecGPU provides a feasible and flexible solution to solve the memory scalability problem for error correction of large-scale datasets.</p>
  </sec>
  <sec>
    <title>Availability and requirements</title>
    <p>• <bold>Project name</bold>: DecGPU</p>
    <p>• <bold>Project home page</bold>: <ext-link ext-link-type="uri" xlink:href="http://decgpu.sourceforge.net">http://decgpu.sourceforge.net</ext-link></p>
    <p>• <bold>Operating system</bold>: 64-bit Linux</p>
    <p>• <bold>Programming language</bold>: C++, CUDA, and MPI 2.0</p>
    <p>• <bold>Other requirements</bold>: CUDA SDK and Toolkits 2.0 or higher</p>
    <p>• <bold>Licence</bold>: GNU General Public License (GPL) version 3</p>
  </sec>
  <sec>
    <title>List of abbreviations</title>
    <p>CPU: Central Processing Unit; CUDA: Compute Unified Device Architecture; FPP: False Positive Probability; GPU: Graphics Processing Units; HTSR: High-Throughput Short Reads; MBPS: Million Bases Processed per Second; MPI: Message Passing Interface; NGS: Next-Generation Sequencing; OpenMP: Open Multi-Processing; OS: Operating System; PBSM: Per-Block Shared Memory; SAP: Spectral Alignment Problem; SIMT: Single Instruction, Multiple Thread; SM: Streaming Multiprocessor; SP: Scalable Processor; PE: Processing Element.</p>
  </sec>
  <sec>
    <title>Authors' contributions</title>
    <p>YL conceptualized the study, carried out the design and implementation of the algorithm, performed benchmark tests, analyzed the results and drafted the manuscript; BS conceptualized the study, participated in the algorithm optimization and analysis of the results and contributed to the revising of the manuscript; DLM conceptualized the study, participated in the analysis of the results, and contributed to the revising of the manuscript. All authors read and approved the final manuscript.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="S1">
      <caption>
        <title>Additional file 1</title>
        <p><bold>Assembled sequences of different assemblers</bold>. This file contains the assembled sequences (<italic>contigs </italic>or <italic>scaffolds</italic>) for the assemblers Velvet, ABySS, DecGPU-Velvet and DecGPU-ABySS for the three real datasets.</p>
      </caption>
      <media xlink:href="1471-2105-12-85-S1.ZIP">
        <caption>
          <p>Click here for file</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Acknowledgements</title>
    <p>The authors thank Dr. Shi Haixiang for his helpful discussion in short read error correction problem, thank Dr. Zheng Zejun for his help in searching for short read datasets, and thank Dr. Liu Weiguo for his help in providing the experimental environments.</p>
  </sec>
  <ref-list>
    <ref id="B1">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Havlak</surname>
          <given-names>P</given-names>
        </name>
        <name>
          <surname>Chen</surname>
          <given-names>R</given-names>
        </name>
        <name>
          <surname>Durbin</surname>
          <given-names>KJ</given-names>
        </name>
        <name>
          <surname>Egan</surname>
          <given-names>A</given-names>
        </name>
        <name>
          <surname>Ren</surname>
          <given-names>Y</given-names>
        </name>
        <name>
          <surname>Song</surname>
          <given-names>XZ</given-names>
        </name>
        <name>
          <surname>Weinstock</surname>
          <given-names>GM</given-names>
        </name>
        <name>
          <surname>Gibbs</surname>
          <given-names>RA</given-names>
        </name>
        <article-title>The Atlas genome assembly system</article-title>
        <source>Genome Res</source>
        <year>2004</year>
        <volume>14</volume>
        <issue>4</issue>
        <fpage>721</fpage>
        <lpage>732</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.2264004</pub-id>
        <?supplied-pmid 15060016?>
        <pub-id pub-id-type="pmid">15060016</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Batzoglou</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Jaffe</surname>
          <given-names>DB</given-names>
        </name>
        <name>
          <surname>Stanley</surname>
          <given-names>K</given-names>
        </name>
        <name>
          <surname>Butler</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Gnerre</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Mauceli</surname>
          <given-names>E</given-names>
        </name>
        <name>
          <surname>Berger</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Mesirov</surname>
          <given-names>JP</given-names>
        </name>
        <name>
          <surname>Lander</surname>
          <given-names>ES</given-names>
        </name>
        <article-title>ARACHNE: a whole-genome shotgun assembler</article-title>
        <source>Genome Res</source>
        <year>2002</year>
        <volume>12</volume>
        <issue>1</issue>
        <fpage>177</fpage>
        <lpage>189</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.208902</pub-id>
        <?supplied-pmid 11779843?>
        <pub-id pub-id-type="pmid">11779843</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Myers</surname>
          <given-names>EW</given-names>
        </name>
        <name>
          <surname>Sutton</surname>
          <given-names>GG</given-names>
        </name>
        <name>
          <surname>Delcher</surname>
          <given-names>AL</given-names>
        </name>
        <name>
          <surname>Dew</surname>
          <given-names>IM</given-names>
        </name>
        <name>
          <surname>Fasulo</surname>
          <given-names>DP</given-names>
        </name>
        <name>
          <surname>Flanigan</surname>
          <given-names>MJ</given-names>
        </name>
        <name>
          <surname>Kravitz</surname>
          <given-names>SA</given-names>
        </name>
        <name>
          <surname>Mobarry</surname>
          <given-names>CM</given-names>
        </name>
        <name>
          <surname>Reinert</surname>
          <given-names>KH</given-names>
        </name>
        <name>
          <surname>Remington</surname>
          <given-names>KA</given-names>
        </name>
        <name>
          <surname>Anson</surname>
          <given-names>EL</given-names>
        </name>
        <name>
          <surname>Bolanos</surname>
          <given-names>RA</given-names>
        </name>
        <name>
          <surname>Chou</surname>
          <given-names>HH</given-names>
        </name>
        <name>
          <surname>Jordan</surname>
          <given-names>CM</given-names>
        </name>
        <name>
          <surname>Halpern</surname>
          <given-names>AL</given-names>
        </name>
        <name>
          <surname>Lonardi</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Beasley</surname>
          <given-names>EM</given-names>
        </name>
        <name>
          <surname>Brandon</surname>
          <given-names>RC</given-names>
        </name>
        <name>
          <surname>Chen</surname>
          <given-names>L</given-names>
        </name>
        <name>
          <surname>Dunn</surname>
          <given-names>PJ</given-names>
        </name>
        <name>
          <surname>Lai</surname>
          <given-names>Z</given-names>
        </name>
        <name>
          <surname>Liang</surname>
          <given-names>Y</given-names>
        </name>
        <name>
          <surname>Nusskern</surname>
          <given-names>DR</given-names>
        </name>
        <name>
          <surname>Zhan</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Zhang</surname>
          <given-names>Q</given-names>
        </name>
        <name>
          <surname>Zheng</surname>
          <given-names>X</given-names>
        </name>
        <name>
          <surname>Rubin</surname>
          <given-names>GM</given-names>
        </name>
        <name>
          <surname>Adams</surname>
          <given-names>MD</given-names>
        </name>
        <name>
          <surname>Venter</surname>
          <given-names>JC</given-names>
        </name>
        <article-title>A whole-genome assembly of Drosophila</article-title>
        <source>Science</source>
        <year>2000</year>
        <volume>287</volume>
        <issue>5461</issue>
        <fpage>2196</fpage>
        <lpage>2204</lpage>
        <pub-id pub-id-type="doi">10.1126/science.287.5461.2196</pub-id>
        <?supplied-pmid 10731133?>
        <pub-id pub-id-type="pmid">10731133</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Huang</surname>
          <given-names>X</given-names>
        </name>
        <name>
          <surname>Wang</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Aluru</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Yang</surname>
          <given-names>SP</given-names>
        </name>
        <name>
          <surname>Hillier</surname>
          <given-names>L</given-names>
        </name>
        <article-title>PCAP: a whole-genome assembly program</article-title>
        <source>Genome Res</source>
        <year>2003</year>
        <volume>13</volume>
        <issue>9</issue>
        <fpage>2164</fpage>
        <lpage>2170</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.1390403</pub-id>
        <?supplied-pmid 12952883?>
        <pub-id pub-id-type="pmid">12952883</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Warren</surname>
          <given-names>RL</given-names>
        </name>
        <name>
          <surname>Sutton</surname>
          <given-names>GG</given-names>
        </name>
        <name>
          <surname>Jones</surname>
          <given-names>SJ</given-names>
        </name>
        <name>
          <surname>Holt</surname>
          <given-names>RA</given-names>
        </name>
        <article-title>Assembling millions of short DNA sequences using SSAKE</article-title>
        <source>Bioinformatics</source>
        <year>2007</year>
        <volume>23</volume>
        <issue>4</issue>
        <fpage>500</fpage>
        <lpage>501</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btl629</pub-id>
        <?supplied-pmid 17158514?>
        <pub-id pub-id-type="pmid">17158514</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Dohm</surname>
          <given-names>JC</given-names>
        </name>
        <name>
          <surname>Lottaz</surname>
          <given-names>C</given-names>
        </name>
        <name>
          <surname>Borodina</surname>
          <given-names>T</given-names>
        </name>
        <name>
          <surname>Himmelbauer</surname>
          <given-names>H</given-names>
        </name>
        <article-title>SHARCGS, a fast and highly accurate short-read assembly algorithm for de novo genomic sequencing</article-title>
        <source>Genome Res</source>
        <year>2007</year>
        <volume>17</volume>
        <issue>11</issue>
        <fpage>1697</fpage>
        <lpage>1706</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.6435207</pub-id>
        <?supplied-pmid 17908823?>
        <pub-id pub-id-type="pmid">17908823</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Jeck</surname>
          <given-names>WR</given-names>
        </name>
        <name>
          <surname>Reinhardt</surname>
          <given-names>JA</given-names>
        </name>
        <name>
          <surname>Baltrus</surname>
          <given-names>DA</given-names>
        </name>
        <name>
          <surname>Hickenbotham</surname>
          <given-names>MT</given-names>
        </name>
        <name>
          <surname>Magrini</surname>
          <given-names>V</given-names>
        </name>
        <name>
          <surname>Mardis</surname>
          <given-names>ER</given-names>
        </name>
        <name>
          <surname>Dangl</surname>
          <given-names>JL</given-names>
        </name>
        <name>
          <surname>Jones</surname>
          <given-names>CD</given-names>
        </name>
        <article-title>Extending assembly of short DNA sequences to handle error</article-title>
        <source>Bioinformatics</source>
        <year>2007</year>
        <volume>23</volume>
        <issue>21</issue>
        <fpage>2942</fpage>
        <lpage>2944</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btm451</pub-id>
        <?supplied-pmid 17893086?>
        <pub-id pub-id-type="pmid">17893086</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Schmidt</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Sinha</surname>
          <given-names>R</given-names>
        </name>
        <name>
          <surname>Beresford-Smith</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Puglisi</surname>
          <given-names>SJ</given-names>
        </name>
        <article-title>A fast hybrid short read fragment assembly algorithm</article-title>
        <source>Bioinformatics</source>
        <year>2009</year>
        <volume>25</volume>
        <issue>17</issue>
        <fpage>2279</fpage>
        <lpage>2280</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btp374</pub-id>
        <?supplied-pmid 19535537?>
        <pub-id pub-id-type="pmid">19535537</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Pevzner</surname>
          <given-names>PA</given-names>
        </name>
        <name>
          <surname>Tang</surname>
          <given-names>H</given-names>
        </name>
        <name>
          <surname>Waterman</surname>
          <given-names>MS</given-names>
        </name>
        <article-title>An Eulerian path approach to DNA fragment assembly</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2001</year>
        <volume>98</volume>
        <issue>17</issue>
        <fpage>9748</fpage>
        <lpage>9753</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.171285098</pub-id>
        <?supplied-pmid 11504945?>
        <pub-id pub-id-type="pmid">11504945</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Chaisson</surname>
          <given-names>MJ</given-names>
        </name>
        <name>
          <surname>Pevzner</surname>
          <given-names>PA</given-names>
        </name>
        <article-title>Short read fragment assembly of bacterial genomes</article-title>
        <source>Genome Res</source>
        <year>2008</year>
        <volume>18</volume>
        <issue>2</issue>
        <fpage>324</fpage>
        <lpage>330</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.7088808</pub-id>
        <?supplied-pmid 18083777?>
        <pub-id pub-id-type="pmid">18083777</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Zerbino</surname>
          <given-names>DR</given-names>
        </name>
        <name>
          <surname>Birney</surname>
          <given-names>E</given-names>
        </name>
        <article-title>Velvet: algorithms for de novo short read assembly using de Bruijn graphs</article-title>
        <source>Genome Res</source>
        <year>2008</year>
        <volume>18</volume>
        <issue>5</issue>
        <fpage>821</fpage>
        <lpage>829</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.074492.107</pub-id>
        <?supplied-pmid 18349386?>
        <pub-id pub-id-type="pmid">18349386</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Butler</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>MacCallum</surname>
          <given-names>I</given-names>
        </name>
        <name>
          <surname>Kleber</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Shlyakhter</surname>
          <given-names>IA</given-names>
        </name>
        <name>
          <surname>Belmonte</surname>
          <given-names>MK</given-names>
        </name>
        <name>
          <surname>Lander</surname>
          <given-names>ES</given-names>
        </name>
        <name>
          <surname>Nusbaum</surname>
          <given-names>C</given-names>
        </name>
        <name>
          <surname>Jaffe</surname>
          <given-names>DB</given-names>
        </name>
        <article-title>ALLPATHS: de novo assembly of whole-genome shotgun microreads</article-title>
        <source>Genome Res</source>
        <year>2008</year>
        <volume>18</volume>
        <issue>5</issue>
        <fpage>810</fpage>
        <lpage>820</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.7337908</pub-id>
        <?supplied-pmid 18340039?>
        <pub-id pub-id-type="pmid">18340039</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Simpson</surname>
          <given-names>JT</given-names>
        </name>
        <name>
          <surname>Wong</surname>
          <given-names>K</given-names>
        </name>
        <name>
          <surname>Jackman</surname>
          <given-names>SD</given-names>
        </name>
        <name>
          <surname>Schein</surname>
          <given-names>JE</given-names>
        </name>
        <name>
          <surname>Jones</surname>
          <given-names>SJ</given-names>
        </name>
        <name>
          <surname>Birol</surname>
          <given-names>I</given-names>
        </name>
        <article-title>ABySS: a parallel assembler for short read sequence data</article-title>
        <source>Genome Res</source>
        <year>2009</year>
        <volume>19</volume>
        <issue>6</issue>
        <fpage>1117</fpage>
        <lpage>1123</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.089532.108</pub-id>
        <?supplied-pmid 19251739?>
        <pub-id pub-id-type="pmid">19251739</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Li</surname>
          <given-names>R</given-names>
        </name>
        <name>
          <surname>Zhu</surname>
          <given-names>H</given-names>
        </name>
        <name>
          <surname>Ruan</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Qian</surname>
          <given-names>W</given-names>
        </name>
        <name>
          <surname>Fang</surname>
          <given-names>X</given-names>
        </name>
        <name>
          <surname>Shi</surname>
          <given-names>Z</given-names>
        </name>
        <name>
          <surname>Li</surname>
          <given-names>Y</given-names>
        </name>
        <name>
          <surname>Li</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Shan</surname>
          <given-names>G</given-names>
        </name>
        <name>
          <surname>Kristiansen</surname>
          <given-names>K</given-names>
        </name>
        <name>
          <surname>Li</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Yang</surname>
          <given-names>H</given-names>
        </name>
        <name>
          <surname>Wang</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Wang</surname>
          <given-names>J</given-names>
        </name>
        <article-title>De novo assembly of human genomes with massively parallel short read sequencing</article-title>
        <source>Genome Res</source>
        <year>2010</year>
        <volume>20</volume>
        <issue>2</issue>
        <fpage>265</fpage>
        <lpage>272</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.097261.109</pub-id>
        <?supplied-pmid 20019144?>
        <pub-id pub-id-type="pmid">20019144</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Salmela</surname>
          <given-names>L</given-names>
        </name>
        <article-title>Correction of sequencing errors in a maxed set of reads</article-title>
        <source>Bioinformatics</source>
        <year>2010</year>
        <volume>26</volume>
        <issue>10</issue>
        <fpage>1284</fpage>
        <lpage>1290</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btq151</pub-id>
        <?supplied-pmid 20378555?>
        <pub-id pub-id-type="pmid">20378555</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Schröder</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Schröder</surname>
          <given-names>H</given-names>
        </name>
        <name>
          <surname>Puglisi</surname>
          <given-names>SJ</given-names>
        </name>
        <name>
          <surname>Sinha</surname>
          <given-names>R</given-names>
        </name>
        <name>
          <surname>Schmidt</surname>
          <given-names>B</given-names>
        </name>
        <article-title>SHREC: a short read error correction method</article-title>
        <source>Bioinformatics</source>
        <year>2009</year>
        <volume>25</volume>
        <issue>17</issue>
        <fpage>2157</fpage>
        <lpage>2163</lpage>
        <?supplied-pmid 19542152?>
        <pub-id pub-id-type="pmid">19542152</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Liu</surname>
          <given-names>Y</given-names>
        </name>
        <name>
          <surname>Maskell</surname>
          <given-names>DL</given-names>
        </name>
        <name>
          <surname>Schmidt</surname>
          <given-names>B</given-names>
        </name>
        <article-title>CUDASW++: optimizing Smith-Waterman sequence database searches for CUDA-enabled graphics processing units</article-title>
        <source>BMC Research Notes</source>
        <year>2009</year>
        <volume>2</volume>
        <fpage>73</fpage>
        <pub-id pub-id-type="doi">10.1186/1756-0500-2-73</pub-id>
        <?supplied-pmid 19416548?>
        <pub-id pub-id-type="pmid">19416548</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Liu</surname>
          <given-names>Y</given-names>
        </name>
        <name>
          <surname>Schmidt</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Maskell</surname>
          <given-names>DL</given-names>
        </name>
        <article-title>CUDASW++ 2.0: enhanced Smith-Waterman protein database search on CUDA-enabled GPUs based on SIMT and virtualized SIMD abstractions</article-title>
        <source>BMC Research Notes</source>
        <year>2010</year>
        <volume>3</volume>
        <fpage>93</fpage>
        <pub-id pub-id-type="doi">10.1186/1756-0500-3-93</pub-id>
        <?supplied-pmid 20370891?>
        <pub-id pub-id-type="pmid">20370891</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="other">
        <name>
          <surname>Liu</surname>
          <given-names>Y</given-names>
        </name>
        <name>
          <surname>Schmidt</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Maskell</surname>
          <given-names>DL</given-names>
        </name>
        <article-title>MSA-CUDA: multiple sequence alignment on graphics processing units with CUDA</article-title>
        <source>20th IEEE International Conference on Application-specific Systems, Architectures and Processors</source>
        <year>2009</year>
        <fpage>121</fpage>
        <lpage>128</lpage>
      </mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Liu</surname>
          <given-names>Y</given-names>
        </name>
        <name>
          <surname>Schmidt</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Liu</surname>
          <given-names>W</given-names>
        </name>
        <name>
          <surname>Maskell</surname>
          <given-names>DL</given-names>
        </name>
        <article-title>CUDA-MEME: accelerating motif discovery in biological sequences using CUDA-enabled graphics processing units</article-title>
        <source>Pattern Recognition Letters</source>
        <year>2010</year>
        <volume>31</volume>
        <issue>14</issue>
        <fpage>2170</fpage>
        <lpage>2177</lpage>
        <pub-id pub-id-type="doi">10.1016/j.patrec.2009.10.009</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Shi</surname>
          <given-names>H</given-names>
        </name>
        <name>
          <surname>Schmidt</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Liu</surname>
          <given-names>W</given-names>
        </name>
        <name>
          <surname>Müller-Wittig</surname>
          <given-names>W</given-names>
        </name>
        <article-title>A parallel algorithm for error correction in high-throughput short-read data on CUDA-enabled graphics hardware</article-title>
        <source>J Comput Biol</source>
        <year>2010</year>
        <volume>17</volume>
        <issue>4</issue>
        <fpage>603</fpage>
        <lpage>615</lpage>
        <pub-id pub-id-type="doi">10.1089/cmb.2009.0062</pub-id>
        <?supplied-pmid 20426693?>
        <pub-id pub-id-type="pmid">20426693</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Bloom</surname>
          <given-names>BH</given-names>
        </name>
        <article-title>Space/time trade-offs in hash coding with allowable errors</article-title>
        <source>Commu ACM</source>
        <year>1970</year>
        <volume>13</volume>
        <fpage>422</fpage>
        <lpage>426</lpage>
        <pub-id pub-id-type="doi">10.1145/362686.362692</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Shi</surname>
          <given-names>H</given-names>
        </name>
        <name>
          <surname>Schmidt</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Liu</surname>
          <given-names>W</given-names>
        </name>
        <name>
          <surname>Müller-Wittig</surname>
          <given-names>W</given-names>
        </name>
        <article-title>Quality-score guided error correction for short-read sequencing data using CUDA</article-title>
        <source>Procedia Computer Science</source>
        <year>2010</year>
        <volume>1</volume>
        <issue>1</issue>
        <fpage>1123</fpage>
        <lpage>1132</lpage>
      </mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="other">
        <article-title>Message Passing Interface (MPI) tutorial</article-title>
        <uri>https://computing.llnl.gov/tutorials/mpi</uri>
      </mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="other">
        <article-title>OpenMP tutorial</article-title>
        <uri>https://computing.llnl.gov/tutorials/openMP</uri>
      </mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Fan</surname>
          <given-names>L</given-names>
        </name>
        <name>
          <surname>Cao</surname>
          <given-names>P</given-names>
        </name>
        <name>
          <surname>Almeida</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Broder</surname>
          <given-names>AZ</given-names>
        </name>
        <article-title>Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol</article-title>
        <source>IEEE/ACM Transaction on Network</source>
        <year>2000</year>
        <volume>8</volume>
        <fpage>3</fpage>
        <pub-id pub-id-type="doi">10.1109/TNET.2000.893877</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Nickolls</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Buck</surname>
          <given-names>I</given-names>
        </name>
        <name>
          <surname>Garland</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Skadron</surname>
          <given-names>K</given-names>
        </name>
        <article-title>Scalable parallel programming with CUDA</article-title>
        <source>ACM Queue</source>
        <year>2008</year>
        <volume>6</volume>
        <issue>2</issue>
        <fpage>40</fpage>
        <lpage>53</lpage>
        <pub-id pub-id-type="doi">10.1145/1365490.1365500</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Lindholm</surname>
          <given-names>E</given-names>
        </name>
        <name>
          <surname>Nickolls</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Oberman</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Montrym</surname>
          <given-names>J</given-names>
        </name>
        <article-title>NVIDIA Tesla: A unified graphics and computing architecture</article-title>
        <source>IEEE Micro</source>
        <year>2008</year>
        <volume>28</volume>
        <issue>2</issue>
        <fpage>39</fpage>
        <lpage>55</lpage>
        <pub-id pub-id-type="doi">10.1109/MM.2008.31</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="other">
        <collab>NVIDIA</collab>
        <article-title>Fermi: NVIDIA's Next Generation CUDA Compute Architecture</article-title>
        <uri>http://www.nvidia.com/content/PDF/fermi_white_papers/NVIDIA_Fermi_Compute_Architecture_Whitepaper.pdf</uri>
      </mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="other">
        <article-title>NCBI homepage</article-title>
        <uri>http://www.ncbi.nlm.nih.gov</uri>
      </mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="other">
        <article-title>MVAPICH2 homepage</article-title>
        <uri>http://mvapich.cse.ohio-state.edu/overview/mvapich2</uri>
      </mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Langmead</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Tranell</surname>
          <given-names>C</given-names>
        </name>
        <name>
          <surname>Pop</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Salzberg</surname>
          <given-names>SL</given-names>
        </name>
        <article-title>Ultrafast and memory-efficient alignment of short DNA sequences to the human genome</article-title>
        <source>Genome Biology</source>
        <year>2009</year>
        <volume>10</volume>
        <fpage>R25</fpage>
        <pub-id pub-id-type="doi">10.1186/gb-2009-10-3-r25</pub-id>
        <?supplied-pmid 19261174?>
        <pub-id pub-id-type="pmid">19261174</pub-id>
      </mixed-citation>
    </ref>
  </ref-list>
</back>
