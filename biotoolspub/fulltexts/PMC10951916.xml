<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Biol Imaging</journal-id>
    <journal-id journal-id-type="iso-abbrev">Biol Imaging</journal-id>
    <journal-id journal-id-type="publisher-id">BLG</journal-id>
    <journal-title-group>
      <journal-title>Biological Imaging</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2633-903X</issn>
    <publisher>
      <publisher-name>Cambridge University Press</publisher-name>
      <publisher-loc>Cambridge, UK</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10951916</article-id>
    <article-id pub-id-type="doi">10.1017/S2633903X23000235</article-id>
    <article-id pub-id-type="publisher-id">S2633903X23000235</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software Report</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title><italic toggle="yes">VistoSeg</italic>: Processing utilities for high-resolution images for spatially resolved transcriptomics data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Tippani</surname>
          <given-names>Madhavi</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Divecha</surname>
          <given-names>Heena R.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Catallini</surname>
          <given-names>Joseph L.</given-names>
          <suffix>II</suffix>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kwon</surname>
          <given-names>Sang H.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Weber</surname>
          <given-names>Lukas M.</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Spangler</surname>
          <given-names>Abby</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jaffe</surname>
          <given-names>Andrew E.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hyde</surname>
          <given-names>Thomas M.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="aff5" ref-type="aff">
          <sup>5</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kleinman</surname>
          <given-names>Joel E.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-7858-0231</contrib-id>
        <name>
          <surname>Hicks</surname>
          <given-names>Stephanie C.</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Martinowich</surname>
          <given-names>Keri</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="aff6" ref-type="aff">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Collado-Torres</surname>
          <given-names>Leonardo</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Page</surname>
          <given-names>Stephanie C.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-0031-8468</contrib-id>
        <name>
          <surname>Maynard</surname>
          <given-names>Kristen R.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><label>1</label>Lieber Institute for Brain Development, <institution>Johns Hopkins Medical Campus</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <aff id="aff2"><label>2</label>Department of Biostatistics, <institution>Johns Hopkins Bloomberg School of Public Health</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <aff id="aff3"><label>3</label>Department of Neuroscience, <institution>Johns Hopkins University School of Medicine</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <aff id="aff4"><label>4</label>Department of Psychiatry and Behavioral Sciences, <institution>Johns Hopkins University School of Medicine</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <aff id="aff5"><label>5</label>Department of Neurology, <institution>Johns Hopkins School of Medicine</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <aff id="aff6"><label>6</label>The Kavli Neuroscience Discovery Institute, <institution>Johns Hopkins University</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <author-notes>
      <corresp id="cor1"><bold>Corresponding authors:</bold> Madhavi Tippani, Stephanie C. Page, and Kristen R. Maynard; Emails: <email>madhavi.tippani@libd.org</email>; <email>stephanie.page@libd.org</email>; <email>kristen.maynard@libd.org</email></corresp>
    </author-notes>
    <pub-date publication-format="electronic" date-type="collection" iso-8601-date="2023">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>13</day>
      <month>11</month>
      <year>2023</year>
    </pub-date>
    <volume>3</volume>
    <elocation-id>e23</elocation-id>
    <history>
      <date date-type="received">
        <day>25</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>14</day>
        <month>7</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>19</day>
        <month>9</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>The Author(s)</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This is an Open Access article, distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivatives licence (<uri xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0</uri>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided that no alterations are made and the original article is properly cited. The written permission of Cambridge University Press must be obtained prior to any commercial use and/or adaptation of the article.</license-p>
      </license>
    </permissions>
    <self-uri xlink:title="pdf" xlink:href="S2633903X23000235a.pdf"/>
    <abstract>
      <p>Spatially resolved transcriptomics (SRT) is a growing field that links gene expression to anatomical context. SRT approaches that use next-generation sequencing (NGS) combine RNA sequencing with histological or fluorescent imaging to generate spatial maps of gene expression in intact tissue sections. These technologies directly couple gene expression measurements with high-resolution histological or immunofluorescent images that contain rich morphological information about the tissue under study. While broad access to NGS-based spatial transcriptomic technology is now commercially available through the Visium platform from the vendor 10× Genomics, computational tools for extracting image-derived metrics for integration with gene expression data remain limited. We developed <italic toggle="yes">VistoSeg</italic> as a MATLAB pipeline to process, analyze and interactively visualize the high-resolution images generated in the Visium platform. <italic toggle="yes">VistoSeg</italic> outputs can be easily integrated with accompanying transcriptomic data to facilitate downstream analyses in common programing languages including R and Python. <italic toggle="yes">VistoSeg</italic> provides user-friendly tools for integrating image-derived metrics from histological and immunofluorescent images with spatially resolved gene expression data. Integration of this data enhances the ability to understand the transcriptional landscape within tissue architecture. <italic toggle="yes">VistoSeg</italic> is freely available at <uri xlink:href="http://research.libd.org/VistoSeg/">http://research.libd.org/VistoSeg/</uri>.</p>
    </abstract>
    <kwd-group>
      <title>Keywords</title>
      <kwd>hematoxylin and eosin</kwd>
      <kwd>immunofluorescence</kwd>
      <kwd>MATLAB</kwd>
      <kwd>segmentation</kwd>
      <kwd>spatially resolved transcriptomics</kwd>
      <kwd>Visium</kwd>
      <kwd>Visium-Spatial Proteogenomics</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="aw001">
        <funding-source>
          <institution-wrap>
            <institution>Lieber Institute for Brain Development</institution>
            <institution-id institution-id-type="doi">http://dx.doi.org/10.13039/100015503</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group id="aw002">
        <funding-source>
          <institution-wrap>
            <institution>National Institute of Mental Health</institution>
            <institution-id institution-id-type="doi">http://dx.doi.org/10.13039/100000025</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R01MH126393</award-id>
      </award-group>
      <award-group id="aw003">
        <funding-source>
          <institution-wrap>
            <institution>National Institute of Mental Health</institution>
            <institution-id institution-id-type="doi">http://dx.doi.org/10.13039/100000025</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>U01MH122849</award-id>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="4"/>
      <ref-count count="49"/>
      <page-count count="15"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="other" id="sec1">
    <title>Impact Statement</title>
    <p>The advent of spatially resolved transcriptomics (SRT) technologies has facilitated the study of gene expression in an anatomical context. However, next-generation sequencing (NGS)-based SRT approaches pose an emerging challenge: integrating transcriptome-wide spatial gene expression with high-resolution tissue images (brightfield histology or fluorescent antibody staining) to generate precise maps of spatial gene expression across intact tissue sections. We developed <italic toggle="yes">VistoSeg</italic> as an image-processing software to address these needs. <italic toggle="yes">VistoSeg</italic> is currently compatible with the Visium and Visium Spatial Proteogenomics (Visium-SPG) platforms (10× Genomics), which are NGS-based SRT assays employing histological and immunofluorescent tissue images, respectively. <italic toggle="yes">VistoSeg</italic> provides computational imaging-processing tools to extract cell number, cell type identity, and other image-derived metrics at spatially defined locations across the tissue section to incorporate with corresponding gene expression measurements.</p>
  </sec>
  <sec sec-type="intro" id="sec2">
    <label>1.</label>
    <title>Introduction</title>
    <p>In the past decade, RNA sequencing (RNA-seq) moved beyond profiling in homogenate tissue to defining gene expression at single-cell or single-nucleus (sc/snRNA-seq) resolution. This technological development motivated the generation of new computational methods that answered many previously unaddressed biological questions. However, spatial information about where cells resided within the tissue remained lacking. Spatially resolved transcriptomics (SRT) is a new class of technologies that measures gene expression along spatial coordinates.<sup>(</sup><xref rid="r1" ref-type="bibr"><sup>1</sup></xref><sup>)</sup> Next-generation sequencing (NGS)-based SRT technologies are especially powerful for their ability to define transcriptome-wide gene expression patterns across intact tissue sections. While there are several laboratories that have developed custom methods to perform NGS-based SRT,<sup>(</sup><xref rid="r2" ref-type="bibr"><sup>2</sup></xref><sup>–</sup><xref rid="r5" ref-type="bibr"><sup>5</sup></xref><sup>)</sup> the commercially available Visium platform from 10× Genomics is the leading and most widely adopted technology for generating transcriptome-wide spatial gene expression data in intact tissue sections.<sup>(</sup><xref rid="r6" ref-type="bibr"><sup>6</sup></xref><sup>)</sup> Because SRT data includes paired gene expression and microscopy images from the same tissue section, analysis of this data necessitates tools to integrate both modalities.</p>
    <p>The Visium workflow uses an on-slide spatial barcoding strategy to map RNA-seq reads to defined anatomical locations (“spots”) in an intact tissue section (<xref rid="fig1" ref-type="fig">Figure 1a</xref>). Briefly, each slide contains four arrays (<xref rid="fig1" ref-type="fig">Figure 1b</xref>: A1, B1, C1, D1), and each array contains ~5,000 gene expression capture “spots,” which are 55 μm in diameter (2,375 μm<sup>2</sup> in area) and spaced 100 μm center-to-center in a honeycomb pattern (<xref rid="fig1" ref-type="fig">Figure 1b</xref>). On-slide cDNA synthesis incorporates spatial barcodes for each spot, which is followed by RNA-seq to obtain gene expression measurements at each anatomical location (<xref rid="fig1" ref-type="fig">Figure 1c</xref>). The platform currently supports two major workflows: Visium-H&amp;E and Visium-Spatial Proteogenomics (Visium-SPG). In the Visium-H&amp;E workflow, tissue sections are stained with hematoxylin and eosin (H&amp;E), and a brightfield histological image is acquired. In Visium-SPG, tissue sections are labeled with antibodies conjugated to fluorophores, and multiplex fluorescent images are acquired to visualize specific proteins of interest. In both cases, images are used to create an integrated map of transcriptome-wide gene expression within the tissue architecture. In the case of Visium-SPG, transcriptomic data can also be analyzed in the context of proteomic data from antibody labeling.<fig position="float" id="fig1"><label>Figure 1.</label><caption><p>Visium workflow. (a) Visium spatial gene expression slide containing four 6.5 mm x 6.5 mm capture areas bound by a fiducial frame. (b) Each capture area contains a grid printed with ~5,000 spots with unique spatial barcodes that allow mRNA measurements to be mapped back to the X–Y location on the tissue. (c) Spatial barcodes are incorporated during on-slide cDNA synthesis. The cDNA is eluted off the slide, and libraries are prepared and sequenced. Reads are mapped to spatial coordinates on the histological image using SpaceRanger software (10× Genomics), which provides a transcriptome-wide readout of gene expression at each spatial coordinate.</p></caption><graphic xlink:href="S2633903X23000235_fig1" position="float"/></fig></p>
    <p>To maintain RNA integrity for compatibility with downstream transcriptomic workflows, speed and throughput capacity are important considerations for image acquisition protocols. In line with these considerations, imaging is often performed on slide scanners or other high-throughput microscopy systems that are commonly used for pathology image acquisition and analysis. To support integration with downstream molecular gene expression data, preprocessing utilities are needed to separate the large whole-slide images into single images representing each individual tissue section. These images then need to be further segmented to extract meaningful metrics about cell number, morphology, position, etc. Current analytical tools available from 10× Genomics focus heavily on gene expression data and do not support in-depth processing or analysis (e.g., nuclear or cellular segmentation) of imaging data. Specifically, 10× Genomics provides two software programs, Loupe Browser<sup>(</sup><xref rid="r7" ref-type="bibr"><sup>7</sup></xref><sup>)</sup> and SpaceRanger,<sup>(</sup><xref rid="r8" ref-type="bibr"><sup>8</sup></xref><sup>)</sup> which enable data extraction and primary visualization of SRT data, but have limited functionality for more advanced processing.</p>
    <p>Other existing software also fail to provide the necessary functionalities that would allow users to take the images from preprocessing to quantitative integration of gene expression data with extracted metrics. For example, the open source software package QuPath<sup>(</sup><xref rid="r9" ref-type="bibr"><sup>9</sup></xref><sup>)</sup> does not support preprocessing of the multichannel fluorescent images and requires downsampling, resulting in reduced image resolution when opening, cropping and exporting images. The commercially available image analysis software HALO enables quantification and classification of cells and nuclei, but does not support integration with gene expression data. Several software packages have been developed in the Python and R programming languages for cell segmentation and subsequent registration of microscopy images to anatomical reference atlases.<sup>(</sup><xref rid="r10" ref-type="bibr"><sup>10</sup></xref><sup>,</sup><xref rid="r11" ref-type="bibr"><sup>11</sup></xref><sup>)</sup> While some of these frameworks have been applied to SRT data,<sup>(</sup><xref rid="r12" ref-type="bibr"><sup>12</sup></xref><sup>)</sup> they were designed and optimized for cultured cells and mouse brain tissue sections. In contrast, other packages, such as Fiji<sup>(</sup><xref rid="r13" ref-type="bibr"><sup>13</sup></xref><sup>)</sup> and CellProfiler,<sup>(</sup><xref rid="r14" ref-type="bibr"><sup>14</sup></xref><sup>)</sup> lack functions to automatically split large whole-slide images into individual arrays and have limited features for visualizing large images.</p>
    <p>The limited functionality of currently available resources poses a significant problem for the field because the acquired images contain valuable information that could be more fully mined and incorporated into downstream analyses.<sup>(</sup><xref rid="r15" ref-type="bibr"><sup>15</sup></xref><sup>,</sup><xref rid="r16" ref-type="bibr"><sup>16</sup></xref><sup>)</sup> For example, in the Visium-H&amp;E platform, cell/nuclei segmentation in the H&amp;E images can be used to estimate the number of cells in each gene expression spot or to identify cell types based on classic morphologies.<sup>(</sup><xref rid="r16" ref-type="bibr"><sup>16</sup></xref><sup>,</sup><xref rid="r17" ref-type="bibr"><sup>17</sup></xref><sup>)</sup> Analysis of H&amp;E images can also identify spots containing a single cell, or spots enriched in specific cellular compartments (i.e., axon- and dendrite-rich neuropil in brain tissue).<sup>(</sup><xref rid="r18" ref-type="bibr"><sup>18</sup></xref><sup>)</sup> Gene expression clustering algorithms are also beginning to incorporate metrics from imaging data, such as RGB (Red, Green, Blue) color values, to better define anatomically relevant spatial regions across tissue sections.<sup>(</sup><xref rid="r15" ref-type="bibr"><sup>15</sup></xref><sup>)</sup></p>
    <p>Furthermore, Visium-SPG technology is especially powerful as it can be used to label specific cell types. Combining gene expression data with images where known cell types have been fluorescently labeled can generate a ground truth for evaluating <italic toggle="yes">in silico</italic> methods that aim to perform spot deconvolution and identify cell type proportions across spots.<sup>(</sup><xref rid="r19" ref-type="bibr"><sup>19</sup></xref><sup>–</sup><xref rid="r21" ref-type="bibr"><sup>21</sup></xref><sup>)</sup> Using the Visium-SPG platform, images can also be segmented to identify the locations and quantify the abundance of proteins that are associated with known pathologies. This data can then be used to analyze local gene expression in the context of pathology to better understand molecular associations of disease.<sup>(</sup><xref rid="r22" ref-type="bibr"><sup>22</sup></xref><sup>)</sup> Moreover, since RNA expression is not always fully predictive of protein abundance levels, Visium-SPG and its associated fluorescent images can be used to quantify protein abundance. This is especially relevant for proteins where RNA quantification cannot serve as a proxy for expression, such as extracellular matrix proteins or secreted factors.<sup>(</sup><xref rid="r23" ref-type="bibr"><sup>23</sup></xref><sup>)</sup></p>
    <p>To address these challenges and provide an end-to-end solution that is tailored to image-processing analysis for the Visium-H&amp;E and -SPG platforms, we developed <italic toggle="yes">VistoSeg.</italic>
<italic toggle="yes">VistoSeg</italic> is a MATLAB-based software package that facilitates preprocessing, segmentation, analysis and visualization of H&amp;E and immunofluorescent images generated on the Visium-H&amp;E and Visium-SPG platforms for integration with gene expression data. We also provide user-friendly tutorials and vignettes to support the application of <italic toggle="yes">VistoSeg</italic> to new datasets generated by the scientific community.</p>
  </sec>
  <sec sec-type="results" id="sec3">
    <label>2.</label>
    <title>Results</title>
    <p>Here we describe the implementation and requirements for <italic toggle="yes">VistoSeg,</italic> an automated pipeline for processing high-resolution histological or immunofluorescent images acquired using Visium-H&amp;E or Visium-SPG workflows, for integration with downstream spatial transcriptomics analysis.</p>
    <sec sec-type="other" id="sec4">
      <label>2.1.</label>
      <title>H&amp;E image processing</title>
      <p>Prior to image analysis, we collected brain tissue sections from the dorsolateral prefrontal cortex (<xref rid="fig2" ref-type="fig">Figure 2a</xref>) and performed the Visium-H&amp;E workflow.<sup>(</sup><xref rid="r18" ref-type="bibr"><sup>18</sup></xref><sup>)</sup> Tissue sections were stained with H&amp;E, and brightfield histology images were acquired using a Leica Aperio CS2 slide scanner (<xref rid="fig2" ref-type="fig">Figure 2b</xref>). Because the TIFF images acquired on the slide scanner include the whole slide, which contains four arrays (<xref rid="fig2" ref-type="fig">Figure 2c</xref>), the image needs to be split into individual capture area arrays to proceed with downstream analysis. We created a function (<italic toggle="yes">splitslide</italic>) that reads in the TIFF image as an RGB matrix and splits it along the x-axis into four equal RGB matrices. Each individual RGB matrix is considered a capture area and is saved as a separate RGB TIFF file at 70% resolution of the raw individual RGB matrix. For example, a matrix that is of size 10,000 × 10,000 × 3 pixels is resized to 7,000 × 7,000 × 3 pixels. Since MATLAB requires that image files (TIFF, PNG, JPEG) be no larger than 2<sup>32</sup> − 1 bytes, image downsampling is necessary since the raw files would exceed these limitations. Individual resized matrices/images are saved at the downsampled resolution of at least 2,000 pixels in either dimension (X and Y).<fig position="float" id="fig2"><label>Figure 2.</label><caption><p>VistoSeg workflow for Visium H&amp;E image processing. (a) Example data collection from postmortem human dorsolateral prefrontal cortex (DLPFC). Each tissue block and corresponding 10-μm section spans the six cortical layers and white matter. (b) Four tissue sections were placed on a Visium gene expression slide and stained with H&amp;E. Brightfield images were acquired using a Leica Aperio CS2 slide scanner. (c) The CS2 scanner produces a large, high-resolution image of the entire slide in TIFF format, which VistoSeg splits into four individual capture areas using splitslide. (d) VistoSeg uses a two-step process for nuclei segmentation, called VNS and refineVNS, to segment nuclei in each individual capture area. (e) Concurrent with nuclei segmentation, individual capture area images from (d) are processed using SpaceRanger (10× Genomics) to align gene expression data to the histological image and export spot metrics including spot diameter, spot spacing and spot coordinates (titled by default as “tissue_positions_list.csv” and “scalefactors_json.json”). (f) The countNuclei function in VistoSeg computes the number of cells/nuclei per spot using the outputs from SpaceRanger, which is then exported as the “tissue_spot_counts.csv” file. (g) VistoSeg includes an interactive GUI, spotspotcheck, which enables the user to toggle between the segmented binary image and raw histology image to visually inspect the segmented nuclei in each spot. Users can zoom in/out on the high-resolution image. A search tab enables users to locate spots of interest based on the barcode identifier, which enables exploration of image features related to gene expression patterns.</p></caption><graphic xlink:href="S2633903X23000235_fig2" position="float"/></fig></p>
      <p>To align the sequencing files containing gene expression information with specific spatial locations (i.e., spots) on the image, users must employ the SpaceRanger software provided by 10× Genomics.<sup>(</sup><xref rid="r8" ref-type="bibr"><sup>8</sup></xref><sup>)</sup> Using the fiducial frame on the image as reference, SpaceRanger uses the downsized TIFF files produced by the <italic toggle="yes">splitSlide</italic> function<sup>(</sup><xref rid="r24" ref-type="bibr"><sup>24</sup></xref><sup>)</sup> as input to extract the barcode identifier (ID), pixel (X, Y) centroid location, and radius of each spot. SpaceRanger does not extract any information from the image beyond the presence or absence of tissue at a particular location. The output of SpaceRanger is a list of tissue positions (<italic toggle="yes">.csv)</italic> and the scale factors (<italic toggle="yes">.json</italic>) (named as tissue_positions_list.csv and scalefactors_json.json by default) to enable the quantification of gene expression in a spatial context. Further information regarding the workflow and implementation of SpaceRanger<sup>(</sup><xref rid="r8" ref-type="bibr"><sup>8</sup></xref><sup>)</sup> is available on our accompanying website: <uri xlink:href="http://research.libd.org/VistoSeg/step-3-spaceranger.html">http://research.libd.org/VistoSeg/step-3-spaceranger.html</uri>. To facilitate extraction of relevant imaging metrics at the same spatial locations (spots) queried for gene expression, <italic toggle="yes">VistoSeg</italic> uses the output .<italic toggle="yes">csv</italic> and .<italic toggle="yes">json</italic> files from SpaceRanger to build the spot grid on the image and enable the extraction of image-based metrics (e.g., nuclei count, percentage spot covered by nuclei) for each spot location (<xref rid="fig2" ref-type="fig">Figure 2e</xref>). The image-based information and the gene expression-based data are grouped together using the spot barcode identifier, which enables the quantification of gene expression and morphology metrics in a spatial context.</p>
      <p>To segment nuclei from the H&amp;E image (<xref rid="fig3" ref-type="fig">Figure 3a</xref>), we performed Gaussian smoothing and then applied contrast adjustments (<xref rid="fig3" ref-type="fig">Figure 3a</xref>) to enhance nuclei visibility in the image (<xref rid="fig3" ref-type="fig">Figure 3b</xref>). The enhanced image was then converted from RGB color space to CIELAB color space, also called L*a*b color space (<xref rid="fig3" ref-type="fig">Figure 3c</xref>). L*a*b color space is defined by: “L,” luminosity layer measures lightness from black to white; “a,” chromaticity layer measures color along the red–green axis; and “b,” chromaticity layer measures color along blue–yellow axis. CIELAB color space enables the quantification of the individual color gradients that are visually observable across the image. The a*b color space is extracted from the L*a*b-converted image and used as input to <italic toggle="yes">K</italic>-means clustering with the MATLAB function <italic toggle="yes">imsegkmeans</italic> (<xref rid="fig3" ref-type="fig">Figure 3d</xref>), along with the number of color gradients (<italic toggle="yes">k</italic>) that were visually identified in the image. The function output creates a binary mask for each color gradient (<italic toggle="yes">k</italic>) in the image. Given that nuclei in H&amp;E images have a bright color that can be easily differentiated from the background, we used a binary mask generated from the nuclei color gradient for initial nuclei segmentation to identify nuclei as regions of interest (ROIs; <xref rid="fig3" ref-type="fig">Figure 3d</xref>, cluster 3, <xref rid="fig3" ref-type="fig">Figure 3d<bold>’</bold></xref>). We combined these steps (<xref rid="fig3" ref-type="fig">Figure 3a–d’</xref>) into a function termed <italic toggle="yes">VNS</italic> (Visium Nuclei Segmentation).<fig position="float" id="fig3"><label>Figure 3.</label><caption><p>VistoSeg workflow for Visium H&amp;E image segmentation. (a) Raw histology image of human dorsolateral prefrontal cortex. (b) Gaussian smoothed and contrast-adjusted image of the raw histology image in (a). (c) Enhanced image from (b) converted from RGB color space to L*a*b color space. (d) Different color gradients (k = 5) identified by the MATLAB function imsegkmeans applied to the raw histology image. Cluster 3 corresponded to the nuclei, stained blue in the raw histology image. (d’) An inset of nuclei cluster 3 in (d). (e) Output of refineVNS from nuclei cluster 3 (d’). The refineVNS function allows for separation of adjacent nuclei. (f) Final binary nuclei segmentation obtained from (e).</p></caption><graphic xlink:href="S2633903X23000235_fig3" position="float"/></fig></p>
      <p>Due to the smoothing step applied, the nuclei edges are blurred, and hence nuclei in close proximity to one another are segmented as a single ROI (<xref rid="fig3" ref-type="fig">Figure 3d’</xref>). To further refine these segmentations to detect and quantify individual nuclei (<xref rid="fig3" ref-type="fig">Figure 3f</xref>), we created a second function (termed <italic toggle="yes">refineVNS</italic>) that extracts the intensity of the pixels from the binary mask of nuclei generated by <italic toggle="yes">VNS</italic> and applies intensity thresholding<sup>(</sup><xref rid="r25" ref-type="bibr"><sup>25</sup></xref><sup>)</sup> to separate the darker nuclei regions at the center from the lighter regions at the borders (<xref rid="fig3" ref-type="fig">Figure 3e</xref>). The final segmentation output is a binary image. The use of our <italic toggle="yes">VNS</italic> and <italic toggle="yes">refineVNS</italic> function results in segmentation of individual cell bodies in human DLPFC tissue (<xref rid="fig2" ref-type="fig">Figures 2g</xref> and <xref rid="fig3" ref-type="fig">3d–f</xref>).</p>
    </sec>
    <sec sec-type="other" id="sec5">
      <label>2.2.</label>
      <title>Multichannel fluorescent image processing</title>
      <p>In the Visium-SPG platform, samples are subjected to immunofluorescent antibody labeling to detect specific proteins of interest, thereby generating proteomic data that can be quantified and integrated with transcriptomic data. We collected four individual tissue sections of the human dorsolateral prefrontal cortex (DLPFC) spanning the six cortical layers and white matter and performed the Visium-SPG workflow (<xref rid="fig4" ref-type="fig">Figure 4</xref>). To visualize cellular composition and cell type distribution across the tissue section, samples were immunostained with four established cell type markers: NeuN (Alexa 555) for neurons, TMEM119 (Alexa 647) for microglia, GFAP (Alexa 488) for astrocytes, and OLIG2 (Alexa 647) for oligodendrocytes. Immunofluorescent images were acquired using a Vectra Polaris slide scanner (Akoya Biosciences) and processed to decompose the multispectral profiles (<xref rid="fig4" ref-type="fig">Figure 4a</xref>).<sup>(</sup><xref rid="r26" ref-type="bibr"><sup>26</sup></xref><sup>,</sup><xref rid="r27" ref-type="bibr"><sup>27</sup></xref><sup>)</sup> The final image outputs were spectrally unmixed multichannel TIFF tiles of the entire slide (~600 tiles). These individual tiles were stitched to recreate a multichannel TIFF image spanning the whole slide (<xref rid="fig4" ref-type="fig">Figure 4b</xref>) using the X and Y coordinates of each tile, as saved in the filename, to position tiles (<italic toggle="yes">inFormStitch</italic>). Next, this image was split along the Y-axis into four individual capture area images in multichannel TIFF format (<italic toggle="yes">splitSlide_IF</italic>; <xref rid="fig4" ref-type="fig">Figure 4c</xref>). We then segmented each fluorescent channel to identify ROIs (<xref rid="fig4" ref-type="fig">Figure 4d</xref>) as previously described.<sup>(</sup><xref rid="r28" ref-type="bibr"><sup>28</sup></xref><sup>)</sup> Finally, we used the <italic toggle="yes">countNuclei</italic> function to quantify the size, intensity and location of segmented signals in each channel for integration with gene expression data (<xref rid="fig4" ref-type="fig">Figure 4e</xref>). The output table from <italic toggle="yes">countNuclei</italic> has two columns per channel by default: (1) count of segmented ROIs per Visium spot and (2) proportion of the spot covered by the segmented signal. Other user-defined metrics, including mean fluorescent intensity per spot or mean intensity of segmented ROIs for each channel within a spot, can also be extracted. Quantification of immunofluorescent signals in white matter of the dorsolateral prefrontal cortex (<xref rid="fig4" ref-type="fig">Figure 4g</xref>) is consistent with our expectation of higher counts for glial cells stained by TMEM119 (microglia), GFAP (astrocytes) and OLIG2 (oligodendrocytes) compared to the neuron-enriched gray matter (<uri xlink:href="https://doi.org/10.1017/S2633903X23000235">Supplementary Figure 1</uri>).<fig position="float" id="fig4"><label>Figure 4.</label><caption><p>VistoSeg workflow for Visium-SPG immunofluorescent image processing and segmentation. (a) Multispectral immunofluorescent images of the gene expression slide from the Visium-SPG workflow were acquired using a Vectra Polaris slide scanner (Akoya). All arrays on the slide were annotated as a single selection using Phenochart software (Akoya) and split into multiple tiles. Each tile was spectrally unmixed into multichannel TIFFs using inForm software (Akoya) by applying spectral fingerprints specific for each fluorophore. Autofluorescence was separated into its own channel. (b) After unmixing, the tiles from (a) were put into the VistoSeg preprocessing workflow and stitched using the inFormstitch function to recreate a multichannel TIFF of the whole slide. (c) The recreated multichannel TIFF was then split into individual arrays using splitSlide_IF. (d) Representative segmentation for capture area A1. Nuclei segmentation to identify fluorescent signal for the nucleus (DAPI) and each labeled protein (GFAP, NEUN, OLIG2, TMEM119) was performed by integrating functions from our previously published software, dotdotdot.<sup>(</sup><xref rid="r28" ref-type="bibr"><sup>28</sup></xref><sup>)</sup> (e) Using the split images from (c), Space Ranger (10× Genomics) was used to align multiplex fluorescent imaging and gene expression data and obtain extracted spot metrics (Visium spot diameter, spot spacing and spot coordinates) from each image in the “tissue_positions_list.csv” and “scalefactors_json.json” files. (f) The spotspotcheck GUI in VisotSeg provides a dropdown menu for each fluorescent channel in the multichannel TIFF (labeled by the spectral profile assigned to each protein of interest: DAPI, GFAP, NeuN, OLIG2, TMEM119 in this example). It allows for visual inspection by hovering over different regions in the image. For example, we explored the white matter (white square) and gray matter (gray square) in this representative sample. (g) The signal count per gene expression spot computed by countNuclei on the white matter (white square in f) confirms increased abundance of OLIG2, GFAP and TMEM119 staining, and relative depletion of NeuN staining, in line with expectations.</p></caption><graphic xlink:href="S2633903X23000235_fig4" position="float"/></fig></p>
    </sec>
    <sec sec-type="other" id="sec6">
      <label>2.3.</label>
      <title>Integration of segmentation output with gene expression spot location</title>
      <p>We generated an additional function (termed <italic toggle="yes">countNuclei</italic>) to calculate the number of nuclei residing within each spot. This function uses the point-in-polygon concept to calculate the number of nuclei per spot by integrating the coordinate information obtained from SpaceRanger with the segmentation mask to calculate the number of nuclei per spot. The <italic toggle="yes">countNuclei</italic> function accepts segmentation from alternative methods, if saved in a “.mat” format. The output of this function is a table that contains the number of nuclei and the percentage nuclei coverage per gene expression spot, which can be exported as a .<italic toggle="yes">csv</italic> file for each sample to be used in downstream analyses. Two types of nuclei counts are provided per spot, based on the two possible measurement criteria for calling presence/absence of nuclei: (1) inclusion of the centroid of the ROI within the spot, (2) user-defined threshold for the number of pixels necessary to count a cell as within the spot.</p>
      <p>To enable the user to visually inspect nuclei segmentation output, we developed a GUI termed <italic toggle="yes">spotspotcheck.</italic> This GUI reconstructs and overlays the spot grid, generated using the output of SpaceRanger, onto the original image and the binary segmentation, generated using the output of <italic toggle="yes">refineVNS,</italic> to display the nuclei count in each spot. The <italic toggle="yes">spotspotcheck</italic> GUI supports both H&amp;E images (<xref rid="fig2" ref-type="fig">Figure 2g</xref> and <uri xlink:href="https://doi.org/10.1017/S2633903X23000235">Supplementary Figures 2</uri> and <uri xlink:href="https://doi.org/10.1017/S2633903X23000235">3</uri>) and immunofluorescent images (<xref rid="fig4" ref-type="fig">Figure 4f</xref>,<xref rid="fig4" ref-type="fig">g</xref>, <uri xlink:href="https://doi.org/10.1017/S2633903X23000235">Supplementary Figure 1</uri>). Additionally, the GUI provides a dropdown menu (<xref rid="fig4" ref-type="fig">Figure 4f</xref>) to select different channels in the multichannel TIFF image. This allows the user to (1) toggle between the nuclei segmentation and images, (2) search for spots with specific spatial barcode IDs, and (3) zoom in and out to a specific location on the image. The user can visualize the nuclei count information by checking the “Get cell counts” option in the <italic toggle="yes">spotspotcheck</italic> start window. <italic toggle="yes">spotspotcheck</italic> enables users to perform bidirectional visual inspection, meaning that the user can evaluate morphological features in the high-resolution image and verify segmentation accuracy. Alternatively, the user can visually inspect whether gene expression patterns are related to any image features by querying specific spots through their barcode ID.</p>
      <p>Following alignment of gene expression with image-based data, the number of nuclei present in each gene expression spot can be integrated into downstream analysis, such as creating a SpatialExperiment (spe) object,<sup>(</sup><xref rid="r29" ref-type="bibr"><sup>29</sup></xref><sup>)</sup> which incorporates image-based quantifications, along with other variables, into the spot-level information. The nuclei count can then be used to perform quality control procedures and downstream analysis at the spot level. For example, during quality control, spots with an abnormally high nuclei count can be excluded.<sup>(</sup><xref rid="r30" ref-type="bibr"><sup>30</sup></xref><sup>)</sup> Furthermore, the nuclei count along with the spot-level gene expression matrix are required inputs for spot deconvolution methods such as Tangram.<sup>(</sup><xref rid="r20" ref-type="bibr"><sup>20</sup></xref><sup>)</sup></p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="sec7">
    <label>3.</label>
    <title>Discussion</title>
    <p><italic toggle="yes">VistoSeg</italic> leverages the MATLAB Image Processing Toolbox<sup>(</sup><xref rid="r31" ref-type="bibr"><sup>31</sup></xref><sup>)</sup> to provide user-friendly functionality for processing, analysis and interactive visualization of both H&amp;E and fluorescent images generated in conjunction with the Visium platform. A major feature of the <italic toggle="yes">VistoSeg</italic> pipeline is the quantification and localization of detected ROIs in H&amp;E images (Visium-H&amp;E workflow) or each individual fluorescent channel (Visium-SPG workflow). <italic toggle="yes">VistoSeg</italic> extracts multiple user-defined metrics, including number of cells per spot, percentage of a spot occupied by cells or proteins of interest, mean fluorescent intensity in a spot, and mean fluorescent intensity of the segmented regions in the spot to aid in the interpretation and utility of SRT data.</p>
    <p>This quantitative output from <italic toggle="yes">VistoSeg</italic> can be integrated with spatial gene expression data to improve spot-level resolution and add biological insights to downstream analyses. For example, using H&amp;E images of the human dorsolateral prefrontal cortex analyzed with <italic toggle="yes">VistoSeg</italic>, we identified “neuropil” spots lacking cell bodies, which we hypothesized were enriched for neuronal processes. We confirmed this hypothesis by demonstrating that these “neuropil” spots are enriched for genes previously shown to be expressed in synaptic terminals.<sup>(</sup><xref rid="r18" ref-type="bibr"><sup>18</sup></xref><sup>)</sup>
<italic toggle="yes">VistoSeg</italic> can also be used to identify spots that contain only a single cell or specific number of cells to help refine the selection of spots used for downstream gene expression analysis. Additionally, <italic toggle="yes">VistoSeg</italic> can identify spots with disease-associated pathology, allowing for the analysis of gene expression changes associated with pathological alterations in local microenvironments. For example, SRT has been used to identify gene expression changes associated with amyloid beta pathology in Alzheimer’s disease.<sup>(</sup><xref rid="r32" ref-type="bibr"><sup>32</sup></xref><sup>)</sup>
<italic toggle="yes">VistoSeg</italic> opens opportunities to directly incorporate different pathology-associated metrics with transcriptomic changes in diseased tissues.</p>
    <p>Importantly, <italic toggle="yes">VistoSeg</italic> output can be further integrated with other software<sup>(</sup><xref rid="r33" ref-type="bibr"><sup>33</sup></xref><sup>,</sup><xref rid="r34" ref-type="bibr"><sup>34</sup></xref><sup>)</sup> to identify and classify specific cell types based on nuclear or cellular morphology. For example, spatial domains corresponding to specific tumor pathology can vary in cell size, shape and density across tissue sections. Identification of these pathological lesions can provide important insights into the role of spatially restricted gene expression in disease progression.<sup>(</sup><xref rid="r35" ref-type="bibr"><sup>35</sup></xref><sup>,</sup><xref rid="r36" ref-type="bibr"><sup>36</sup></xref><sup>)</sup> We further anticipate that outputs of <italic toggle="yes">VistoSeg</italic> can be used to calculate other tissue parameters, such as cell density, for incorporation into unsupervised clustering approaches to identify data-driven spatial domains more directly related to cytoarchitecture. Given that a single Visium spot contains multiple cells with several cell types, spot deconvolution algorithms are rapidly being developed to predict the proportion of different cell types in each spot.<sup>(</sup><xref rid="r37" ref-type="bibr"><sup>37</sup></xref><sup>,</sup><xref rid="r38" ref-type="bibr"><sup>38</sup></xref><sup>)</sup> Spot deconvolution algorithms generally require Visium gene expression data (with or without cell counts) and single cell/nucleus RNA-seq gene expression data from the same tissue type (<uri xlink:href="https://doi.org/10.1017/S2633903X23000235">Supplementary Figure 4</uri>). Some spot deconvolution software, including Tangram<sup>(</sup><xref rid="r20" ref-type="bibr"><sup>20</sup></xref><sup>)</sup> and Cell2Location,<sup>(</sup><xref rid="r19" ref-type="bibr"><sup>19</sup></xref><sup>)</sup> require the user to input the number of cells per spot, while others do not require this information. However, spot deconvolution results were improved for methods that include cell counts per spot compared to methods that do not use any image-level spot metrics.<sup>(</sup><xref rid="r39" ref-type="bibr"><sup>39</sup></xref><sup>)</sup> Spot deconvolution algorithms have already begun to leverage cell counts from imaging data,<sup>(</sup><xref rid="r15" ref-type="bibr"><sup>15</sup></xref><sup>)</sup> and we anticipate that more quantitative outputs from software such as <italic toggle="yes">VistoSeg</italic> can improve the identification of biologically relevant spatial domains and associated cell type proportions.</p>
    <p>In summary, <italic toggle="yes">VistoSeg</italic> was designed to address an image analysis gap in the most widely used, commercially available SRT-processing pipeline, the Visium Spatial Gene Expression platforms. However, we note some limitations with <italic toggle="yes">Vistoseg</italic>, such as large memory requirements (~75 GB) for loading and saving images. Furthermore, the <italic toggle="yes">VNS</italic> function requires manual user inputs and cannot currently be fully automated. However, we note that similar existing image analysis software, such as HALO,<sup>(</sup><xref rid="r40" ref-type="bibr"><sup>40</sup></xref><sup>)</sup> QuPath<sup>(</sup><xref rid="r9" ref-type="bibr"><sup>9</sup></xref><sup>)</sup> and Squidpy,<sup>(</sup><xref rid="r36" ref-type="bibr"><sup>36</sup></xref><sup>)</sup> also have limitations on processing times and parametrization, and there are currently no available modules to support integration of gene expression data with segmented images. While <italic toggle="yes">Vistoseg</italic> was primarily designed for the available Visium platforms, we anticipate its functions will be relevant to other NGS-based SRT platforms should future assays become available from other vendors. We note that among all current SRT technologies, Visium is by far the leading platform in the field<sup>(</sup><xref rid="r6" ref-type="bibr"><sup>6</sup></xref><sup>)</sup> with over 60 institutions utilizing the technology at the time of publication, further supporting the need for improved imaging-processing tools.</p>
    <p>While we recognize that MATLAB is closed source, it is compatible with open science<sup>(</sup><xref rid="r41" ref-type="bibr"><sup>41</sup></xref><sup>)</sup> and readily available to academic users. MATLAB supports the ability to read images from various proprietary file formats from multiple instrument manufacturers. All code for <italic toggle="yes">VistoSeg</italic> is freely available (see Data Availability), and the main output of <italic toggle="yes">VistoSeg</italic> is in <italic toggle="yes">.csv</italic> format, which can be easily incorporated into commonly used pipelines for analysis of SRT data such as R objects for SpatialExperiment<sup>(</sup><xref rid="r29" ref-type="bibr"><sup>29</sup></xref><sup>)</sup> and Seurat,<sup>(</sup><xref rid="r42" ref-type="bibr"><sup>42</sup></xref><sup>)</sup> or Python objects for AnnData.<sup>(</sup><xref rid="r43" ref-type="bibr"><sup>43</sup></xref><sup>)</sup> In addition, conversion utilities like zellkonverter<sup>(</sup><xref rid="r44" ref-type="bibr"><sup>44</sup></xref><sup>)</sup> facilitate intercommunication among these programing languages. As other packages are made available that expand on the key infrastructure provided by SpatialExperiment, <italic toggle="yes">VistoSeg</italic> will continue to be compatible with them.</p>
  </sec>
  <sec sec-type="conclusions" id="sec8">
    <label>4.</label>
    <title>Conclusion</title>
    <p>We developed <italic toggle="yes">VistoSeg</italic> as a user-friendly image-processing toolkit, which is optimized for NGS-based SRT technologies, including the commercially available Visium platforms, to facilitate integration of the rich anatomical and/or proteomic data in the H&amp;E and fluorescent images accompanying spatial gene expression data. <italic toggle="yes">VistoSeg</italic> performs automatic splitting of whole-slide images for downstream data processing and allows for segmenting, visualizing, and quantifying individual high-resolution raw histology and immunofluorescent images. The pipeline is easily adaptable for images obtained from Visium H&amp;E and Visium-SPG workflows from different tissues, organs and species. The pipeline is available at <uri xlink:href="http://research.libd.org/VistoSeg">http://research.libd.org/VistoSeg</uri> and includes a detailed tutorial with example data for implementing <italic toggle="yes">VistoSeg.</italic></p>
  </sec>
  <sec sec-type="materials" id="sec9">
    <label>5.</label>
    <title>Materials and methods</title>
    <sec sec-type="other" id="sec10">
      <label>5.1.</label>
      <title>Post-mortem human brain tissue</title>
      <p>Post-mortem human brain tissue was obtained at the time of autopsy with informed consent from the legal next of kin, through the Maryland Department of Health IRB protocol #12–24, and from the Department of Pathology of Western Michigan University Homer Stryker MD School of Medicine, the Department of Pathology of University of North Dakota School of Medicine and Health Sciences, and the County of Santa Clara Medical Examiner-Coroner Office in San Jose, CA, all under the WCG protocol #20111080. Details of tissue acquisition, handling, processing, dissection, clinical characterization, diagnoses, neuropathological examinations and quality control measures have been described previously.<sup>(</sup><xref rid="r45" ref-type="bibr"><sup>45</sup></xref><sup>)</sup></p>
    </sec>
    <sec sec-type="other" id="sec11">
      <label>5.2.</label>
      <title>Tissue preparation and image acquisition for Visium H&amp;E</title>
      <p>Tissue was cryosectioned on a Leica 3050 cryostat at 10-micron thickness and collected onto a Visium Spatial Gene Expression slide (catalog no. 2000233; 10× Genomics). H&amp;E staining was performed on fresh-frozen tissue according to manufacturer’s instructions to identify nuclei (dark blue/purple) and cytoplasm (pink) in the tissue section. The two stains combine to label features of the tissue in various shades of pink and blue. Thus, the range of colors present in the staining depends on the cellular composition of the tissue. Following H&amp;E staining, the Visium slide was imaged on a Leica Aperio CS2 slide scanner (<xref rid="fig1" ref-type="fig">Figure 1b</xref>) equipped with a color camera and a 20×/0.75 NA objective with a 2× optical magnification changer, which meets the recommended microscopy specification outlined by Visium Spatial Gene Expression Imaging Guidelines from 10× Genomics.<sup>(</sup><xref rid="r46" ref-type="bibr"><sup>46</sup></xref><sup>)</sup> This protocol produced high-resolution (0.253 μm per pixel) images for downstream analysis.</p>
    </sec>
    <sec sec-type="other" id="sec12">
      <label>5.3.</label>
      <title>Immunofluorescent staining and image acquisition for Visium-SPG</title>
      <p>Immunofluorescent staining was performed according to the manufacturer’s instructions (catalog no.CG000312 Rev C; 10× Genomics). Briefly, post-mortem human dorsolateral prefrontal cortex (<italic toggle="yes">n</italic> = 4 tissue sections from four individual donors) was microdissected and cryosectioned at 10-micron thickness. Sections were mounted on a Visium Spatial Gene Expression Slide (catalog no. 2000233; 10× Genomics), fixed in prechilled methanol, blocked in BSA-containing buffer, and incubated for 30 min at room temperature with primary antibodies against NeuN, TMEM119, GFAP, and OLIG2 (mouse anti-NeuN antibody conjugated to Alexa 488 [Sigma Aldrich; Cat# MAB377X, 1:100], rabbit anti-TMEM119 antibody [Sigma Aldrich; Cat# HPA051870, 1:20], rat anti-GFAP antibody [Thermofisher; Cat# 13-0300, 1:100], and goat anti-OLIG2 antibody [R&amp;D systems; Cat# AF2418, 1:20]). Following washes, appropriate secondary antibodies were applied for 30 min at room temperature (donkey anti-rabbit IgG conjugated to Alexa 555 [Thermofisher; Cat# A-31572, 1:300], donkey anti-rat IgG conjugated to Alexa 594 [Thermofisher; Cat# A-21209, 1: 600], and donkey anti-goat IgG conjugated to Alexa 647 [Thermofisher, Cat# A-21447, 1:400]). DAPI (Thermofisher; Cat# D1306, 1:3000, 1.67 μg/ml) was applied for nuclear counterstaining. The slide was coverslipped with 85% glycerol and imaged on a Vectra Polaris slide scanner (Akoya Biosciences) at 20× magnification with the following exposure time per given channel: 2.1 ms for DAPI, 143 ms for Opal 520, 330 ms for Opal 570, 200 ms for Opal 620, 1070 ms for Opal 690, 100 ms for Autofluorescence prior to downstream transcriptomics. Slide scanning generated a qptiff image file, which was then selected for a region of interest (ROI) in Phenochart software (Akoya Biosciences) with an annotation tool outlining the entire slide. The resulting boundaries created a grid line of multiple tiles that made up the entire demarcated ROI. The annotated qptiff image was then processed in InForm software (Akoya Biosciences) and subjected to linear unmixing with the reference spectral profiles of corresponding fluorophores. InForm performs linear unmixing tile by tile while producing linearly unmixed tile images in tiff. The subsequent individual tile images were processed through the <italic toggle="yes">VistoSeg</italic> pipeline to extract final quantitative output.</p>
    </sec>
    <sec sec-type="other" id="sec13">
      <label>5.4.</label>
      <title>cDNA synthesis and library preparation</title>
      <p>Following imaging, gene expression libraries were generated on the slide, followed by denaturing and amplification. Standard Illumina sequencing was performed according to manufacturer’s specifications.</p>
    </sec>
    <sec sec-type="other" id="sec14">
      <label>5.5.</label>
      <title>System requirements and availability for VistoSeg</title>
      <p>Project name: <italic toggle="yes">VistoSeg</italic></p>
      <p>Project home page: <uri xlink:href="https://github.com/LieberInstitute/VistoSeg">https://github.com/LieberInstitute/VistoSeg</uri>, <uri xlink:href="http://research.libd.org/VistoSeg/">http://research.libd.org/VistoSeg/</uri></p>
      <p>Operating system(s): MAC, Windows, LINUX</p>
      <p>Programming language: MATLAB</p>
      <p>Other requirements:</p>
      <p>(1) MATLAB Image Processing Toolbox</p>
      <p>(2) MATLAB v2019a or later</p>
      <p>(3) Minimum ~ (3*raw image) 80 GB RAM for the initial (<italic toggle="yes">splitSlide</italic>) step and &lt;16GB for all the remaining steps</p>
      <p>(4) SpaceRanger (10× Genomics) v1.0 or higher</p>
      <p>(5) Loupe browser (10× Genomics) v5 or higher</p>
      <p>License: GNU GENERAL PUBLIC LICENSE, Version 3, June 29, 2007.</p>
      <p>Any restrictions to use by nonacademics: license required.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material" id="sec19">
    <title>Supporting information</title>
    <supplementary-material id="sm01" position="float" content-type="local-data">
      <caption>
        <title>Tippani et al. supplementary material</title>
        <p>Tippani et al. supplementary material</p>
      </caption>
      <media xlink:href="S2633903X23000235sup001.docx" id="d66e1107" position="anchor"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>We thank Anthony Ramnauth (LIBD) and Uma Kaipa (LIBD) for testing code functionality. We thank the “spatialLIBD” team (LIBD and JHU) for their feedback on <italic toggle="yes">VistoSeg</italic> and testing the software across multiple datasets. We thank Amy Deep-Soboslay and her diagnostic team for curation of brain samples. We thank the neuropathology team for their assistance with tissue dissection. We thank the physicians and staff at the brain donation sites and the generosity of donor families for supporting our research efforts. Finally, we thank the families of Connie and Stephen Lieber and Milton and Tamar Maltz for their generous support to this work. A preprint of this work is available on bioRxiv: <ext-link xlink:href="10.1101/2021.08.04.452489" ext-link-type="doi">https://doi.org/10.1101/2021.08.04.452489</ext-link>.</p>
  </ack>
  <glossary id="glsy1">
    <title>Glossary of terms</title>
    <p>
      <def-list list-type="simple" list-content="abbreviation">
        <def-item>
          <term>10× Genomics:</term>
          <def>
            <p>commercial vendor producing Visium technology</p>
          </def>
        </def-item>
        <def-item>
          <term>barcode identifier (ID):</term>
          <def>
            <p>unique genomic sequence for each spatially restricted position on a Visium slide</p>
          </def>
        </def-item>
        <def-item>
          <term>CIELAB or L*a*b:</term>
          <def>
            <p>color model incorporating perceptual lightness (L) with colors unique to human vision (red, green, blue and yellow), to enable the detection and calculation of visibly evident changes in color patterns</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">countNuclei:</italic>
          </term>
          <def>
            <p>a function used to generate the nuclei count file that stores the information about the number of segmented nuclei in each spot</p>
          </def>
        </def-item>
        <def-item>
          <term>GUI:</term>
          <def>
            <p>graphical user interface</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">imsegkmeans:</italic>
          </term>
          <def>
            <p>a MATLAB function that uses K-means clustering-based image segmentation</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">inFormstitch:</italic>
          </term>
          <def>
            <p>a MATLAB function used to stitch all spectrally unmixed individual tiles of a Visium-SPG immunofluorescent slide image to recreate a multispectral TIFF image</p>
          </def>
        </def-item>
        <def-item>
          <term>Loupe browser:</term>
          <def>
            <p>Primary Visualization software provided by 10× Genomics</p>
          </def>
        </def-item>
        <def-item>
          <term>MATLAB:</term>
          <def>
            <p>MATrix LABoratory</p>
          </def>
        </def-item>
        <def-item>
          <term>NGS:</term>
          <def>
            <p>next-generation sequencing</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">refine(VNS):</italic>
          </term>
          <def>
            <p>a function that refines the segmentation done using <italic toggle="yes">VNS</italic> function</p>
          </def>
        </def-item>
        <def-item>
          <term>RGB:</term>
          <def>
            <p>red, green, blue color model</p>
          </def>
        </def-item>
        <def-item>
          <term>ROI:</term>
          <def>
            <p>region of interest</p>
          </def>
        </def-item>
        <def-item>
          <term>SpaceRanger:</term>
          <def>
            <p>analysis software provided by 10× Genomics to align transcript reads to the genome and assign them to a Visium spot</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">splitslide:</italic>
          </term>
          <def>
            <p>a MATLAB function used to split the whole-slide Visium-H&amp;E image into individual capture arrays</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">splitSlide_IF:</italic>
          </term>
          <def>
            <p>a MATLAB function that splits the multispectral TIFF image obtained using <italic toggle="yes">inFormStitch</italic> function into individual capture arrays</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">spotspotcheck:</italic>
          </term>
          <def>
            <p>a GUI that allows the user to visualize and quantify nuclei segmentation results performed using <italic toggle="yes">VNS</italic> and <italic toggle="yes">refineVNS</italic></p>
          </def>
        </def-item>
        <def-item>
          <term>SRT:</term>
          <def>
            <p>spatially resolved transcriptomics</p>
          </def>
        </def-item>
        <def-item>
          <term>Visium H&amp;E:</term>
          <def>
            <p>Visium assay using H&amp;E staining.</p>
          </def>
        </def-item>
        <def-item>
          <term>Visium-SPG:</term>
          <def>
            <p>Visium Spatial Proteogenomics assay using immunofluorescent staining</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">VNS:</italic>
          </term>
          <def>
            <p>a MATLAB function that segments nuclei for Visium H&amp;E images</p>
          </def>
        </def-item>
      </def-list>
    </p>
  </glossary>
  <sec sec-type="supplementary-material" id="nts1">
    <title>Supplementary material</title>
    <p>The supplementary material for this article can be found at <uri xlink:href="https://doi.org/10.1017/S2633903X23000235">https://doi.org/10.1017/S2633903X23000235</uri>.</p>
  </sec>
  <sec sec-type="data-availability" id="sec16">
    <title>Data availability statement</title>
    <p>Examples of code, data, output and results are available at <uri xlink:href="http://research.libd.org/VistoSeg/index.html#data-availability">http://research.libd.org/VistoSeg/index.html#data-availability</uri> and <uri xlink:href="https://github.com/LieberInstitute/VistoSeg">https://github.com/LieberInstitute/VistoSeg</uri>.<sup>(</sup><xref rid="r47" ref-type="bibr"><sup>47</sup></xref><sup>)</sup> All inputs and outputs are available through Figshare.<sup>(</sup><xref rid="r48" ref-type="bibr"><sup>48</sup></xref><sup>)</sup> Public datasets provided by 10× Genomics.<sup>(</sup><xref rid="r49" ref-type="bibr"><sup>49</sup></xref><sup>)</sup></p>
  </sec>
  <sec sec-type="funding-statement" id="sec17">
    <title>Funding statement</title>
    <p>This work was supported by the Lieber Institute for Brain Development and the National Institute of Health grants U01MH122849 and R01MH126393.</p>
  </sec>
  <sec sec-type="COI-statement" id="sec18">
    <title>Competing interest</title>
    <p>A.E.J. is now a full-time employee at Neumora Therapeutics, a for-profit biotechnology company, which is unrelated to the contents of this manuscript. J.L.C. is now a full-time employee at Delfi Diagnostics, a for-profit biotechnology company, which is unrelated to the contents of this manuscript. Their contributions to the manuscript were made while previously employed by the Lieber Institute for Brain Development. All other authors declare no competing interests.</p>
  </sec>
  <ref-list id="refs1" content-type="normal">
    <title>References</title>
    <ref id="r1">
      <label>1.</label>
      <mixed-citation publication-type="journal" id="ref1"><string-name><surname>Marx</surname><given-names>V</given-names></string-name> (<year>2021</year>) <article-title>Method of the year: spatially resolved transcriptomics</article-title>. <source>Nature Methods</source>
<volume>18</volume>(<issue>1</issue>), <fpage>9</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">33408395</pub-id>
</mixed-citation>
    </ref>
    <ref id="r2">
      <label>2.</label>
      <mixed-citation publication-type="journal" id="ref2"><string-name><surname>Rodriques</surname><given-names>SG</given-names></string-name>, <string-name><surname>Stickels</surname><given-names>RR</given-names></string-name>, <string-name><surname>Goeva</surname><given-names>A</given-names></string-name>, <string-name><surname>Martin</surname><given-names>CA</given-names></string-name>, <string-name><surname>Murray</surname><given-names>E</given-names></string-name>, <string-name><surname>Vanderburg</surname><given-names>CR</given-names></string-name>, <string-name><surname>Welch</surname><given-names>J</given-names></string-name>, <string-name><surname>Chen</surname><given-names>LM</given-names></string-name>, <string-name><surname>Chen</surname><given-names>F</given-names></string-name>, <string-name><surname>Macosko</surname><given-names>EZ</given-names></string-name> (<year>2019</year>) <article-title>Slide-seq: a scalable technology for measuring genome-wide expression at high spatial resolution</article-title>. <source>Science</source>
<volume>363</volume>(<issue>6434</issue>), <fpage>1463</fpage>–<lpage>1467</lpage>.<pub-id pub-id-type="pmid">30923225</pub-id>
</mixed-citation>
    </ref>
    <ref id="r3">
      <label>3.</label>
      <mixed-citation publication-type="journal" id="ref3"><string-name><surname>Liu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Yang</surname><given-names>M</given-names></string-name>, <string-name><surname>Deng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Su</surname><given-names>G</given-names></string-name>, <string-name><surname>Enninful</surname><given-names>A</given-names></string-name>, <string-name><surname>Guo</surname><given-names>CC</given-names></string-name>, <string-name><surname>Tebaldi</surname><given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>D</given-names></string-name>, <string-name><surname>Kim</surname><given-names>D</given-names></string-name>, <string-name><surname>Bai</surname><given-names>Z</given-names></string-name>, <string-name><surname>Norris</surname><given-names>E</given-names></string-name>, <string-name><surname>Pan</surname><given-names>A</given-names></string-name>, <string-name><surname>Li</surname><given-names>J</given-names></string-name>, <string-name><surname>Xiao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Halene</surname><given-names>S</given-names></string-name>, <string-name><surname>Fan</surname><given-names>R</given-names></string-name> (<year>2020</year>) <article-title>High-spatial-resolution multi-omics sequencing via deterministic barcoding in tissue</article-title>. <source>Cell</source>
<volume>183</volume>(<issue>6</issue>), <fpage>1665</fpage>–<lpage>1681</lpage>.e18.<pub-id pub-id-type="pmid">33188776</pub-id>
</mixed-citation>
    </ref>
    <ref id="r4">
      <label>4.</label>
      <mixed-citation publication-type="journal" id="ref4"><string-name><surname>Vickovic</surname><given-names>S</given-names></string-name>, <string-name><surname>Eraslan</surname><given-names>G</given-names></string-name>, <string-name><surname>Salmén</surname><given-names>F</given-names></string-name>, <string-name><surname>Klughammer</surname><given-names>J</given-names></string-name>, <string-name><surname>Stenbeck</surname><given-names>L</given-names></string-name>, <string-name><surname>Schapiro</surname><given-names>D</given-names></string-name>, <string-name><surname>Äijö</surname><given-names>T</given-names></string-name>, <string-name><surname>Bonneau</surname><given-names>R</given-names></string-name>, <string-name><surname>Bergenstråhle</surname><given-names>L</given-names></string-name>, <string-name><surname>Navarro</surname><given-names>JF</given-names></string-name>, <string-name><surname>Gould</surname><given-names>J</given-names></string-name>, <string-name><surname>Griffin</surname><given-names>GK</given-names></string-name>, <string-name><surname>Borg</surname><given-names>Å</given-names></string-name>, <string-name><surname>Ronaghi</surname><given-names>M</given-names></string-name>, <string-name><surname>Frisén</surname><given-names>J</given-names></string-name>, <string-name><surname>Lundeberg</surname><given-names>J</given-names></string-name>, <string-name><surname>Regev</surname><given-names>A</given-names></string-name>, <string-name><surname>Ståhl</surname><given-names>PL</given-names></string-name> (<year>2019</year>) <article-title>High-definition spatial transcriptomics for in situ tissue profiling</article-title>. <source>Nature Methods</source>
<volume>16</volume>(<issue>10</issue>), <fpage>987</fpage>–<lpage>990</lpage>.<pub-id pub-id-type="pmid">31501547</pub-id>
</mixed-citation>
    </ref>
    <ref id="r5">
      <label>5.</label>
      <mixed-citation publication-type="other" id="ref5"><string-name><surname>Fu</surname><given-names>X</given-names></string-name>, <string-name><surname>Sun</surname><given-names>L</given-names></string-name>, <string-name><surname>Chen</surname><given-names>J</given-names></string-name>, <string-name><surname>Dong</surname><given-names>R</given-names></string-name>, <string-name><surname>Lin</surname><given-names>Y</given-names></string-name>, <string-name><surname>Palmiter</surname><given-names>R</given-names></string-name>, <string-name><surname>Lin</surname><given-names>S</given-names></string-name>, <string-name><surname>Gu</surname><given-names>L</given-names></string-name> (<year>2021</year>) Continuous polony gels for tissue mapping with high resolution and RNA capture efficiency. BioRxiv.</mixed-citation>
    </ref>
    <ref id="r6">
      <label>6.</label>
      <mixed-citation publication-type="journal" id="ref6"><string-name><surname>Moses</surname><given-names>L</given-names></string-name>, <string-name><surname>Pachter</surname><given-names>L</given-names></string-name> (<year>2022</year>) <article-title>Museum of spatial transcriptomics</article-title>. <source>Nat Methods</source>
<volume>19</volume>(<issue>5</issue>), <fpage>534</fpage>–<lpage>546</lpage>.<pub-id pub-id-type="pmid">35273392</pub-id>
</mixed-citation>
    </ref>
    <ref id="r7">
      <label>7.</label>
      <mixed-citation publication-type="other" id="ref7">10× Genomics (2022) Loupe Browser, 10× Genomics [Internet]. [cited 18 April 2022]. Available at <uri xlink:href="https://support.10xgenomics.com/spatial-gene-expression/software/visualization/latest/analysis">https://support.10xgenomics.com/spatial-gene-expression/software/visualization/latest/analysis</uri>.</mixed-citation>
    </ref>
    <ref id="r8">
      <label>8.</label>
      <mixed-citation publication-type="other" id="ref8">10× Genomics April (2022) Space Ranger, 10× Genomics [Internet]. [cited 18 April 2022]. Available at <uri xlink:href="https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/what-is-space-ranger">https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/what-is-space-ranger</uri>.</mixed-citation>
    </ref>
    <ref id="r9">
      <label>9.</label>
      <mixed-citation publication-type="journal" id="ref9"><string-name><surname>Bankhead</surname><given-names>P</given-names></string-name>, <string-name><surname>Loughrey</surname><given-names>MB</given-names></string-name>, <string-name><surname>Fernández</surname><given-names>JA</given-names></string-name>, <string-name><surname>Dombrowski</surname><given-names>Y</given-names></string-name>, <string-name><surname>McArt</surname><given-names>DG</given-names></string-name>, <string-name><surname>Dunne</surname><given-names>PD</given-names></string-name>, <string-name><surname>McQuaid</surname><given-names>S</given-names></string-name>, <string-name><surname>Gray</surname><given-names>RT</given-names></string-name>, <string-name><surname>Murray</surname><given-names>LJ</given-names></string-name>, <string-name><surname>Coleman</surname><given-names>HG</given-names></string-name>, <string-name><surname>James</surname><given-names>JA</given-names></string-name>, <string-name><surname>Salto-Tellez</surname><given-names>M</given-names></string-name>, <string-name><surname>Hamilton</surname><given-names>PW</given-names></string-name> (<year>2017</year>) <article-title>QuPath: open-source software for digital pathology image analysis</article-title>. <source>Scientific Reports</source>
<volume>7</volume>(<issue>1</issue>), <fpage>16878</fpage>.<pub-id pub-id-type="pmid">29203879</pub-id>
</mixed-citation>
    </ref>
    <ref id="r10">
      <label>10.</label>
      <mixed-citation publication-type="journal" id="ref10"><string-name><surname>Stringer</surname><given-names>C</given-names></string-name>, <string-name><surname>Wang</surname><given-names>T</given-names></string-name>, <string-name><surname>Michaelos</surname><given-names>M</given-names></string-name>, <string-name><surname>Pachitariu</surname><given-names>M</given-names></string-name> (<year>2021</year>) <article-title>Cellpose: a generalist algorithm for cellular segmentation</article-title>. <source>Nature Methods</source>
<volume>18</volume>(<issue>1</issue>), <fpage>100</fpage>–<lpage>106</lpage>.<pub-id pub-id-type="pmid">33318659</pub-id>
</mixed-citation>
    </ref>
    <ref id="r11">
      <label>11.</label>
      <mixed-citation publication-type="journal" id="ref11"><string-name><surname>Fürth</surname><given-names>D</given-names></string-name>, <string-name><surname>Vaissière</surname><given-names>T</given-names></string-name>, <string-name><surname>Tzortzi</surname><given-names>O</given-names></string-name>, <string-name><surname>Xuan</surname><given-names>Y</given-names></string-name>, <string-name><surname>Märtin</surname><given-names>A</given-names></string-name>, <string-name><surname>Lazaridis</surname><given-names>I</given-names></string-name>, <string-name><surname>Spigolon</surname><given-names>G</given-names></string-name>, <string-name><surname>Fisone</surname><given-names>G</given-names></string-name>, <string-name><surname>Tomer</surname><given-names>R</given-names></string-name>, <string-name><surname>Deisseroth</surname><given-names>K</given-names></string-name>, <string-name><surname>Carlén</surname><given-names>M</given-names></string-name>, <string-name><surname>Miller</surname><given-names>CA</given-names></string-name>, <string-name><surname>Rumbaugh</surname><given-names>G</given-names></string-name>, <string-name><surname>Meletis</surname><given-names>K</given-names></string-name> (<year>2018</year>) <article-title>An interactive framework for whole-brain maps at cellular resolution</article-title>. <source>Nature Neurosciene</source>
<volume>21</volume>(<issue>1</issue>), <fpage>139</fpage>–<lpage>149</lpage>.</mixed-citation>
    </ref>
    <ref id="r12">
      <label>12.</label>
      <mixed-citation publication-type="journal" id="ref12"><string-name><surname>Ortiz</surname><given-names>C</given-names></string-name>, <string-name><surname>Navarro</surname><given-names>JF</given-names></string-name>, <string-name><surname>Jurek</surname><given-names>A</given-names></string-name>, <string-name><surname>Märtin</surname><given-names>A</given-names></string-name>, <string-name><surname>Lundeberg</surname><given-names>J</given-names></string-name>, <string-name><surname>Meletis</surname><given-names>K</given-names></string-name> (<year>2020</year>) <article-title>Molecular atlas of the adult mouse brain</article-title>. <source>Science Advances</source>
<volume>6</volume>(<issue>26</issue>), <fpage>eabb3446</fpage>.<pub-id pub-id-type="pmid">32637622</pub-id>
</mixed-citation>
    </ref>
    <ref id="r13">
      <label>13.</label>
      <mixed-citation publication-type="journal" id="ref13"><string-name><surname>Schindelin</surname><given-names>J</given-names></string-name>, <string-name><surname>Arganda-Carreras</surname><given-names>I</given-names></string-name>, <string-name><surname>Frise</surname><given-names>E</given-names></string-name>, <string-name><surname>Kaynig</surname><given-names>V</given-names></string-name>, <string-name><surname>Longair</surname><given-names>M</given-names></string-name>, <string-name><surname>Pietzsch</surname><given-names>T</given-names></string-name>, <string-name><surname>Preibisch</surname><given-names>S</given-names></string-name>, <string-name><surname>Rueden</surname><given-names>C</given-names></string-name>, <string-name><surname>Saalfeld</surname><given-names>S</given-names></string-name>, <string-name><surname>Schmid</surname><given-names>B</given-names></string-name>, <string-name><surname>Tinevez</surname><given-names>J-Y</given-names></string-name>, <string-name><surname>White</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Hartenstein</surname><given-names>V</given-names></string-name>, <string-name><surname>Eliceiri</surname><given-names>K</given-names></string-name>, <string-name><surname>Tomancak</surname><given-names>P</given-names></string-name>, <string-name><surname>Cardona</surname><given-names>A</given-names></string-name> (<year>2012</year>) <article-title>Fiji: an open-source platform for biological-image analysis</article-title>. <source>Nature Methods</source>
<volume>9</volume>(<issue>7</issue>), <fpage>676</fpage>–<lpage>682</lpage>.<pub-id pub-id-type="pmid">22743772</pub-id>
</mixed-citation>
    </ref>
    <ref id="r14">
      <label>14.</label>
      <mixed-citation publication-type="journal" id="ref14"><string-name><surname>McQuin</surname><given-names>C</given-names></string-name>, <string-name><surname>Goodman</surname><given-names>A</given-names></string-name>, <string-name><surname>Chernyshev</surname><given-names>V</given-names></string-name>, <string-name><surname>Kamentsky</surname><given-names>L</given-names></string-name>, <string-name><surname>Cimini</surname><given-names>BA</given-names></string-name>, <string-name><surname>Karhohs</surname><given-names>KW</given-names></string-name>, <string-name><surname>Doan</surname><given-names>M</given-names></string-name>, <string-name><surname>Ding</surname><given-names>L</given-names></string-name>, <string-name><surname>Rafelski</surname><given-names>SM</given-names></string-name>, <string-name><surname>Thirstrup</surname><given-names>D</given-names></string-name>, <string-name><surname>Wiegraebe</surname><given-names>W</given-names></string-name>, <string-name><surname>Singh</surname><given-names>S</given-names></string-name>, <string-name><surname>Becker</surname><given-names>T</given-names></string-name>, <string-name><surname>Caicedo</surname><given-names>JC</given-names></string-name>, <string-name><surname>Carpenter</surname><given-names>AE</given-names></string-name> (<year>2018</year>) <article-title>CellProfiler 3.0: next-generation image processing for biology</article-title>. <source>PLoS Biology</source>
<volume>16</volume>(<issue>7</issue>), <fpage>e2005970</fpage>.<pub-id pub-id-type="pmid">29969450</pub-id>
</mixed-citation>
    </ref>
    <ref id="r15">
      <label>15.</label>
      <mixed-citation publication-type="journal" id="ref15"><string-name><surname>Hu</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name>, <string-name><surname>Coleman</surname><given-names>K</given-names></string-name>, <string-name><surname>Schroeder</surname><given-names>A</given-names></string-name>, <string-name><surname>Ma</surname><given-names>N</given-names></string-name>, <string-name><surname>Irwin</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Lee</surname><given-names>EB</given-names></string-name>, <string-name><surname>Shinohara</surname><given-names>RT</given-names></string-name>, <string-name><surname>Li</surname><given-names>M</given-names></string-name> (<year>2021</year>) <article-title>SpaGCN: integrating gene expression, spatial location and histology to identify spatial domains and spatially variable genes by graph convolutional network</article-title>. <source>Nature Methods</source>
<volume>18</volume>(<issue>11</issue>), <fpage>1342</fpage>–<lpage>1351</lpage>.<pub-id pub-id-type="pmid">34711970</pub-id>
</mixed-citation>
    </ref>
    <ref id="r16">
      <label>16.</label>
      <mixed-citation publication-type="journal" id="ref16"><string-name><surname>Bao</surname><given-names>F</given-names></string-name>, <string-name><surname>Deng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wan</surname><given-names>S</given-names></string-name>, <string-name><surname>Shen</surname><given-names>SQ</given-names></string-name>, <string-name><surname>Wang</surname><given-names>B</given-names></string-name>, <string-name><surname>Dai</surname><given-names>Q</given-names></string-name>, <string-name><surname>Altschuler</surname><given-names>SJ</given-names></string-name>, <string-name><surname>Wu</surname><given-names>LF</given-names></string-name> (<year>2022</year>) <article-title>Integrative spatial analysis of cell morphologies and transcriptional states with MUSE</article-title>. <source>Nature Biotechnology</source>
<volume>40</volume>(<issue>8</issue>), <fpage>1200</fpage>–<lpage>1209</lpage>.</mixed-citation>
    </ref>
    <ref id="r17">
      <label>17.</label>
      <mixed-citation publication-type="journal" id="ref17"><string-name><surname>Pratapa</surname><given-names>A</given-names></string-name>, <string-name><surname>Doron</surname><given-names>M</given-names></string-name>, <string-name><surname>Caicedo</surname><given-names>JC</given-names></string-name> (<year>2021</year>) <article-title>Image-based cell phenotyping with deep learning</article-title>. <source>Current Opinion in Chemical Biology</source>
<volume>65</volume>, <fpage>9</fpage>–<lpage>17</lpage>.<pub-id pub-id-type="pmid">34023800</pub-id>
</mixed-citation>
    </ref>
    <ref id="r18">
      <label>18.</label>
      <mixed-citation publication-type="journal" id="ref18"><string-name><surname>Maynard</surname><given-names>KR</given-names></string-name>, <string-name><surname>Collado-Torres</surname><given-names>L</given-names></string-name>, <string-name><surname>Weber</surname><given-names>LM</given-names></string-name>, <string-name><surname>Uytingco</surname><given-names>C</given-names></string-name>, <string-name><surname>Barry</surname><given-names>BK</given-names></string-name>, <string-name><surname>Williams</surname><given-names>SR</given-names></string-name>, <string-name><surname>Catallini</surname><given-names>JL</given-names></string-name>, <string-name><surname>Tran</surname><given-names>MN</given-names></string-name>, <string-name><surname>Besich</surname><given-names>Z</given-names></string-name>, <string-name><surname>Tippani</surname><given-names>M</given-names></string-name>, <string-name><surname>Chew</surname><given-names>J</given-names></string-name>, <string-name><surname>Yin</surname><given-names>Y</given-names></string-name>, <string-name><surname>Kleinman</surname><given-names>JE</given-names></string-name>, <string-name><surname>Hyde</surname><given-names>TM</given-names></string-name>, <string-name><surname>Rao</surname><given-names>N</given-names></string-name>, <string-name><surname>Hicks</surname><given-names>SC</given-names></string-name>, <string-name><surname>Martinowich</surname><given-names>K</given-names></string-name>, <string-name><surname>Jaffe</surname><given-names>AE</given-names></string-name> (<year>2021</year>) <article-title>Transcriptome-scale spatial gene expression in the human dorsolateral prefrontal cortex</article-title>. <source>Nature Neuroscience</source>
<volume>24</volume>(<issue>3</issue>), <fpage>425</fpage>–<lpage>436</lpage>.<pub-id pub-id-type="pmid">33558695</pub-id>
</mixed-citation>
    </ref>
    <ref id="r19">
      <label>19.</label>
      <mixed-citation publication-type="journal" id="ref19"><string-name><surname>Kleshchevnikov</surname><given-names>V</given-names></string-name>, <string-name><surname>Shmatko</surname><given-names>A</given-names></string-name>, <string-name><surname>Dann</surname><given-names>E</given-names></string-name>, <string-name><surname>Aivazidis</surname><given-names>A</given-names></string-name>, <string-name><surname>King</surname><given-names>HW</given-names></string-name>, <string-name><surname>Li</surname><given-names>T</given-names></string-name>, <string-name><surname>Elmentaite</surname><given-names>R</given-names></string-name>, <string-name><surname>Lomakin</surname><given-names>A</given-names></string-name>, <string-name><surname>Kedlian</surname><given-names>V</given-names></string-name>, <string-name><surname>Gayoso</surname><given-names>A</given-names></string-name>, <string-name><surname>Jain</surname><given-names>MS</given-names></string-name>, <string-name><surname>Park</surname><given-names>JS</given-names></string-name>, <string-name><surname>Ramona</surname><given-names>L</given-names></string-name>, <string-name><surname>Tuck</surname><given-names>E</given-names></string-name>, <string-name><surname>Arutyunyan</surname><given-names>A</given-names></string-name>, <string-name><surname>Vento-Tormo</surname><given-names>R</given-names></string-name>, <string-name><surname>Gerstung</surname><given-names>M</given-names></string-name>, <string-name><surname>James</surname><given-names>L</given-names></string-name>, <string-name><surname>Stegle</surname><given-names>O</given-names></string-name>, <string-name><surname>Bayraktar</surname><given-names>OA</given-names></string-name> (<year>2022</year>) <article-title>Cell2location maps fine-grained cell types in spatial transcriptomics</article-title>. <source>Nature Biotechnology</source>
<volume>40</volume>(<issue>5</issue>), <fpage>661</fpage>–<lpage>671</lpage>.</mixed-citation>
    </ref>
    <ref id="r20">
      <label>20.</label>
      <mixed-citation publication-type="journal" id="ref20"><string-name><surname>Biancalani</surname><given-names>T</given-names></string-name>, <string-name><surname>Scalia</surname><given-names>G</given-names></string-name>, <string-name><surname>Buffoni</surname><given-names>L</given-names></string-name>, <string-name><surname>Avasthi</surname><given-names>R</given-names></string-name>, <string-name><surname>Lu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Sanger</surname><given-names>A</given-names></string-name>, <string-name><surname>Tokcan</surname><given-names>N</given-names></string-name>, <string-name><surname>Vanderburg</surname><given-names>CR</given-names></string-name>, <string-name><surname>Segerstolpe</surname><given-names>Å</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>M</given-names></string-name>, <string-name><surname>Avraham-Davidi</surname><given-names>I</given-names></string-name>, <string-name><surname>Vickovic</surname><given-names>S</given-names></string-name>, <string-name><surname>Nitzan</surname><given-names>M</given-names></string-name>, <string-name><surname>Ma</surname><given-names>S</given-names></string-name>, <string-name><surname>Subramanian</surname><given-names>A</given-names></string-name>, <string-name><surname>Lipinski</surname><given-names>M</given-names></string-name>, <string-name><surname>Buenrostro</surname><given-names>J</given-names></string-name>, <string-name><surname>Brown</surname><given-names>NB</given-names></string-name>, <string-name><surname>Fanelli</surname><given-names>D</given-names></string-name>, <string-name><surname>Zhuang</surname><given-names>X</given-names></string-name>, <string-name><surname>Regev</surname><given-names>A</given-names></string-name> (<year>2021</year>) <article-title>Deep learning and alignment of spatially resolved single-cell transcriptomes with tangram</article-title>. <source>Nature Methods</source>
<volume>18</volume>(<issue>11</issue>), <fpage>1352</fpage>–<lpage>1362</lpage>.<pub-id pub-id-type="pmid">34711971</pub-id>
</mixed-citation>
    </ref>
    <ref id="r21">
      <label>21.</label>
      <mixed-citation publication-type="journal" id="ref21"><string-name><surname>Elosua-Bayes</surname><given-names>M</given-names></string-name>, <string-name><surname>Nieto</surname><given-names>P</given-names></string-name>, <string-name><surname>Mereu</surname><given-names>E</given-names></string-name>, <string-name><surname>Gut</surname><given-names>I</given-names></string-name>, <string-name><surname>Heyn</surname><given-names>H</given-names></string-name> (<year>2021</year>) <article-title>SPOTlight: seeded NMF regression to deconvolute spatial transcriptomics spots with single-cell transcriptomes</article-title>. <source>Nucleic Acids Research</source>
<volume>49</volume>(<issue>9</issue>), <fpage>e50</fpage>.<pub-id pub-id-type="pmid">33544846</pub-id>
</mixed-citation>
    </ref>
    <ref id="r22">
      <label>22.</label>
      <mixed-citation publication-type="journal" id="ref22"><string-name><surname>Andersson</surname><given-names>A</given-names></string-name>, <string-name><surname>Larsson</surname><given-names>L</given-names></string-name>, <string-name><surname>Stenbeck</surname><given-names>L</given-names></string-name>, <string-name><surname>Salmén</surname><given-names>F</given-names></string-name>, <string-name><surname>Ehinger</surname><given-names>A</given-names></string-name>, <string-name><surname>Wu</surname><given-names>SZ</given-names></string-name>, <string-name><surname>Al-Eryani</surname><given-names>G</given-names></string-name>, <string-name><surname>Roden</surname><given-names>D</given-names></string-name>, <string-name><surname>Swarbrick</surname><given-names>A</given-names></string-name>, <string-name><surname>Borg</surname><given-names>Å</given-names></string-name>, <string-name><surname>Frisén</surname><given-names>J</given-names></string-name>, <string-name><surname>Engblom</surname><given-names>C</given-names></string-name>, <string-name><surname>Lundeberg</surname><given-names>J</given-names></string-name> (<year>2021</year>) <article-title>Spatial deconvolution of HER2-positive breast cancer delineates tumor-associated cell type interactions</article-title>. <source>Nature Communications</source>
<volume>12</volume>(<issue>1</issue>), <fpage>6012</fpage>.</mixed-citation>
    </ref>
    <ref id="r23">
      <label>23.</label>
      <mixed-citation publication-type="journal" id="ref23"><string-name><surname>Buccitelli</surname><given-names>C</given-names></string-name>, <string-name><surname>Selbach</surname><given-names>M</given-names></string-name> (<year>2020</year>) <article-title>mRNAs, proteins and the emerging principles of gene expression control</article-title>. <source>Nature Reviews Genetics</source>
<volume>21</volume>(<issue>10</issue>), <fpage>630</fpage>–<lpage>644</lpage>.</mixed-citation>
    </ref>
    <ref id="r24">
      <label>24.</label>
      <mixed-citation publication-type="other" id="ref24"><collab>10× Genomics</collab> (<year>2021</year>) Input Recommendations-Software-Spatial Gene Expression-Official 10× Genomics Support [Internet]. [cited 1 January 2021]. Available at <uri xlink:href="https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/using/input-recommendations">https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/using/input-recommendations</uri>.</mixed-citation>
    </ref>
    <ref id="r25">
      <label>25.</label>
      <mixed-citation publication-type="journal" id="ref25"><string-name><surname>Raju</surname><given-names>PD</given-names></string-name>, <string-name><surname>Neelima</surname><given-names>G</given-names></string-name> (<year>2012</year>) <article-title>Image segmentation by using histogram thresholding</article-title>. <source>IJCSET</source>
<volume>2</volume>(<issue>1</issue>), <fpage>776</fpage>–<lpage>779</lpage>.</mixed-citation>
    </ref>
    <ref id="r26">
      <label>26.</label>
      <mixed-citation publication-type="other" id="ref26"><collab>Akoya Bioscience</collab> (<year>2019</year>) inForm® Tissue Finder Software [Internet]. [cited 13 April 2022]. Available at <uri xlink:href="https://www.akoyabio.com/support/software/inform-tissue-finder-software/">https://www.akoyabio.com/support/software/inform-tissue-finder-software/</uri>.</mixed-citation>
    </ref>
    <ref id="r27">
      <label>27.</label>
      <mixed-citation publication-type="other" id="ref27"><collab>Akoya Bioscience</collab> (<year>2019</year>) Phenochart Whole Slide Viewer [Internet]. [cited 12 April 2022]. Available at <uri xlink:href="https://www.akoyabio.com/support/software/phenochart-whole-slide-viewer/">https://www.akoyabio.com/support/software/phenochart-whole-slide-viewer/</uri>.</mixed-citation>
    </ref>
    <ref id="r28">
      <label>28.</label>
      <mixed-citation publication-type="journal" id="ref28"><string-name><surname>Maynard</surname><given-names>KR</given-names></string-name>, <string-name><surname>Tippani</surname><given-names>M</given-names></string-name>, <string-name><surname>Takahashi</surname><given-names>Y</given-names></string-name>, <string-name><surname>Phan</surname><given-names>BN</given-names></string-name>, <string-name><surname>Hyde</surname><given-names>TM</given-names></string-name>, <string-name><surname>Jaffe</surname><given-names>AE</given-names></string-name>, <string-name><surname>Martinowich</surname><given-names>K</given-names></string-name> (<year>2020</year>) <article-title>dotdotdot: an automated approach to quantify multiplex single molecule fluorescent in situ hybridization (smFISH) images in complex tissues</article-title>. <source>Nucleic Acids Research</source>
<volume>48</volume>(<issue>11</issue>), <fpage>e66</fpage>.<pub-id pub-id-type="pmid">32383753</pub-id>
</mixed-citation>
    </ref>
    <ref id="r29">
      <label>29.</label>
      <mixed-citation publication-type="journal" id="ref29"><string-name><surname>Righelli</surname><given-names>D</given-names></string-name>, <string-name><surname>Weber</surname><given-names>LM</given-names></string-name>, <string-name><surname>Crowell</surname><given-names>HL</given-names></string-name>, <string-name><surname>Pardo</surname><given-names>B</given-names></string-name>, <string-name><surname>Collado-Torres</surname><given-names>L</given-names></string-name>, <string-name><surname>Ghazanfar</surname><given-names>S</given-names></string-name>, <string-name><surname>Lun</surname><given-names>ATL</given-names></string-name>, <string-name><surname>Hicks</surname><given-names>SC</given-names></string-name>, <string-name><surname>Risso</surname><given-names>D</given-names></string-name> (<year>2022</year>) <article-title>Spatial experiment: infrastructure for spatially-resolved transcriptomics data in R using Bioconductor</article-title>. <source>Bioinformatics</source>
<volume>38</volume>(<issue>11</issue>), <fpage>3128</fpage>–<lpage>3131</lpage>.<pub-id pub-id-type="pmid">35482478</pub-id>
</mixed-citation>
    </ref>
    <ref id="r30">
      <label>30.</label>
      <mixed-citation publication-type="journal" id="ref30"><string-name><surname>McCarthy</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Campbell</surname><given-names>KR</given-names></string-name>, <string-name><surname>Lun</surname><given-names>ATL</given-names></string-name>, <string-name><surname>Wills</surname><given-names>QF</given-names></string-name> (<year>2017</year>) <article-title>Scater: pre-processing, quality control, normalization and visualization of single-cell RNA-seq data in R</article-title>. <source>Bioinformatics</source>
<volume>33</volume>(<issue>8</issue>), <fpage>1179</fpage>–<lpage>1186</lpage>.<pub-id pub-id-type="pmid">28088763</pub-id>
</mixed-citation>
    </ref>
    <ref id="r31">
      <label>31.</label>
      <mixed-citation publication-type="other" id="ref31"><collab>The MathWorks, Inc</collab>. (<year>2019</year>) MATLAB and Image processing toolbox. MATLAB.</mixed-citation>
    </ref>
    <ref id="r32">
      <label>32.</label>
      <mixed-citation publication-type="journal" id="ref32"><string-name><surname>Chen</surname><given-names>W-T</given-names></string-name>, <string-name><surname>Lu</surname><given-names>A</given-names></string-name>, <string-name><surname>Craessaerts</surname><given-names>K</given-names></string-name>, <string-name><surname>Pavie</surname><given-names>B</given-names></string-name>, <string-name><surname>Sala Frigerio</surname><given-names>C</given-names></string-name>, <string-name><surname>Corthout</surname><given-names>N</given-names></string-name>, <string-name><surname>Qian</surname><given-names>X</given-names></string-name>, <string-name><surname>Laláková</surname><given-names>J</given-names></string-name>, <string-name><surname>Kühnemund</surname><given-names>M</given-names></string-name>, <string-name><surname>Voytyuk</surname><given-names>I</given-names></string-name>, <string-name><surname>Wolfs</surname><given-names>L</given-names></string-name>, <string-name><surname>Mancuso</surname><given-names>R</given-names></string-name>, <string-name><surname>Salta</surname><given-names>E</given-names></string-name>, <string-name><surname>Balusu</surname><given-names>S</given-names></string-name>, <string-name><surname>Snellinx</surname><given-names>A</given-names></string-name>, <string-name><surname>Munck</surname><given-names>S</given-names></string-name>, <string-name><surname>Jurek</surname><given-names>A</given-names></string-name>, <string-name><surname>Fernandez</surname><given-names>Navarro J</given-names></string-name>, <string-name><surname>Saido</surname><given-names>TC</given-names></string-name>, <string-name><surname>Huitinga</surname><given-names>I</given-names></string-name>, <string-name><surname>De Strooper</surname><given-names>B</given-names></string-name> (<year>2020</year>) <article-title>Spatial transcriptomics and in situ sequencing to study Alzheimer’s disease</article-title>. <source>Cell</source>
<volume>182</volume>(<issue>4</issue>), <fpage>976</fpage>–<lpage>991</lpage>.e19.<pub-id pub-id-type="pmid">32702314</pub-id>
</mixed-citation>
    </ref>
    <ref id="r33">
      <label>33.</label>
      <mixed-citation publication-type="journal" id="ref33"><string-name><surname>Phillip</surname><given-names>JM</given-names></string-name>, <string-name><surname>Han</surname><given-names>K-S</given-names></string-name>, <string-name><surname>Chen</surname><given-names>W-C</given-names></string-name>, <string-name><surname>Wirtz</surname><given-names>D</given-names></string-name>, <string-name><surname>Wu</surname><given-names>P-H</given-names></string-name> (<year>2021</year>) <article-title>A robust unsupervised machine-learning method to quantify the morphological heterogeneity of cells and nuclei</article-title>. <source>Nature Protocols</source>
<volume>16</volume>(<issue>2</issue>), <fpage>754</fpage>–<lpage>774</lpage>.<pub-id pub-id-type="pmid">33424024</pub-id>
</mixed-citation>
    </ref>
    <ref id="r34">
      <label>34.</label>
      <mixed-citation publication-type="journal" id="ref34"><string-name><surname>Logan</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Shan</surname><given-names>J</given-names></string-name>, <string-name><surname>Bhatia</surname><given-names>SN</given-names></string-name>, <string-name><surname>Carpenter</surname><given-names>AE</given-names></string-name> (<year>2016</year>) <article-title>Quantifying co-cultured cell phenotypes in high-throughput using pixel-based classification</article-title>. <source>Methods</source>
<volume>96</volume>, <fpage>6</fpage>–<lpage>11</lpage>.<pub-id pub-id-type="pmid">26687239</pub-id>
</mixed-citation>
    </ref>
    <ref id="r35">
      <label>35.</label>
      <mixed-citation publication-type="journal" id="ref35"><string-name><surname>Chang</surname><given-names>Y</given-names></string-name>, <string-name><surname>He</surname><given-names>F</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Chen</surname><given-names>S</given-names></string-name>, <string-name><surname>Li</surname><given-names>J</given-names></string-name>, <string-name><surname>Liu</surname><given-names>J</given-names></string-name>, <string-name><surname>Yu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Su</surname><given-names>L</given-names></string-name>, <string-name><surname>Ma</surname><given-names>A</given-names></string-name>, <string-name><surname>Allen</surname><given-names>C</given-names></string-name>, <string-name><surname>Lin</surname><given-names>Y</given-names></string-name>, <string-name><surname>Sun</surname><given-names>S</given-names></string-name>, <string-name><surname>Liu</surname><given-names>B</given-names></string-name>, <string-name><surname>Javier Otero</surname><given-names>J</given-names></string-name>, <string-name><surname>Chung</surname><given-names>D</given-names></string-name>, <string-name><surname>Fu</surname><given-names>H</given-names></string-name>, <string-name><surname>Li</surname><given-names>Z</given-names></string-name>, <string-name><surname>Xu</surname><given-names>D</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Q</given-names></string-name> (<year>2022</year>) <article-title>Define and visualize pathological architectures of human tissues from spatially resolved transcriptomics using deep learning</article-title>. <source>Computational and Structural Biotechnology Journal</source>
<volume>20</volume>, <fpage>4600</fpage>–<lpage>4617</lpage>.<pub-id pub-id-type="pmid">36090815</pub-id>
</mixed-citation>
    </ref>
    <ref id="r36">
      <label>36.</label>
      <mixed-citation publication-type="journal" id="ref36"><string-name><surname>Palla</surname><given-names>G</given-names></string-name>, <string-name><surname>Spitzer</surname><given-names>H</given-names></string-name>, <string-name><surname>Klein</surname><given-names>M</given-names></string-name>, <string-name><surname>Fischer</surname><given-names>D</given-names></string-name>, <string-name><surname>Schaar</surname><given-names>AC</given-names></string-name>, <string-name><surname>Kuemmerle</surname><given-names>LB</given-names></string-name>, <string-name><surname>Rybakov</surname><given-names>S</given-names></string-name>, <string-name><surname>Ibarra</surname><given-names>IL</given-names></string-name>, <string-name><surname>Holmberg</surname><given-names>O</given-names></string-name>, <string-name><surname>Virshup</surname><given-names>I</given-names></string-name>, <string-name><surname>Lotfollahi</surname><given-names>M</given-names></string-name>, <string-name><surname>Richter</surname><given-names>S</given-names></string-name>, <string-name><surname>Theis</surname><given-names>FJ</given-names></string-name> (<year>2022</year>) <article-title>Squidpy: a scalable framework for spatial omics analysis</article-title>. <source>Nature Methods</source>
<volume>19</volume>(<issue>2</issue>), <fpage>171</fpage>–<lpage>178</lpage>.<pub-id pub-id-type="pmid">35102346</pub-id>
</mixed-citation>
    </ref>
    <ref id="r37">
      <label>37.</label>
      <mixed-citation publication-type="other" id="ref37"><string-name><surname>Sang-aram</surname><given-names>C</given-names></string-name>, <string-name><surname>Browaeys</surname><given-names>R</given-names></string-name>, <string-name><surname>Seurinck</surname><given-names>R</given-names></string-name>, <string-name><surname>Saeys</surname><given-names>Y</given-names></string-name> (<year>2023</year>) Spotless: a reproducible pipeline for benchmarking cell type deconvolution in spatial transcriptomics. BioRxiv.</mixed-citation>
    </ref>
    <ref id="r38">
      <label>38.</label>
      <mixed-citation publication-type="journal" id="ref38"><string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>Z</given-names></string-name>, <string-name><surname>Chen</surname><given-names>S</given-names></string-name>, <string-name><surname>Liao</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>B</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>R</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Sun</surname><given-names>S</given-names></string-name>, <string-name><surname>Gao</surname><given-names>X</given-names></string-name> (<year>2023</year>) <article-title>A comprehensive benchmarking with practical guidelines for cellular deconvolution of spatial transcriptomics</article-title>. <source>Nature Communications</source>
<volume>14</volume>(<issue>1</issue>):<fpage>1548</fpage>.</mixed-citation>
    </ref>
    <ref id="r39">
      <label>39.</label>
      <mixed-citation publication-type="other" id="ref39"><string-name><surname>Huuki-Myers</surname><given-names>L</given-names></string-name>, <string-name><surname>Spangler</surname><given-names>A</given-names></string-name>, <string-name><surname>Eagles</surname><given-names>N</given-names></string-name>, <string-name><surname>Montgomery</surname><given-names>KD</given-names></string-name>, <string-name><surname>Kwon</surname><given-names>SH</given-names></string-name>, <string-name><surname>Guo</surname><given-names>B</given-names></string-name>, <string-name><surname>Grant-Peters</surname><given-names>M</given-names></string-name>, <string-name><surname>Divecha</surname><given-names>HR</given-names></string-name>, <string-name><surname>Tippani</surname><given-names>M</given-names></string-name>, <string-name><surname>Sriworarat</surname><given-names>C</given-names></string-name>, <string-name><surname>Nguyen</surname><given-names>AB</given-names></string-name>, <string-name><surname>Ravichandran</surname><given-names>P</given-names></string-name>, <string-name><surname>Tran</surname><given-names>MN</given-names></string-name>, <string-name><surname>Seyedian</surname><given-names>A</given-names></string-name>, <string-name><surname>PsychENCODE</surname><given-names>consortium</given-names></string-name>, <string-name><surname>Hyde</surname><given-names>TM</given-names></string-name>, <string-name><surname>Kleinman</surname><given-names>JE</given-names></string-name>, <string-name><surname>Battle</surname><given-names>A</given-names></string-name>, <string-name><surname>Page</surname><given-names>SC</given-names></string-name>, <string-name><surname>Ryten</surname><given-names>M</given-names></string-name>, <string-name><surname>Maynard</surname><given-names>KR</given-names></string-name> (<year>2023</year>) Integrated single cell and unsupervised spatial transcriptomic analysis defines molecular anatomy of the human dorsolateral prefrontal cortex. BioRxiv.</mixed-citation>
    </ref>
    <ref id="r40">
      <label>40.</label>
      <mixed-citation publication-type="other" id="ref40"><collab>Indica Labs</collab> (<year>2022</year>) HALO [Internet]. [cited 19 April 2022]. Available at <uri xlink:href="https://indicalab.com/?page_id=2637">https://indicalab.com/?page_id=2637</uri>.</mixed-citation>
    </ref>
    <ref id="r41">
      <label>41.</label>
      <mixed-citation publication-type="other" id="ref41"><collab>The MathWorks, Inc.</collab> (<year>2022</year>) MATLAB Open Science [Internet]. [cited 28 April 2022]. Available at <uri xlink:href="https://www.mathworks.com/discovery/open-science.html">https://www.mathworks.com/discovery/open-science.html</uri>.</mixed-citation>
    </ref>
    <ref id="r42">
      <label>42.</label>
      <mixed-citation publication-type="journal" id="ref42"><string-name><surname>Hao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hao</surname><given-names>S</given-names></string-name>, <string-name><surname>Andersen-Nissen</surname><given-names>E</given-names></string-name>, <string-name><surname>Mauck</surname><given-names>WM</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>S</given-names></string-name>, <string-name><surname>Butler</surname><given-names>A</given-names></string-name>, <string-name><surname>Lee</surname><given-names>MJ</given-names></string-name>, <string-name><surname>Wilk</surname><given-names>AJ</given-names></string-name>, <string-name><surname>Darby</surname><given-names>C</given-names></string-name>, <string-name><surname>Zager</surname><given-names>M</given-names></string-name>, <string-name><surname>Hoffman</surname><given-names>P</given-names></string-name>, <string-name><surname>Stoeckius</surname><given-names>M</given-names></string-name>, <string-name><surname>Papalexi</surname><given-names>E</given-names></string-name>, <string-name><surname>Mimitou</surname><given-names>EP</given-names></string-name>, <string-name><surname>Jain</surname><given-names>J</given-names></string-name>, <string-name><surname>Srivastava</surname><given-names>A</given-names></string-name>, <string-name><surname>Stuart</surname><given-names>T</given-names></string-name>, <string-name><surname>Fleming</surname><given-names>LM</given-names></string-name>, <string-name><surname>Yeung</surname><given-names>B</given-names></string-name>, <string-name><surname>Rogers</surname><given-names>AJ</given-names></string-name>, <string-name><surname>Satija</surname><given-names>R</given-names></string-name> (<year>2021</year>) <article-title>Integrated analysis of multimodal single-cell data</article-title>. <source>Cell</source>
<volume>184</volume>(<issue>13</issue>), <fpage>3573</fpage>–<lpage>3587</lpage>.e29.<pub-id pub-id-type="pmid">34062119</pub-id>
</mixed-citation>
    </ref>
    <ref id="r43">
      <label>43.</label>
      <mixed-citation publication-type="other" id="ref43"><string-name><surname>Virshup</surname><given-names>I</given-names></string-name>, <string-name><surname>Rybakov</surname><given-names>S</given-names></string-name>, <string-name><surname>Theis</surname><given-names>FJ</given-names></string-name>, <string-name><surname>Angerer</surname><given-names>P</given-names></string-name>, <string-name><surname>Wolf</surname><given-names>FA</given-names></string-name> (<year>2021</year>) anndata: annotated data. BioRxiv.</mixed-citation>
    </ref>
    <ref id="r44">
      <label>44.</label>
      <mixed-citation publication-type="other" id="ref44"><string-name><surname>Zappia</surname><given-names>L, Lun A, Cannoodt R</given-names></string-name> (<year>2020</year>) zellkonverter: Conversion Between scRNA-seq Objects. Bioconductor.</mixed-citation>
    </ref>
    <ref id="r45">
      <label>45.</label>
      <mixed-citation publication-type="journal" id="ref45"><string-name><surname>Lipska</surname><given-names>BK</given-names></string-name>, <string-name><surname>Deep-Soboslay</surname><given-names>A</given-names></string-name>, <string-name><surname>Weickert</surname><given-names>CS</given-names></string-name>, <string-name><surname>Hyde</surname><given-names>TM</given-names></string-name>, <string-name><surname>Martin</surname><given-names>CE</given-names></string-name>, <string-name><surname>Herman</surname><given-names>MM</given-names></string-name>, <string-name><surname>Kleinman</surname><given-names>JE</given-names></string-name> (<year>2006</year>) <article-title>Critical factors in gene expression in postmortem human brain: focus on studies in schizophrenia</article-title>. <source>Biological Psychiatry</source>
<volume>60</volume>(<issue>6</issue>), <fpage>650</fpage>–<lpage>658</lpage>.<pub-id pub-id-type="pmid">16997002</pub-id>
</mixed-citation>
    </ref>
    <ref id="r46">
      <label>46.</label>
      <mixed-citation publication-type="other" id="ref46">10× Genomics (<year>2021</year>) Imaging guidelines. [cited 18 April 2022]. Available at <uri xlink:href="https://assets.ctfassets.net/an68im79xiti/7t2k87zNaujdxcaAesoPB8/add94b0b5869d3c50825b691ffc98373/CG000241_VisiumImagingGuidelinesTN_RevD.pdf">https://assets.ctfassets.net/an68im79xiti/7t2k87zNaujdxcaAesoPB8/add94b0b5869d3c50825b691ffc98373/CG000241_VisiumImagingGuidelinesTN_RevD.pdf</uri>.</mixed-citation>
    </ref>
    <ref id="r47">
      <label>47.</label>
      <mixed-citation publication-type="other" id="ref47"><collab>Lieber Institute for Brain Development MT</collab> (<year>2021</year>) <italic toggle="yes">VistoSeg Software [Internet]. Zenodo.</italic> [cited 24 April 2022]. Available at <pub-id pub-id-type="doi">10.5281/zenodo.5156783</pub-id>.</mixed-citation>
    </ref>
    <ref id="r48">
      <label>48.</label>
      <mixed-citation publication-type="other" id="ref48"><string-name><surname>Tippani</surname><given-names>M</given-names></string-name>, <string-name><surname>Divecha</surname><given-names>HR</given-names></string-name>, Catallini II JL, <string-name><surname>Weber</surname><given-names>LM</given-names></string-name>, <string-name><surname>Kwon</surname><given-names>SH</given-names></string-name>, <string-name><surname>Spangler</surname><given-names>A</given-names></string-name>, <string-name><surname>Jaffe</surname><given-names>A</given-names></string-name>, <string-name><surname>Hicks</surname><given-names>SC</given-names></string-name>, <string-name><surname>Martinowich</surname><given-names>K</given-names></string-name>, <string-name><surname>Collado-Torres</surname><given-names>L</given-names></string-name>, <string-name><surname>Page</surname><given-names>SC</given-names></string-name>, <string-name><surname>Maynard</surname><given-names>K</given-names></string-name> (<year>2022</year>) VistoSeg: processing utilities for high-resolution Visium/Visium-IF images for spatial transcriptomics data (supplementary material). Figshare.</mixed-citation>
    </ref>
    <ref id="r49">
      <label>49.</label>
      <mixed-citation publication-type="other" id="ref49"><collab>10× Genomics</collab> (<year>2022</year>) 10× Genomics public datasets [Internet]. [cited 17 April 2022]. Available at <uri xlink:href="https://www.10xgenomics.com/resources/datasets">https://www.10xgenomics.com/resources/datasets</uri>.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Biol Imaging</journal-id>
    <journal-id journal-id-type="iso-abbrev">Biol Imaging</journal-id>
    <journal-id journal-id-type="publisher-id">BLG</journal-id>
    <journal-title-group>
      <journal-title>Biological Imaging</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2633-903X</issn>
    <publisher>
      <publisher-name>Cambridge University Press</publisher-name>
      <publisher-loc>Cambridge, UK</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10951916</article-id>
    <article-id pub-id-type="doi">10.1017/S2633903X23000235</article-id>
    <article-id pub-id-type="publisher-id">S2633903X23000235</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software Report</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title><italic toggle="yes">VistoSeg</italic>: Processing utilities for high-resolution images for spatially resolved transcriptomics data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Tippani</surname>
          <given-names>Madhavi</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Divecha</surname>
          <given-names>Heena R.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Catallini</surname>
          <given-names>Joseph L.</given-names>
          <suffix>II</suffix>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kwon</surname>
          <given-names>Sang H.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Weber</surname>
          <given-names>Lukas M.</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Spangler</surname>
          <given-names>Abby</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jaffe</surname>
          <given-names>Andrew E.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hyde</surname>
          <given-names>Thomas M.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="aff5" ref-type="aff">
          <sup>5</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kleinman</surname>
          <given-names>Joel E.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-7858-0231</contrib-id>
        <name>
          <surname>Hicks</surname>
          <given-names>Stephanie C.</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Martinowich</surname>
          <given-names>Keri</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="aff6" ref-type="aff">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Collado-Torres</surname>
          <given-names>Leonardo</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Page</surname>
          <given-names>Stephanie C.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-0031-8468</contrib-id>
        <name>
          <surname>Maynard</surname>
          <given-names>Kristen R.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><label>1</label>Lieber Institute for Brain Development, <institution>Johns Hopkins Medical Campus</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <aff id="aff2"><label>2</label>Department of Biostatistics, <institution>Johns Hopkins Bloomberg School of Public Health</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <aff id="aff3"><label>3</label>Department of Neuroscience, <institution>Johns Hopkins University School of Medicine</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <aff id="aff4"><label>4</label>Department of Psychiatry and Behavioral Sciences, <institution>Johns Hopkins University School of Medicine</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <aff id="aff5"><label>5</label>Department of Neurology, <institution>Johns Hopkins School of Medicine</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <aff id="aff6"><label>6</label>The Kavli Neuroscience Discovery Institute, <institution>Johns Hopkins University</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <author-notes>
      <corresp id="cor1"><bold>Corresponding authors:</bold> Madhavi Tippani, Stephanie C. Page, and Kristen R. Maynard; Emails: <email>madhavi.tippani@libd.org</email>; <email>stephanie.page@libd.org</email>; <email>kristen.maynard@libd.org</email></corresp>
    </author-notes>
    <pub-date publication-format="electronic" date-type="collection" iso-8601-date="2023">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>13</day>
      <month>11</month>
      <year>2023</year>
    </pub-date>
    <volume>3</volume>
    <elocation-id>e23</elocation-id>
    <history>
      <date date-type="received">
        <day>25</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>14</day>
        <month>7</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>19</day>
        <month>9</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>The Author(s)</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This is an Open Access article, distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivatives licence (<uri xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0</uri>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided that no alterations are made and the original article is properly cited. The written permission of Cambridge University Press must be obtained prior to any commercial use and/or adaptation of the article.</license-p>
      </license>
    </permissions>
    <self-uri xlink:title="pdf" xlink:href="S2633903X23000235a.pdf"/>
    <abstract>
      <p>Spatially resolved transcriptomics (SRT) is a growing field that links gene expression to anatomical context. SRT approaches that use next-generation sequencing (NGS) combine RNA sequencing with histological or fluorescent imaging to generate spatial maps of gene expression in intact tissue sections. These technologies directly couple gene expression measurements with high-resolution histological or immunofluorescent images that contain rich morphological information about the tissue under study. While broad access to NGS-based spatial transcriptomic technology is now commercially available through the Visium platform from the vendor 10× Genomics, computational tools for extracting image-derived metrics for integration with gene expression data remain limited. We developed <italic toggle="yes">VistoSeg</italic> as a MATLAB pipeline to process, analyze and interactively visualize the high-resolution images generated in the Visium platform. <italic toggle="yes">VistoSeg</italic> outputs can be easily integrated with accompanying transcriptomic data to facilitate downstream analyses in common programing languages including R and Python. <italic toggle="yes">VistoSeg</italic> provides user-friendly tools for integrating image-derived metrics from histological and immunofluorescent images with spatially resolved gene expression data. Integration of this data enhances the ability to understand the transcriptional landscape within tissue architecture. <italic toggle="yes">VistoSeg</italic> is freely available at <uri xlink:href="http://research.libd.org/VistoSeg/">http://research.libd.org/VistoSeg/</uri>.</p>
    </abstract>
    <kwd-group>
      <title>Keywords</title>
      <kwd>hematoxylin and eosin</kwd>
      <kwd>immunofluorescence</kwd>
      <kwd>MATLAB</kwd>
      <kwd>segmentation</kwd>
      <kwd>spatially resolved transcriptomics</kwd>
      <kwd>Visium</kwd>
      <kwd>Visium-Spatial Proteogenomics</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="aw001">
        <funding-source>
          <institution-wrap>
            <institution>Lieber Institute for Brain Development</institution>
            <institution-id institution-id-type="doi">http://dx.doi.org/10.13039/100015503</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group id="aw002">
        <funding-source>
          <institution-wrap>
            <institution>National Institute of Mental Health</institution>
            <institution-id institution-id-type="doi">http://dx.doi.org/10.13039/100000025</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R01MH126393</award-id>
      </award-group>
      <award-group id="aw003">
        <funding-source>
          <institution-wrap>
            <institution>National Institute of Mental Health</institution>
            <institution-id institution-id-type="doi">http://dx.doi.org/10.13039/100000025</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>U01MH122849</award-id>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="4"/>
      <ref-count count="49"/>
      <page-count count="15"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="other" id="sec1">
    <title>Impact Statement</title>
    <p>The advent of spatially resolved transcriptomics (SRT) technologies has facilitated the study of gene expression in an anatomical context. However, next-generation sequencing (NGS)-based SRT approaches pose an emerging challenge: integrating transcriptome-wide spatial gene expression with high-resolution tissue images (brightfield histology or fluorescent antibody staining) to generate precise maps of spatial gene expression across intact tissue sections. We developed <italic toggle="yes">VistoSeg</italic> as an image-processing software to address these needs. <italic toggle="yes">VistoSeg</italic> is currently compatible with the Visium and Visium Spatial Proteogenomics (Visium-SPG) platforms (10× Genomics), which are NGS-based SRT assays employing histological and immunofluorescent tissue images, respectively. <italic toggle="yes">VistoSeg</italic> provides computational imaging-processing tools to extract cell number, cell type identity, and other image-derived metrics at spatially defined locations across the tissue section to incorporate with corresponding gene expression measurements.</p>
  </sec>
  <sec sec-type="intro" id="sec2">
    <label>1.</label>
    <title>Introduction</title>
    <p>In the past decade, RNA sequencing (RNA-seq) moved beyond profiling in homogenate tissue to defining gene expression at single-cell or single-nucleus (sc/snRNA-seq) resolution. This technological development motivated the generation of new computational methods that answered many previously unaddressed biological questions. However, spatial information about where cells resided within the tissue remained lacking. Spatially resolved transcriptomics (SRT) is a new class of technologies that measures gene expression along spatial coordinates.<sup>(</sup><xref rid="r1" ref-type="bibr"><sup>1</sup></xref><sup>)</sup> Next-generation sequencing (NGS)-based SRT technologies are especially powerful for their ability to define transcriptome-wide gene expression patterns across intact tissue sections. While there are several laboratories that have developed custom methods to perform NGS-based SRT,<sup>(</sup><xref rid="r2" ref-type="bibr"><sup>2</sup></xref><sup>–</sup><xref rid="r5" ref-type="bibr"><sup>5</sup></xref><sup>)</sup> the commercially available Visium platform from 10× Genomics is the leading and most widely adopted technology for generating transcriptome-wide spatial gene expression data in intact tissue sections.<sup>(</sup><xref rid="r6" ref-type="bibr"><sup>6</sup></xref><sup>)</sup> Because SRT data includes paired gene expression and microscopy images from the same tissue section, analysis of this data necessitates tools to integrate both modalities.</p>
    <p>The Visium workflow uses an on-slide spatial barcoding strategy to map RNA-seq reads to defined anatomical locations (“spots”) in an intact tissue section (<xref rid="fig1" ref-type="fig">Figure 1a</xref>). Briefly, each slide contains four arrays (<xref rid="fig1" ref-type="fig">Figure 1b</xref>: A1, B1, C1, D1), and each array contains ~5,000 gene expression capture “spots,” which are 55 μm in diameter (2,375 μm<sup>2</sup> in area) and spaced 100 μm center-to-center in a honeycomb pattern (<xref rid="fig1" ref-type="fig">Figure 1b</xref>). On-slide cDNA synthesis incorporates spatial barcodes for each spot, which is followed by RNA-seq to obtain gene expression measurements at each anatomical location (<xref rid="fig1" ref-type="fig">Figure 1c</xref>). The platform currently supports two major workflows: Visium-H&amp;E and Visium-Spatial Proteogenomics (Visium-SPG). In the Visium-H&amp;E workflow, tissue sections are stained with hematoxylin and eosin (H&amp;E), and a brightfield histological image is acquired. In Visium-SPG, tissue sections are labeled with antibodies conjugated to fluorophores, and multiplex fluorescent images are acquired to visualize specific proteins of interest. In both cases, images are used to create an integrated map of transcriptome-wide gene expression within the tissue architecture. In the case of Visium-SPG, transcriptomic data can also be analyzed in the context of proteomic data from antibody labeling.<fig position="float" id="fig1"><label>Figure 1.</label><caption><p>Visium workflow. (a) Visium spatial gene expression slide containing four 6.5 mm x 6.5 mm capture areas bound by a fiducial frame. (b) Each capture area contains a grid printed with ~5,000 spots with unique spatial barcodes that allow mRNA measurements to be mapped back to the X–Y location on the tissue. (c) Spatial barcodes are incorporated during on-slide cDNA synthesis. The cDNA is eluted off the slide, and libraries are prepared and sequenced. Reads are mapped to spatial coordinates on the histological image using SpaceRanger software (10× Genomics), which provides a transcriptome-wide readout of gene expression at each spatial coordinate.</p></caption><graphic xlink:href="S2633903X23000235_fig1" position="float"/></fig></p>
    <p>To maintain RNA integrity for compatibility with downstream transcriptomic workflows, speed and throughput capacity are important considerations for image acquisition protocols. In line with these considerations, imaging is often performed on slide scanners or other high-throughput microscopy systems that are commonly used for pathology image acquisition and analysis. To support integration with downstream molecular gene expression data, preprocessing utilities are needed to separate the large whole-slide images into single images representing each individual tissue section. These images then need to be further segmented to extract meaningful metrics about cell number, morphology, position, etc. Current analytical tools available from 10× Genomics focus heavily on gene expression data and do not support in-depth processing or analysis (e.g., nuclear or cellular segmentation) of imaging data. Specifically, 10× Genomics provides two software programs, Loupe Browser<sup>(</sup><xref rid="r7" ref-type="bibr"><sup>7</sup></xref><sup>)</sup> and SpaceRanger,<sup>(</sup><xref rid="r8" ref-type="bibr"><sup>8</sup></xref><sup>)</sup> which enable data extraction and primary visualization of SRT data, but have limited functionality for more advanced processing.</p>
    <p>Other existing software also fail to provide the necessary functionalities that would allow users to take the images from preprocessing to quantitative integration of gene expression data with extracted metrics. For example, the open source software package QuPath<sup>(</sup><xref rid="r9" ref-type="bibr"><sup>9</sup></xref><sup>)</sup> does not support preprocessing of the multichannel fluorescent images and requires downsampling, resulting in reduced image resolution when opening, cropping and exporting images. The commercially available image analysis software HALO enables quantification and classification of cells and nuclei, but does not support integration with gene expression data. Several software packages have been developed in the Python and R programming languages for cell segmentation and subsequent registration of microscopy images to anatomical reference atlases.<sup>(</sup><xref rid="r10" ref-type="bibr"><sup>10</sup></xref><sup>,</sup><xref rid="r11" ref-type="bibr"><sup>11</sup></xref><sup>)</sup> While some of these frameworks have been applied to SRT data,<sup>(</sup><xref rid="r12" ref-type="bibr"><sup>12</sup></xref><sup>)</sup> they were designed and optimized for cultured cells and mouse brain tissue sections. In contrast, other packages, such as Fiji<sup>(</sup><xref rid="r13" ref-type="bibr"><sup>13</sup></xref><sup>)</sup> and CellProfiler,<sup>(</sup><xref rid="r14" ref-type="bibr"><sup>14</sup></xref><sup>)</sup> lack functions to automatically split large whole-slide images into individual arrays and have limited features for visualizing large images.</p>
    <p>The limited functionality of currently available resources poses a significant problem for the field because the acquired images contain valuable information that could be more fully mined and incorporated into downstream analyses.<sup>(</sup><xref rid="r15" ref-type="bibr"><sup>15</sup></xref><sup>,</sup><xref rid="r16" ref-type="bibr"><sup>16</sup></xref><sup>)</sup> For example, in the Visium-H&amp;E platform, cell/nuclei segmentation in the H&amp;E images can be used to estimate the number of cells in each gene expression spot or to identify cell types based on classic morphologies.<sup>(</sup><xref rid="r16" ref-type="bibr"><sup>16</sup></xref><sup>,</sup><xref rid="r17" ref-type="bibr"><sup>17</sup></xref><sup>)</sup> Analysis of H&amp;E images can also identify spots containing a single cell, or spots enriched in specific cellular compartments (i.e., axon- and dendrite-rich neuropil in brain tissue).<sup>(</sup><xref rid="r18" ref-type="bibr"><sup>18</sup></xref><sup>)</sup> Gene expression clustering algorithms are also beginning to incorporate metrics from imaging data, such as RGB (Red, Green, Blue) color values, to better define anatomically relevant spatial regions across tissue sections.<sup>(</sup><xref rid="r15" ref-type="bibr"><sup>15</sup></xref><sup>)</sup></p>
    <p>Furthermore, Visium-SPG technology is especially powerful as it can be used to label specific cell types. Combining gene expression data with images where known cell types have been fluorescently labeled can generate a ground truth for evaluating <italic toggle="yes">in silico</italic> methods that aim to perform spot deconvolution and identify cell type proportions across spots.<sup>(</sup><xref rid="r19" ref-type="bibr"><sup>19</sup></xref><sup>–</sup><xref rid="r21" ref-type="bibr"><sup>21</sup></xref><sup>)</sup> Using the Visium-SPG platform, images can also be segmented to identify the locations and quantify the abundance of proteins that are associated with known pathologies. This data can then be used to analyze local gene expression in the context of pathology to better understand molecular associations of disease.<sup>(</sup><xref rid="r22" ref-type="bibr"><sup>22</sup></xref><sup>)</sup> Moreover, since RNA expression is not always fully predictive of protein abundance levels, Visium-SPG and its associated fluorescent images can be used to quantify protein abundance. This is especially relevant for proteins where RNA quantification cannot serve as a proxy for expression, such as extracellular matrix proteins or secreted factors.<sup>(</sup><xref rid="r23" ref-type="bibr"><sup>23</sup></xref><sup>)</sup></p>
    <p>To address these challenges and provide an end-to-end solution that is tailored to image-processing analysis for the Visium-H&amp;E and -SPG platforms, we developed <italic toggle="yes">VistoSeg.</italic>
<italic toggle="yes">VistoSeg</italic> is a MATLAB-based software package that facilitates preprocessing, segmentation, analysis and visualization of H&amp;E and immunofluorescent images generated on the Visium-H&amp;E and Visium-SPG platforms for integration with gene expression data. We also provide user-friendly tutorials and vignettes to support the application of <italic toggle="yes">VistoSeg</italic> to new datasets generated by the scientific community.</p>
  </sec>
  <sec sec-type="results" id="sec3">
    <label>2.</label>
    <title>Results</title>
    <p>Here we describe the implementation and requirements for <italic toggle="yes">VistoSeg,</italic> an automated pipeline for processing high-resolution histological or immunofluorescent images acquired using Visium-H&amp;E or Visium-SPG workflows, for integration with downstream spatial transcriptomics analysis.</p>
    <sec sec-type="other" id="sec4">
      <label>2.1.</label>
      <title>H&amp;E image processing</title>
      <p>Prior to image analysis, we collected brain tissue sections from the dorsolateral prefrontal cortex (<xref rid="fig2" ref-type="fig">Figure 2a</xref>) and performed the Visium-H&amp;E workflow.<sup>(</sup><xref rid="r18" ref-type="bibr"><sup>18</sup></xref><sup>)</sup> Tissue sections were stained with H&amp;E, and brightfield histology images were acquired using a Leica Aperio CS2 slide scanner (<xref rid="fig2" ref-type="fig">Figure 2b</xref>). Because the TIFF images acquired on the slide scanner include the whole slide, which contains four arrays (<xref rid="fig2" ref-type="fig">Figure 2c</xref>), the image needs to be split into individual capture area arrays to proceed with downstream analysis. We created a function (<italic toggle="yes">splitslide</italic>) that reads in the TIFF image as an RGB matrix and splits it along the x-axis into four equal RGB matrices. Each individual RGB matrix is considered a capture area and is saved as a separate RGB TIFF file at 70% resolution of the raw individual RGB matrix. For example, a matrix that is of size 10,000 × 10,000 × 3 pixels is resized to 7,000 × 7,000 × 3 pixels. Since MATLAB requires that image files (TIFF, PNG, JPEG) be no larger than 2<sup>32</sup> − 1 bytes, image downsampling is necessary since the raw files would exceed these limitations. Individual resized matrices/images are saved at the downsampled resolution of at least 2,000 pixels in either dimension (X and Y).<fig position="float" id="fig2"><label>Figure 2.</label><caption><p>VistoSeg workflow for Visium H&amp;E image processing. (a) Example data collection from postmortem human dorsolateral prefrontal cortex (DLPFC). Each tissue block and corresponding 10-μm section spans the six cortical layers and white matter. (b) Four tissue sections were placed on a Visium gene expression slide and stained with H&amp;E. Brightfield images were acquired using a Leica Aperio CS2 slide scanner. (c) The CS2 scanner produces a large, high-resolution image of the entire slide in TIFF format, which VistoSeg splits into four individual capture areas using splitslide. (d) VistoSeg uses a two-step process for nuclei segmentation, called VNS and refineVNS, to segment nuclei in each individual capture area. (e) Concurrent with nuclei segmentation, individual capture area images from (d) are processed using SpaceRanger (10× Genomics) to align gene expression data to the histological image and export spot metrics including spot diameter, spot spacing and spot coordinates (titled by default as “tissue_positions_list.csv” and “scalefactors_json.json”). (f) The countNuclei function in VistoSeg computes the number of cells/nuclei per spot using the outputs from SpaceRanger, which is then exported as the “tissue_spot_counts.csv” file. (g) VistoSeg includes an interactive GUI, spotspotcheck, which enables the user to toggle between the segmented binary image and raw histology image to visually inspect the segmented nuclei in each spot. Users can zoom in/out on the high-resolution image. A search tab enables users to locate spots of interest based on the barcode identifier, which enables exploration of image features related to gene expression patterns.</p></caption><graphic xlink:href="S2633903X23000235_fig2" position="float"/></fig></p>
      <p>To align the sequencing files containing gene expression information with specific spatial locations (i.e., spots) on the image, users must employ the SpaceRanger software provided by 10× Genomics.<sup>(</sup><xref rid="r8" ref-type="bibr"><sup>8</sup></xref><sup>)</sup> Using the fiducial frame on the image as reference, SpaceRanger uses the downsized TIFF files produced by the <italic toggle="yes">splitSlide</italic> function<sup>(</sup><xref rid="r24" ref-type="bibr"><sup>24</sup></xref><sup>)</sup> as input to extract the barcode identifier (ID), pixel (X, Y) centroid location, and radius of each spot. SpaceRanger does not extract any information from the image beyond the presence or absence of tissue at a particular location. The output of SpaceRanger is a list of tissue positions (<italic toggle="yes">.csv)</italic> and the scale factors (<italic toggle="yes">.json</italic>) (named as tissue_positions_list.csv and scalefactors_json.json by default) to enable the quantification of gene expression in a spatial context. Further information regarding the workflow and implementation of SpaceRanger<sup>(</sup><xref rid="r8" ref-type="bibr"><sup>8</sup></xref><sup>)</sup> is available on our accompanying website: <uri xlink:href="http://research.libd.org/VistoSeg/step-3-spaceranger.html">http://research.libd.org/VistoSeg/step-3-spaceranger.html</uri>. To facilitate extraction of relevant imaging metrics at the same spatial locations (spots) queried for gene expression, <italic toggle="yes">VistoSeg</italic> uses the output .<italic toggle="yes">csv</italic> and .<italic toggle="yes">json</italic> files from SpaceRanger to build the spot grid on the image and enable the extraction of image-based metrics (e.g., nuclei count, percentage spot covered by nuclei) for each spot location (<xref rid="fig2" ref-type="fig">Figure 2e</xref>). The image-based information and the gene expression-based data are grouped together using the spot barcode identifier, which enables the quantification of gene expression and morphology metrics in a spatial context.</p>
      <p>To segment nuclei from the H&amp;E image (<xref rid="fig3" ref-type="fig">Figure 3a</xref>), we performed Gaussian smoothing and then applied contrast adjustments (<xref rid="fig3" ref-type="fig">Figure 3a</xref>) to enhance nuclei visibility in the image (<xref rid="fig3" ref-type="fig">Figure 3b</xref>). The enhanced image was then converted from RGB color space to CIELAB color space, also called L*a*b color space (<xref rid="fig3" ref-type="fig">Figure 3c</xref>). L*a*b color space is defined by: “L,” luminosity layer measures lightness from black to white; “a,” chromaticity layer measures color along the red–green axis; and “b,” chromaticity layer measures color along blue–yellow axis. CIELAB color space enables the quantification of the individual color gradients that are visually observable across the image. The a*b color space is extracted from the L*a*b-converted image and used as input to <italic toggle="yes">K</italic>-means clustering with the MATLAB function <italic toggle="yes">imsegkmeans</italic> (<xref rid="fig3" ref-type="fig">Figure 3d</xref>), along with the number of color gradients (<italic toggle="yes">k</italic>) that were visually identified in the image. The function output creates a binary mask for each color gradient (<italic toggle="yes">k</italic>) in the image. Given that nuclei in H&amp;E images have a bright color that can be easily differentiated from the background, we used a binary mask generated from the nuclei color gradient for initial nuclei segmentation to identify nuclei as regions of interest (ROIs; <xref rid="fig3" ref-type="fig">Figure 3d</xref>, cluster 3, <xref rid="fig3" ref-type="fig">Figure 3d<bold>’</bold></xref>). We combined these steps (<xref rid="fig3" ref-type="fig">Figure 3a–d’</xref>) into a function termed <italic toggle="yes">VNS</italic> (Visium Nuclei Segmentation).<fig position="float" id="fig3"><label>Figure 3.</label><caption><p>VistoSeg workflow for Visium H&amp;E image segmentation. (a) Raw histology image of human dorsolateral prefrontal cortex. (b) Gaussian smoothed and contrast-adjusted image of the raw histology image in (a). (c) Enhanced image from (b) converted from RGB color space to L*a*b color space. (d) Different color gradients (k = 5) identified by the MATLAB function imsegkmeans applied to the raw histology image. Cluster 3 corresponded to the nuclei, stained blue in the raw histology image. (d’) An inset of nuclei cluster 3 in (d). (e) Output of refineVNS from nuclei cluster 3 (d’). The refineVNS function allows for separation of adjacent nuclei. (f) Final binary nuclei segmentation obtained from (e).</p></caption><graphic xlink:href="S2633903X23000235_fig3" position="float"/></fig></p>
      <p>Due to the smoothing step applied, the nuclei edges are blurred, and hence nuclei in close proximity to one another are segmented as a single ROI (<xref rid="fig3" ref-type="fig">Figure 3d’</xref>). To further refine these segmentations to detect and quantify individual nuclei (<xref rid="fig3" ref-type="fig">Figure 3f</xref>), we created a second function (termed <italic toggle="yes">refineVNS</italic>) that extracts the intensity of the pixels from the binary mask of nuclei generated by <italic toggle="yes">VNS</italic> and applies intensity thresholding<sup>(</sup><xref rid="r25" ref-type="bibr"><sup>25</sup></xref><sup>)</sup> to separate the darker nuclei regions at the center from the lighter regions at the borders (<xref rid="fig3" ref-type="fig">Figure 3e</xref>). The final segmentation output is a binary image. The use of our <italic toggle="yes">VNS</italic> and <italic toggle="yes">refineVNS</italic> function results in segmentation of individual cell bodies in human DLPFC tissue (<xref rid="fig2" ref-type="fig">Figures 2g</xref> and <xref rid="fig3" ref-type="fig">3d–f</xref>).</p>
    </sec>
    <sec sec-type="other" id="sec5">
      <label>2.2.</label>
      <title>Multichannel fluorescent image processing</title>
      <p>In the Visium-SPG platform, samples are subjected to immunofluorescent antibody labeling to detect specific proteins of interest, thereby generating proteomic data that can be quantified and integrated with transcriptomic data. We collected four individual tissue sections of the human dorsolateral prefrontal cortex (DLPFC) spanning the six cortical layers and white matter and performed the Visium-SPG workflow (<xref rid="fig4" ref-type="fig">Figure 4</xref>). To visualize cellular composition and cell type distribution across the tissue section, samples were immunostained with four established cell type markers: NeuN (Alexa 555) for neurons, TMEM119 (Alexa 647) for microglia, GFAP (Alexa 488) for astrocytes, and OLIG2 (Alexa 647) for oligodendrocytes. Immunofluorescent images were acquired using a Vectra Polaris slide scanner (Akoya Biosciences) and processed to decompose the multispectral profiles (<xref rid="fig4" ref-type="fig">Figure 4a</xref>).<sup>(</sup><xref rid="r26" ref-type="bibr"><sup>26</sup></xref><sup>,</sup><xref rid="r27" ref-type="bibr"><sup>27</sup></xref><sup>)</sup> The final image outputs were spectrally unmixed multichannel TIFF tiles of the entire slide (~600 tiles). These individual tiles were stitched to recreate a multichannel TIFF image spanning the whole slide (<xref rid="fig4" ref-type="fig">Figure 4b</xref>) using the X and Y coordinates of each tile, as saved in the filename, to position tiles (<italic toggle="yes">inFormStitch</italic>). Next, this image was split along the Y-axis into four individual capture area images in multichannel TIFF format (<italic toggle="yes">splitSlide_IF</italic>; <xref rid="fig4" ref-type="fig">Figure 4c</xref>). We then segmented each fluorescent channel to identify ROIs (<xref rid="fig4" ref-type="fig">Figure 4d</xref>) as previously described.<sup>(</sup><xref rid="r28" ref-type="bibr"><sup>28</sup></xref><sup>)</sup> Finally, we used the <italic toggle="yes">countNuclei</italic> function to quantify the size, intensity and location of segmented signals in each channel for integration with gene expression data (<xref rid="fig4" ref-type="fig">Figure 4e</xref>). The output table from <italic toggle="yes">countNuclei</italic> has two columns per channel by default: (1) count of segmented ROIs per Visium spot and (2) proportion of the spot covered by the segmented signal. Other user-defined metrics, including mean fluorescent intensity per spot or mean intensity of segmented ROIs for each channel within a spot, can also be extracted. Quantification of immunofluorescent signals in white matter of the dorsolateral prefrontal cortex (<xref rid="fig4" ref-type="fig">Figure 4g</xref>) is consistent with our expectation of higher counts for glial cells stained by TMEM119 (microglia), GFAP (astrocytes) and OLIG2 (oligodendrocytes) compared to the neuron-enriched gray matter (<uri xlink:href="https://doi.org/10.1017/S2633903X23000235">Supplementary Figure 1</uri>).<fig position="float" id="fig4"><label>Figure 4.</label><caption><p>VistoSeg workflow for Visium-SPG immunofluorescent image processing and segmentation. (a) Multispectral immunofluorescent images of the gene expression slide from the Visium-SPG workflow were acquired using a Vectra Polaris slide scanner (Akoya). All arrays on the slide were annotated as a single selection using Phenochart software (Akoya) and split into multiple tiles. Each tile was spectrally unmixed into multichannel TIFFs using inForm software (Akoya) by applying spectral fingerprints specific for each fluorophore. Autofluorescence was separated into its own channel. (b) After unmixing, the tiles from (a) were put into the VistoSeg preprocessing workflow and stitched using the inFormstitch function to recreate a multichannel TIFF of the whole slide. (c) The recreated multichannel TIFF was then split into individual arrays using splitSlide_IF. (d) Representative segmentation for capture area A1. Nuclei segmentation to identify fluorescent signal for the nucleus (DAPI) and each labeled protein (GFAP, NEUN, OLIG2, TMEM119) was performed by integrating functions from our previously published software, dotdotdot.<sup>(</sup><xref rid="r28" ref-type="bibr"><sup>28</sup></xref><sup>)</sup> (e) Using the split images from (c), Space Ranger (10× Genomics) was used to align multiplex fluorescent imaging and gene expression data and obtain extracted spot metrics (Visium spot diameter, spot spacing and spot coordinates) from each image in the “tissue_positions_list.csv” and “scalefactors_json.json” files. (f) The spotspotcheck GUI in VisotSeg provides a dropdown menu for each fluorescent channel in the multichannel TIFF (labeled by the spectral profile assigned to each protein of interest: DAPI, GFAP, NeuN, OLIG2, TMEM119 in this example). It allows for visual inspection by hovering over different regions in the image. For example, we explored the white matter (white square) and gray matter (gray square) in this representative sample. (g) The signal count per gene expression spot computed by countNuclei on the white matter (white square in f) confirms increased abundance of OLIG2, GFAP and TMEM119 staining, and relative depletion of NeuN staining, in line with expectations.</p></caption><graphic xlink:href="S2633903X23000235_fig4" position="float"/></fig></p>
    </sec>
    <sec sec-type="other" id="sec6">
      <label>2.3.</label>
      <title>Integration of segmentation output with gene expression spot location</title>
      <p>We generated an additional function (termed <italic toggle="yes">countNuclei</italic>) to calculate the number of nuclei residing within each spot. This function uses the point-in-polygon concept to calculate the number of nuclei per spot by integrating the coordinate information obtained from SpaceRanger with the segmentation mask to calculate the number of nuclei per spot. The <italic toggle="yes">countNuclei</italic> function accepts segmentation from alternative methods, if saved in a “.mat” format. The output of this function is a table that contains the number of nuclei and the percentage nuclei coverage per gene expression spot, which can be exported as a .<italic toggle="yes">csv</italic> file for each sample to be used in downstream analyses. Two types of nuclei counts are provided per spot, based on the two possible measurement criteria for calling presence/absence of nuclei: (1) inclusion of the centroid of the ROI within the spot, (2) user-defined threshold for the number of pixels necessary to count a cell as within the spot.</p>
      <p>To enable the user to visually inspect nuclei segmentation output, we developed a GUI termed <italic toggle="yes">spotspotcheck.</italic> This GUI reconstructs and overlays the spot grid, generated using the output of SpaceRanger, onto the original image and the binary segmentation, generated using the output of <italic toggle="yes">refineVNS,</italic> to display the nuclei count in each spot. The <italic toggle="yes">spotspotcheck</italic> GUI supports both H&amp;E images (<xref rid="fig2" ref-type="fig">Figure 2g</xref> and <uri xlink:href="https://doi.org/10.1017/S2633903X23000235">Supplementary Figures 2</uri> and <uri xlink:href="https://doi.org/10.1017/S2633903X23000235">3</uri>) and immunofluorescent images (<xref rid="fig4" ref-type="fig">Figure 4f</xref>,<xref rid="fig4" ref-type="fig">g</xref>, <uri xlink:href="https://doi.org/10.1017/S2633903X23000235">Supplementary Figure 1</uri>). Additionally, the GUI provides a dropdown menu (<xref rid="fig4" ref-type="fig">Figure 4f</xref>) to select different channels in the multichannel TIFF image. This allows the user to (1) toggle between the nuclei segmentation and images, (2) search for spots with specific spatial barcode IDs, and (3) zoom in and out to a specific location on the image. The user can visualize the nuclei count information by checking the “Get cell counts” option in the <italic toggle="yes">spotspotcheck</italic> start window. <italic toggle="yes">spotspotcheck</italic> enables users to perform bidirectional visual inspection, meaning that the user can evaluate morphological features in the high-resolution image and verify segmentation accuracy. Alternatively, the user can visually inspect whether gene expression patterns are related to any image features by querying specific spots through their barcode ID.</p>
      <p>Following alignment of gene expression with image-based data, the number of nuclei present in each gene expression spot can be integrated into downstream analysis, such as creating a SpatialExperiment (spe) object,<sup>(</sup><xref rid="r29" ref-type="bibr"><sup>29</sup></xref><sup>)</sup> which incorporates image-based quantifications, along with other variables, into the spot-level information. The nuclei count can then be used to perform quality control procedures and downstream analysis at the spot level. For example, during quality control, spots with an abnormally high nuclei count can be excluded.<sup>(</sup><xref rid="r30" ref-type="bibr"><sup>30</sup></xref><sup>)</sup> Furthermore, the nuclei count along with the spot-level gene expression matrix are required inputs for spot deconvolution methods such as Tangram.<sup>(</sup><xref rid="r20" ref-type="bibr"><sup>20</sup></xref><sup>)</sup></p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="sec7">
    <label>3.</label>
    <title>Discussion</title>
    <p><italic toggle="yes">VistoSeg</italic> leverages the MATLAB Image Processing Toolbox<sup>(</sup><xref rid="r31" ref-type="bibr"><sup>31</sup></xref><sup>)</sup> to provide user-friendly functionality for processing, analysis and interactive visualization of both H&amp;E and fluorescent images generated in conjunction with the Visium platform. A major feature of the <italic toggle="yes">VistoSeg</italic> pipeline is the quantification and localization of detected ROIs in H&amp;E images (Visium-H&amp;E workflow) or each individual fluorescent channel (Visium-SPG workflow). <italic toggle="yes">VistoSeg</italic> extracts multiple user-defined metrics, including number of cells per spot, percentage of a spot occupied by cells or proteins of interest, mean fluorescent intensity in a spot, and mean fluorescent intensity of the segmented regions in the spot to aid in the interpretation and utility of SRT data.</p>
    <p>This quantitative output from <italic toggle="yes">VistoSeg</italic> can be integrated with spatial gene expression data to improve spot-level resolution and add biological insights to downstream analyses. For example, using H&amp;E images of the human dorsolateral prefrontal cortex analyzed with <italic toggle="yes">VistoSeg</italic>, we identified “neuropil” spots lacking cell bodies, which we hypothesized were enriched for neuronal processes. We confirmed this hypothesis by demonstrating that these “neuropil” spots are enriched for genes previously shown to be expressed in synaptic terminals.<sup>(</sup><xref rid="r18" ref-type="bibr"><sup>18</sup></xref><sup>)</sup>
<italic toggle="yes">VistoSeg</italic> can also be used to identify spots that contain only a single cell or specific number of cells to help refine the selection of spots used for downstream gene expression analysis. Additionally, <italic toggle="yes">VistoSeg</italic> can identify spots with disease-associated pathology, allowing for the analysis of gene expression changes associated with pathological alterations in local microenvironments. For example, SRT has been used to identify gene expression changes associated with amyloid beta pathology in Alzheimer’s disease.<sup>(</sup><xref rid="r32" ref-type="bibr"><sup>32</sup></xref><sup>)</sup>
<italic toggle="yes">VistoSeg</italic> opens opportunities to directly incorporate different pathology-associated metrics with transcriptomic changes in diseased tissues.</p>
    <p>Importantly, <italic toggle="yes">VistoSeg</italic> output can be further integrated with other software<sup>(</sup><xref rid="r33" ref-type="bibr"><sup>33</sup></xref><sup>,</sup><xref rid="r34" ref-type="bibr"><sup>34</sup></xref><sup>)</sup> to identify and classify specific cell types based on nuclear or cellular morphology. For example, spatial domains corresponding to specific tumor pathology can vary in cell size, shape and density across tissue sections. Identification of these pathological lesions can provide important insights into the role of spatially restricted gene expression in disease progression.<sup>(</sup><xref rid="r35" ref-type="bibr"><sup>35</sup></xref><sup>,</sup><xref rid="r36" ref-type="bibr"><sup>36</sup></xref><sup>)</sup> We further anticipate that outputs of <italic toggle="yes">VistoSeg</italic> can be used to calculate other tissue parameters, such as cell density, for incorporation into unsupervised clustering approaches to identify data-driven spatial domains more directly related to cytoarchitecture. Given that a single Visium spot contains multiple cells with several cell types, spot deconvolution algorithms are rapidly being developed to predict the proportion of different cell types in each spot.<sup>(</sup><xref rid="r37" ref-type="bibr"><sup>37</sup></xref><sup>,</sup><xref rid="r38" ref-type="bibr"><sup>38</sup></xref><sup>)</sup> Spot deconvolution algorithms generally require Visium gene expression data (with or without cell counts) and single cell/nucleus RNA-seq gene expression data from the same tissue type (<uri xlink:href="https://doi.org/10.1017/S2633903X23000235">Supplementary Figure 4</uri>). Some spot deconvolution software, including Tangram<sup>(</sup><xref rid="r20" ref-type="bibr"><sup>20</sup></xref><sup>)</sup> and Cell2Location,<sup>(</sup><xref rid="r19" ref-type="bibr"><sup>19</sup></xref><sup>)</sup> require the user to input the number of cells per spot, while others do not require this information. However, spot deconvolution results were improved for methods that include cell counts per spot compared to methods that do not use any image-level spot metrics.<sup>(</sup><xref rid="r39" ref-type="bibr"><sup>39</sup></xref><sup>)</sup> Spot deconvolution algorithms have already begun to leverage cell counts from imaging data,<sup>(</sup><xref rid="r15" ref-type="bibr"><sup>15</sup></xref><sup>)</sup> and we anticipate that more quantitative outputs from software such as <italic toggle="yes">VistoSeg</italic> can improve the identification of biologically relevant spatial domains and associated cell type proportions.</p>
    <p>In summary, <italic toggle="yes">VistoSeg</italic> was designed to address an image analysis gap in the most widely used, commercially available SRT-processing pipeline, the Visium Spatial Gene Expression platforms. However, we note some limitations with <italic toggle="yes">Vistoseg</italic>, such as large memory requirements (~75 GB) for loading and saving images. Furthermore, the <italic toggle="yes">VNS</italic> function requires manual user inputs and cannot currently be fully automated. However, we note that similar existing image analysis software, such as HALO,<sup>(</sup><xref rid="r40" ref-type="bibr"><sup>40</sup></xref><sup>)</sup> QuPath<sup>(</sup><xref rid="r9" ref-type="bibr"><sup>9</sup></xref><sup>)</sup> and Squidpy,<sup>(</sup><xref rid="r36" ref-type="bibr"><sup>36</sup></xref><sup>)</sup> also have limitations on processing times and parametrization, and there are currently no available modules to support integration of gene expression data with segmented images. While <italic toggle="yes">Vistoseg</italic> was primarily designed for the available Visium platforms, we anticipate its functions will be relevant to other NGS-based SRT platforms should future assays become available from other vendors. We note that among all current SRT technologies, Visium is by far the leading platform in the field<sup>(</sup><xref rid="r6" ref-type="bibr"><sup>6</sup></xref><sup>)</sup> with over 60 institutions utilizing the technology at the time of publication, further supporting the need for improved imaging-processing tools.</p>
    <p>While we recognize that MATLAB is closed source, it is compatible with open science<sup>(</sup><xref rid="r41" ref-type="bibr"><sup>41</sup></xref><sup>)</sup> and readily available to academic users. MATLAB supports the ability to read images from various proprietary file formats from multiple instrument manufacturers. All code for <italic toggle="yes">VistoSeg</italic> is freely available (see Data Availability), and the main output of <italic toggle="yes">VistoSeg</italic> is in <italic toggle="yes">.csv</italic> format, which can be easily incorporated into commonly used pipelines for analysis of SRT data such as R objects for SpatialExperiment<sup>(</sup><xref rid="r29" ref-type="bibr"><sup>29</sup></xref><sup>)</sup> and Seurat,<sup>(</sup><xref rid="r42" ref-type="bibr"><sup>42</sup></xref><sup>)</sup> or Python objects for AnnData.<sup>(</sup><xref rid="r43" ref-type="bibr"><sup>43</sup></xref><sup>)</sup> In addition, conversion utilities like zellkonverter<sup>(</sup><xref rid="r44" ref-type="bibr"><sup>44</sup></xref><sup>)</sup> facilitate intercommunication among these programing languages. As other packages are made available that expand on the key infrastructure provided by SpatialExperiment, <italic toggle="yes">VistoSeg</italic> will continue to be compatible with them.</p>
  </sec>
  <sec sec-type="conclusions" id="sec8">
    <label>4.</label>
    <title>Conclusion</title>
    <p>We developed <italic toggle="yes">VistoSeg</italic> as a user-friendly image-processing toolkit, which is optimized for NGS-based SRT technologies, including the commercially available Visium platforms, to facilitate integration of the rich anatomical and/or proteomic data in the H&amp;E and fluorescent images accompanying spatial gene expression data. <italic toggle="yes">VistoSeg</italic> performs automatic splitting of whole-slide images for downstream data processing and allows for segmenting, visualizing, and quantifying individual high-resolution raw histology and immunofluorescent images. The pipeline is easily adaptable for images obtained from Visium H&amp;E and Visium-SPG workflows from different tissues, organs and species. The pipeline is available at <uri xlink:href="http://research.libd.org/VistoSeg">http://research.libd.org/VistoSeg</uri> and includes a detailed tutorial with example data for implementing <italic toggle="yes">VistoSeg.</italic></p>
  </sec>
  <sec sec-type="materials" id="sec9">
    <label>5.</label>
    <title>Materials and methods</title>
    <sec sec-type="other" id="sec10">
      <label>5.1.</label>
      <title>Post-mortem human brain tissue</title>
      <p>Post-mortem human brain tissue was obtained at the time of autopsy with informed consent from the legal next of kin, through the Maryland Department of Health IRB protocol #12–24, and from the Department of Pathology of Western Michigan University Homer Stryker MD School of Medicine, the Department of Pathology of University of North Dakota School of Medicine and Health Sciences, and the County of Santa Clara Medical Examiner-Coroner Office in San Jose, CA, all under the WCG protocol #20111080. Details of tissue acquisition, handling, processing, dissection, clinical characterization, diagnoses, neuropathological examinations and quality control measures have been described previously.<sup>(</sup><xref rid="r45" ref-type="bibr"><sup>45</sup></xref><sup>)</sup></p>
    </sec>
    <sec sec-type="other" id="sec11">
      <label>5.2.</label>
      <title>Tissue preparation and image acquisition for Visium H&amp;E</title>
      <p>Tissue was cryosectioned on a Leica 3050 cryostat at 10-micron thickness and collected onto a Visium Spatial Gene Expression slide (catalog no. 2000233; 10× Genomics). H&amp;E staining was performed on fresh-frozen tissue according to manufacturer’s instructions to identify nuclei (dark blue/purple) and cytoplasm (pink) in the tissue section. The two stains combine to label features of the tissue in various shades of pink and blue. Thus, the range of colors present in the staining depends on the cellular composition of the tissue. Following H&amp;E staining, the Visium slide was imaged on a Leica Aperio CS2 slide scanner (<xref rid="fig1" ref-type="fig">Figure 1b</xref>) equipped with a color camera and a 20×/0.75 NA objective with a 2× optical magnification changer, which meets the recommended microscopy specification outlined by Visium Spatial Gene Expression Imaging Guidelines from 10× Genomics.<sup>(</sup><xref rid="r46" ref-type="bibr"><sup>46</sup></xref><sup>)</sup> This protocol produced high-resolution (0.253 μm per pixel) images for downstream analysis.</p>
    </sec>
    <sec sec-type="other" id="sec12">
      <label>5.3.</label>
      <title>Immunofluorescent staining and image acquisition for Visium-SPG</title>
      <p>Immunofluorescent staining was performed according to the manufacturer’s instructions (catalog no.CG000312 Rev C; 10× Genomics). Briefly, post-mortem human dorsolateral prefrontal cortex (<italic toggle="yes">n</italic> = 4 tissue sections from four individual donors) was microdissected and cryosectioned at 10-micron thickness. Sections were mounted on a Visium Spatial Gene Expression Slide (catalog no. 2000233; 10× Genomics), fixed in prechilled methanol, blocked in BSA-containing buffer, and incubated for 30 min at room temperature with primary antibodies against NeuN, TMEM119, GFAP, and OLIG2 (mouse anti-NeuN antibody conjugated to Alexa 488 [Sigma Aldrich; Cat# MAB377X, 1:100], rabbit anti-TMEM119 antibody [Sigma Aldrich; Cat# HPA051870, 1:20], rat anti-GFAP antibody [Thermofisher; Cat# 13-0300, 1:100], and goat anti-OLIG2 antibody [R&amp;D systems; Cat# AF2418, 1:20]). Following washes, appropriate secondary antibodies were applied for 30 min at room temperature (donkey anti-rabbit IgG conjugated to Alexa 555 [Thermofisher; Cat# A-31572, 1:300], donkey anti-rat IgG conjugated to Alexa 594 [Thermofisher; Cat# A-21209, 1: 600], and donkey anti-goat IgG conjugated to Alexa 647 [Thermofisher, Cat# A-21447, 1:400]). DAPI (Thermofisher; Cat# D1306, 1:3000, 1.67 μg/ml) was applied for nuclear counterstaining. The slide was coverslipped with 85% glycerol and imaged on a Vectra Polaris slide scanner (Akoya Biosciences) at 20× magnification with the following exposure time per given channel: 2.1 ms for DAPI, 143 ms for Opal 520, 330 ms for Opal 570, 200 ms for Opal 620, 1070 ms for Opal 690, 100 ms for Autofluorescence prior to downstream transcriptomics. Slide scanning generated a qptiff image file, which was then selected for a region of interest (ROI) in Phenochart software (Akoya Biosciences) with an annotation tool outlining the entire slide. The resulting boundaries created a grid line of multiple tiles that made up the entire demarcated ROI. The annotated qptiff image was then processed in InForm software (Akoya Biosciences) and subjected to linear unmixing with the reference spectral profiles of corresponding fluorophores. InForm performs linear unmixing tile by tile while producing linearly unmixed tile images in tiff. The subsequent individual tile images were processed through the <italic toggle="yes">VistoSeg</italic> pipeline to extract final quantitative output.</p>
    </sec>
    <sec sec-type="other" id="sec13">
      <label>5.4.</label>
      <title>cDNA synthesis and library preparation</title>
      <p>Following imaging, gene expression libraries were generated on the slide, followed by denaturing and amplification. Standard Illumina sequencing was performed according to manufacturer’s specifications.</p>
    </sec>
    <sec sec-type="other" id="sec14">
      <label>5.5.</label>
      <title>System requirements and availability for VistoSeg</title>
      <p>Project name: <italic toggle="yes">VistoSeg</italic></p>
      <p>Project home page: <uri xlink:href="https://github.com/LieberInstitute/VistoSeg">https://github.com/LieberInstitute/VistoSeg</uri>, <uri xlink:href="http://research.libd.org/VistoSeg/">http://research.libd.org/VistoSeg/</uri></p>
      <p>Operating system(s): MAC, Windows, LINUX</p>
      <p>Programming language: MATLAB</p>
      <p>Other requirements:</p>
      <p>(1) MATLAB Image Processing Toolbox</p>
      <p>(2) MATLAB v2019a or later</p>
      <p>(3) Minimum ~ (3*raw image) 80 GB RAM for the initial (<italic toggle="yes">splitSlide</italic>) step and &lt;16GB for all the remaining steps</p>
      <p>(4) SpaceRanger (10× Genomics) v1.0 or higher</p>
      <p>(5) Loupe browser (10× Genomics) v5 or higher</p>
      <p>License: GNU GENERAL PUBLIC LICENSE, Version 3, June 29, 2007.</p>
      <p>Any restrictions to use by nonacademics: license required.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material" id="sec19">
    <title>Supporting information</title>
    <supplementary-material id="sm01" position="float" content-type="local-data">
      <caption>
        <title>Tippani et al. supplementary material</title>
        <p>Tippani et al. supplementary material</p>
      </caption>
      <media xlink:href="S2633903X23000235sup001.docx" id="d66e1107" position="anchor"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>We thank Anthony Ramnauth (LIBD) and Uma Kaipa (LIBD) for testing code functionality. We thank the “spatialLIBD” team (LIBD and JHU) for their feedback on <italic toggle="yes">VistoSeg</italic> and testing the software across multiple datasets. We thank Amy Deep-Soboslay and her diagnostic team for curation of brain samples. We thank the neuropathology team for their assistance with tissue dissection. We thank the physicians and staff at the brain donation sites and the generosity of donor families for supporting our research efforts. Finally, we thank the families of Connie and Stephen Lieber and Milton and Tamar Maltz for their generous support to this work. A preprint of this work is available on bioRxiv: <ext-link xlink:href="10.1101/2021.08.04.452489" ext-link-type="doi">https://doi.org/10.1101/2021.08.04.452489</ext-link>.</p>
  </ack>
  <glossary id="glsy1">
    <title>Glossary of terms</title>
    <p>
      <def-list list-type="simple" list-content="abbreviation">
        <def-item>
          <term>10× Genomics:</term>
          <def>
            <p>commercial vendor producing Visium technology</p>
          </def>
        </def-item>
        <def-item>
          <term>barcode identifier (ID):</term>
          <def>
            <p>unique genomic sequence for each spatially restricted position on a Visium slide</p>
          </def>
        </def-item>
        <def-item>
          <term>CIELAB or L*a*b:</term>
          <def>
            <p>color model incorporating perceptual lightness (L) with colors unique to human vision (red, green, blue and yellow), to enable the detection and calculation of visibly evident changes in color patterns</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">countNuclei:</italic>
          </term>
          <def>
            <p>a function used to generate the nuclei count file that stores the information about the number of segmented nuclei in each spot</p>
          </def>
        </def-item>
        <def-item>
          <term>GUI:</term>
          <def>
            <p>graphical user interface</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">imsegkmeans:</italic>
          </term>
          <def>
            <p>a MATLAB function that uses K-means clustering-based image segmentation</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">inFormstitch:</italic>
          </term>
          <def>
            <p>a MATLAB function used to stitch all spectrally unmixed individual tiles of a Visium-SPG immunofluorescent slide image to recreate a multispectral TIFF image</p>
          </def>
        </def-item>
        <def-item>
          <term>Loupe browser:</term>
          <def>
            <p>Primary Visualization software provided by 10× Genomics</p>
          </def>
        </def-item>
        <def-item>
          <term>MATLAB:</term>
          <def>
            <p>MATrix LABoratory</p>
          </def>
        </def-item>
        <def-item>
          <term>NGS:</term>
          <def>
            <p>next-generation sequencing</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">refine(VNS):</italic>
          </term>
          <def>
            <p>a function that refines the segmentation done using <italic toggle="yes">VNS</italic> function</p>
          </def>
        </def-item>
        <def-item>
          <term>RGB:</term>
          <def>
            <p>red, green, blue color model</p>
          </def>
        </def-item>
        <def-item>
          <term>ROI:</term>
          <def>
            <p>region of interest</p>
          </def>
        </def-item>
        <def-item>
          <term>SpaceRanger:</term>
          <def>
            <p>analysis software provided by 10× Genomics to align transcript reads to the genome and assign them to a Visium spot</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">splitslide:</italic>
          </term>
          <def>
            <p>a MATLAB function used to split the whole-slide Visium-H&amp;E image into individual capture arrays</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">splitSlide_IF:</italic>
          </term>
          <def>
            <p>a MATLAB function that splits the multispectral TIFF image obtained using <italic toggle="yes">inFormStitch</italic> function into individual capture arrays</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">spotspotcheck:</italic>
          </term>
          <def>
            <p>a GUI that allows the user to visualize and quantify nuclei segmentation results performed using <italic toggle="yes">VNS</italic> and <italic toggle="yes">refineVNS</italic></p>
          </def>
        </def-item>
        <def-item>
          <term>SRT:</term>
          <def>
            <p>spatially resolved transcriptomics</p>
          </def>
        </def-item>
        <def-item>
          <term>Visium H&amp;E:</term>
          <def>
            <p>Visium assay using H&amp;E staining.</p>
          </def>
        </def-item>
        <def-item>
          <term>Visium-SPG:</term>
          <def>
            <p>Visium Spatial Proteogenomics assay using immunofluorescent staining</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">VNS:</italic>
          </term>
          <def>
            <p>a MATLAB function that segments nuclei for Visium H&amp;E images</p>
          </def>
        </def-item>
      </def-list>
    </p>
  </glossary>
  <sec sec-type="supplementary-material" id="nts1">
    <title>Supplementary material</title>
    <p>The supplementary material for this article can be found at <uri xlink:href="https://doi.org/10.1017/S2633903X23000235">https://doi.org/10.1017/S2633903X23000235</uri>.</p>
  </sec>
  <sec sec-type="data-availability" id="sec16">
    <title>Data availability statement</title>
    <p>Examples of code, data, output and results are available at <uri xlink:href="http://research.libd.org/VistoSeg/index.html#data-availability">http://research.libd.org/VistoSeg/index.html#data-availability</uri> and <uri xlink:href="https://github.com/LieberInstitute/VistoSeg">https://github.com/LieberInstitute/VistoSeg</uri>.<sup>(</sup><xref rid="r47" ref-type="bibr"><sup>47</sup></xref><sup>)</sup> All inputs and outputs are available through Figshare.<sup>(</sup><xref rid="r48" ref-type="bibr"><sup>48</sup></xref><sup>)</sup> Public datasets provided by 10× Genomics.<sup>(</sup><xref rid="r49" ref-type="bibr"><sup>49</sup></xref><sup>)</sup></p>
  </sec>
  <sec sec-type="funding-statement" id="sec17">
    <title>Funding statement</title>
    <p>This work was supported by the Lieber Institute for Brain Development and the National Institute of Health grants U01MH122849 and R01MH126393.</p>
  </sec>
  <sec sec-type="COI-statement" id="sec18">
    <title>Competing interest</title>
    <p>A.E.J. is now a full-time employee at Neumora Therapeutics, a for-profit biotechnology company, which is unrelated to the contents of this manuscript. J.L.C. is now a full-time employee at Delfi Diagnostics, a for-profit biotechnology company, which is unrelated to the contents of this manuscript. Their contributions to the manuscript were made while previously employed by the Lieber Institute for Brain Development. All other authors declare no competing interests.</p>
  </sec>
  <ref-list id="refs1" content-type="normal">
    <title>References</title>
    <ref id="r1">
      <label>1.</label>
      <mixed-citation publication-type="journal" id="ref1"><string-name><surname>Marx</surname><given-names>V</given-names></string-name> (<year>2021</year>) <article-title>Method of the year: spatially resolved transcriptomics</article-title>. <source>Nature Methods</source>
<volume>18</volume>(<issue>1</issue>), <fpage>9</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">33408395</pub-id>
</mixed-citation>
    </ref>
    <ref id="r2">
      <label>2.</label>
      <mixed-citation publication-type="journal" id="ref2"><string-name><surname>Rodriques</surname><given-names>SG</given-names></string-name>, <string-name><surname>Stickels</surname><given-names>RR</given-names></string-name>, <string-name><surname>Goeva</surname><given-names>A</given-names></string-name>, <string-name><surname>Martin</surname><given-names>CA</given-names></string-name>, <string-name><surname>Murray</surname><given-names>E</given-names></string-name>, <string-name><surname>Vanderburg</surname><given-names>CR</given-names></string-name>, <string-name><surname>Welch</surname><given-names>J</given-names></string-name>, <string-name><surname>Chen</surname><given-names>LM</given-names></string-name>, <string-name><surname>Chen</surname><given-names>F</given-names></string-name>, <string-name><surname>Macosko</surname><given-names>EZ</given-names></string-name> (<year>2019</year>) <article-title>Slide-seq: a scalable technology for measuring genome-wide expression at high spatial resolution</article-title>. <source>Science</source>
<volume>363</volume>(<issue>6434</issue>), <fpage>1463</fpage>–<lpage>1467</lpage>.<pub-id pub-id-type="pmid">30923225</pub-id>
</mixed-citation>
    </ref>
    <ref id="r3">
      <label>3.</label>
      <mixed-citation publication-type="journal" id="ref3"><string-name><surname>Liu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Yang</surname><given-names>M</given-names></string-name>, <string-name><surname>Deng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Su</surname><given-names>G</given-names></string-name>, <string-name><surname>Enninful</surname><given-names>A</given-names></string-name>, <string-name><surname>Guo</surname><given-names>CC</given-names></string-name>, <string-name><surname>Tebaldi</surname><given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>D</given-names></string-name>, <string-name><surname>Kim</surname><given-names>D</given-names></string-name>, <string-name><surname>Bai</surname><given-names>Z</given-names></string-name>, <string-name><surname>Norris</surname><given-names>E</given-names></string-name>, <string-name><surname>Pan</surname><given-names>A</given-names></string-name>, <string-name><surname>Li</surname><given-names>J</given-names></string-name>, <string-name><surname>Xiao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Halene</surname><given-names>S</given-names></string-name>, <string-name><surname>Fan</surname><given-names>R</given-names></string-name> (<year>2020</year>) <article-title>High-spatial-resolution multi-omics sequencing via deterministic barcoding in tissue</article-title>. <source>Cell</source>
<volume>183</volume>(<issue>6</issue>), <fpage>1665</fpage>–<lpage>1681</lpage>.e18.<pub-id pub-id-type="pmid">33188776</pub-id>
</mixed-citation>
    </ref>
    <ref id="r4">
      <label>4.</label>
      <mixed-citation publication-type="journal" id="ref4"><string-name><surname>Vickovic</surname><given-names>S</given-names></string-name>, <string-name><surname>Eraslan</surname><given-names>G</given-names></string-name>, <string-name><surname>Salmén</surname><given-names>F</given-names></string-name>, <string-name><surname>Klughammer</surname><given-names>J</given-names></string-name>, <string-name><surname>Stenbeck</surname><given-names>L</given-names></string-name>, <string-name><surname>Schapiro</surname><given-names>D</given-names></string-name>, <string-name><surname>Äijö</surname><given-names>T</given-names></string-name>, <string-name><surname>Bonneau</surname><given-names>R</given-names></string-name>, <string-name><surname>Bergenstråhle</surname><given-names>L</given-names></string-name>, <string-name><surname>Navarro</surname><given-names>JF</given-names></string-name>, <string-name><surname>Gould</surname><given-names>J</given-names></string-name>, <string-name><surname>Griffin</surname><given-names>GK</given-names></string-name>, <string-name><surname>Borg</surname><given-names>Å</given-names></string-name>, <string-name><surname>Ronaghi</surname><given-names>M</given-names></string-name>, <string-name><surname>Frisén</surname><given-names>J</given-names></string-name>, <string-name><surname>Lundeberg</surname><given-names>J</given-names></string-name>, <string-name><surname>Regev</surname><given-names>A</given-names></string-name>, <string-name><surname>Ståhl</surname><given-names>PL</given-names></string-name> (<year>2019</year>) <article-title>High-definition spatial transcriptomics for in situ tissue profiling</article-title>. <source>Nature Methods</source>
<volume>16</volume>(<issue>10</issue>), <fpage>987</fpage>–<lpage>990</lpage>.<pub-id pub-id-type="pmid">31501547</pub-id>
</mixed-citation>
    </ref>
    <ref id="r5">
      <label>5.</label>
      <mixed-citation publication-type="other" id="ref5"><string-name><surname>Fu</surname><given-names>X</given-names></string-name>, <string-name><surname>Sun</surname><given-names>L</given-names></string-name>, <string-name><surname>Chen</surname><given-names>J</given-names></string-name>, <string-name><surname>Dong</surname><given-names>R</given-names></string-name>, <string-name><surname>Lin</surname><given-names>Y</given-names></string-name>, <string-name><surname>Palmiter</surname><given-names>R</given-names></string-name>, <string-name><surname>Lin</surname><given-names>S</given-names></string-name>, <string-name><surname>Gu</surname><given-names>L</given-names></string-name> (<year>2021</year>) Continuous polony gels for tissue mapping with high resolution and RNA capture efficiency. BioRxiv.</mixed-citation>
    </ref>
    <ref id="r6">
      <label>6.</label>
      <mixed-citation publication-type="journal" id="ref6"><string-name><surname>Moses</surname><given-names>L</given-names></string-name>, <string-name><surname>Pachter</surname><given-names>L</given-names></string-name> (<year>2022</year>) <article-title>Museum of spatial transcriptomics</article-title>. <source>Nat Methods</source>
<volume>19</volume>(<issue>5</issue>), <fpage>534</fpage>–<lpage>546</lpage>.<pub-id pub-id-type="pmid">35273392</pub-id>
</mixed-citation>
    </ref>
    <ref id="r7">
      <label>7.</label>
      <mixed-citation publication-type="other" id="ref7">10× Genomics (2022) Loupe Browser, 10× Genomics [Internet]. [cited 18 April 2022]. Available at <uri xlink:href="https://support.10xgenomics.com/spatial-gene-expression/software/visualization/latest/analysis">https://support.10xgenomics.com/spatial-gene-expression/software/visualization/latest/analysis</uri>.</mixed-citation>
    </ref>
    <ref id="r8">
      <label>8.</label>
      <mixed-citation publication-type="other" id="ref8">10× Genomics April (2022) Space Ranger, 10× Genomics [Internet]. [cited 18 April 2022]. Available at <uri xlink:href="https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/what-is-space-ranger">https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/what-is-space-ranger</uri>.</mixed-citation>
    </ref>
    <ref id="r9">
      <label>9.</label>
      <mixed-citation publication-type="journal" id="ref9"><string-name><surname>Bankhead</surname><given-names>P</given-names></string-name>, <string-name><surname>Loughrey</surname><given-names>MB</given-names></string-name>, <string-name><surname>Fernández</surname><given-names>JA</given-names></string-name>, <string-name><surname>Dombrowski</surname><given-names>Y</given-names></string-name>, <string-name><surname>McArt</surname><given-names>DG</given-names></string-name>, <string-name><surname>Dunne</surname><given-names>PD</given-names></string-name>, <string-name><surname>McQuaid</surname><given-names>S</given-names></string-name>, <string-name><surname>Gray</surname><given-names>RT</given-names></string-name>, <string-name><surname>Murray</surname><given-names>LJ</given-names></string-name>, <string-name><surname>Coleman</surname><given-names>HG</given-names></string-name>, <string-name><surname>James</surname><given-names>JA</given-names></string-name>, <string-name><surname>Salto-Tellez</surname><given-names>M</given-names></string-name>, <string-name><surname>Hamilton</surname><given-names>PW</given-names></string-name> (<year>2017</year>) <article-title>QuPath: open-source software for digital pathology image analysis</article-title>. <source>Scientific Reports</source>
<volume>7</volume>(<issue>1</issue>), <fpage>16878</fpage>.<pub-id pub-id-type="pmid">29203879</pub-id>
</mixed-citation>
    </ref>
    <ref id="r10">
      <label>10.</label>
      <mixed-citation publication-type="journal" id="ref10"><string-name><surname>Stringer</surname><given-names>C</given-names></string-name>, <string-name><surname>Wang</surname><given-names>T</given-names></string-name>, <string-name><surname>Michaelos</surname><given-names>M</given-names></string-name>, <string-name><surname>Pachitariu</surname><given-names>M</given-names></string-name> (<year>2021</year>) <article-title>Cellpose: a generalist algorithm for cellular segmentation</article-title>. <source>Nature Methods</source>
<volume>18</volume>(<issue>1</issue>), <fpage>100</fpage>–<lpage>106</lpage>.<pub-id pub-id-type="pmid">33318659</pub-id>
</mixed-citation>
    </ref>
    <ref id="r11">
      <label>11.</label>
      <mixed-citation publication-type="journal" id="ref11"><string-name><surname>Fürth</surname><given-names>D</given-names></string-name>, <string-name><surname>Vaissière</surname><given-names>T</given-names></string-name>, <string-name><surname>Tzortzi</surname><given-names>O</given-names></string-name>, <string-name><surname>Xuan</surname><given-names>Y</given-names></string-name>, <string-name><surname>Märtin</surname><given-names>A</given-names></string-name>, <string-name><surname>Lazaridis</surname><given-names>I</given-names></string-name>, <string-name><surname>Spigolon</surname><given-names>G</given-names></string-name>, <string-name><surname>Fisone</surname><given-names>G</given-names></string-name>, <string-name><surname>Tomer</surname><given-names>R</given-names></string-name>, <string-name><surname>Deisseroth</surname><given-names>K</given-names></string-name>, <string-name><surname>Carlén</surname><given-names>M</given-names></string-name>, <string-name><surname>Miller</surname><given-names>CA</given-names></string-name>, <string-name><surname>Rumbaugh</surname><given-names>G</given-names></string-name>, <string-name><surname>Meletis</surname><given-names>K</given-names></string-name> (<year>2018</year>) <article-title>An interactive framework for whole-brain maps at cellular resolution</article-title>. <source>Nature Neurosciene</source>
<volume>21</volume>(<issue>1</issue>), <fpage>139</fpage>–<lpage>149</lpage>.</mixed-citation>
    </ref>
    <ref id="r12">
      <label>12.</label>
      <mixed-citation publication-type="journal" id="ref12"><string-name><surname>Ortiz</surname><given-names>C</given-names></string-name>, <string-name><surname>Navarro</surname><given-names>JF</given-names></string-name>, <string-name><surname>Jurek</surname><given-names>A</given-names></string-name>, <string-name><surname>Märtin</surname><given-names>A</given-names></string-name>, <string-name><surname>Lundeberg</surname><given-names>J</given-names></string-name>, <string-name><surname>Meletis</surname><given-names>K</given-names></string-name> (<year>2020</year>) <article-title>Molecular atlas of the adult mouse brain</article-title>. <source>Science Advances</source>
<volume>6</volume>(<issue>26</issue>), <fpage>eabb3446</fpage>.<pub-id pub-id-type="pmid">32637622</pub-id>
</mixed-citation>
    </ref>
    <ref id="r13">
      <label>13.</label>
      <mixed-citation publication-type="journal" id="ref13"><string-name><surname>Schindelin</surname><given-names>J</given-names></string-name>, <string-name><surname>Arganda-Carreras</surname><given-names>I</given-names></string-name>, <string-name><surname>Frise</surname><given-names>E</given-names></string-name>, <string-name><surname>Kaynig</surname><given-names>V</given-names></string-name>, <string-name><surname>Longair</surname><given-names>M</given-names></string-name>, <string-name><surname>Pietzsch</surname><given-names>T</given-names></string-name>, <string-name><surname>Preibisch</surname><given-names>S</given-names></string-name>, <string-name><surname>Rueden</surname><given-names>C</given-names></string-name>, <string-name><surname>Saalfeld</surname><given-names>S</given-names></string-name>, <string-name><surname>Schmid</surname><given-names>B</given-names></string-name>, <string-name><surname>Tinevez</surname><given-names>J-Y</given-names></string-name>, <string-name><surname>White</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Hartenstein</surname><given-names>V</given-names></string-name>, <string-name><surname>Eliceiri</surname><given-names>K</given-names></string-name>, <string-name><surname>Tomancak</surname><given-names>P</given-names></string-name>, <string-name><surname>Cardona</surname><given-names>A</given-names></string-name> (<year>2012</year>) <article-title>Fiji: an open-source platform for biological-image analysis</article-title>. <source>Nature Methods</source>
<volume>9</volume>(<issue>7</issue>), <fpage>676</fpage>–<lpage>682</lpage>.<pub-id pub-id-type="pmid">22743772</pub-id>
</mixed-citation>
    </ref>
    <ref id="r14">
      <label>14.</label>
      <mixed-citation publication-type="journal" id="ref14"><string-name><surname>McQuin</surname><given-names>C</given-names></string-name>, <string-name><surname>Goodman</surname><given-names>A</given-names></string-name>, <string-name><surname>Chernyshev</surname><given-names>V</given-names></string-name>, <string-name><surname>Kamentsky</surname><given-names>L</given-names></string-name>, <string-name><surname>Cimini</surname><given-names>BA</given-names></string-name>, <string-name><surname>Karhohs</surname><given-names>KW</given-names></string-name>, <string-name><surname>Doan</surname><given-names>M</given-names></string-name>, <string-name><surname>Ding</surname><given-names>L</given-names></string-name>, <string-name><surname>Rafelski</surname><given-names>SM</given-names></string-name>, <string-name><surname>Thirstrup</surname><given-names>D</given-names></string-name>, <string-name><surname>Wiegraebe</surname><given-names>W</given-names></string-name>, <string-name><surname>Singh</surname><given-names>S</given-names></string-name>, <string-name><surname>Becker</surname><given-names>T</given-names></string-name>, <string-name><surname>Caicedo</surname><given-names>JC</given-names></string-name>, <string-name><surname>Carpenter</surname><given-names>AE</given-names></string-name> (<year>2018</year>) <article-title>CellProfiler 3.0: next-generation image processing for biology</article-title>. <source>PLoS Biology</source>
<volume>16</volume>(<issue>7</issue>), <fpage>e2005970</fpage>.<pub-id pub-id-type="pmid">29969450</pub-id>
</mixed-citation>
    </ref>
    <ref id="r15">
      <label>15.</label>
      <mixed-citation publication-type="journal" id="ref15"><string-name><surname>Hu</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name>, <string-name><surname>Coleman</surname><given-names>K</given-names></string-name>, <string-name><surname>Schroeder</surname><given-names>A</given-names></string-name>, <string-name><surname>Ma</surname><given-names>N</given-names></string-name>, <string-name><surname>Irwin</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Lee</surname><given-names>EB</given-names></string-name>, <string-name><surname>Shinohara</surname><given-names>RT</given-names></string-name>, <string-name><surname>Li</surname><given-names>M</given-names></string-name> (<year>2021</year>) <article-title>SpaGCN: integrating gene expression, spatial location and histology to identify spatial domains and spatially variable genes by graph convolutional network</article-title>. <source>Nature Methods</source>
<volume>18</volume>(<issue>11</issue>), <fpage>1342</fpage>–<lpage>1351</lpage>.<pub-id pub-id-type="pmid">34711970</pub-id>
</mixed-citation>
    </ref>
    <ref id="r16">
      <label>16.</label>
      <mixed-citation publication-type="journal" id="ref16"><string-name><surname>Bao</surname><given-names>F</given-names></string-name>, <string-name><surname>Deng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wan</surname><given-names>S</given-names></string-name>, <string-name><surname>Shen</surname><given-names>SQ</given-names></string-name>, <string-name><surname>Wang</surname><given-names>B</given-names></string-name>, <string-name><surname>Dai</surname><given-names>Q</given-names></string-name>, <string-name><surname>Altschuler</surname><given-names>SJ</given-names></string-name>, <string-name><surname>Wu</surname><given-names>LF</given-names></string-name> (<year>2022</year>) <article-title>Integrative spatial analysis of cell morphologies and transcriptional states with MUSE</article-title>. <source>Nature Biotechnology</source>
<volume>40</volume>(<issue>8</issue>), <fpage>1200</fpage>–<lpage>1209</lpage>.</mixed-citation>
    </ref>
    <ref id="r17">
      <label>17.</label>
      <mixed-citation publication-type="journal" id="ref17"><string-name><surname>Pratapa</surname><given-names>A</given-names></string-name>, <string-name><surname>Doron</surname><given-names>M</given-names></string-name>, <string-name><surname>Caicedo</surname><given-names>JC</given-names></string-name> (<year>2021</year>) <article-title>Image-based cell phenotyping with deep learning</article-title>. <source>Current Opinion in Chemical Biology</source>
<volume>65</volume>, <fpage>9</fpage>–<lpage>17</lpage>.<pub-id pub-id-type="pmid">34023800</pub-id>
</mixed-citation>
    </ref>
    <ref id="r18">
      <label>18.</label>
      <mixed-citation publication-type="journal" id="ref18"><string-name><surname>Maynard</surname><given-names>KR</given-names></string-name>, <string-name><surname>Collado-Torres</surname><given-names>L</given-names></string-name>, <string-name><surname>Weber</surname><given-names>LM</given-names></string-name>, <string-name><surname>Uytingco</surname><given-names>C</given-names></string-name>, <string-name><surname>Barry</surname><given-names>BK</given-names></string-name>, <string-name><surname>Williams</surname><given-names>SR</given-names></string-name>, <string-name><surname>Catallini</surname><given-names>JL</given-names></string-name>, <string-name><surname>Tran</surname><given-names>MN</given-names></string-name>, <string-name><surname>Besich</surname><given-names>Z</given-names></string-name>, <string-name><surname>Tippani</surname><given-names>M</given-names></string-name>, <string-name><surname>Chew</surname><given-names>J</given-names></string-name>, <string-name><surname>Yin</surname><given-names>Y</given-names></string-name>, <string-name><surname>Kleinman</surname><given-names>JE</given-names></string-name>, <string-name><surname>Hyde</surname><given-names>TM</given-names></string-name>, <string-name><surname>Rao</surname><given-names>N</given-names></string-name>, <string-name><surname>Hicks</surname><given-names>SC</given-names></string-name>, <string-name><surname>Martinowich</surname><given-names>K</given-names></string-name>, <string-name><surname>Jaffe</surname><given-names>AE</given-names></string-name> (<year>2021</year>) <article-title>Transcriptome-scale spatial gene expression in the human dorsolateral prefrontal cortex</article-title>. <source>Nature Neuroscience</source>
<volume>24</volume>(<issue>3</issue>), <fpage>425</fpage>–<lpage>436</lpage>.<pub-id pub-id-type="pmid">33558695</pub-id>
</mixed-citation>
    </ref>
    <ref id="r19">
      <label>19.</label>
      <mixed-citation publication-type="journal" id="ref19"><string-name><surname>Kleshchevnikov</surname><given-names>V</given-names></string-name>, <string-name><surname>Shmatko</surname><given-names>A</given-names></string-name>, <string-name><surname>Dann</surname><given-names>E</given-names></string-name>, <string-name><surname>Aivazidis</surname><given-names>A</given-names></string-name>, <string-name><surname>King</surname><given-names>HW</given-names></string-name>, <string-name><surname>Li</surname><given-names>T</given-names></string-name>, <string-name><surname>Elmentaite</surname><given-names>R</given-names></string-name>, <string-name><surname>Lomakin</surname><given-names>A</given-names></string-name>, <string-name><surname>Kedlian</surname><given-names>V</given-names></string-name>, <string-name><surname>Gayoso</surname><given-names>A</given-names></string-name>, <string-name><surname>Jain</surname><given-names>MS</given-names></string-name>, <string-name><surname>Park</surname><given-names>JS</given-names></string-name>, <string-name><surname>Ramona</surname><given-names>L</given-names></string-name>, <string-name><surname>Tuck</surname><given-names>E</given-names></string-name>, <string-name><surname>Arutyunyan</surname><given-names>A</given-names></string-name>, <string-name><surname>Vento-Tormo</surname><given-names>R</given-names></string-name>, <string-name><surname>Gerstung</surname><given-names>M</given-names></string-name>, <string-name><surname>James</surname><given-names>L</given-names></string-name>, <string-name><surname>Stegle</surname><given-names>O</given-names></string-name>, <string-name><surname>Bayraktar</surname><given-names>OA</given-names></string-name> (<year>2022</year>) <article-title>Cell2location maps fine-grained cell types in spatial transcriptomics</article-title>. <source>Nature Biotechnology</source>
<volume>40</volume>(<issue>5</issue>), <fpage>661</fpage>–<lpage>671</lpage>.</mixed-citation>
    </ref>
    <ref id="r20">
      <label>20.</label>
      <mixed-citation publication-type="journal" id="ref20"><string-name><surname>Biancalani</surname><given-names>T</given-names></string-name>, <string-name><surname>Scalia</surname><given-names>G</given-names></string-name>, <string-name><surname>Buffoni</surname><given-names>L</given-names></string-name>, <string-name><surname>Avasthi</surname><given-names>R</given-names></string-name>, <string-name><surname>Lu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Sanger</surname><given-names>A</given-names></string-name>, <string-name><surname>Tokcan</surname><given-names>N</given-names></string-name>, <string-name><surname>Vanderburg</surname><given-names>CR</given-names></string-name>, <string-name><surname>Segerstolpe</surname><given-names>Å</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>M</given-names></string-name>, <string-name><surname>Avraham-Davidi</surname><given-names>I</given-names></string-name>, <string-name><surname>Vickovic</surname><given-names>S</given-names></string-name>, <string-name><surname>Nitzan</surname><given-names>M</given-names></string-name>, <string-name><surname>Ma</surname><given-names>S</given-names></string-name>, <string-name><surname>Subramanian</surname><given-names>A</given-names></string-name>, <string-name><surname>Lipinski</surname><given-names>M</given-names></string-name>, <string-name><surname>Buenrostro</surname><given-names>J</given-names></string-name>, <string-name><surname>Brown</surname><given-names>NB</given-names></string-name>, <string-name><surname>Fanelli</surname><given-names>D</given-names></string-name>, <string-name><surname>Zhuang</surname><given-names>X</given-names></string-name>, <string-name><surname>Regev</surname><given-names>A</given-names></string-name> (<year>2021</year>) <article-title>Deep learning and alignment of spatially resolved single-cell transcriptomes with tangram</article-title>. <source>Nature Methods</source>
<volume>18</volume>(<issue>11</issue>), <fpage>1352</fpage>–<lpage>1362</lpage>.<pub-id pub-id-type="pmid">34711971</pub-id>
</mixed-citation>
    </ref>
    <ref id="r21">
      <label>21.</label>
      <mixed-citation publication-type="journal" id="ref21"><string-name><surname>Elosua-Bayes</surname><given-names>M</given-names></string-name>, <string-name><surname>Nieto</surname><given-names>P</given-names></string-name>, <string-name><surname>Mereu</surname><given-names>E</given-names></string-name>, <string-name><surname>Gut</surname><given-names>I</given-names></string-name>, <string-name><surname>Heyn</surname><given-names>H</given-names></string-name> (<year>2021</year>) <article-title>SPOTlight: seeded NMF regression to deconvolute spatial transcriptomics spots with single-cell transcriptomes</article-title>. <source>Nucleic Acids Research</source>
<volume>49</volume>(<issue>9</issue>), <fpage>e50</fpage>.<pub-id pub-id-type="pmid">33544846</pub-id>
</mixed-citation>
    </ref>
    <ref id="r22">
      <label>22.</label>
      <mixed-citation publication-type="journal" id="ref22"><string-name><surname>Andersson</surname><given-names>A</given-names></string-name>, <string-name><surname>Larsson</surname><given-names>L</given-names></string-name>, <string-name><surname>Stenbeck</surname><given-names>L</given-names></string-name>, <string-name><surname>Salmén</surname><given-names>F</given-names></string-name>, <string-name><surname>Ehinger</surname><given-names>A</given-names></string-name>, <string-name><surname>Wu</surname><given-names>SZ</given-names></string-name>, <string-name><surname>Al-Eryani</surname><given-names>G</given-names></string-name>, <string-name><surname>Roden</surname><given-names>D</given-names></string-name>, <string-name><surname>Swarbrick</surname><given-names>A</given-names></string-name>, <string-name><surname>Borg</surname><given-names>Å</given-names></string-name>, <string-name><surname>Frisén</surname><given-names>J</given-names></string-name>, <string-name><surname>Engblom</surname><given-names>C</given-names></string-name>, <string-name><surname>Lundeberg</surname><given-names>J</given-names></string-name> (<year>2021</year>) <article-title>Spatial deconvolution of HER2-positive breast cancer delineates tumor-associated cell type interactions</article-title>. <source>Nature Communications</source>
<volume>12</volume>(<issue>1</issue>), <fpage>6012</fpage>.</mixed-citation>
    </ref>
    <ref id="r23">
      <label>23.</label>
      <mixed-citation publication-type="journal" id="ref23"><string-name><surname>Buccitelli</surname><given-names>C</given-names></string-name>, <string-name><surname>Selbach</surname><given-names>M</given-names></string-name> (<year>2020</year>) <article-title>mRNAs, proteins and the emerging principles of gene expression control</article-title>. <source>Nature Reviews Genetics</source>
<volume>21</volume>(<issue>10</issue>), <fpage>630</fpage>–<lpage>644</lpage>.</mixed-citation>
    </ref>
    <ref id="r24">
      <label>24.</label>
      <mixed-citation publication-type="other" id="ref24"><collab>10× Genomics</collab> (<year>2021</year>) Input Recommendations-Software-Spatial Gene Expression-Official 10× Genomics Support [Internet]. [cited 1 January 2021]. Available at <uri xlink:href="https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/using/input-recommendations">https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/using/input-recommendations</uri>.</mixed-citation>
    </ref>
    <ref id="r25">
      <label>25.</label>
      <mixed-citation publication-type="journal" id="ref25"><string-name><surname>Raju</surname><given-names>PD</given-names></string-name>, <string-name><surname>Neelima</surname><given-names>G</given-names></string-name> (<year>2012</year>) <article-title>Image segmentation by using histogram thresholding</article-title>. <source>IJCSET</source>
<volume>2</volume>(<issue>1</issue>), <fpage>776</fpage>–<lpage>779</lpage>.</mixed-citation>
    </ref>
    <ref id="r26">
      <label>26.</label>
      <mixed-citation publication-type="other" id="ref26"><collab>Akoya Bioscience</collab> (<year>2019</year>) inForm® Tissue Finder Software [Internet]. [cited 13 April 2022]. Available at <uri xlink:href="https://www.akoyabio.com/support/software/inform-tissue-finder-software/">https://www.akoyabio.com/support/software/inform-tissue-finder-software/</uri>.</mixed-citation>
    </ref>
    <ref id="r27">
      <label>27.</label>
      <mixed-citation publication-type="other" id="ref27"><collab>Akoya Bioscience</collab> (<year>2019</year>) Phenochart Whole Slide Viewer [Internet]. [cited 12 April 2022]. Available at <uri xlink:href="https://www.akoyabio.com/support/software/phenochart-whole-slide-viewer/">https://www.akoyabio.com/support/software/phenochart-whole-slide-viewer/</uri>.</mixed-citation>
    </ref>
    <ref id="r28">
      <label>28.</label>
      <mixed-citation publication-type="journal" id="ref28"><string-name><surname>Maynard</surname><given-names>KR</given-names></string-name>, <string-name><surname>Tippani</surname><given-names>M</given-names></string-name>, <string-name><surname>Takahashi</surname><given-names>Y</given-names></string-name>, <string-name><surname>Phan</surname><given-names>BN</given-names></string-name>, <string-name><surname>Hyde</surname><given-names>TM</given-names></string-name>, <string-name><surname>Jaffe</surname><given-names>AE</given-names></string-name>, <string-name><surname>Martinowich</surname><given-names>K</given-names></string-name> (<year>2020</year>) <article-title>dotdotdot: an automated approach to quantify multiplex single molecule fluorescent in situ hybridization (smFISH) images in complex tissues</article-title>. <source>Nucleic Acids Research</source>
<volume>48</volume>(<issue>11</issue>), <fpage>e66</fpage>.<pub-id pub-id-type="pmid">32383753</pub-id>
</mixed-citation>
    </ref>
    <ref id="r29">
      <label>29.</label>
      <mixed-citation publication-type="journal" id="ref29"><string-name><surname>Righelli</surname><given-names>D</given-names></string-name>, <string-name><surname>Weber</surname><given-names>LM</given-names></string-name>, <string-name><surname>Crowell</surname><given-names>HL</given-names></string-name>, <string-name><surname>Pardo</surname><given-names>B</given-names></string-name>, <string-name><surname>Collado-Torres</surname><given-names>L</given-names></string-name>, <string-name><surname>Ghazanfar</surname><given-names>S</given-names></string-name>, <string-name><surname>Lun</surname><given-names>ATL</given-names></string-name>, <string-name><surname>Hicks</surname><given-names>SC</given-names></string-name>, <string-name><surname>Risso</surname><given-names>D</given-names></string-name> (<year>2022</year>) <article-title>Spatial experiment: infrastructure for spatially-resolved transcriptomics data in R using Bioconductor</article-title>. <source>Bioinformatics</source>
<volume>38</volume>(<issue>11</issue>), <fpage>3128</fpage>–<lpage>3131</lpage>.<pub-id pub-id-type="pmid">35482478</pub-id>
</mixed-citation>
    </ref>
    <ref id="r30">
      <label>30.</label>
      <mixed-citation publication-type="journal" id="ref30"><string-name><surname>McCarthy</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Campbell</surname><given-names>KR</given-names></string-name>, <string-name><surname>Lun</surname><given-names>ATL</given-names></string-name>, <string-name><surname>Wills</surname><given-names>QF</given-names></string-name> (<year>2017</year>) <article-title>Scater: pre-processing, quality control, normalization and visualization of single-cell RNA-seq data in R</article-title>. <source>Bioinformatics</source>
<volume>33</volume>(<issue>8</issue>), <fpage>1179</fpage>–<lpage>1186</lpage>.<pub-id pub-id-type="pmid">28088763</pub-id>
</mixed-citation>
    </ref>
    <ref id="r31">
      <label>31.</label>
      <mixed-citation publication-type="other" id="ref31"><collab>The MathWorks, Inc</collab>. (<year>2019</year>) MATLAB and Image processing toolbox. MATLAB.</mixed-citation>
    </ref>
    <ref id="r32">
      <label>32.</label>
      <mixed-citation publication-type="journal" id="ref32"><string-name><surname>Chen</surname><given-names>W-T</given-names></string-name>, <string-name><surname>Lu</surname><given-names>A</given-names></string-name>, <string-name><surname>Craessaerts</surname><given-names>K</given-names></string-name>, <string-name><surname>Pavie</surname><given-names>B</given-names></string-name>, <string-name><surname>Sala Frigerio</surname><given-names>C</given-names></string-name>, <string-name><surname>Corthout</surname><given-names>N</given-names></string-name>, <string-name><surname>Qian</surname><given-names>X</given-names></string-name>, <string-name><surname>Laláková</surname><given-names>J</given-names></string-name>, <string-name><surname>Kühnemund</surname><given-names>M</given-names></string-name>, <string-name><surname>Voytyuk</surname><given-names>I</given-names></string-name>, <string-name><surname>Wolfs</surname><given-names>L</given-names></string-name>, <string-name><surname>Mancuso</surname><given-names>R</given-names></string-name>, <string-name><surname>Salta</surname><given-names>E</given-names></string-name>, <string-name><surname>Balusu</surname><given-names>S</given-names></string-name>, <string-name><surname>Snellinx</surname><given-names>A</given-names></string-name>, <string-name><surname>Munck</surname><given-names>S</given-names></string-name>, <string-name><surname>Jurek</surname><given-names>A</given-names></string-name>, <string-name><surname>Fernandez</surname><given-names>Navarro J</given-names></string-name>, <string-name><surname>Saido</surname><given-names>TC</given-names></string-name>, <string-name><surname>Huitinga</surname><given-names>I</given-names></string-name>, <string-name><surname>De Strooper</surname><given-names>B</given-names></string-name> (<year>2020</year>) <article-title>Spatial transcriptomics and in situ sequencing to study Alzheimer’s disease</article-title>. <source>Cell</source>
<volume>182</volume>(<issue>4</issue>), <fpage>976</fpage>–<lpage>991</lpage>.e19.<pub-id pub-id-type="pmid">32702314</pub-id>
</mixed-citation>
    </ref>
    <ref id="r33">
      <label>33.</label>
      <mixed-citation publication-type="journal" id="ref33"><string-name><surname>Phillip</surname><given-names>JM</given-names></string-name>, <string-name><surname>Han</surname><given-names>K-S</given-names></string-name>, <string-name><surname>Chen</surname><given-names>W-C</given-names></string-name>, <string-name><surname>Wirtz</surname><given-names>D</given-names></string-name>, <string-name><surname>Wu</surname><given-names>P-H</given-names></string-name> (<year>2021</year>) <article-title>A robust unsupervised machine-learning method to quantify the morphological heterogeneity of cells and nuclei</article-title>. <source>Nature Protocols</source>
<volume>16</volume>(<issue>2</issue>), <fpage>754</fpage>–<lpage>774</lpage>.<pub-id pub-id-type="pmid">33424024</pub-id>
</mixed-citation>
    </ref>
    <ref id="r34">
      <label>34.</label>
      <mixed-citation publication-type="journal" id="ref34"><string-name><surname>Logan</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Shan</surname><given-names>J</given-names></string-name>, <string-name><surname>Bhatia</surname><given-names>SN</given-names></string-name>, <string-name><surname>Carpenter</surname><given-names>AE</given-names></string-name> (<year>2016</year>) <article-title>Quantifying co-cultured cell phenotypes in high-throughput using pixel-based classification</article-title>. <source>Methods</source>
<volume>96</volume>, <fpage>6</fpage>–<lpage>11</lpage>.<pub-id pub-id-type="pmid">26687239</pub-id>
</mixed-citation>
    </ref>
    <ref id="r35">
      <label>35.</label>
      <mixed-citation publication-type="journal" id="ref35"><string-name><surname>Chang</surname><given-names>Y</given-names></string-name>, <string-name><surname>He</surname><given-names>F</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Chen</surname><given-names>S</given-names></string-name>, <string-name><surname>Li</surname><given-names>J</given-names></string-name>, <string-name><surname>Liu</surname><given-names>J</given-names></string-name>, <string-name><surname>Yu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Su</surname><given-names>L</given-names></string-name>, <string-name><surname>Ma</surname><given-names>A</given-names></string-name>, <string-name><surname>Allen</surname><given-names>C</given-names></string-name>, <string-name><surname>Lin</surname><given-names>Y</given-names></string-name>, <string-name><surname>Sun</surname><given-names>S</given-names></string-name>, <string-name><surname>Liu</surname><given-names>B</given-names></string-name>, <string-name><surname>Javier Otero</surname><given-names>J</given-names></string-name>, <string-name><surname>Chung</surname><given-names>D</given-names></string-name>, <string-name><surname>Fu</surname><given-names>H</given-names></string-name>, <string-name><surname>Li</surname><given-names>Z</given-names></string-name>, <string-name><surname>Xu</surname><given-names>D</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Q</given-names></string-name> (<year>2022</year>) <article-title>Define and visualize pathological architectures of human tissues from spatially resolved transcriptomics using deep learning</article-title>. <source>Computational and Structural Biotechnology Journal</source>
<volume>20</volume>, <fpage>4600</fpage>–<lpage>4617</lpage>.<pub-id pub-id-type="pmid">36090815</pub-id>
</mixed-citation>
    </ref>
    <ref id="r36">
      <label>36.</label>
      <mixed-citation publication-type="journal" id="ref36"><string-name><surname>Palla</surname><given-names>G</given-names></string-name>, <string-name><surname>Spitzer</surname><given-names>H</given-names></string-name>, <string-name><surname>Klein</surname><given-names>M</given-names></string-name>, <string-name><surname>Fischer</surname><given-names>D</given-names></string-name>, <string-name><surname>Schaar</surname><given-names>AC</given-names></string-name>, <string-name><surname>Kuemmerle</surname><given-names>LB</given-names></string-name>, <string-name><surname>Rybakov</surname><given-names>S</given-names></string-name>, <string-name><surname>Ibarra</surname><given-names>IL</given-names></string-name>, <string-name><surname>Holmberg</surname><given-names>O</given-names></string-name>, <string-name><surname>Virshup</surname><given-names>I</given-names></string-name>, <string-name><surname>Lotfollahi</surname><given-names>M</given-names></string-name>, <string-name><surname>Richter</surname><given-names>S</given-names></string-name>, <string-name><surname>Theis</surname><given-names>FJ</given-names></string-name> (<year>2022</year>) <article-title>Squidpy: a scalable framework for spatial omics analysis</article-title>. <source>Nature Methods</source>
<volume>19</volume>(<issue>2</issue>), <fpage>171</fpage>–<lpage>178</lpage>.<pub-id pub-id-type="pmid">35102346</pub-id>
</mixed-citation>
    </ref>
    <ref id="r37">
      <label>37.</label>
      <mixed-citation publication-type="other" id="ref37"><string-name><surname>Sang-aram</surname><given-names>C</given-names></string-name>, <string-name><surname>Browaeys</surname><given-names>R</given-names></string-name>, <string-name><surname>Seurinck</surname><given-names>R</given-names></string-name>, <string-name><surname>Saeys</surname><given-names>Y</given-names></string-name> (<year>2023</year>) Spotless: a reproducible pipeline for benchmarking cell type deconvolution in spatial transcriptomics. BioRxiv.</mixed-citation>
    </ref>
    <ref id="r38">
      <label>38.</label>
      <mixed-citation publication-type="journal" id="ref38"><string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>Z</given-names></string-name>, <string-name><surname>Chen</surname><given-names>S</given-names></string-name>, <string-name><surname>Liao</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>B</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>R</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Sun</surname><given-names>S</given-names></string-name>, <string-name><surname>Gao</surname><given-names>X</given-names></string-name> (<year>2023</year>) <article-title>A comprehensive benchmarking with practical guidelines for cellular deconvolution of spatial transcriptomics</article-title>. <source>Nature Communications</source>
<volume>14</volume>(<issue>1</issue>):<fpage>1548</fpage>.</mixed-citation>
    </ref>
    <ref id="r39">
      <label>39.</label>
      <mixed-citation publication-type="other" id="ref39"><string-name><surname>Huuki-Myers</surname><given-names>L</given-names></string-name>, <string-name><surname>Spangler</surname><given-names>A</given-names></string-name>, <string-name><surname>Eagles</surname><given-names>N</given-names></string-name>, <string-name><surname>Montgomery</surname><given-names>KD</given-names></string-name>, <string-name><surname>Kwon</surname><given-names>SH</given-names></string-name>, <string-name><surname>Guo</surname><given-names>B</given-names></string-name>, <string-name><surname>Grant-Peters</surname><given-names>M</given-names></string-name>, <string-name><surname>Divecha</surname><given-names>HR</given-names></string-name>, <string-name><surname>Tippani</surname><given-names>M</given-names></string-name>, <string-name><surname>Sriworarat</surname><given-names>C</given-names></string-name>, <string-name><surname>Nguyen</surname><given-names>AB</given-names></string-name>, <string-name><surname>Ravichandran</surname><given-names>P</given-names></string-name>, <string-name><surname>Tran</surname><given-names>MN</given-names></string-name>, <string-name><surname>Seyedian</surname><given-names>A</given-names></string-name>, <string-name><surname>PsychENCODE</surname><given-names>consortium</given-names></string-name>, <string-name><surname>Hyde</surname><given-names>TM</given-names></string-name>, <string-name><surname>Kleinman</surname><given-names>JE</given-names></string-name>, <string-name><surname>Battle</surname><given-names>A</given-names></string-name>, <string-name><surname>Page</surname><given-names>SC</given-names></string-name>, <string-name><surname>Ryten</surname><given-names>M</given-names></string-name>, <string-name><surname>Maynard</surname><given-names>KR</given-names></string-name> (<year>2023</year>) Integrated single cell and unsupervised spatial transcriptomic analysis defines molecular anatomy of the human dorsolateral prefrontal cortex. BioRxiv.</mixed-citation>
    </ref>
    <ref id="r40">
      <label>40.</label>
      <mixed-citation publication-type="other" id="ref40"><collab>Indica Labs</collab> (<year>2022</year>) HALO [Internet]. [cited 19 April 2022]. Available at <uri xlink:href="https://indicalab.com/?page_id=2637">https://indicalab.com/?page_id=2637</uri>.</mixed-citation>
    </ref>
    <ref id="r41">
      <label>41.</label>
      <mixed-citation publication-type="other" id="ref41"><collab>The MathWorks, Inc.</collab> (<year>2022</year>) MATLAB Open Science [Internet]. [cited 28 April 2022]. Available at <uri xlink:href="https://www.mathworks.com/discovery/open-science.html">https://www.mathworks.com/discovery/open-science.html</uri>.</mixed-citation>
    </ref>
    <ref id="r42">
      <label>42.</label>
      <mixed-citation publication-type="journal" id="ref42"><string-name><surname>Hao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hao</surname><given-names>S</given-names></string-name>, <string-name><surname>Andersen-Nissen</surname><given-names>E</given-names></string-name>, <string-name><surname>Mauck</surname><given-names>WM</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>S</given-names></string-name>, <string-name><surname>Butler</surname><given-names>A</given-names></string-name>, <string-name><surname>Lee</surname><given-names>MJ</given-names></string-name>, <string-name><surname>Wilk</surname><given-names>AJ</given-names></string-name>, <string-name><surname>Darby</surname><given-names>C</given-names></string-name>, <string-name><surname>Zager</surname><given-names>M</given-names></string-name>, <string-name><surname>Hoffman</surname><given-names>P</given-names></string-name>, <string-name><surname>Stoeckius</surname><given-names>M</given-names></string-name>, <string-name><surname>Papalexi</surname><given-names>E</given-names></string-name>, <string-name><surname>Mimitou</surname><given-names>EP</given-names></string-name>, <string-name><surname>Jain</surname><given-names>J</given-names></string-name>, <string-name><surname>Srivastava</surname><given-names>A</given-names></string-name>, <string-name><surname>Stuart</surname><given-names>T</given-names></string-name>, <string-name><surname>Fleming</surname><given-names>LM</given-names></string-name>, <string-name><surname>Yeung</surname><given-names>B</given-names></string-name>, <string-name><surname>Rogers</surname><given-names>AJ</given-names></string-name>, <string-name><surname>Satija</surname><given-names>R</given-names></string-name> (<year>2021</year>) <article-title>Integrated analysis of multimodal single-cell data</article-title>. <source>Cell</source>
<volume>184</volume>(<issue>13</issue>), <fpage>3573</fpage>–<lpage>3587</lpage>.e29.<pub-id pub-id-type="pmid">34062119</pub-id>
</mixed-citation>
    </ref>
    <ref id="r43">
      <label>43.</label>
      <mixed-citation publication-type="other" id="ref43"><string-name><surname>Virshup</surname><given-names>I</given-names></string-name>, <string-name><surname>Rybakov</surname><given-names>S</given-names></string-name>, <string-name><surname>Theis</surname><given-names>FJ</given-names></string-name>, <string-name><surname>Angerer</surname><given-names>P</given-names></string-name>, <string-name><surname>Wolf</surname><given-names>FA</given-names></string-name> (<year>2021</year>) anndata: annotated data. BioRxiv.</mixed-citation>
    </ref>
    <ref id="r44">
      <label>44.</label>
      <mixed-citation publication-type="other" id="ref44"><string-name><surname>Zappia</surname><given-names>L, Lun A, Cannoodt R</given-names></string-name> (<year>2020</year>) zellkonverter: Conversion Between scRNA-seq Objects. Bioconductor.</mixed-citation>
    </ref>
    <ref id="r45">
      <label>45.</label>
      <mixed-citation publication-type="journal" id="ref45"><string-name><surname>Lipska</surname><given-names>BK</given-names></string-name>, <string-name><surname>Deep-Soboslay</surname><given-names>A</given-names></string-name>, <string-name><surname>Weickert</surname><given-names>CS</given-names></string-name>, <string-name><surname>Hyde</surname><given-names>TM</given-names></string-name>, <string-name><surname>Martin</surname><given-names>CE</given-names></string-name>, <string-name><surname>Herman</surname><given-names>MM</given-names></string-name>, <string-name><surname>Kleinman</surname><given-names>JE</given-names></string-name> (<year>2006</year>) <article-title>Critical factors in gene expression in postmortem human brain: focus on studies in schizophrenia</article-title>. <source>Biological Psychiatry</source>
<volume>60</volume>(<issue>6</issue>), <fpage>650</fpage>–<lpage>658</lpage>.<pub-id pub-id-type="pmid">16997002</pub-id>
</mixed-citation>
    </ref>
    <ref id="r46">
      <label>46.</label>
      <mixed-citation publication-type="other" id="ref46">10× Genomics (<year>2021</year>) Imaging guidelines. [cited 18 April 2022]. Available at <uri xlink:href="https://assets.ctfassets.net/an68im79xiti/7t2k87zNaujdxcaAesoPB8/add94b0b5869d3c50825b691ffc98373/CG000241_VisiumImagingGuidelinesTN_RevD.pdf">https://assets.ctfassets.net/an68im79xiti/7t2k87zNaujdxcaAesoPB8/add94b0b5869d3c50825b691ffc98373/CG000241_VisiumImagingGuidelinesTN_RevD.pdf</uri>.</mixed-citation>
    </ref>
    <ref id="r47">
      <label>47.</label>
      <mixed-citation publication-type="other" id="ref47"><collab>Lieber Institute for Brain Development MT</collab> (<year>2021</year>) <italic toggle="yes">VistoSeg Software [Internet]. Zenodo.</italic> [cited 24 April 2022]. Available at <pub-id pub-id-type="doi">10.5281/zenodo.5156783</pub-id>.</mixed-citation>
    </ref>
    <ref id="r48">
      <label>48.</label>
      <mixed-citation publication-type="other" id="ref48"><string-name><surname>Tippani</surname><given-names>M</given-names></string-name>, <string-name><surname>Divecha</surname><given-names>HR</given-names></string-name>, Catallini II JL, <string-name><surname>Weber</surname><given-names>LM</given-names></string-name>, <string-name><surname>Kwon</surname><given-names>SH</given-names></string-name>, <string-name><surname>Spangler</surname><given-names>A</given-names></string-name>, <string-name><surname>Jaffe</surname><given-names>A</given-names></string-name>, <string-name><surname>Hicks</surname><given-names>SC</given-names></string-name>, <string-name><surname>Martinowich</surname><given-names>K</given-names></string-name>, <string-name><surname>Collado-Torres</surname><given-names>L</given-names></string-name>, <string-name><surname>Page</surname><given-names>SC</given-names></string-name>, <string-name><surname>Maynard</surname><given-names>K</given-names></string-name> (<year>2022</year>) VistoSeg: processing utilities for high-resolution Visium/Visium-IF images for spatial transcriptomics data (supplementary material). Figshare.</mixed-citation>
    </ref>
    <ref id="r49">
      <label>49.</label>
      <mixed-citation publication-type="other" id="ref49"><collab>10× Genomics</collab> (<year>2022</year>) 10× Genomics public datasets [Internet]. [cited 17 April 2022]. Available at <uri xlink:href="https://www.10xgenomics.com/resources/datasets">https://www.10xgenomics.com/resources/datasets</uri>.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Biol Imaging</journal-id>
    <journal-id journal-id-type="iso-abbrev">Biol Imaging</journal-id>
    <journal-id journal-id-type="publisher-id">BLG</journal-id>
    <journal-title-group>
      <journal-title>Biological Imaging</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2633-903X</issn>
    <publisher>
      <publisher-name>Cambridge University Press</publisher-name>
      <publisher-loc>Cambridge, UK</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10951916</article-id>
    <article-id pub-id-type="doi">10.1017/S2633903X23000235</article-id>
    <article-id pub-id-type="publisher-id">S2633903X23000235</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software Report</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title><italic toggle="yes">VistoSeg</italic>: Processing utilities for high-resolution images for spatially resolved transcriptomics data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Tippani</surname>
          <given-names>Madhavi</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Divecha</surname>
          <given-names>Heena R.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Catallini</surname>
          <given-names>Joseph L.</given-names>
          <suffix>II</suffix>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kwon</surname>
          <given-names>Sang H.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Weber</surname>
          <given-names>Lukas M.</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Spangler</surname>
          <given-names>Abby</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jaffe</surname>
          <given-names>Andrew E.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hyde</surname>
          <given-names>Thomas M.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="aff5" ref-type="aff">
          <sup>5</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kleinman</surname>
          <given-names>Joel E.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-7858-0231</contrib-id>
        <name>
          <surname>Hicks</surname>
          <given-names>Stephanie C.</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Martinowich</surname>
          <given-names>Keri</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="aff6" ref-type="aff">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Collado-Torres</surname>
          <given-names>Leonardo</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Page</surname>
          <given-names>Stephanie C.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-0031-8468</contrib-id>
        <name>
          <surname>Maynard</surname>
          <given-names>Kristen R.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><label>1</label>Lieber Institute for Brain Development, <institution>Johns Hopkins Medical Campus</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <aff id="aff2"><label>2</label>Department of Biostatistics, <institution>Johns Hopkins Bloomberg School of Public Health</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <aff id="aff3"><label>3</label>Department of Neuroscience, <institution>Johns Hopkins University School of Medicine</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <aff id="aff4"><label>4</label>Department of Psychiatry and Behavioral Sciences, <institution>Johns Hopkins University School of Medicine</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <aff id="aff5"><label>5</label>Department of Neurology, <institution>Johns Hopkins School of Medicine</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <aff id="aff6"><label>6</label>The Kavli Neuroscience Discovery Institute, <institution>Johns Hopkins University</institution>, <city>Baltimore</city>, <state>MD</state>, <country>USA</country></aff>
    <author-notes>
      <corresp id="cor1"><bold>Corresponding authors:</bold> Madhavi Tippani, Stephanie C. Page, and Kristen R. Maynard; Emails: <email>madhavi.tippani@libd.org</email>; <email>stephanie.page@libd.org</email>; <email>kristen.maynard@libd.org</email></corresp>
    </author-notes>
    <pub-date publication-format="electronic" date-type="collection" iso-8601-date="2023">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>13</day>
      <month>11</month>
      <year>2023</year>
    </pub-date>
    <volume>3</volume>
    <elocation-id>e23</elocation-id>
    <history>
      <date date-type="received">
        <day>25</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>14</day>
        <month>7</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>19</day>
        <month>9</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>The Author(s)</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This is an Open Access article, distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivatives licence (<uri xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0</uri>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided that no alterations are made and the original article is properly cited. The written permission of Cambridge University Press must be obtained prior to any commercial use and/or adaptation of the article.</license-p>
      </license>
    </permissions>
    <self-uri xlink:title="pdf" xlink:href="S2633903X23000235a.pdf"/>
    <abstract>
      <p>Spatially resolved transcriptomics (SRT) is a growing field that links gene expression to anatomical context. SRT approaches that use next-generation sequencing (NGS) combine RNA sequencing with histological or fluorescent imaging to generate spatial maps of gene expression in intact tissue sections. These technologies directly couple gene expression measurements with high-resolution histological or immunofluorescent images that contain rich morphological information about the tissue under study. While broad access to NGS-based spatial transcriptomic technology is now commercially available through the Visium platform from the vendor 10× Genomics, computational tools for extracting image-derived metrics for integration with gene expression data remain limited. We developed <italic toggle="yes">VistoSeg</italic> as a MATLAB pipeline to process, analyze and interactively visualize the high-resolution images generated in the Visium platform. <italic toggle="yes">VistoSeg</italic> outputs can be easily integrated with accompanying transcriptomic data to facilitate downstream analyses in common programing languages including R and Python. <italic toggle="yes">VistoSeg</italic> provides user-friendly tools for integrating image-derived metrics from histological and immunofluorescent images with spatially resolved gene expression data. Integration of this data enhances the ability to understand the transcriptional landscape within tissue architecture. <italic toggle="yes">VistoSeg</italic> is freely available at <uri xlink:href="http://research.libd.org/VistoSeg/">http://research.libd.org/VistoSeg/</uri>.</p>
    </abstract>
    <kwd-group>
      <title>Keywords</title>
      <kwd>hematoxylin and eosin</kwd>
      <kwd>immunofluorescence</kwd>
      <kwd>MATLAB</kwd>
      <kwd>segmentation</kwd>
      <kwd>spatially resolved transcriptomics</kwd>
      <kwd>Visium</kwd>
      <kwd>Visium-Spatial Proteogenomics</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="aw001">
        <funding-source>
          <institution-wrap>
            <institution>Lieber Institute for Brain Development</institution>
            <institution-id institution-id-type="doi">http://dx.doi.org/10.13039/100015503</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group id="aw002">
        <funding-source>
          <institution-wrap>
            <institution>National Institute of Mental Health</institution>
            <institution-id institution-id-type="doi">http://dx.doi.org/10.13039/100000025</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R01MH126393</award-id>
      </award-group>
      <award-group id="aw003">
        <funding-source>
          <institution-wrap>
            <institution>National Institute of Mental Health</institution>
            <institution-id institution-id-type="doi">http://dx.doi.org/10.13039/100000025</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>U01MH122849</award-id>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="4"/>
      <ref-count count="49"/>
      <page-count count="15"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="other" id="sec1">
    <title>Impact Statement</title>
    <p>The advent of spatially resolved transcriptomics (SRT) technologies has facilitated the study of gene expression in an anatomical context. However, next-generation sequencing (NGS)-based SRT approaches pose an emerging challenge: integrating transcriptome-wide spatial gene expression with high-resolution tissue images (brightfield histology or fluorescent antibody staining) to generate precise maps of spatial gene expression across intact tissue sections. We developed <italic toggle="yes">VistoSeg</italic> as an image-processing software to address these needs. <italic toggle="yes">VistoSeg</italic> is currently compatible with the Visium and Visium Spatial Proteogenomics (Visium-SPG) platforms (10× Genomics), which are NGS-based SRT assays employing histological and immunofluorescent tissue images, respectively. <italic toggle="yes">VistoSeg</italic> provides computational imaging-processing tools to extract cell number, cell type identity, and other image-derived metrics at spatially defined locations across the tissue section to incorporate with corresponding gene expression measurements.</p>
  </sec>
  <sec sec-type="intro" id="sec2">
    <label>1.</label>
    <title>Introduction</title>
    <p>In the past decade, RNA sequencing (RNA-seq) moved beyond profiling in homogenate tissue to defining gene expression at single-cell or single-nucleus (sc/snRNA-seq) resolution. This technological development motivated the generation of new computational methods that answered many previously unaddressed biological questions. However, spatial information about where cells resided within the tissue remained lacking. Spatially resolved transcriptomics (SRT) is a new class of technologies that measures gene expression along spatial coordinates.<sup>(</sup><xref rid="r1" ref-type="bibr"><sup>1</sup></xref><sup>)</sup> Next-generation sequencing (NGS)-based SRT technologies are especially powerful for their ability to define transcriptome-wide gene expression patterns across intact tissue sections. While there are several laboratories that have developed custom methods to perform NGS-based SRT,<sup>(</sup><xref rid="r2" ref-type="bibr"><sup>2</sup></xref><sup>–</sup><xref rid="r5" ref-type="bibr"><sup>5</sup></xref><sup>)</sup> the commercially available Visium platform from 10× Genomics is the leading and most widely adopted technology for generating transcriptome-wide spatial gene expression data in intact tissue sections.<sup>(</sup><xref rid="r6" ref-type="bibr"><sup>6</sup></xref><sup>)</sup> Because SRT data includes paired gene expression and microscopy images from the same tissue section, analysis of this data necessitates tools to integrate both modalities.</p>
    <p>The Visium workflow uses an on-slide spatial barcoding strategy to map RNA-seq reads to defined anatomical locations (“spots”) in an intact tissue section (<xref rid="fig1" ref-type="fig">Figure 1a</xref>). Briefly, each slide contains four arrays (<xref rid="fig1" ref-type="fig">Figure 1b</xref>: A1, B1, C1, D1), and each array contains ~5,000 gene expression capture “spots,” which are 55 μm in diameter (2,375 μm<sup>2</sup> in area) and spaced 100 μm center-to-center in a honeycomb pattern (<xref rid="fig1" ref-type="fig">Figure 1b</xref>). On-slide cDNA synthesis incorporates spatial barcodes for each spot, which is followed by RNA-seq to obtain gene expression measurements at each anatomical location (<xref rid="fig1" ref-type="fig">Figure 1c</xref>). The platform currently supports two major workflows: Visium-H&amp;E and Visium-Spatial Proteogenomics (Visium-SPG). In the Visium-H&amp;E workflow, tissue sections are stained with hematoxylin and eosin (H&amp;E), and a brightfield histological image is acquired. In Visium-SPG, tissue sections are labeled with antibodies conjugated to fluorophores, and multiplex fluorescent images are acquired to visualize specific proteins of interest. In both cases, images are used to create an integrated map of transcriptome-wide gene expression within the tissue architecture. In the case of Visium-SPG, transcriptomic data can also be analyzed in the context of proteomic data from antibody labeling.<fig position="float" id="fig1"><label>Figure 1.</label><caption><p>Visium workflow. (a) Visium spatial gene expression slide containing four 6.5 mm x 6.5 mm capture areas bound by a fiducial frame. (b) Each capture area contains a grid printed with ~5,000 spots with unique spatial barcodes that allow mRNA measurements to be mapped back to the X–Y location on the tissue. (c) Spatial barcodes are incorporated during on-slide cDNA synthesis. The cDNA is eluted off the slide, and libraries are prepared and sequenced. Reads are mapped to spatial coordinates on the histological image using SpaceRanger software (10× Genomics), which provides a transcriptome-wide readout of gene expression at each spatial coordinate.</p></caption><graphic xlink:href="S2633903X23000235_fig1" position="float"/></fig></p>
    <p>To maintain RNA integrity for compatibility with downstream transcriptomic workflows, speed and throughput capacity are important considerations for image acquisition protocols. In line with these considerations, imaging is often performed on slide scanners or other high-throughput microscopy systems that are commonly used for pathology image acquisition and analysis. To support integration with downstream molecular gene expression data, preprocessing utilities are needed to separate the large whole-slide images into single images representing each individual tissue section. These images then need to be further segmented to extract meaningful metrics about cell number, morphology, position, etc. Current analytical tools available from 10× Genomics focus heavily on gene expression data and do not support in-depth processing or analysis (e.g., nuclear or cellular segmentation) of imaging data. Specifically, 10× Genomics provides two software programs, Loupe Browser<sup>(</sup><xref rid="r7" ref-type="bibr"><sup>7</sup></xref><sup>)</sup> and SpaceRanger,<sup>(</sup><xref rid="r8" ref-type="bibr"><sup>8</sup></xref><sup>)</sup> which enable data extraction and primary visualization of SRT data, but have limited functionality for more advanced processing.</p>
    <p>Other existing software also fail to provide the necessary functionalities that would allow users to take the images from preprocessing to quantitative integration of gene expression data with extracted metrics. For example, the open source software package QuPath<sup>(</sup><xref rid="r9" ref-type="bibr"><sup>9</sup></xref><sup>)</sup> does not support preprocessing of the multichannel fluorescent images and requires downsampling, resulting in reduced image resolution when opening, cropping and exporting images. The commercially available image analysis software HALO enables quantification and classification of cells and nuclei, but does not support integration with gene expression data. Several software packages have been developed in the Python and R programming languages for cell segmentation and subsequent registration of microscopy images to anatomical reference atlases.<sup>(</sup><xref rid="r10" ref-type="bibr"><sup>10</sup></xref><sup>,</sup><xref rid="r11" ref-type="bibr"><sup>11</sup></xref><sup>)</sup> While some of these frameworks have been applied to SRT data,<sup>(</sup><xref rid="r12" ref-type="bibr"><sup>12</sup></xref><sup>)</sup> they were designed and optimized for cultured cells and mouse brain tissue sections. In contrast, other packages, such as Fiji<sup>(</sup><xref rid="r13" ref-type="bibr"><sup>13</sup></xref><sup>)</sup> and CellProfiler,<sup>(</sup><xref rid="r14" ref-type="bibr"><sup>14</sup></xref><sup>)</sup> lack functions to automatically split large whole-slide images into individual arrays and have limited features for visualizing large images.</p>
    <p>The limited functionality of currently available resources poses a significant problem for the field because the acquired images contain valuable information that could be more fully mined and incorporated into downstream analyses.<sup>(</sup><xref rid="r15" ref-type="bibr"><sup>15</sup></xref><sup>,</sup><xref rid="r16" ref-type="bibr"><sup>16</sup></xref><sup>)</sup> For example, in the Visium-H&amp;E platform, cell/nuclei segmentation in the H&amp;E images can be used to estimate the number of cells in each gene expression spot or to identify cell types based on classic morphologies.<sup>(</sup><xref rid="r16" ref-type="bibr"><sup>16</sup></xref><sup>,</sup><xref rid="r17" ref-type="bibr"><sup>17</sup></xref><sup>)</sup> Analysis of H&amp;E images can also identify spots containing a single cell, or spots enriched in specific cellular compartments (i.e., axon- and dendrite-rich neuropil in brain tissue).<sup>(</sup><xref rid="r18" ref-type="bibr"><sup>18</sup></xref><sup>)</sup> Gene expression clustering algorithms are also beginning to incorporate metrics from imaging data, such as RGB (Red, Green, Blue) color values, to better define anatomically relevant spatial regions across tissue sections.<sup>(</sup><xref rid="r15" ref-type="bibr"><sup>15</sup></xref><sup>)</sup></p>
    <p>Furthermore, Visium-SPG technology is especially powerful as it can be used to label specific cell types. Combining gene expression data with images where known cell types have been fluorescently labeled can generate a ground truth for evaluating <italic toggle="yes">in silico</italic> methods that aim to perform spot deconvolution and identify cell type proportions across spots.<sup>(</sup><xref rid="r19" ref-type="bibr"><sup>19</sup></xref><sup>–</sup><xref rid="r21" ref-type="bibr"><sup>21</sup></xref><sup>)</sup> Using the Visium-SPG platform, images can also be segmented to identify the locations and quantify the abundance of proteins that are associated with known pathologies. This data can then be used to analyze local gene expression in the context of pathology to better understand molecular associations of disease.<sup>(</sup><xref rid="r22" ref-type="bibr"><sup>22</sup></xref><sup>)</sup> Moreover, since RNA expression is not always fully predictive of protein abundance levels, Visium-SPG and its associated fluorescent images can be used to quantify protein abundance. This is especially relevant for proteins where RNA quantification cannot serve as a proxy for expression, such as extracellular matrix proteins or secreted factors.<sup>(</sup><xref rid="r23" ref-type="bibr"><sup>23</sup></xref><sup>)</sup></p>
    <p>To address these challenges and provide an end-to-end solution that is tailored to image-processing analysis for the Visium-H&amp;E and -SPG platforms, we developed <italic toggle="yes">VistoSeg.</italic>
<italic toggle="yes">VistoSeg</italic> is a MATLAB-based software package that facilitates preprocessing, segmentation, analysis and visualization of H&amp;E and immunofluorescent images generated on the Visium-H&amp;E and Visium-SPG platforms for integration with gene expression data. We also provide user-friendly tutorials and vignettes to support the application of <italic toggle="yes">VistoSeg</italic> to new datasets generated by the scientific community.</p>
  </sec>
  <sec sec-type="results" id="sec3">
    <label>2.</label>
    <title>Results</title>
    <p>Here we describe the implementation and requirements for <italic toggle="yes">VistoSeg,</italic> an automated pipeline for processing high-resolution histological or immunofluorescent images acquired using Visium-H&amp;E or Visium-SPG workflows, for integration with downstream spatial transcriptomics analysis.</p>
    <sec sec-type="other" id="sec4">
      <label>2.1.</label>
      <title>H&amp;E image processing</title>
      <p>Prior to image analysis, we collected brain tissue sections from the dorsolateral prefrontal cortex (<xref rid="fig2" ref-type="fig">Figure 2a</xref>) and performed the Visium-H&amp;E workflow.<sup>(</sup><xref rid="r18" ref-type="bibr"><sup>18</sup></xref><sup>)</sup> Tissue sections were stained with H&amp;E, and brightfield histology images were acquired using a Leica Aperio CS2 slide scanner (<xref rid="fig2" ref-type="fig">Figure 2b</xref>). Because the TIFF images acquired on the slide scanner include the whole slide, which contains four arrays (<xref rid="fig2" ref-type="fig">Figure 2c</xref>), the image needs to be split into individual capture area arrays to proceed with downstream analysis. We created a function (<italic toggle="yes">splitslide</italic>) that reads in the TIFF image as an RGB matrix and splits it along the x-axis into four equal RGB matrices. Each individual RGB matrix is considered a capture area and is saved as a separate RGB TIFF file at 70% resolution of the raw individual RGB matrix. For example, a matrix that is of size 10,000 × 10,000 × 3 pixels is resized to 7,000 × 7,000 × 3 pixels. Since MATLAB requires that image files (TIFF, PNG, JPEG) be no larger than 2<sup>32</sup> − 1 bytes, image downsampling is necessary since the raw files would exceed these limitations. Individual resized matrices/images are saved at the downsampled resolution of at least 2,000 pixels in either dimension (X and Y).<fig position="float" id="fig2"><label>Figure 2.</label><caption><p>VistoSeg workflow for Visium H&amp;E image processing. (a) Example data collection from postmortem human dorsolateral prefrontal cortex (DLPFC). Each tissue block and corresponding 10-μm section spans the six cortical layers and white matter. (b) Four tissue sections were placed on a Visium gene expression slide and stained with H&amp;E. Brightfield images were acquired using a Leica Aperio CS2 slide scanner. (c) The CS2 scanner produces a large, high-resolution image of the entire slide in TIFF format, which VistoSeg splits into four individual capture areas using splitslide. (d) VistoSeg uses a two-step process for nuclei segmentation, called VNS and refineVNS, to segment nuclei in each individual capture area. (e) Concurrent with nuclei segmentation, individual capture area images from (d) are processed using SpaceRanger (10× Genomics) to align gene expression data to the histological image and export spot metrics including spot diameter, spot spacing and spot coordinates (titled by default as “tissue_positions_list.csv” and “scalefactors_json.json”). (f) The countNuclei function in VistoSeg computes the number of cells/nuclei per spot using the outputs from SpaceRanger, which is then exported as the “tissue_spot_counts.csv” file. (g) VistoSeg includes an interactive GUI, spotspotcheck, which enables the user to toggle between the segmented binary image and raw histology image to visually inspect the segmented nuclei in each spot. Users can zoom in/out on the high-resolution image. A search tab enables users to locate spots of interest based on the barcode identifier, which enables exploration of image features related to gene expression patterns.</p></caption><graphic xlink:href="S2633903X23000235_fig2" position="float"/></fig></p>
      <p>To align the sequencing files containing gene expression information with specific spatial locations (i.e., spots) on the image, users must employ the SpaceRanger software provided by 10× Genomics.<sup>(</sup><xref rid="r8" ref-type="bibr"><sup>8</sup></xref><sup>)</sup> Using the fiducial frame on the image as reference, SpaceRanger uses the downsized TIFF files produced by the <italic toggle="yes">splitSlide</italic> function<sup>(</sup><xref rid="r24" ref-type="bibr"><sup>24</sup></xref><sup>)</sup> as input to extract the barcode identifier (ID), pixel (X, Y) centroid location, and radius of each spot. SpaceRanger does not extract any information from the image beyond the presence or absence of tissue at a particular location. The output of SpaceRanger is a list of tissue positions (<italic toggle="yes">.csv)</italic> and the scale factors (<italic toggle="yes">.json</italic>) (named as tissue_positions_list.csv and scalefactors_json.json by default) to enable the quantification of gene expression in a spatial context. Further information regarding the workflow and implementation of SpaceRanger<sup>(</sup><xref rid="r8" ref-type="bibr"><sup>8</sup></xref><sup>)</sup> is available on our accompanying website: <uri xlink:href="http://research.libd.org/VistoSeg/step-3-spaceranger.html">http://research.libd.org/VistoSeg/step-3-spaceranger.html</uri>. To facilitate extraction of relevant imaging metrics at the same spatial locations (spots) queried for gene expression, <italic toggle="yes">VistoSeg</italic> uses the output .<italic toggle="yes">csv</italic> and .<italic toggle="yes">json</italic> files from SpaceRanger to build the spot grid on the image and enable the extraction of image-based metrics (e.g., nuclei count, percentage spot covered by nuclei) for each spot location (<xref rid="fig2" ref-type="fig">Figure 2e</xref>). The image-based information and the gene expression-based data are grouped together using the spot barcode identifier, which enables the quantification of gene expression and morphology metrics in a spatial context.</p>
      <p>To segment nuclei from the H&amp;E image (<xref rid="fig3" ref-type="fig">Figure 3a</xref>), we performed Gaussian smoothing and then applied contrast adjustments (<xref rid="fig3" ref-type="fig">Figure 3a</xref>) to enhance nuclei visibility in the image (<xref rid="fig3" ref-type="fig">Figure 3b</xref>). The enhanced image was then converted from RGB color space to CIELAB color space, also called L*a*b color space (<xref rid="fig3" ref-type="fig">Figure 3c</xref>). L*a*b color space is defined by: “L,” luminosity layer measures lightness from black to white; “a,” chromaticity layer measures color along the red–green axis; and “b,” chromaticity layer measures color along blue–yellow axis. CIELAB color space enables the quantification of the individual color gradients that are visually observable across the image. The a*b color space is extracted from the L*a*b-converted image and used as input to <italic toggle="yes">K</italic>-means clustering with the MATLAB function <italic toggle="yes">imsegkmeans</italic> (<xref rid="fig3" ref-type="fig">Figure 3d</xref>), along with the number of color gradients (<italic toggle="yes">k</italic>) that were visually identified in the image. The function output creates a binary mask for each color gradient (<italic toggle="yes">k</italic>) in the image. Given that nuclei in H&amp;E images have a bright color that can be easily differentiated from the background, we used a binary mask generated from the nuclei color gradient for initial nuclei segmentation to identify nuclei as regions of interest (ROIs; <xref rid="fig3" ref-type="fig">Figure 3d</xref>, cluster 3, <xref rid="fig3" ref-type="fig">Figure 3d<bold>’</bold></xref>). We combined these steps (<xref rid="fig3" ref-type="fig">Figure 3a–d’</xref>) into a function termed <italic toggle="yes">VNS</italic> (Visium Nuclei Segmentation).<fig position="float" id="fig3"><label>Figure 3.</label><caption><p>VistoSeg workflow for Visium H&amp;E image segmentation. (a) Raw histology image of human dorsolateral prefrontal cortex. (b) Gaussian smoothed and contrast-adjusted image of the raw histology image in (a). (c) Enhanced image from (b) converted from RGB color space to L*a*b color space. (d) Different color gradients (k = 5) identified by the MATLAB function imsegkmeans applied to the raw histology image. Cluster 3 corresponded to the nuclei, stained blue in the raw histology image. (d’) An inset of nuclei cluster 3 in (d). (e) Output of refineVNS from nuclei cluster 3 (d’). The refineVNS function allows for separation of adjacent nuclei. (f) Final binary nuclei segmentation obtained from (e).</p></caption><graphic xlink:href="S2633903X23000235_fig3" position="float"/></fig></p>
      <p>Due to the smoothing step applied, the nuclei edges are blurred, and hence nuclei in close proximity to one another are segmented as a single ROI (<xref rid="fig3" ref-type="fig">Figure 3d’</xref>). To further refine these segmentations to detect and quantify individual nuclei (<xref rid="fig3" ref-type="fig">Figure 3f</xref>), we created a second function (termed <italic toggle="yes">refineVNS</italic>) that extracts the intensity of the pixels from the binary mask of nuclei generated by <italic toggle="yes">VNS</italic> and applies intensity thresholding<sup>(</sup><xref rid="r25" ref-type="bibr"><sup>25</sup></xref><sup>)</sup> to separate the darker nuclei regions at the center from the lighter regions at the borders (<xref rid="fig3" ref-type="fig">Figure 3e</xref>). The final segmentation output is a binary image. The use of our <italic toggle="yes">VNS</italic> and <italic toggle="yes">refineVNS</italic> function results in segmentation of individual cell bodies in human DLPFC tissue (<xref rid="fig2" ref-type="fig">Figures 2g</xref> and <xref rid="fig3" ref-type="fig">3d–f</xref>).</p>
    </sec>
    <sec sec-type="other" id="sec5">
      <label>2.2.</label>
      <title>Multichannel fluorescent image processing</title>
      <p>In the Visium-SPG platform, samples are subjected to immunofluorescent antibody labeling to detect specific proteins of interest, thereby generating proteomic data that can be quantified and integrated with transcriptomic data. We collected four individual tissue sections of the human dorsolateral prefrontal cortex (DLPFC) spanning the six cortical layers and white matter and performed the Visium-SPG workflow (<xref rid="fig4" ref-type="fig">Figure 4</xref>). To visualize cellular composition and cell type distribution across the tissue section, samples were immunostained with four established cell type markers: NeuN (Alexa 555) for neurons, TMEM119 (Alexa 647) for microglia, GFAP (Alexa 488) for astrocytes, and OLIG2 (Alexa 647) for oligodendrocytes. Immunofluorescent images were acquired using a Vectra Polaris slide scanner (Akoya Biosciences) and processed to decompose the multispectral profiles (<xref rid="fig4" ref-type="fig">Figure 4a</xref>).<sup>(</sup><xref rid="r26" ref-type="bibr"><sup>26</sup></xref><sup>,</sup><xref rid="r27" ref-type="bibr"><sup>27</sup></xref><sup>)</sup> The final image outputs were spectrally unmixed multichannel TIFF tiles of the entire slide (~600 tiles). These individual tiles were stitched to recreate a multichannel TIFF image spanning the whole slide (<xref rid="fig4" ref-type="fig">Figure 4b</xref>) using the X and Y coordinates of each tile, as saved in the filename, to position tiles (<italic toggle="yes">inFormStitch</italic>). Next, this image was split along the Y-axis into four individual capture area images in multichannel TIFF format (<italic toggle="yes">splitSlide_IF</italic>; <xref rid="fig4" ref-type="fig">Figure 4c</xref>). We then segmented each fluorescent channel to identify ROIs (<xref rid="fig4" ref-type="fig">Figure 4d</xref>) as previously described.<sup>(</sup><xref rid="r28" ref-type="bibr"><sup>28</sup></xref><sup>)</sup> Finally, we used the <italic toggle="yes">countNuclei</italic> function to quantify the size, intensity and location of segmented signals in each channel for integration with gene expression data (<xref rid="fig4" ref-type="fig">Figure 4e</xref>). The output table from <italic toggle="yes">countNuclei</italic> has two columns per channel by default: (1) count of segmented ROIs per Visium spot and (2) proportion of the spot covered by the segmented signal. Other user-defined metrics, including mean fluorescent intensity per spot or mean intensity of segmented ROIs for each channel within a spot, can also be extracted. Quantification of immunofluorescent signals in white matter of the dorsolateral prefrontal cortex (<xref rid="fig4" ref-type="fig">Figure 4g</xref>) is consistent with our expectation of higher counts for glial cells stained by TMEM119 (microglia), GFAP (astrocytes) and OLIG2 (oligodendrocytes) compared to the neuron-enriched gray matter (<uri xlink:href="https://doi.org/10.1017/S2633903X23000235">Supplementary Figure 1</uri>).<fig position="float" id="fig4"><label>Figure 4.</label><caption><p>VistoSeg workflow for Visium-SPG immunofluorescent image processing and segmentation. (a) Multispectral immunofluorescent images of the gene expression slide from the Visium-SPG workflow were acquired using a Vectra Polaris slide scanner (Akoya). All arrays on the slide were annotated as a single selection using Phenochart software (Akoya) and split into multiple tiles. Each tile was spectrally unmixed into multichannel TIFFs using inForm software (Akoya) by applying spectral fingerprints specific for each fluorophore. Autofluorescence was separated into its own channel. (b) After unmixing, the tiles from (a) were put into the VistoSeg preprocessing workflow and stitched using the inFormstitch function to recreate a multichannel TIFF of the whole slide. (c) The recreated multichannel TIFF was then split into individual arrays using splitSlide_IF. (d) Representative segmentation for capture area A1. Nuclei segmentation to identify fluorescent signal for the nucleus (DAPI) and each labeled protein (GFAP, NEUN, OLIG2, TMEM119) was performed by integrating functions from our previously published software, dotdotdot.<sup>(</sup><xref rid="r28" ref-type="bibr"><sup>28</sup></xref><sup>)</sup> (e) Using the split images from (c), Space Ranger (10× Genomics) was used to align multiplex fluorescent imaging and gene expression data and obtain extracted spot metrics (Visium spot diameter, spot spacing and spot coordinates) from each image in the “tissue_positions_list.csv” and “scalefactors_json.json” files. (f) The spotspotcheck GUI in VisotSeg provides a dropdown menu for each fluorescent channel in the multichannel TIFF (labeled by the spectral profile assigned to each protein of interest: DAPI, GFAP, NeuN, OLIG2, TMEM119 in this example). It allows for visual inspection by hovering over different regions in the image. For example, we explored the white matter (white square) and gray matter (gray square) in this representative sample. (g) The signal count per gene expression spot computed by countNuclei on the white matter (white square in f) confirms increased abundance of OLIG2, GFAP and TMEM119 staining, and relative depletion of NeuN staining, in line with expectations.</p></caption><graphic xlink:href="S2633903X23000235_fig4" position="float"/></fig></p>
    </sec>
    <sec sec-type="other" id="sec6">
      <label>2.3.</label>
      <title>Integration of segmentation output with gene expression spot location</title>
      <p>We generated an additional function (termed <italic toggle="yes">countNuclei</italic>) to calculate the number of nuclei residing within each spot. This function uses the point-in-polygon concept to calculate the number of nuclei per spot by integrating the coordinate information obtained from SpaceRanger with the segmentation mask to calculate the number of nuclei per spot. The <italic toggle="yes">countNuclei</italic> function accepts segmentation from alternative methods, if saved in a “.mat” format. The output of this function is a table that contains the number of nuclei and the percentage nuclei coverage per gene expression spot, which can be exported as a .<italic toggle="yes">csv</italic> file for each sample to be used in downstream analyses. Two types of nuclei counts are provided per spot, based on the two possible measurement criteria for calling presence/absence of nuclei: (1) inclusion of the centroid of the ROI within the spot, (2) user-defined threshold for the number of pixels necessary to count a cell as within the spot.</p>
      <p>To enable the user to visually inspect nuclei segmentation output, we developed a GUI termed <italic toggle="yes">spotspotcheck.</italic> This GUI reconstructs and overlays the spot grid, generated using the output of SpaceRanger, onto the original image and the binary segmentation, generated using the output of <italic toggle="yes">refineVNS,</italic> to display the nuclei count in each spot. The <italic toggle="yes">spotspotcheck</italic> GUI supports both H&amp;E images (<xref rid="fig2" ref-type="fig">Figure 2g</xref> and <uri xlink:href="https://doi.org/10.1017/S2633903X23000235">Supplementary Figures 2</uri> and <uri xlink:href="https://doi.org/10.1017/S2633903X23000235">3</uri>) and immunofluorescent images (<xref rid="fig4" ref-type="fig">Figure 4f</xref>,<xref rid="fig4" ref-type="fig">g</xref>, <uri xlink:href="https://doi.org/10.1017/S2633903X23000235">Supplementary Figure 1</uri>). Additionally, the GUI provides a dropdown menu (<xref rid="fig4" ref-type="fig">Figure 4f</xref>) to select different channels in the multichannel TIFF image. This allows the user to (1) toggle between the nuclei segmentation and images, (2) search for spots with specific spatial barcode IDs, and (3) zoom in and out to a specific location on the image. The user can visualize the nuclei count information by checking the “Get cell counts” option in the <italic toggle="yes">spotspotcheck</italic> start window. <italic toggle="yes">spotspotcheck</italic> enables users to perform bidirectional visual inspection, meaning that the user can evaluate morphological features in the high-resolution image and verify segmentation accuracy. Alternatively, the user can visually inspect whether gene expression patterns are related to any image features by querying specific spots through their barcode ID.</p>
      <p>Following alignment of gene expression with image-based data, the number of nuclei present in each gene expression spot can be integrated into downstream analysis, such as creating a SpatialExperiment (spe) object,<sup>(</sup><xref rid="r29" ref-type="bibr"><sup>29</sup></xref><sup>)</sup> which incorporates image-based quantifications, along with other variables, into the spot-level information. The nuclei count can then be used to perform quality control procedures and downstream analysis at the spot level. For example, during quality control, spots with an abnormally high nuclei count can be excluded.<sup>(</sup><xref rid="r30" ref-type="bibr"><sup>30</sup></xref><sup>)</sup> Furthermore, the nuclei count along with the spot-level gene expression matrix are required inputs for spot deconvolution methods such as Tangram.<sup>(</sup><xref rid="r20" ref-type="bibr"><sup>20</sup></xref><sup>)</sup></p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="sec7">
    <label>3.</label>
    <title>Discussion</title>
    <p><italic toggle="yes">VistoSeg</italic> leverages the MATLAB Image Processing Toolbox<sup>(</sup><xref rid="r31" ref-type="bibr"><sup>31</sup></xref><sup>)</sup> to provide user-friendly functionality for processing, analysis and interactive visualization of both H&amp;E and fluorescent images generated in conjunction with the Visium platform. A major feature of the <italic toggle="yes">VistoSeg</italic> pipeline is the quantification and localization of detected ROIs in H&amp;E images (Visium-H&amp;E workflow) or each individual fluorescent channel (Visium-SPG workflow). <italic toggle="yes">VistoSeg</italic> extracts multiple user-defined metrics, including number of cells per spot, percentage of a spot occupied by cells or proteins of interest, mean fluorescent intensity in a spot, and mean fluorescent intensity of the segmented regions in the spot to aid in the interpretation and utility of SRT data.</p>
    <p>This quantitative output from <italic toggle="yes">VistoSeg</italic> can be integrated with spatial gene expression data to improve spot-level resolution and add biological insights to downstream analyses. For example, using H&amp;E images of the human dorsolateral prefrontal cortex analyzed with <italic toggle="yes">VistoSeg</italic>, we identified “neuropil” spots lacking cell bodies, which we hypothesized were enriched for neuronal processes. We confirmed this hypothesis by demonstrating that these “neuropil” spots are enriched for genes previously shown to be expressed in synaptic terminals.<sup>(</sup><xref rid="r18" ref-type="bibr"><sup>18</sup></xref><sup>)</sup>
<italic toggle="yes">VistoSeg</italic> can also be used to identify spots that contain only a single cell or specific number of cells to help refine the selection of spots used for downstream gene expression analysis. Additionally, <italic toggle="yes">VistoSeg</italic> can identify spots with disease-associated pathology, allowing for the analysis of gene expression changes associated with pathological alterations in local microenvironments. For example, SRT has been used to identify gene expression changes associated with amyloid beta pathology in Alzheimer’s disease.<sup>(</sup><xref rid="r32" ref-type="bibr"><sup>32</sup></xref><sup>)</sup>
<italic toggle="yes">VistoSeg</italic> opens opportunities to directly incorporate different pathology-associated metrics with transcriptomic changes in diseased tissues.</p>
    <p>Importantly, <italic toggle="yes">VistoSeg</italic> output can be further integrated with other software<sup>(</sup><xref rid="r33" ref-type="bibr"><sup>33</sup></xref><sup>,</sup><xref rid="r34" ref-type="bibr"><sup>34</sup></xref><sup>)</sup> to identify and classify specific cell types based on nuclear or cellular morphology. For example, spatial domains corresponding to specific tumor pathology can vary in cell size, shape and density across tissue sections. Identification of these pathological lesions can provide important insights into the role of spatially restricted gene expression in disease progression.<sup>(</sup><xref rid="r35" ref-type="bibr"><sup>35</sup></xref><sup>,</sup><xref rid="r36" ref-type="bibr"><sup>36</sup></xref><sup>)</sup> We further anticipate that outputs of <italic toggle="yes">VistoSeg</italic> can be used to calculate other tissue parameters, such as cell density, for incorporation into unsupervised clustering approaches to identify data-driven spatial domains more directly related to cytoarchitecture. Given that a single Visium spot contains multiple cells with several cell types, spot deconvolution algorithms are rapidly being developed to predict the proportion of different cell types in each spot.<sup>(</sup><xref rid="r37" ref-type="bibr"><sup>37</sup></xref><sup>,</sup><xref rid="r38" ref-type="bibr"><sup>38</sup></xref><sup>)</sup> Spot deconvolution algorithms generally require Visium gene expression data (with or without cell counts) and single cell/nucleus RNA-seq gene expression data from the same tissue type (<uri xlink:href="https://doi.org/10.1017/S2633903X23000235">Supplementary Figure 4</uri>). Some spot deconvolution software, including Tangram<sup>(</sup><xref rid="r20" ref-type="bibr"><sup>20</sup></xref><sup>)</sup> and Cell2Location,<sup>(</sup><xref rid="r19" ref-type="bibr"><sup>19</sup></xref><sup>)</sup> require the user to input the number of cells per spot, while others do not require this information. However, spot deconvolution results were improved for methods that include cell counts per spot compared to methods that do not use any image-level spot metrics.<sup>(</sup><xref rid="r39" ref-type="bibr"><sup>39</sup></xref><sup>)</sup> Spot deconvolution algorithms have already begun to leverage cell counts from imaging data,<sup>(</sup><xref rid="r15" ref-type="bibr"><sup>15</sup></xref><sup>)</sup> and we anticipate that more quantitative outputs from software such as <italic toggle="yes">VistoSeg</italic> can improve the identification of biologically relevant spatial domains and associated cell type proportions.</p>
    <p>In summary, <italic toggle="yes">VistoSeg</italic> was designed to address an image analysis gap in the most widely used, commercially available SRT-processing pipeline, the Visium Spatial Gene Expression platforms. However, we note some limitations with <italic toggle="yes">Vistoseg</italic>, such as large memory requirements (~75 GB) for loading and saving images. Furthermore, the <italic toggle="yes">VNS</italic> function requires manual user inputs and cannot currently be fully automated. However, we note that similar existing image analysis software, such as HALO,<sup>(</sup><xref rid="r40" ref-type="bibr"><sup>40</sup></xref><sup>)</sup> QuPath<sup>(</sup><xref rid="r9" ref-type="bibr"><sup>9</sup></xref><sup>)</sup> and Squidpy,<sup>(</sup><xref rid="r36" ref-type="bibr"><sup>36</sup></xref><sup>)</sup> also have limitations on processing times and parametrization, and there are currently no available modules to support integration of gene expression data with segmented images. While <italic toggle="yes">Vistoseg</italic> was primarily designed for the available Visium platforms, we anticipate its functions will be relevant to other NGS-based SRT platforms should future assays become available from other vendors. We note that among all current SRT technologies, Visium is by far the leading platform in the field<sup>(</sup><xref rid="r6" ref-type="bibr"><sup>6</sup></xref><sup>)</sup> with over 60 institutions utilizing the technology at the time of publication, further supporting the need for improved imaging-processing tools.</p>
    <p>While we recognize that MATLAB is closed source, it is compatible with open science<sup>(</sup><xref rid="r41" ref-type="bibr"><sup>41</sup></xref><sup>)</sup> and readily available to academic users. MATLAB supports the ability to read images from various proprietary file formats from multiple instrument manufacturers. All code for <italic toggle="yes">VistoSeg</italic> is freely available (see Data Availability), and the main output of <italic toggle="yes">VistoSeg</italic> is in <italic toggle="yes">.csv</italic> format, which can be easily incorporated into commonly used pipelines for analysis of SRT data such as R objects for SpatialExperiment<sup>(</sup><xref rid="r29" ref-type="bibr"><sup>29</sup></xref><sup>)</sup> and Seurat,<sup>(</sup><xref rid="r42" ref-type="bibr"><sup>42</sup></xref><sup>)</sup> or Python objects for AnnData.<sup>(</sup><xref rid="r43" ref-type="bibr"><sup>43</sup></xref><sup>)</sup> In addition, conversion utilities like zellkonverter<sup>(</sup><xref rid="r44" ref-type="bibr"><sup>44</sup></xref><sup>)</sup> facilitate intercommunication among these programing languages. As other packages are made available that expand on the key infrastructure provided by SpatialExperiment, <italic toggle="yes">VistoSeg</italic> will continue to be compatible with them.</p>
  </sec>
  <sec sec-type="conclusions" id="sec8">
    <label>4.</label>
    <title>Conclusion</title>
    <p>We developed <italic toggle="yes">VistoSeg</italic> as a user-friendly image-processing toolkit, which is optimized for NGS-based SRT technologies, including the commercially available Visium platforms, to facilitate integration of the rich anatomical and/or proteomic data in the H&amp;E and fluorescent images accompanying spatial gene expression data. <italic toggle="yes">VistoSeg</italic> performs automatic splitting of whole-slide images for downstream data processing and allows for segmenting, visualizing, and quantifying individual high-resolution raw histology and immunofluorescent images. The pipeline is easily adaptable for images obtained from Visium H&amp;E and Visium-SPG workflows from different tissues, organs and species. The pipeline is available at <uri xlink:href="http://research.libd.org/VistoSeg">http://research.libd.org/VistoSeg</uri> and includes a detailed tutorial with example data for implementing <italic toggle="yes">VistoSeg.</italic></p>
  </sec>
  <sec sec-type="materials" id="sec9">
    <label>5.</label>
    <title>Materials and methods</title>
    <sec sec-type="other" id="sec10">
      <label>5.1.</label>
      <title>Post-mortem human brain tissue</title>
      <p>Post-mortem human brain tissue was obtained at the time of autopsy with informed consent from the legal next of kin, through the Maryland Department of Health IRB protocol #12–24, and from the Department of Pathology of Western Michigan University Homer Stryker MD School of Medicine, the Department of Pathology of University of North Dakota School of Medicine and Health Sciences, and the County of Santa Clara Medical Examiner-Coroner Office in San Jose, CA, all under the WCG protocol #20111080. Details of tissue acquisition, handling, processing, dissection, clinical characterization, diagnoses, neuropathological examinations and quality control measures have been described previously.<sup>(</sup><xref rid="r45" ref-type="bibr"><sup>45</sup></xref><sup>)</sup></p>
    </sec>
    <sec sec-type="other" id="sec11">
      <label>5.2.</label>
      <title>Tissue preparation and image acquisition for Visium H&amp;E</title>
      <p>Tissue was cryosectioned on a Leica 3050 cryostat at 10-micron thickness and collected onto a Visium Spatial Gene Expression slide (catalog no. 2000233; 10× Genomics). H&amp;E staining was performed on fresh-frozen tissue according to manufacturer’s instructions to identify nuclei (dark blue/purple) and cytoplasm (pink) in the tissue section. The two stains combine to label features of the tissue in various shades of pink and blue. Thus, the range of colors present in the staining depends on the cellular composition of the tissue. Following H&amp;E staining, the Visium slide was imaged on a Leica Aperio CS2 slide scanner (<xref rid="fig1" ref-type="fig">Figure 1b</xref>) equipped with a color camera and a 20×/0.75 NA objective with a 2× optical magnification changer, which meets the recommended microscopy specification outlined by Visium Spatial Gene Expression Imaging Guidelines from 10× Genomics.<sup>(</sup><xref rid="r46" ref-type="bibr"><sup>46</sup></xref><sup>)</sup> This protocol produced high-resolution (0.253 μm per pixel) images for downstream analysis.</p>
    </sec>
    <sec sec-type="other" id="sec12">
      <label>5.3.</label>
      <title>Immunofluorescent staining and image acquisition for Visium-SPG</title>
      <p>Immunofluorescent staining was performed according to the manufacturer’s instructions (catalog no.CG000312 Rev C; 10× Genomics). Briefly, post-mortem human dorsolateral prefrontal cortex (<italic toggle="yes">n</italic> = 4 tissue sections from four individual donors) was microdissected and cryosectioned at 10-micron thickness. Sections were mounted on a Visium Spatial Gene Expression Slide (catalog no. 2000233; 10× Genomics), fixed in prechilled methanol, blocked in BSA-containing buffer, and incubated for 30 min at room temperature with primary antibodies against NeuN, TMEM119, GFAP, and OLIG2 (mouse anti-NeuN antibody conjugated to Alexa 488 [Sigma Aldrich; Cat# MAB377X, 1:100], rabbit anti-TMEM119 antibody [Sigma Aldrich; Cat# HPA051870, 1:20], rat anti-GFAP antibody [Thermofisher; Cat# 13-0300, 1:100], and goat anti-OLIG2 antibody [R&amp;D systems; Cat# AF2418, 1:20]). Following washes, appropriate secondary antibodies were applied for 30 min at room temperature (donkey anti-rabbit IgG conjugated to Alexa 555 [Thermofisher; Cat# A-31572, 1:300], donkey anti-rat IgG conjugated to Alexa 594 [Thermofisher; Cat# A-21209, 1: 600], and donkey anti-goat IgG conjugated to Alexa 647 [Thermofisher, Cat# A-21447, 1:400]). DAPI (Thermofisher; Cat# D1306, 1:3000, 1.67 μg/ml) was applied for nuclear counterstaining. The slide was coverslipped with 85% glycerol and imaged on a Vectra Polaris slide scanner (Akoya Biosciences) at 20× magnification with the following exposure time per given channel: 2.1 ms for DAPI, 143 ms for Opal 520, 330 ms for Opal 570, 200 ms for Opal 620, 1070 ms for Opal 690, 100 ms for Autofluorescence prior to downstream transcriptomics. Slide scanning generated a qptiff image file, which was then selected for a region of interest (ROI) in Phenochart software (Akoya Biosciences) with an annotation tool outlining the entire slide. The resulting boundaries created a grid line of multiple tiles that made up the entire demarcated ROI. The annotated qptiff image was then processed in InForm software (Akoya Biosciences) and subjected to linear unmixing with the reference spectral profiles of corresponding fluorophores. InForm performs linear unmixing tile by tile while producing linearly unmixed tile images in tiff. The subsequent individual tile images were processed through the <italic toggle="yes">VistoSeg</italic> pipeline to extract final quantitative output.</p>
    </sec>
    <sec sec-type="other" id="sec13">
      <label>5.4.</label>
      <title>cDNA synthesis and library preparation</title>
      <p>Following imaging, gene expression libraries were generated on the slide, followed by denaturing and amplification. Standard Illumina sequencing was performed according to manufacturer’s specifications.</p>
    </sec>
    <sec sec-type="other" id="sec14">
      <label>5.5.</label>
      <title>System requirements and availability for VistoSeg</title>
      <p>Project name: <italic toggle="yes">VistoSeg</italic></p>
      <p>Project home page: <uri xlink:href="https://github.com/LieberInstitute/VistoSeg">https://github.com/LieberInstitute/VistoSeg</uri>, <uri xlink:href="http://research.libd.org/VistoSeg/">http://research.libd.org/VistoSeg/</uri></p>
      <p>Operating system(s): MAC, Windows, LINUX</p>
      <p>Programming language: MATLAB</p>
      <p>Other requirements:</p>
      <p>(1) MATLAB Image Processing Toolbox</p>
      <p>(2) MATLAB v2019a or later</p>
      <p>(3) Minimum ~ (3*raw image) 80 GB RAM for the initial (<italic toggle="yes">splitSlide</italic>) step and &lt;16GB for all the remaining steps</p>
      <p>(4) SpaceRanger (10× Genomics) v1.0 or higher</p>
      <p>(5) Loupe browser (10× Genomics) v5 or higher</p>
      <p>License: GNU GENERAL PUBLIC LICENSE, Version 3, June 29, 2007.</p>
      <p>Any restrictions to use by nonacademics: license required.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material" id="sec19">
    <title>Supporting information</title>
    <supplementary-material id="sm01" position="float" content-type="local-data">
      <caption>
        <title>Tippani et al. supplementary material</title>
        <p>Tippani et al. supplementary material</p>
      </caption>
      <media xlink:href="S2633903X23000235sup001.docx" id="d66e1107" position="anchor"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>We thank Anthony Ramnauth (LIBD) and Uma Kaipa (LIBD) for testing code functionality. We thank the “spatialLIBD” team (LIBD and JHU) for their feedback on <italic toggle="yes">VistoSeg</italic> and testing the software across multiple datasets. We thank Amy Deep-Soboslay and her diagnostic team for curation of brain samples. We thank the neuropathology team for their assistance with tissue dissection. We thank the physicians and staff at the brain donation sites and the generosity of donor families for supporting our research efforts. Finally, we thank the families of Connie and Stephen Lieber and Milton and Tamar Maltz for their generous support to this work. A preprint of this work is available on bioRxiv: <ext-link xlink:href="10.1101/2021.08.04.452489" ext-link-type="doi">https://doi.org/10.1101/2021.08.04.452489</ext-link>.</p>
  </ack>
  <glossary id="glsy1">
    <title>Glossary of terms</title>
    <p>
      <def-list list-type="simple" list-content="abbreviation">
        <def-item>
          <term>10× Genomics:</term>
          <def>
            <p>commercial vendor producing Visium technology</p>
          </def>
        </def-item>
        <def-item>
          <term>barcode identifier (ID):</term>
          <def>
            <p>unique genomic sequence for each spatially restricted position on a Visium slide</p>
          </def>
        </def-item>
        <def-item>
          <term>CIELAB or L*a*b:</term>
          <def>
            <p>color model incorporating perceptual lightness (L) with colors unique to human vision (red, green, blue and yellow), to enable the detection and calculation of visibly evident changes in color patterns</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">countNuclei:</italic>
          </term>
          <def>
            <p>a function used to generate the nuclei count file that stores the information about the number of segmented nuclei in each spot</p>
          </def>
        </def-item>
        <def-item>
          <term>GUI:</term>
          <def>
            <p>graphical user interface</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">imsegkmeans:</italic>
          </term>
          <def>
            <p>a MATLAB function that uses K-means clustering-based image segmentation</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">inFormstitch:</italic>
          </term>
          <def>
            <p>a MATLAB function used to stitch all spectrally unmixed individual tiles of a Visium-SPG immunofluorescent slide image to recreate a multispectral TIFF image</p>
          </def>
        </def-item>
        <def-item>
          <term>Loupe browser:</term>
          <def>
            <p>Primary Visualization software provided by 10× Genomics</p>
          </def>
        </def-item>
        <def-item>
          <term>MATLAB:</term>
          <def>
            <p>MATrix LABoratory</p>
          </def>
        </def-item>
        <def-item>
          <term>NGS:</term>
          <def>
            <p>next-generation sequencing</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">refine(VNS):</italic>
          </term>
          <def>
            <p>a function that refines the segmentation done using <italic toggle="yes">VNS</italic> function</p>
          </def>
        </def-item>
        <def-item>
          <term>RGB:</term>
          <def>
            <p>red, green, blue color model</p>
          </def>
        </def-item>
        <def-item>
          <term>ROI:</term>
          <def>
            <p>region of interest</p>
          </def>
        </def-item>
        <def-item>
          <term>SpaceRanger:</term>
          <def>
            <p>analysis software provided by 10× Genomics to align transcript reads to the genome and assign them to a Visium spot</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">splitslide:</italic>
          </term>
          <def>
            <p>a MATLAB function used to split the whole-slide Visium-H&amp;E image into individual capture arrays</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">splitSlide_IF:</italic>
          </term>
          <def>
            <p>a MATLAB function that splits the multispectral TIFF image obtained using <italic toggle="yes">inFormStitch</italic> function into individual capture arrays</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">spotspotcheck:</italic>
          </term>
          <def>
            <p>a GUI that allows the user to visualize and quantify nuclei segmentation results performed using <italic toggle="yes">VNS</italic> and <italic toggle="yes">refineVNS</italic></p>
          </def>
        </def-item>
        <def-item>
          <term>SRT:</term>
          <def>
            <p>spatially resolved transcriptomics</p>
          </def>
        </def-item>
        <def-item>
          <term>Visium H&amp;E:</term>
          <def>
            <p>Visium assay using H&amp;E staining.</p>
          </def>
        </def-item>
        <def-item>
          <term>Visium-SPG:</term>
          <def>
            <p>Visium Spatial Proteogenomics assay using immunofluorescent staining</p>
          </def>
        </def-item>
        <def-item>
          <term>
            <italic toggle="yes">VNS:</italic>
          </term>
          <def>
            <p>a MATLAB function that segments nuclei for Visium H&amp;E images</p>
          </def>
        </def-item>
      </def-list>
    </p>
  </glossary>
  <sec sec-type="supplementary-material" id="nts1">
    <title>Supplementary material</title>
    <p>The supplementary material for this article can be found at <uri xlink:href="https://doi.org/10.1017/S2633903X23000235">https://doi.org/10.1017/S2633903X23000235</uri>.</p>
  </sec>
  <sec sec-type="data-availability" id="sec16">
    <title>Data availability statement</title>
    <p>Examples of code, data, output and results are available at <uri xlink:href="http://research.libd.org/VistoSeg/index.html#data-availability">http://research.libd.org/VistoSeg/index.html#data-availability</uri> and <uri xlink:href="https://github.com/LieberInstitute/VistoSeg">https://github.com/LieberInstitute/VistoSeg</uri>.<sup>(</sup><xref rid="r47" ref-type="bibr"><sup>47</sup></xref><sup>)</sup> All inputs and outputs are available through Figshare.<sup>(</sup><xref rid="r48" ref-type="bibr"><sup>48</sup></xref><sup>)</sup> Public datasets provided by 10× Genomics.<sup>(</sup><xref rid="r49" ref-type="bibr"><sup>49</sup></xref><sup>)</sup></p>
  </sec>
  <sec sec-type="funding-statement" id="sec17">
    <title>Funding statement</title>
    <p>This work was supported by the Lieber Institute for Brain Development and the National Institute of Health grants U01MH122849 and R01MH126393.</p>
  </sec>
  <sec sec-type="COI-statement" id="sec18">
    <title>Competing interest</title>
    <p>A.E.J. is now a full-time employee at Neumora Therapeutics, a for-profit biotechnology company, which is unrelated to the contents of this manuscript. J.L.C. is now a full-time employee at Delfi Diagnostics, a for-profit biotechnology company, which is unrelated to the contents of this manuscript. Their contributions to the manuscript were made while previously employed by the Lieber Institute for Brain Development. All other authors declare no competing interests.</p>
  </sec>
  <ref-list id="refs1" content-type="normal">
    <title>References</title>
    <ref id="r1">
      <label>1.</label>
      <mixed-citation publication-type="journal" id="ref1"><string-name><surname>Marx</surname><given-names>V</given-names></string-name> (<year>2021</year>) <article-title>Method of the year: spatially resolved transcriptomics</article-title>. <source>Nature Methods</source>
<volume>18</volume>(<issue>1</issue>), <fpage>9</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">33408395</pub-id>
</mixed-citation>
    </ref>
    <ref id="r2">
      <label>2.</label>
      <mixed-citation publication-type="journal" id="ref2"><string-name><surname>Rodriques</surname><given-names>SG</given-names></string-name>, <string-name><surname>Stickels</surname><given-names>RR</given-names></string-name>, <string-name><surname>Goeva</surname><given-names>A</given-names></string-name>, <string-name><surname>Martin</surname><given-names>CA</given-names></string-name>, <string-name><surname>Murray</surname><given-names>E</given-names></string-name>, <string-name><surname>Vanderburg</surname><given-names>CR</given-names></string-name>, <string-name><surname>Welch</surname><given-names>J</given-names></string-name>, <string-name><surname>Chen</surname><given-names>LM</given-names></string-name>, <string-name><surname>Chen</surname><given-names>F</given-names></string-name>, <string-name><surname>Macosko</surname><given-names>EZ</given-names></string-name> (<year>2019</year>) <article-title>Slide-seq: a scalable technology for measuring genome-wide expression at high spatial resolution</article-title>. <source>Science</source>
<volume>363</volume>(<issue>6434</issue>), <fpage>1463</fpage>–<lpage>1467</lpage>.<pub-id pub-id-type="pmid">30923225</pub-id>
</mixed-citation>
    </ref>
    <ref id="r3">
      <label>3.</label>
      <mixed-citation publication-type="journal" id="ref3"><string-name><surname>Liu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Yang</surname><given-names>M</given-names></string-name>, <string-name><surname>Deng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Su</surname><given-names>G</given-names></string-name>, <string-name><surname>Enninful</surname><given-names>A</given-names></string-name>, <string-name><surname>Guo</surname><given-names>CC</given-names></string-name>, <string-name><surname>Tebaldi</surname><given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>D</given-names></string-name>, <string-name><surname>Kim</surname><given-names>D</given-names></string-name>, <string-name><surname>Bai</surname><given-names>Z</given-names></string-name>, <string-name><surname>Norris</surname><given-names>E</given-names></string-name>, <string-name><surname>Pan</surname><given-names>A</given-names></string-name>, <string-name><surname>Li</surname><given-names>J</given-names></string-name>, <string-name><surname>Xiao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Halene</surname><given-names>S</given-names></string-name>, <string-name><surname>Fan</surname><given-names>R</given-names></string-name> (<year>2020</year>) <article-title>High-spatial-resolution multi-omics sequencing via deterministic barcoding in tissue</article-title>. <source>Cell</source>
<volume>183</volume>(<issue>6</issue>), <fpage>1665</fpage>–<lpage>1681</lpage>.e18.<pub-id pub-id-type="pmid">33188776</pub-id>
</mixed-citation>
    </ref>
    <ref id="r4">
      <label>4.</label>
      <mixed-citation publication-type="journal" id="ref4"><string-name><surname>Vickovic</surname><given-names>S</given-names></string-name>, <string-name><surname>Eraslan</surname><given-names>G</given-names></string-name>, <string-name><surname>Salmén</surname><given-names>F</given-names></string-name>, <string-name><surname>Klughammer</surname><given-names>J</given-names></string-name>, <string-name><surname>Stenbeck</surname><given-names>L</given-names></string-name>, <string-name><surname>Schapiro</surname><given-names>D</given-names></string-name>, <string-name><surname>Äijö</surname><given-names>T</given-names></string-name>, <string-name><surname>Bonneau</surname><given-names>R</given-names></string-name>, <string-name><surname>Bergenstråhle</surname><given-names>L</given-names></string-name>, <string-name><surname>Navarro</surname><given-names>JF</given-names></string-name>, <string-name><surname>Gould</surname><given-names>J</given-names></string-name>, <string-name><surname>Griffin</surname><given-names>GK</given-names></string-name>, <string-name><surname>Borg</surname><given-names>Å</given-names></string-name>, <string-name><surname>Ronaghi</surname><given-names>M</given-names></string-name>, <string-name><surname>Frisén</surname><given-names>J</given-names></string-name>, <string-name><surname>Lundeberg</surname><given-names>J</given-names></string-name>, <string-name><surname>Regev</surname><given-names>A</given-names></string-name>, <string-name><surname>Ståhl</surname><given-names>PL</given-names></string-name> (<year>2019</year>) <article-title>High-definition spatial transcriptomics for in situ tissue profiling</article-title>. <source>Nature Methods</source>
<volume>16</volume>(<issue>10</issue>), <fpage>987</fpage>–<lpage>990</lpage>.<pub-id pub-id-type="pmid">31501547</pub-id>
</mixed-citation>
    </ref>
    <ref id="r5">
      <label>5.</label>
      <mixed-citation publication-type="other" id="ref5"><string-name><surname>Fu</surname><given-names>X</given-names></string-name>, <string-name><surname>Sun</surname><given-names>L</given-names></string-name>, <string-name><surname>Chen</surname><given-names>J</given-names></string-name>, <string-name><surname>Dong</surname><given-names>R</given-names></string-name>, <string-name><surname>Lin</surname><given-names>Y</given-names></string-name>, <string-name><surname>Palmiter</surname><given-names>R</given-names></string-name>, <string-name><surname>Lin</surname><given-names>S</given-names></string-name>, <string-name><surname>Gu</surname><given-names>L</given-names></string-name> (<year>2021</year>) Continuous polony gels for tissue mapping with high resolution and RNA capture efficiency. BioRxiv.</mixed-citation>
    </ref>
    <ref id="r6">
      <label>6.</label>
      <mixed-citation publication-type="journal" id="ref6"><string-name><surname>Moses</surname><given-names>L</given-names></string-name>, <string-name><surname>Pachter</surname><given-names>L</given-names></string-name> (<year>2022</year>) <article-title>Museum of spatial transcriptomics</article-title>. <source>Nat Methods</source>
<volume>19</volume>(<issue>5</issue>), <fpage>534</fpage>–<lpage>546</lpage>.<pub-id pub-id-type="pmid">35273392</pub-id>
</mixed-citation>
    </ref>
    <ref id="r7">
      <label>7.</label>
      <mixed-citation publication-type="other" id="ref7">10× Genomics (2022) Loupe Browser, 10× Genomics [Internet]. [cited 18 April 2022]. Available at <uri xlink:href="https://support.10xgenomics.com/spatial-gene-expression/software/visualization/latest/analysis">https://support.10xgenomics.com/spatial-gene-expression/software/visualization/latest/analysis</uri>.</mixed-citation>
    </ref>
    <ref id="r8">
      <label>8.</label>
      <mixed-citation publication-type="other" id="ref8">10× Genomics April (2022) Space Ranger, 10× Genomics [Internet]. [cited 18 April 2022]. Available at <uri xlink:href="https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/what-is-space-ranger">https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/what-is-space-ranger</uri>.</mixed-citation>
    </ref>
    <ref id="r9">
      <label>9.</label>
      <mixed-citation publication-type="journal" id="ref9"><string-name><surname>Bankhead</surname><given-names>P</given-names></string-name>, <string-name><surname>Loughrey</surname><given-names>MB</given-names></string-name>, <string-name><surname>Fernández</surname><given-names>JA</given-names></string-name>, <string-name><surname>Dombrowski</surname><given-names>Y</given-names></string-name>, <string-name><surname>McArt</surname><given-names>DG</given-names></string-name>, <string-name><surname>Dunne</surname><given-names>PD</given-names></string-name>, <string-name><surname>McQuaid</surname><given-names>S</given-names></string-name>, <string-name><surname>Gray</surname><given-names>RT</given-names></string-name>, <string-name><surname>Murray</surname><given-names>LJ</given-names></string-name>, <string-name><surname>Coleman</surname><given-names>HG</given-names></string-name>, <string-name><surname>James</surname><given-names>JA</given-names></string-name>, <string-name><surname>Salto-Tellez</surname><given-names>M</given-names></string-name>, <string-name><surname>Hamilton</surname><given-names>PW</given-names></string-name> (<year>2017</year>) <article-title>QuPath: open-source software for digital pathology image analysis</article-title>. <source>Scientific Reports</source>
<volume>7</volume>(<issue>1</issue>), <fpage>16878</fpage>.<pub-id pub-id-type="pmid">29203879</pub-id>
</mixed-citation>
    </ref>
    <ref id="r10">
      <label>10.</label>
      <mixed-citation publication-type="journal" id="ref10"><string-name><surname>Stringer</surname><given-names>C</given-names></string-name>, <string-name><surname>Wang</surname><given-names>T</given-names></string-name>, <string-name><surname>Michaelos</surname><given-names>M</given-names></string-name>, <string-name><surname>Pachitariu</surname><given-names>M</given-names></string-name> (<year>2021</year>) <article-title>Cellpose: a generalist algorithm for cellular segmentation</article-title>. <source>Nature Methods</source>
<volume>18</volume>(<issue>1</issue>), <fpage>100</fpage>–<lpage>106</lpage>.<pub-id pub-id-type="pmid">33318659</pub-id>
</mixed-citation>
    </ref>
    <ref id="r11">
      <label>11.</label>
      <mixed-citation publication-type="journal" id="ref11"><string-name><surname>Fürth</surname><given-names>D</given-names></string-name>, <string-name><surname>Vaissière</surname><given-names>T</given-names></string-name>, <string-name><surname>Tzortzi</surname><given-names>O</given-names></string-name>, <string-name><surname>Xuan</surname><given-names>Y</given-names></string-name>, <string-name><surname>Märtin</surname><given-names>A</given-names></string-name>, <string-name><surname>Lazaridis</surname><given-names>I</given-names></string-name>, <string-name><surname>Spigolon</surname><given-names>G</given-names></string-name>, <string-name><surname>Fisone</surname><given-names>G</given-names></string-name>, <string-name><surname>Tomer</surname><given-names>R</given-names></string-name>, <string-name><surname>Deisseroth</surname><given-names>K</given-names></string-name>, <string-name><surname>Carlén</surname><given-names>M</given-names></string-name>, <string-name><surname>Miller</surname><given-names>CA</given-names></string-name>, <string-name><surname>Rumbaugh</surname><given-names>G</given-names></string-name>, <string-name><surname>Meletis</surname><given-names>K</given-names></string-name> (<year>2018</year>) <article-title>An interactive framework for whole-brain maps at cellular resolution</article-title>. <source>Nature Neurosciene</source>
<volume>21</volume>(<issue>1</issue>), <fpage>139</fpage>–<lpage>149</lpage>.</mixed-citation>
    </ref>
    <ref id="r12">
      <label>12.</label>
      <mixed-citation publication-type="journal" id="ref12"><string-name><surname>Ortiz</surname><given-names>C</given-names></string-name>, <string-name><surname>Navarro</surname><given-names>JF</given-names></string-name>, <string-name><surname>Jurek</surname><given-names>A</given-names></string-name>, <string-name><surname>Märtin</surname><given-names>A</given-names></string-name>, <string-name><surname>Lundeberg</surname><given-names>J</given-names></string-name>, <string-name><surname>Meletis</surname><given-names>K</given-names></string-name> (<year>2020</year>) <article-title>Molecular atlas of the adult mouse brain</article-title>. <source>Science Advances</source>
<volume>6</volume>(<issue>26</issue>), <fpage>eabb3446</fpage>.<pub-id pub-id-type="pmid">32637622</pub-id>
</mixed-citation>
    </ref>
    <ref id="r13">
      <label>13.</label>
      <mixed-citation publication-type="journal" id="ref13"><string-name><surname>Schindelin</surname><given-names>J</given-names></string-name>, <string-name><surname>Arganda-Carreras</surname><given-names>I</given-names></string-name>, <string-name><surname>Frise</surname><given-names>E</given-names></string-name>, <string-name><surname>Kaynig</surname><given-names>V</given-names></string-name>, <string-name><surname>Longair</surname><given-names>M</given-names></string-name>, <string-name><surname>Pietzsch</surname><given-names>T</given-names></string-name>, <string-name><surname>Preibisch</surname><given-names>S</given-names></string-name>, <string-name><surname>Rueden</surname><given-names>C</given-names></string-name>, <string-name><surname>Saalfeld</surname><given-names>S</given-names></string-name>, <string-name><surname>Schmid</surname><given-names>B</given-names></string-name>, <string-name><surname>Tinevez</surname><given-names>J-Y</given-names></string-name>, <string-name><surname>White</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Hartenstein</surname><given-names>V</given-names></string-name>, <string-name><surname>Eliceiri</surname><given-names>K</given-names></string-name>, <string-name><surname>Tomancak</surname><given-names>P</given-names></string-name>, <string-name><surname>Cardona</surname><given-names>A</given-names></string-name> (<year>2012</year>) <article-title>Fiji: an open-source platform for biological-image analysis</article-title>. <source>Nature Methods</source>
<volume>9</volume>(<issue>7</issue>), <fpage>676</fpage>–<lpage>682</lpage>.<pub-id pub-id-type="pmid">22743772</pub-id>
</mixed-citation>
    </ref>
    <ref id="r14">
      <label>14.</label>
      <mixed-citation publication-type="journal" id="ref14"><string-name><surname>McQuin</surname><given-names>C</given-names></string-name>, <string-name><surname>Goodman</surname><given-names>A</given-names></string-name>, <string-name><surname>Chernyshev</surname><given-names>V</given-names></string-name>, <string-name><surname>Kamentsky</surname><given-names>L</given-names></string-name>, <string-name><surname>Cimini</surname><given-names>BA</given-names></string-name>, <string-name><surname>Karhohs</surname><given-names>KW</given-names></string-name>, <string-name><surname>Doan</surname><given-names>M</given-names></string-name>, <string-name><surname>Ding</surname><given-names>L</given-names></string-name>, <string-name><surname>Rafelski</surname><given-names>SM</given-names></string-name>, <string-name><surname>Thirstrup</surname><given-names>D</given-names></string-name>, <string-name><surname>Wiegraebe</surname><given-names>W</given-names></string-name>, <string-name><surname>Singh</surname><given-names>S</given-names></string-name>, <string-name><surname>Becker</surname><given-names>T</given-names></string-name>, <string-name><surname>Caicedo</surname><given-names>JC</given-names></string-name>, <string-name><surname>Carpenter</surname><given-names>AE</given-names></string-name> (<year>2018</year>) <article-title>CellProfiler 3.0: next-generation image processing for biology</article-title>. <source>PLoS Biology</source>
<volume>16</volume>(<issue>7</issue>), <fpage>e2005970</fpage>.<pub-id pub-id-type="pmid">29969450</pub-id>
</mixed-citation>
    </ref>
    <ref id="r15">
      <label>15.</label>
      <mixed-citation publication-type="journal" id="ref15"><string-name><surname>Hu</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name>, <string-name><surname>Coleman</surname><given-names>K</given-names></string-name>, <string-name><surname>Schroeder</surname><given-names>A</given-names></string-name>, <string-name><surname>Ma</surname><given-names>N</given-names></string-name>, <string-name><surname>Irwin</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Lee</surname><given-names>EB</given-names></string-name>, <string-name><surname>Shinohara</surname><given-names>RT</given-names></string-name>, <string-name><surname>Li</surname><given-names>M</given-names></string-name> (<year>2021</year>) <article-title>SpaGCN: integrating gene expression, spatial location and histology to identify spatial domains and spatially variable genes by graph convolutional network</article-title>. <source>Nature Methods</source>
<volume>18</volume>(<issue>11</issue>), <fpage>1342</fpage>–<lpage>1351</lpage>.<pub-id pub-id-type="pmid">34711970</pub-id>
</mixed-citation>
    </ref>
    <ref id="r16">
      <label>16.</label>
      <mixed-citation publication-type="journal" id="ref16"><string-name><surname>Bao</surname><given-names>F</given-names></string-name>, <string-name><surname>Deng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wan</surname><given-names>S</given-names></string-name>, <string-name><surname>Shen</surname><given-names>SQ</given-names></string-name>, <string-name><surname>Wang</surname><given-names>B</given-names></string-name>, <string-name><surname>Dai</surname><given-names>Q</given-names></string-name>, <string-name><surname>Altschuler</surname><given-names>SJ</given-names></string-name>, <string-name><surname>Wu</surname><given-names>LF</given-names></string-name> (<year>2022</year>) <article-title>Integrative spatial analysis of cell morphologies and transcriptional states with MUSE</article-title>. <source>Nature Biotechnology</source>
<volume>40</volume>(<issue>8</issue>), <fpage>1200</fpage>–<lpage>1209</lpage>.</mixed-citation>
    </ref>
    <ref id="r17">
      <label>17.</label>
      <mixed-citation publication-type="journal" id="ref17"><string-name><surname>Pratapa</surname><given-names>A</given-names></string-name>, <string-name><surname>Doron</surname><given-names>M</given-names></string-name>, <string-name><surname>Caicedo</surname><given-names>JC</given-names></string-name> (<year>2021</year>) <article-title>Image-based cell phenotyping with deep learning</article-title>. <source>Current Opinion in Chemical Biology</source>
<volume>65</volume>, <fpage>9</fpage>–<lpage>17</lpage>.<pub-id pub-id-type="pmid">34023800</pub-id>
</mixed-citation>
    </ref>
    <ref id="r18">
      <label>18.</label>
      <mixed-citation publication-type="journal" id="ref18"><string-name><surname>Maynard</surname><given-names>KR</given-names></string-name>, <string-name><surname>Collado-Torres</surname><given-names>L</given-names></string-name>, <string-name><surname>Weber</surname><given-names>LM</given-names></string-name>, <string-name><surname>Uytingco</surname><given-names>C</given-names></string-name>, <string-name><surname>Barry</surname><given-names>BK</given-names></string-name>, <string-name><surname>Williams</surname><given-names>SR</given-names></string-name>, <string-name><surname>Catallini</surname><given-names>JL</given-names></string-name>, <string-name><surname>Tran</surname><given-names>MN</given-names></string-name>, <string-name><surname>Besich</surname><given-names>Z</given-names></string-name>, <string-name><surname>Tippani</surname><given-names>M</given-names></string-name>, <string-name><surname>Chew</surname><given-names>J</given-names></string-name>, <string-name><surname>Yin</surname><given-names>Y</given-names></string-name>, <string-name><surname>Kleinman</surname><given-names>JE</given-names></string-name>, <string-name><surname>Hyde</surname><given-names>TM</given-names></string-name>, <string-name><surname>Rao</surname><given-names>N</given-names></string-name>, <string-name><surname>Hicks</surname><given-names>SC</given-names></string-name>, <string-name><surname>Martinowich</surname><given-names>K</given-names></string-name>, <string-name><surname>Jaffe</surname><given-names>AE</given-names></string-name> (<year>2021</year>) <article-title>Transcriptome-scale spatial gene expression in the human dorsolateral prefrontal cortex</article-title>. <source>Nature Neuroscience</source>
<volume>24</volume>(<issue>3</issue>), <fpage>425</fpage>–<lpage>436</lpage>.<pub-id pub-id-type="pmid">33558695</pub-id>
</mixed-citation>
    </ref>
    <ref id="r19">
      <label>19.</label>
      <mixed-citation publication-type="journal" id="ref19"><string-name><surname>Kleshchevnikov</surname><given-names>V</given-names></string-name>, <string-name><surname>Shmatko</surname><given-names>A</given-names></string-name>, <string-name><surname>Dann</surname><given-names>E</given-names></string-name>, <string-name><surname>Aivazidis</surname><given-names>A</given-names></string-name>, <string-name><surname>King</surname><given-names>HW</given-names></string-name>, <string-name><surname>Li</surname><given-names>T</given-names></string-name>, <string-name><surname>Elmentaite</surname><given-names>R</given-names></string-name>, <string-name><surname>Lomakin</surname><given-names>A</given-names></string-name>, <string-name><surname>Kedlian</surname><given-names>V</given-names></string-name>, <string-name><surname>Gayoso</surname><given-names>A</given-names></string-name>, <string-name><surname>Jain</surname><given-names>MS</given-names></string-name>, <string-name><surname>Park</surname><given-names>JS</given-names></string-name>, <string-name><surname>Ramona</surname><given-names>L</given-names></string-name>, <string-name><surname>Tuck</surname><given-names>E</given-names></string-name>, <string-name><surname>Arutyunyan</surname><given-names>A</given-names></string-name>, <string-name><surname>Vento-Tormo</surname><given-names>R</given-names></string-name>, <string-name><surname>Gerstung</surname><given-names>M</given-names></string-name>, <string-name><surname>James</surname><given-names>L</given-names></string-name>, <string-name><surname>Stegle</surname><given-names>O</given-names></string-name>, <string-name><surname>Bayraktar</surname><given-names>OA</given-names></string-name> (<year>2022</year>) <article-title>Cell2location maps fine-grained cell types in spatial transcriptomics</article-title>. <source>Nature Biotechnology</source>
<volume>40</volume>(<issue>5</issue>), <fpage>661</fpage>–<lpage>671</lpage>.</mixed-citation>
    </ref>
    <ref id="r20">
      <label>20.</label>
      <mixed-citation publication-type="journal" id="ref20"><string-name><surname>Biancalani</surname><given-names>T</given-names></string-name>, <string-name><surname>Scalia</surname><given-names>G</given-names></string-name>, <string-name><surname>Buffoni</surname><given-names>L</given-names></string-name>, <string-name><surname>Avasthi</surname><given-names>R</given-names></string-name>, <string-name><surname>Lu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Sanger</surname><given-names>A</given-names></string-name>, <string-name><surname>Tokcan</surname><given-names>N</given-names></string-name>, <string-name><surname>Vanderburg</surname><given-names>CR</given-names></string-name>, <string-name><surname>Segerstolpe</surname><given-names>Å</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>M</given-names></string-name>, <string-name><surname>Avraham-Davidi</surname><given-names>I</given-names></string-name>, <string-name><surname>Vickovic</surname><given-names>S</given-names></string-name>, <string-name><surname>Nitzan</surname><given-names>M</given-names></string-name>, <string-name><surname>Ma</surname><given-names>S</given-names></string-name>, <string-name><surname>Subramanian</surname><given-names>A</given-names></string-name>, <string-name><surname>Lipinski</surname><given-names>M</given-names></string-name>, <string-name><surname>Buenrostro</surname><given-names>J</given-names></string-name>, <string-name><surname>Brown</surname><given-names>NB</given-names></string-name>, <string-name><surname>Fanelli</surname><given-names>D</given-names></string-name>, <string-name><surname>Zhuang</surname><given-names>X</given-names></string-name>, <string-name><surname>Regev</surname><given-names>A</given-names></string-name> (<year>2021</year>) <article-title>Deep learning and alignment of spatially resolved single-cell transcriptomes with tangram</article-title>. <source>Nature Methods</source>
<volume>18</volume>(<issue>11</issue>), <fpage>1352</fpage>–<lpage>1362</lpage>.<pub-id pub-id-type="pmid">34711971</pub-id>
</mixed-citation>
    </ref>
    <ref id="r21">
      <label>21.</label>
      <mixed-citation publication-type="journal" id="ref21"><string-name><surname>Elosua-Bayes</surname><given-names>M</given-names></string-name>, <string-name><surname>Nieto</surname><given-names>P</given-names></string-name>, <string-name><surname>Mereu</surname><given-names>E</given-names></string-name>, <string-name><surname>Gut</surname><given-names>I</given-names></string-name>, <string-name><surname>Heyn</surname><given-names>H</given-names></string-name> (<year>2021</year>) <article-title>SPOTlight: seeded NMF regression to deconvolute spatial transcriptomics spots with single-cell transcriptomes</article-title>. <source>Nucleic Acids Research</source>
<volume>49</volume>(<issue>9</issue>), <fpage>e50</fpage>.<pub-id pub-id-type="pmid">33544846</pub-id>
</mixed-citation>
    </ref>
    <ref id="r22">
      <label>22.</label>
      <mixed-citation publication-type="journal" id="ref22"><string-name><surname>Andersson</surname><given-names>A</given-names></string-name>, <string-name><surname>Larsson</surname><given-names>L</given-names></string-name>, <string-name><surname>Stenbeck</surname><given-names>L</given-names></string-name>, <string-name><surname>Salmén</surname><given-names>F</given-names></string-name>, <string-name><surname>Ehinger</surname><given-names>A</given-names></string-name>, <string-name><surname>Wu</surname><given-names>SZ</given-names></string-name>, <string-name><surname>Al-Eryani</surname><given-names>G</given-names></string-name>, <string-name><surname>Roden</surname><given-names>D</given-names></string-name>, <string-name><surname>Swarbrick</surname><given-names>A</given-names></string-name>, <string-name><surname>Borg</surname><given-names>Å</given-names></string-name>, <string-name><surname>Frisén</surname><given-names>J</given-names></string-name>, <string-name><surname>Engblom</surname><given-names>C</given-names></string-name>, <string-name><surname>Lundeberg</surname><given-names>J</given-names></string-name> (<year>2021</year>) <article-title>Spatial deconvolution of HER2-positive breast cancer delineates tumor-associated cell type interactions</article-title>. <source>Nature Communications</source>
<volume>12</volume>(<issue>1</issue>), <fpage>6012</fpage>.</mixed-citation>
    </ref>
    <ref id="r23">
      <label>23.</label>
      <mixed-citation publication-type="journal" id="ref23"><string-name><surname>Buccitelli</surname><given-names>C</given-names></string-name>, <string-name><surname>Selbach</surname><given-names>M</given-names></string-name> (<year>2020</year>) <article-title>mRNAs, proteins and the emerging principles of gene expression control</article-title>. <source>Nature Reviews Genetics</source>
<volume>21</volume>(<issue>10</issue>), <fpage>630</fpage>–<lpage>644</lpage>.</mixed-citation>
    </ref>
    <ref id="r24">
      <label>24.</label>
      <mixed-citation publication-type="other" id="ref24"><collab>10× Genomics</collab> (<year>2021</year>) Input Recommendations-Software-Spatial Gene Expression-Official 10× Genomics Support [Internet]. [cited 1 January 2021]. Available at <uri xlink:href="https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/using/input-recommendations">https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/using/input-recommendations</uri>.</mixed-citation>
    </ref>
    <ref id="r25">
      <label>25.</label>
      <mixed-citation publication-type="journal" id="ref25"><string-name><surname>Raju</surname><given-names>PD</given-names></string-name>, <string-name><surname>Neelima</surname><given-names>G</given-names></string-name> (<year>2012</year>) <article-title>Image segmentation by using histogram thresholding</article-title>. <source>IJCSET</source>
<volume>2</volume>(<issue>1</issue>), <fpage>776</fpage>–<lpage>779</lpage>.</mixed-citation>
    </ref>
    <ref id="r26">
      <label>26.</label>
      <mixed-citation publication-type="other" id="ref26"><collab>Akoya Bioscience</collab> (<year>2019</year>) inForm® Tissue Finder Software [Internet]. [cited 13 April 2022]. Available at <uri xlink:href="https://www.akoyabio.com/support/software/inform-tissue-finder-software/">https://www.akoyabio.com/support/software/inform-tissue-finder-software/</uri>.</mixed-citation>
    </ref>
    <ref id="r27">
      <label>27.</label>
      <mixed-citation publication-type="other" id="ref27"><collab>Akoya Bioscience</collab> (<year>2019</year>) Phenochart Whole Slide Viewer [Internet]. [cited 12 April 2022]. Available at <uri xlink:href="https://www.akoyabio.com/support/software/phenochart-whole-slide-viewer/">https://www.akoyabio.com/support/software/phenochart-whole-slide-viewer/</uri>.</mixed-citation>
    </ref>
    <ref id="r28">
      <label>28.</label>
      <mixed-citation publication-type="journal" id="ref28"><string-name><surname>Maynard</surname><given-names>KR</given-names></string-name>, <string-name><surname>Tippani</surname><given-names>M</given-names></string-name>, <string-name><surname>Takahashi</surname><given-names>Y</given-names></string-name>, <string-name><surname>Phan</surname><given-names>BN</given-names></string-name>, <string-name><surname>Hyde</surname><given-names>TM</given-names></string-name>, <string-name><surname>Jaffe</surname><given-names>AE</given-names></string-name>, <string-name><surname>Martinowich</surname><given-names>K</given-names></string-name> (<year>2020</year>) <article-title>dotdotdot: an automated approach to quantify multiplex single molecule fluorescent in situ hybridization (smFISH) images in complex tissues</article-title>. <source>Nucleic Acids Research</source>
<volume>48</volume>(<issue>11</issue>), <fpage>e66</fpage>.<pub-id pub-id-type="pmid">32383753</pub-id>
</mixed-citation>
    </ref>
    <ref id="r29">
      <label>29.</label>
      <mixed-citation publication-type="journal" id="ref29"><string-name><surname>Righelli</surname><given-names>D</given-names></string-name>, <string-name><surname>Weber</surname><given-names>LM</given-names></string-name>, <string-name><surname>Crowell</surname><given-names>HL</given-names></string-name>, <string-name><surname>Pardo</surname><given-names>B</given-names></string-name>, <string-name><surname>Collado-Torres</surname><given-names>L</given-names></string-name>, <string-name><surname>Ghazanfar</surname><given-names>S</given-names></string-name>, <string-name><surname>Lun</surname><given-names>ATL</given-names></string-name>, <string-name><surname>Hicks</surname><given-names>SC</given-names></string-name>, <string-name><surname>Risso</surname><given-names>D</given-names></string-name> (<year>2022</year>) <article-title>Spatial experiment: infrastructure for spatially-resolved transcriptomics data in R using Bioconductor</article-title>. <source>Bioinformatics</source>
<volume>38</volume>(<issue>11</issue>), <fpage>3128</fpage>–<lpage>3131</lpage>.<pub-id pub-id-type="pmid">35482478</pub-id>
</mixed-citation>
    </ref>
    <ref id="r30">
      <label>30.</label>
      <mixed-citation publication-type="journal" id="ref30"><string-name><surname>McCarthy</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Campbell</surname><given-names>KR</given-names></string-name>, <string-name><surname>Lun</surname><given-names>ATL</given-names></string-name>, <string-name><surname>Wills</surname><given-names>QF</given-names></string-name> (<year>2017</year>) <article-title>Scater: pre-processing, quality control, normalization and visualization of single-cell RNA-seq data in R</article-title>. <source>Bioinformatics</source>
<volume>33</volume>(<issue>8</issue>), <fpage>1179</fpage>–<lpage>1186</lpage>.<pub-id pub-id-type="pmid">28088763</pub-id>
</mixed-citation>
    </ref>
    <ref id="r31">
      <label>31.</label>
      <mixed-citation publication-type="other" id="ref31"><collab>The MathWorks, Inc</collab>. (<year>2019</year>) MATLAB and Image processing toolbox. MATLAB.</mixed-citation>
    </ref>
    <ref id="r32">
      <label>32.</label>
      <mixed-citation publication-type="journal" id="ref32"><string-name><surname>Chen</surname><given-names>W-T</given-names></string-name>, <string-name><surname>Lu</surname><given-names>A</given-names></string-name>, <string-name><surname>Craessaerts</surname><given-names>K</given-names></string-name>, <string-name><surname>Pavie</surname><given-names>B</given-names></string-name>, <string-name><surname>Sala Frigerio</surname><given-names>C</given-names></string-name>, <string-name><surname>Corthout</surname><given-names>N</given-names></string-name>, <string-name><surname>Qian</surname><given-names>X</given-names></string-name>, <string-name><surname>Laláková</surname><given-names>J</given-names></string-name>, <string-name><surname>Kühnemund</surname><given-names>M</given-names></string-name>, <string-name><surname>Voytyuk</surname><given-names>I</given-names></string-name>, <string-name><surname>Wolfs</surname><given-names>L</given-names></string-name>, <string-name><surname>Mancuso</surname><given-names>R</given-names></string-name>, <string-name><surname>Salta</surname><given-names>E</given-names></string-name>, <string-name><surname>Balusu</surname><given-names>S</given-names></string-name>, <string-name><surname>Snellinx</surname><given-names>A</given-names></string-name>, <string-name><surname>Munck</surname><given-names>S</given-names></string-name>, <string-name><surname>Jurek</surname><given-names>A</given-names></string-name>, <string-name><surname>Fernandez</surname><given-names>Navarro J</given-names></string-name>, <string-name><surname>Saido</surname><given-names>TC</given-names></string-name>, <string-name><surname>Huitinga</surname><given-names>I</given-names></string-name>, <string-name><surname>De Strooper</surname><given-names>B</given-names></string-name> (<year>2020</year>) <article-title>Spatial transcriptomics and in situ sequencing to study Alzheimer’s disease</article-title>. <source>Cell</source>
<volume>182</volume>(<issue>4</issue>), <fpage>976</fpage>–<lpage>991</lpage>.e19.<pub-id pub-id-type="pmid">32702314</pub-id>
</mixed-citation>
    </ref>
    <ref id="r33">
      <label>33.</label>
      <mixed-citation publication-type="journal" id="ref33"><string-name><surname>Phillip</surname><given-names>JM</given-names></string-name>, <string-name><surname>Han</surname><given-names>K-S</given-names></string-name>, <string-name><surname>Chen</surname><given-names>W-C</given-names></string-name>, <string-name><surname>Wirtz</surname><given-names>D</given-names></string-name>, <string-name><surname>Wu</surname><given-names>P-H</given-names></string-name> (<year>2021</year>) <article-title>A robust unsupervised machine-learning method to quantify the morphological heterogeneity of cells and nuclei</article-title>. <source>Nature Protocols</source>
<volume>16</volume>(<issue>2</issue>), <fpage>754</fpage>–<lpage>774</lpage>.<pub-id pub-id-type="pmid">33424024</pub-id>
</mixed-citation>
    </ref>
    <ref id="r34">
      <label>34.</label>
      <mixed-citation publication-type="journal" id="ref34"><string-name><surname>Logan</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Shan</surname><given-names>J</given-names></string-name>, <string-name><surname>Bhatia</surname><given-names>SN</given-names></string-name>, <string-name><surname>Carpenter</surname><given-names>AE</given-names></string-name> (<year>2016</year>) <article-title>Quantifying co-cultured cell phenotypes in high-throughput using pixel-based classification</article-title>. <source>Methods</source>
<volume>96</volume>, <fpage>6</fpage>–<lpage>11</lpage>.<pub-id pub-id-type="pmid">26687239</pub-id>
</mixed-citation>
    </ref>
    <ref id="r35">
      <label>35.</label>
      <mixed-citation publication-type="journal" id="ref35"><string-name><surname>Chang</surname><given-names>Y</given-names></string-name>, <string-name><surname>He</surname><given-names>F</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Chen</surname><given-names>S</given-names></string-name>, <string-name><surname>Li</surname><given-names>J</given-names></string-name>, <string-name><surname>Liu</surname><given-names>J</given-names></string-name>, <string-name><surname>Yu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Su</surname><given-names>L</given-names></string-name>, <string-name><surname>Ma</surname><given-names>A</given-names></string-name>, <string-name><surname>Allen</surname><given-names>C</given-names></string-name>, <string-name><surname>Lin</surname><given-names>Y</given-names></string-name>, <string-name><surname>Sun</surname><given-names>S</given-names></string-name>, <string-name><surname>Liu</surname><given-names>B</given-names></string-name>, <string-name><surname>Javier Otero</surname><given-names>J</given-names></string-name>, <string-name><surname>Chung</surname><given-names>D</given-names></string-name>, <string-name><surname>Fu</surname><given-names>H</given-names></string-name>, <string-name><surname>Li</surname><given-names>Z</given-names></string-name>, <string-name><surname>Xu</surname><given-names>D</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Q</given-names></string-name> (<year>2022</year>) <article-title>Define and visualize pathological architectures of human tissues from spatially resolved transcriptomics using deep learning</article-title>. <source>Computational and Structural Biotechnology Journal</source>
<volume>20</volume>, <fpage>4600</fpage>–<lpage>4617</lpage>.<pub-id pub-id-type="pmid">36090815</pub-id>
</mixed-citation>
    </ref>
    <ref id="r36">
      <label>36.</label>
      <mixed-citation publication-type="journal" id="ref36"><string-name><surname>Palla</surname><given-names>G</given-names></string-name>, <string-name><surname>Spitzer</surname><given-names>H</given-names></string-name>, <string-name><surname>Klein</surname><given-names>M</given-names></string-name>, <string-name><surname>Fischer</surname><given-names>D</given-names></string-name>, <string-name><surname>Schaar</surname><given-names>AC</given-names></string-name>, <string-name><surname>Kuemmerle</surname><given-names>LB</given-names></string-name>, <string-name><surname>Rybakov</surname><given-names>S</given-names></string-name>, <string-name><surname>Ibarra</surname><given-names>IL</given-names></string-name>, <string-name><surname>Holmberg</surname><given-names>O</given-names></string-name>, <string-name><surname>Virshup</surname><given-names>I</given-names></string-name>, <string-name><surname>Lotfollahi</surname><given-names>M</given-names></string-name>, <string-name><surname>Richter</surname><given-names>S</given-names></string-name>, <string-name><surname>Theis</surname><given-names>FJ</given-names></string-name> (<year>2022</year>) <article-title>Squidpy: a scalable framework for spatial omics analysis</article-title>. <source>Nature Methods</source>
<volume>19</volume>(<issue>2</issue>), <fpage>171</fpage>–<lpage>178</lpage>.<pub-id pub-id-type="pmid">35102346</pub-id>
</mixed-citation>
    </ref>
    <ref id="r37">
      <label>37.</label>
      <mixed-citation publication-type="other" id="ref37"><string-name><surname>Sang-aram</surname><given-names>C</given-names></string-name>, <string-name><surname>Browaeys</surname><given-names>R</given-names></string-name>, <string-name><surname>Seurinck</surname><given-names>R</given-names></string-name>, <string-name><surname>Saeys</surname><given-names>Y</given-names></string-name> (<year>2023</year>) Spotless: a reproducible pipeline for benchmarking cell type deconvolution in spatial transcriptomics. BioRxiv.</mixed-citation>
    </ref>
    <ref id="r38">
      <label>38.</label>
      <mixed-citation publication-type="journal" id="ref38"><string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>Z</given-names></string-name>, <string-name><surname>Chen</surname><given-names>S</given-names></string-name>, <string-name><surname>Liao</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>B</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>R</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Sun</surname><given-names>S</given-names></string-name>, <string-name><surname>Gao</surname><given-names>X</given-names></string-name> (<year>2023</year>) <article-title>A comprehensive benchmarking with practical guidelines for cellular deconvolution of spatial transcriptomics</article-title>. <source>Nature Communications</source>
<volume>14</volume>(<issue>1</issue>):<fpage>1548</fpage>.</mixed-citation>
    </ref>
    <ref id="r39">
      <label>39.</label>
      <mixed-citation publication-type="other" id="ref39"><string-name><surname>Huuki-Myers</surname><given-names>L</given-names></string-name>, <string-name><surname>Spangler</surname><given-names>A</given-names></string-name>, <string-name><surname>Eagles</surname><given-names>N</given-names></string-name>, <string-name><surname>Montgomery</surname><given-names>KD</given-names></string-name>, <string-name><surname>Kwon</surname><given-names>SH</given-names></string-name>, <string-name><surname>Guo</surname><given-names>B</given-names></string-name>, <string-name><surname>Grant-Peters</surname><given-names>M</given-names></string-name>, <string-name><surname>Divecha</surname><given-names>HR</given-names></string-name>, <string-name><surname>Tippani</surname><given-names>M</given-names></string-name>, <string-name><surname>Sriworarat</surname><given-names>C</given-names></string-name>, <string-name><surname>Nguyen</surname><given-names>AB</given-names></string-name>, <string-name><surname>Ravichandran</surname><given-names>P</given-names></string-name>, <string-name><surname>Tran</surname><given-names>MN</given-names></string-name>, <string-name><surname>Seyedian</surname><given-names>A</given-names></string-name>, <string-name><surname>PsychENCODE</surname><given-names>consortium</given-names></string-name>, <string-name><surname>Hyde</surname><given-names>TM</given-names></string-name>, <string-name><surname>Kleinman</surname><given-names>JE</given-names></string-name>, <string-name><surname>Battle</surname><given-names>A</given-names></string-name>, <string-name><surname>Page</surname><given-names>SC</given-names></string-name>, <string-name><surname>Ryten</surname><given-names>M</given-names></string-name>, <string-name><surname>Maynard</surname><given-names>KR</given-names></string-name> (<year>2023</year>) Integrated single cell and unsupervised spatial transcriptomic analysis defines molecular anatomy of the human dorsolateral prefrontal cortex. BioRxiv.</mixed-citation>
    </ref>
    <ref id="r40">
      <label>40.</label>
      <mixed-citation publication-type="other" id="ref40"><collab>Indica Labs</collab> (<year>2022</year>) HALO [Internet]. [cited 19 April 2022]. Available at <uri xlink:href="https://indicalab.com/?page_id=2637">https://indicalab.com/?page_id=2637</uri>.</mixed-citation>
    </ref>
    <ref id="r41">
      <label>41.</label>
      <mixed-citation publication-type="other" id="ref41"><collab>The MathWorks, Inc.</collab> (<year>2022</year>) MATLAB Open Science [Internet]. [cited 28 April 2022]. Available at <uri xlink:href="https://www.mathworks.com/discovery/open-science.html">https://www.mathworks.com/discovery/open-science.html</uri>.</mixed-citation>
    </ref>
    <ref id="r42">
      <label>42.</label>
      <mixed-citation publication-type="journal" id="ref42"><string-name><surname>Hao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hao</surname><given-names>S</given-names></string-name>, <string-name><surname>Andersen-Nissen</surname><given-names>E</given-names></string-name>, <string-name><surname>Mauck</surname><given-names>WM</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>S</given-names></string-name>, <string-name><surname>Butler</surname><given-names>A</given-names></string-name>, <string-name><surname>Lee</surname><given-names>MJ</given-names></string-name>, <string-name><surname>Wilk</surname><given-names>AJ</given-names></string-name>, <string-name><surname>Darby</surname><given-names>C</given-names></string-name>, <string-name><surname>Zager</surname><given-names>M</given-names></string-name>, <string-name><surname>Hoffman</surname><given-names>P</given-names></string-name>, <string-name><surname>Stoeckius</surname><given-names>M</given-names></string-name>, <string-name><surname>Papalexi</surname><given-names>E</given-names></string-name>, <string-name><surname>Mimitou</surname><given-names>EP</given-names></string-name>, <string-name><surname>Jain</surname><given-names>J</given-names></string-name>, <string-name><surname>Srivastava</surname><given-names>A</given-names></string-name>, <string-name><surname>Stuart</surname><given-names>T</given-names></string-name>, <string-name><surname>Fleming</surname><given-names>LM</given-names></string-name>, <string-name><surname>Yeung</surname><given-names>B</given-names></string-name>, <string-name><surname>Rogers</surname><given-names>AJ</given-names></string-name>, <string-name><surname>Satija</surname><given-names>R</given-names></string-name> (<year>2021</year>) <article-title>Integrated analysis of multimodal single-cell data</article-title>. <source>Cell</source>
<volume>184</volume>(<issue>13</issue>), <fpage>3573</fpage>–<lpage>3587</lpage>.e29.<pub-id pub-id-type="pmid">34062119</pub-id>
</mixed-citation>
    </ref>
    <ref id="r43">
      <label>43.</label>
      <mixed-citation publication-type="other" id="ref43"><string-name><surname>Virshup</surname><given-names>I</given-names></string-name>, <string-name><surname>Rybakov</surname><given-names>S</given-names></string-name>, <string-name><surname>Theis</surname><given-names>FJ</given-names></string-name>, <string-name><surname>Angerer</surname><given-names>P</given-names></string-name>, <string-name><surname>Wolf</surname><given-names>FA</given-names></string-name> (<year>2021</year>) anndata: annotated data. BioRxiv.</mixed-citation>
    </ref>
    <ref id="r44">
      <label>44.</label>
      <mixed-citation publication-type="other" id="ref44"><string-name><surname>Zappia</surname><given-names>L, Lun A, Cannoodt R</given-names></string-name> (<year>2020</year>) zellkonverter: Conversion Between scRNA-seq Objects. Bioconductor.</mixed-citation>
    </ref>
    <ref id="r45">
      <label>45.</label>
      <mixed-citation publication-type="journal" id="ref45"><string-name><surname>Lipska</surname><given-names>BK</given-names></string-name>, <string-name><surname>Deep-Soboslay</surname><given-names>A</given-names></string-name>, <string-name><surname>Weickert</surname><given-names>CS</given-names></string-name>, <string-name><surname>Hyde</surname><given-names>TM</given-names></string-name>, <string-name><surname>Martin</surname><given-names>CE</given-names></string-name>, <string-name><surname>Herman</surname><given-names>MM</given-names></string-name>, <string-name><surname>Kleinman</surname><given-names>JE</given-names></string-name> (<year>2006</year>) <article-title>Critical factors in gene expression in postmortem human brain: focus on studies in schizophrenia</article-title>. <source>Biological Psychiatry</source>
<volume>60</volume>(<issue>6</issue>), <fpage>650</fpage>–<lpage>658</lpage>.<pub-id pub-id-type="pmid">16997002</pub-id>
</mixed-citation>
    </ref>
    <ref id="r46">
      <label>46.</label>
      <mixed-citation publication-type="other" id="ref46">10× Genomics (<year>2021</year>) Imaging guidelines. [cited 18 April 2022]. Available at <uri xlink:href="https://assets.ctfassets.net/an68im79xiti/7t2k87zNaujdxcaAesoPB8/add94b0b5869d3c50825b691ffc98373/CG000241_VisiumImagingGuidelinesTN_RevD.pdf">https://assets.ctfassets.net/an68im79xiti/7t2k87zNaujdxcaAesoPB8/add94b0b5869d3c50825b691ffc98373/CG000241_VisiumImagingGuidelinesTN_RevD.pdf</uri>.</mixed-citation>
    </ref>
    <ref id="r47">
      <label>47.</label>
      <mixed-citation publication-type="other" id="ref47"><collab>Lieber Institute for Brain Development MT</collab> (<year>2021</year>) <italic toggle="yes">VistoSeg Software [Internet]. Zenodo.</italic> [cited 24 April 2022]. Available at <pub-id pub-id-type="doi">10.5281/zenodo.5156783</pub-id>.</mixed-citation>
    </ref>
    <ref id="r48">
      <label>48.</label>
      <mixed-citation publication-type="other" id="ref48"><string-name><surname>Tippani</surname><given-names>M</given-names></string-name>, <string-name><surname>Divecha</surname><given-names>HR</given-names></string-name>, Catallini II JL, <string-name><surname>Weber</surname><given-names>LM</given-names></string-name>, <string-name><surname>Kwon</surname><given-names>SH</given-names></string-name>, <string-name><surname>Spangler</surname><given-names>A</given-names></string-name>, <string-name><surname>Jaffe</surname><given-names>A</given-names></string-name>, <string-name><surname>Hicks</surname><given-names>SC</given-names></string-name>, <string-name><surname>Martinowich</surname><given-names>K</given-names></string-name>, <string-name><surname>Collado-Torres</surname><given-names>L</given-names></string-name>, <string-name><surname>Page</surname><given-names>SC</given-names></string-name>, <string-name><surname>Maynard</surname><given-names>K</given-names></string-name> (<year>2022</year>) VistoSeg: processing utilities for high-resolution Visium/Visium-IF images for spatial transcriptomics data (supplementary material). Figshare.</mixed-citation>
    </ref>
    <ref id="r49">
      <label>49.</label>
      <mixed-citation publication-type="other" id="ref49"><collab>10× Genomics</collab> (<year>2022</year>) 10× Genomics public datasets [Internet]. [cited 17 April 2022]. Available at <uri xlink:href="https://www.10xgenomics.com/resources/datasets">https://www.10xgenomics.com/resources/datasets</uri>.</mixed-citation>
    </ref>
  </ref-list>
</back>
