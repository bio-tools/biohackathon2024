<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6540523</article-id>
    <article-id pub-id-type="publisher-id">2892</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-019-2892-4</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MHCSeqNet: a deep neural network model for universal MHC binding prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Phloyphisut</surname>
          <given-names>Poomarin</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Pornputtapong</surname>
          <given-names>Natapol</given-names>
        </name>
        <address>
          <email>natapol.p@chula.ac.th</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4117-3632</contrib-id>
        <name>
          <surname>Sriswasdi</surname>
          <given-names>Sira</given-names>
        </name>
        <address>
          <email>sira.sr@chula.ac.th</email>
        </address>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Chuangsuwanich</surname>
          <given-names>Ekapol</given-names>
        </name>
        <address>
          <email>ekapol.c@chula.ac.th</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0244 7875</institution-id><institution-id institution-id-type="GRID">grid.7922.e</institution-id><institution>Department of Computer Engineering, Faculty of Engineering, </institution><institution>Chulalongkorn University, </institution></institution-wrap>254 Phayathai Road, Pathumwan, Bangkok, 10330 Thailand </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0244 7875</institution-id><institution-id institution-id-type="GRID">grid.7922.e</institution-id><institution>Department of Biochemistry and Microbiology, Faculty of Pharmaceutical Sciences, </institution><institution>Chulalongkorn University, </institution></institution-wrap>254 Phayathai Road, Pathumwan, Bangkok, 10330 Thailand </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0244 7875</institution-id><institution-id institution-id-type="GRID">grid.7922.e</institution-id><institution>Vaccine and Therapeutic Protein, the Special Task Force for Activating Research, Faculty of Pharmaceutical Sciences, Chulalongkorn University, </institution></institution-wrap>Bangkok, Thailand </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0244 7875</institution-id><institution-id institution-id-type="GRID">grid.7922.e</institution-id><institution>Computational Molecular Biology Group, Faculty of Medicine, Chulalongkorn University, </institution></institution-wrap>Bangkok, Thailand </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0244 7875</institution-id><institution-id institution-id-type="GRID">grid.7922.e</institution-id><institution>Research Affairs, Faculty of Medicine, Chulalongkorn University, </institution></institution-wrap>1873 Rama IV Road, Pathum Wan, Bangkok, 10330 Thailand </aff>
      <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="GRID">grid.494627.a</institution-id><institution>The School of Information Science and Technology, Vidyasirimedhi Institute of Science and Technology, </institution></institution-wrap>Wangchan Valley 555 Moo 1 Payupnai, Wangchan, Rayong, 21210 Thailand </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>28</day>
      <month>5</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>28</day>
      <month>5</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>20</volume>
    <elocation-id>270</elocation-id>
    <history>
      <date date-type="received">
        <day>21</day>
        <month>1</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>10</day>
        <month>5</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p>Immunotherapy is an emerging approach in cancer treatment that activates the host immune system to destroy cancer cells expressing unique peptide signatures (neoepitopes). Administrations of cancer-specific neoepitopes in the form of synthetic peptide vaccine have been proven effective in both mouse models and human patients. Because only a tiny fraction of cancer-specific neoepitopes actually elicits immune response, selection of potent, immunogenic neoepitopes remains a challenging step in cancer vaccine development. A basic approach for immunogenicity prediction is based on the premise that effective neoepitope should bind with the Major Histocompatibility Complex (MHC) with high affinity.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>In this study, we developed MHCSeqNet, an open-source deep learning model, which not only outperforms state-of-the-art predictors on both MHC binding affinity and MHC ligand peptidome datasets but also exhibits promising generalization to unseen MHC class I alleles. MHCSeqNet employed neural network architectures developed for natural language processing to model amino acid sequence representations of MHC allele and epitope peptide as sentences with amino acids as individual words. This consideration allows MHCSeqNet to accept new MHC alleles as well as peptides of any length.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p>The improved performance and the flexibility offered by MHCSeqNet should make it a valuable tool for screening effective neoepitopes in cancer vaccine development.</p>
      </sec>
      <sec>
        <title>Electronic supplementary material</title>
        <p>The online version of this article (10.1186/s12859-019-2892-4) contains supplementary material, which is available to authorized users.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>MHC epitope prediction</kwd>
      <kwd>Deep learning</kwd>
      <kwd>Recurrent neural networks</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Ratchadaphisek Sompoch Endowment Fund</institution>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Ratchadaphisek Sompoch Endowment Fund</institution>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004396</institution-id>
            <institution>Thailand Research Fund</institution>
          </institution-wrap>
        </funding-source>
        <award-id>MRG6080087</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>The Chulalongkorn Academic Advancement in Its 2nd Century Project</institution>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Vidyasirimedhi Institute of Science and Technology Fellowship</institution>
        </funding-source>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p>Immunotherapy is a promising approach in cancer treatment that activates the host immune system to specifically destroy cancer cells, with far fewer adverse effects than chemotherapy or radiotherapy. This is possible because cancer cells produce unique peptide signatures (neoepitopes), some of which are presented on the cancer cells’ outer surface and recognized by T cells [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Administrations of vaccines composed of synthetic peptides resembling cancer-specific neoepitopes have been proven to boost T cell activity to destroy cancer cells in both mouse models and human patients [<xref ref-type="bibr" rid="CR2">2</xref>–<xref ref-type="bibr" rid="CR4">4</xref>]. Nonetheless, because only a tiny fraction of hundreds of cancer-specific neoepitopes can elicit immune response, selection of immunogenic neoepitopes remains a challenging step in cancer vaccine development.</p>
    <p>A basic approach for immunogenicity prediction is based on the fact that the Major Histocompatibility Complex (MHC), also called Human Leukocyte Antigen (HLA) complex, binds to peptide epitopes and presents them on the outer cell surface for recognition by T cells. In other words, a good neoepitope should be able to bind with MHC molecule with high affinity [<xref ref-type="bibr" rid="CR5">5</xref>]. Current state-of-the-art software tools for peptide-MHC binding affinity prediction achieved high accuracy due to the availability of large-scale training datasets [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>] and the application of artificial neural networks [<xref ref-type="bibr" rid="CR8">8</xref>–<xref ref-type="bibr" rid="CR10">10</xref>]. Although recent approaches that employed deep learning models [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR10">10</xref>] have demonstrated considerable performance gains over established tools including NetMHCpan [<xref ref-type="bibr" rid="CR8">8</xref>], they limited the length of input peptide epitopes (9 amino acids for ConvMHC and 8-15 amino acids for MHCflurry) and supported only specific MHC alleles that the models had been trained for. In contrast, NetMHCPan can make binding affinity prediction for any peptide and even for MHC alleles not present in the training dataset – as long as the alleles’ amino acid sequences are known.</p>
    <p>Amongst different fundamental architectures for deep learning, Recurrent Neural Networks (RNNs) have been used to encode time series information in many tasks such as automatic speech recognition [<xref ref-type="bibr" rid="CR11">11</xref>], natural language processing [<xref ref-type="bibr" rid="CR12">12</xref>], and bioinformatics [<xref ref-type="bibr" rid="CR13">13</xref>]. Unlike fully connected feed forward networks, RNNs can better capture temporal relationships by remembering previous inputs. A popular choice for RNNs is the Long Short-Term Memory (LSTM) which alleviates the vanishing and exploding gradient problems presented in normal RNNs. Gated Recurrent Unit (GRU) is a recently developed model which can be considered as a simplified version of the LSTM [<xref ref-type="bibr" rid="CR14">14</xref>]. Not only are GRUs easier to train than LSTMs, but also they outperform LSTMs in many tasks [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR16">16</xref>].</p>
    <p>In this study, we developed MHCSeqNet, an open-source deep learning model that can predict peptide-MHC binding with high accuracy and with no restriction on the input peptide or MHC allele, as long as its amino acid sequence is known. Our training and testing datasets were derived from the Immune Epitope Database (IEDB) [<xref ref-type="bibr" rid="CR6">6</xref>] and recent publications [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR17">17</xref>]. Compared to NetMHCPan [<xref ref-type="bibr" rid="CR8">8</xref>] and MHCflurry [<xref ref-type="bibr" rid="CR9">9</xref>] which pre-process amino acid sequences of peptide and MHC allele into fixed-length inputs for the underlying fully connected or convolutional neural networks, the key innovation of our approach lies in the recurrent neural network architecture which can naturally handle variable-length input amino acid sequences. Furthermore, we utilize a context-aware amino acid embedding model instead of a position-specific encoding system based on amino acid substitution matrices that was used by both NetMHCPan and MHCflurry. This allows us to incorporate multiple amino acid sequence datasets to learn better embedding representations.</p>
    <p>Our evaluations show that transfer learning from a larger amino acid database can help improve the embeddings, with further improvements possible through the use of additional model fine-tunings. Representing an MHC allele with the embedding of its amino acid sequences] instead of its type name (one-hot representation) also helps the generalization of the model in most cases. MHCSeqNet outperforms NetMHCPan [<xref ref-type="bibr" rid="CR8">8</xref>] and MHCflurry [<xref ref-type="bibr" rid="CR9">9</xref>] on both MHC binding affinity and MHC ligand peptidome datasets. The improved performance and the flexibility offered by MHCSeqNet should make it a valuable tool for screening effective neoepitopes in cancer vaccine development.</p>
  </sec>
  <sec id="Sec2">
    <title>Implementation</title>
    <p>MHCSeqNet was implemented using Python 3 and the following packages: numpy version 1.14.3, Keras version 2.2.0, tensowflow version 1.6.0, scipy version 1.1.0, and scikit-learn version 0.19.1. Details and source codes can be found on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/cmbcu/MHCSeqNet">https://github.com/cmbcu/MHCSeqNet</ext-link>.</p>
    <sec id="Sec3">
      <title>Architecture overview</title>
      <p>We trained deep learning models to predict the probability of binding between peptide and MHC allele where a prediction of 0.0 indicates no binding and 1.0 indicates a strong binding. Our models accept two inputs: peptide, in the form of amino acid sequence, and MHC allele, in the form of either amino acid sequence or allele name. Figure <xref rid="Fig1" ref-type="fig">1</xref> shows an overview of our model. The model consists of three main parts, namely the peptide input processing (Fig. <xref rid="Fig1" ref-type="fig">1</xref>a and c), the MHC allele input processing (Fig. <xref rid="Fig1" ref-type="fig">1</xref>b and d), and the output layer (Fig. <xref rid="Fig1" ref-type="fig">1</xref>e). The input processing modules try to learn the best internal representations for peptide and MHC allele. They then pass the processed representations to the output layer which perform the final classification. In the following subsections we will go over each part of the model.
<fig id="Fig1"><label>Fig. 1</label><caption><p>An overview of the MHCSeqNet’s architecture. The model is comprised of three main parts: the peptide sequence processing part (<bold>a</bold> &amp; <bold>c</bold>), the MHC processing part (<bold>b</bold> &amp; <bold>d</bold>), and the main processing part which accepts the processed information from the previous parts (<bold>e</bold>). The entire model is a single deep learning model which can be trained altogether. <bold>f</bold> Our models output binding probability for the given peptide and MHC allele on the scale of 0 to 1, with 1 indicating likely ligand</p></caption><graphic xlink:href="12859_2019_2892_Fig1_HTML" id="MO1"/></fig></p>
    </sec>
    <sec id="Sec4">
      <title>Peptide embedding layer</title>
      <p>We considered two representation models for amino acids. The first is a simple one-hot model where each amino acid is represented by a unit binary vector, e.g. [1,0,0,…] for one amino acid and [0,1,0,…] for another amino acid. The second is a continuous vector representation, called embeddings [<xref ref-type="bibr" rid="CR18">18</xref>], one of the most successful models in Natural Language Processing (NLP) which can capture the semantic and syntactic relationships between words in a sentence. In our case, a peptide may be considered a sentence and amino acids the individual words. Using embeddings allows us to train the representations on a much larger dataset than the target task (pre-training). The embeddings can then be used or adapted to tasks with smaller datasets.</p>
      <p>The Skip-Gram Model [<xref ref-type="bibr" rid="CR19">19</xref>] was used to train the continuous vectors by treating each set of 1 or 3 consecutive amino acids (1-gram or 3-gram) as a unit. The choice of the 3-gram model, also called ProtVec, was selected according to an earlier study [<xref ref-type="bibr" rid="CR20">20</xref>]. For each peptide, there are three different 3-gram representations with 0, 1, or 2 amino acid offset from the N-terminus of the peptide. For the tunable parameters, we tested window sizes of 3, 5, or 7 and embedding dimension of 4, 5, and 6 for the 1-gram model. We found that the exact choice of these parameters have little effect on the performance of the model. In the case of the 3-gram model, we fixed the embedding dimension at 100, which was the reported optimal parameter [<xref ref-type="bibr" rid="CR20">20</xref>].</p>
    </sec>
    <sec id="Sec5">
      <title>Peptide processing layer</title>
      <p>GRU was chosen as the peptide processing layer (Fig. <xref rid="Fig1" ref-type="fig">1</xref>c) because it is capable of processing sequences with variable lengths and generalizing the relationship between the amino acid representation in peptide sequence. We used one GRU layer. For the 1-Gram amino acid representation, a bi-directional GRU was used. For the ProtVec model (3-gram), three parallel GRU layers (one for each offset) were used. The number of GRU units tested ranged from 32 to 224.</p>
      <p>The input to the GRU is the embedded amino acid sequence. We searched for the best amino acid representation by performing 5-fold cross-validation to train and test the entire model for each candidate embedding. We also allowed the model to adapt parameters in the peptide embedding layer via back-propagation. However, the large number of parameters in ProtVec representation caused the model to overfit during the adaptation and ultimately worsened the performance. To overcome this problem, the ProtVec model was trained with the following procedure. First, the model was trained without adaptation until the loss steadied. Then, we enabled adaptation and resumed model training for 1-3 epochs. Finally, adaptation was disabled again, and the model was trained until it stopped improving. This procedure is similar in spirit to other transfer learning methods [<xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR22">22</xref>].</p>
    </sec>
    <sec id="Sec6">
      <title>MHC allele embedding layer</title>
      <p>We considered representing an MHC allele with its amino acid sequence in order to allow the model to predict binding probabilities for new MHC alleles that were not part of the training dataset, as long as the new allele’s amino acid sequence is known beforehand. We obtained the amino acid sequence of human MHC class I alleles from the Immuno Polymorphism Database (IPD) [<xref ref-type="bibr" rid="CR23">23</xref>]. Then, we extracted the amino acid sequence portions that correspond to the two alpha helices that participate in the binding with peptide ligand [<xref ref-type="bibr" rid="CR8">8</xref>], e.g. the residues 50-84 and 140-179 on the structure of HLA-B*35:01 (PDB ID: 1A1N, Additional file <xref rid="MOESM1" ref-type="media">1</xref>) [<xref ref-type="bibr" rid="CR24">24</xref>]. It should be noted that inclusion of amino acid sequences from the beta sheet which was known to participate in ligand binding (e.g., residues 3-37 and 94-126, Additional file <xref rid="MOESM1" ref-type="media">1</xref>) into our model worsened the performance. To define the corresponding amino acid residues of the alpha helices in each MHC allele, we used MUSCLE v 3.8.31 [<xref ref-type="bibr" rid="CR25">25</xref>] with default parameter to create a multiple-sequence alignment of all MHC alleles and then mapped the location of residues 50-84 and 140-179 from HLA-B*35:01 to other alleles.</p>
      <p>Each MHC allele is inputted into the MHC allele embedding layer as a sequence of amino acids (Fig. <xref rid="Fig1" ref-type="fig">1</xref>b). The MHC allele embedding layer was randomly initialized instead of using pre-trained weights because the alignments can contain gaps which were represented by a special character. For the MHC allele processing layer (Fig. <xref rid="Fig1" ref-type="fig">1</xref>d), two different layers were tested, namely the fully connected layer and the GRU. We tuned the models by varying the layer sizes from 50 to 350 neurons for the fully connected layer, and from 8 to 80 for the GRU. Additionally, we implemented a one-hot representation of the MHC allele. This representation ignores the amino acid sequence of MHC allele and therefore does not capture relationship between MHC alleles.</p>
    </sec>
    <sec id="Sec7">
      <title>Output layer</title>
      <p>The outputs from both the peptide processing layer and the MHC allele processing layer are then passed through two fully connected layers with rectified linear unit (ReLU) as the activation function (Fig. <xref rid="Fig1" ref-type="fig">1</xref>e). A final classification layer employs a sigmoid activation function to obtain the final output in the form of binding probability (Fig. <xref rid="Fig1" ref-type="fig">1</xref>f). We varied the layer size of the fully connected layers from 64 to 512 neurons. In order to prevent overfitting, dropouts [<xref ref-type="bibr" rid="CR26">26</xref>] were also applied to the fully connected and the GRU layers [<xref ref-type="bibr" rid="CR14">14</xref>]. We tested dropout probabilities of 0, 0.1, 0.2, 0.3, 0.4, and 0.5 and obtained similar performances. In the final configuration, the default dropout probabilities were set at 0.4 for outputs from the fully-connected layers and for inputs to the GRU layers, and 0.3 for recurrent dropout in the GRU layers.</p>
    </sec>
    <sec id="Sec8">
      <title>Neural network training and final model development</title>
      <p>We employed a 5-fold cross-validation scheme where the dataset was divided into five partitions of equal size. Entries with the same peptide sequence were also grouped so that all of them are assigned to the same partition. For each fold, four partitions were used for training and the remaining partition for testing. Furthermore, in each fold, we used 20% of the training data for hyperparameter tuning and early stopping of the training process. In our model, architecture weights are shared across all MHC alleles, as suppose to building one model per MHC allele [<xref ref-type="bibr" rid="CR9">9</xref>]. Adam optimization algorithm was used for the training [<xref ref-type="bibr" rid="CR27">27</xref>].</p>
      <p>The final model was developed by using the representation of peptide and MHC alleles as well as the neural network architectures that achieved highest performances. The best representation for peptide is the 1-Gram model trained on the combination of Swiss-Prot proteins and predicted proteasome-cleaved human peptides as described below. For the best representation of MHC allele, there are two representations which produce similar results. The first candidate is the one-hot amino acid representation coupled with fully connected layers. The second candidate is the one-hot MHC allele representation. Thus, we included both models in the software. We then created a simple ensemble model using the 5 models each trained on one data partition. The final binding probability prediction is defined as the median of the outputs from these 5 models.</p>
    </sec>
    <sec id="Sec9">
      <title>Performance evaluation</title>
      <p>The performance of our models were measured using the area under the receiver operating curve (AUC). The AUC were calculated for both the whole test set and for individual MHC alleles. Performance over all 92 MHC alleles were included in the calculation for the whole test set. For individual alleles, we only evaluate 43 MHC alleles that have at least 30 data points in total and at least 5 positive and at least 5 negative data points. AUC across the five folds from cross-validation were averaged. Additionally, we also report the F1 scores. The score is calculated by selecting the threshold that achieves the highest F1 from the receiver operating curve.</p>
      <p>We compared the AUCs of our models to those of NetMHCPan 4.0 [<xref ref-type="bibr" rid="CR8">8</xref>] and MHCflurry version 1.1.0 [<xref ref-type="bibr" rid="CR9">9</xref>] by using them to make binding affinity predictions on the same test sets as MHCSeqNet. To ensure a fair comparison, MHCflurry was re-trained using our cleaned dataset. We evaluated the impact of MHCflurry’s hyperparameters on its performance by varying the values of two key parameters, namely the number of filters in locally connected layers and the number of layers, to be 8, 16, 32, and 64 (the default values are 8 and 16, respectively), and calculating the corresponding AUCs. Overall, the change in performance is minimal, with standard deviation of AUC among these parameter sets being only 0.0063. Hence, we decided to keep the default hyperparameters for MHCflurry. On the other hand, as the public version of NetMHCPan could not be re-trained, we evaluated its performance as is. In each comparison, only MHC alleles supported by all software tools involved were considered. This restricted the evaluation sets to 41 MHC alleles (Additional file <xref rid="MOESM2" ref-type="media">2</xref>). Furthermore, MHCflurry limits the length of input peptides to be between 8 and 15 amino acids while NetMHCPan can make prediction for peptide of any length.</p>
      <p>Additionally, we tested all models on an external dataset [<xref ref-type="bibr" rid="CR17">17</xref>] that consists of MHC class I peptidome from four human individuals whose HLA-A, HLA-B, and HLA-C alleles have been determined. Since a detected ligand in this dataset could be bound to any of the MHC alleles present, we took the maximal predicted binding probability or affinity over the set of MHC alleles in each individual as the prediction of each model. To enable the calculation of AUC here, we also include the negative data from the test set which were not used during the training of our models into this evaluation.</p>
    </sec>
    <sec id="Sec10">
      <title>Prediction for unseen MHC alleles</title>
      <p>We evaluated the capability of our sequence-based model to predict peptide-MHC binding for unseen MHC alleles by purposely omitting one MHC allele at a time from the training dataset, retraining the model, and then predicting the binding for peptides contained in the omitted data. This process was repeated for every MHC allele in the dataset and the prediction performance in term of average AUCs over 5 models (derived from 5-fold cross-validation) were recorded.</p>
    </sec>
    <sec id="Sec11">
      <title>Peptide sequence and peptide-MHC binding affinity datasets</title>
      <p>To obtain a large amount of amino acid sequences for pre-training the 1-Gram and 3-Gram amino acid representation models described above, we downloaded 468,891 verified protein sequences of all species from Swiss-Prot [<xref ref-type="bibr" rid="CR28">28</xref>] and also constructed a dataset of 16 million simulated proteasome-cleaved human 9-mer peptides using NetChop [<xref ref-type="bibr" rid="CR29">29</xref>]. Likely proteasome-cleaved 9-mers were defined as those flanked by cleavage sites with predicted cleavage probability ≥0.5. The 1-Gram and 3-Gram models were then trained on the Swiss-Prot proteins alone, the simulated 9-mers alone, or the combination of the two.</p>
      <p>We combined peptide-MHC binding affinity data from IEDB [<xref ref-type="bibr" rid="CR23">23</xref>] and MHCflurry [<xref ref-type="bibr" rid="CR9">9</xref>], and selected entries corresponding to human MHC class I molecules (HLA-A, HLA-B, and HLA-C) with peptide ligand lengths between 8 and 15 amino acids. Entries with ambiguous amino acids, namely B, X, J, and Z, or non-specific MHC allele names, such as HLA-A30 or MHC class I, were excluded. Furthermore, as one of our models needs the amino acid sequence of MHC allele as an input, only alleles whose amino acid sequences are present in the Immuno Polymorphism Database [<xref ref-type="bibr" rid="CR23">23</xref>] were selected.</p>
      <p>We chose to disregard all quantitative binding affinity values and used only qualitative binding classifications, namely Positive-High, Positive, Positive-Intermediate, Positive-Low, and Negative, because the binding affinity values were acquired through diverse, non-standardized experimental techniques performed in multiple laboratories. Furthermore, we found that removing low-confidence entries (Positive-Intermediate and Positive-Low) slightly improved the prediction performances. There were also a number of conflicting entries which contained the same MHC allele and peptide ligand but opposite binding classifications. As the majority of these conflicts come from a few published sources (PubMed IDs), we decided to exclude all entries from these sources. For each of the remaining conflicts, we reassigned the binding classification based on the majority vote. If there is an equal number of Positive and Negative entries, all of the associated conflicting entries were excluded from further considerations.</p>
      <p>In total, the final cleaned dataset contains 228,348 peptide-MHC entries consisting of 31 HLA-A, 49 HLA-B, and 12 HLA-C alleles. The number of ligands per MHC allele ranges from 41 to 21,480. The cleaned dataset is provided as Additional file <xref rid="MOESM3" ref-type="media">3</xref> and can also be found on MHCSeqNet’s GitHub page.</p>
    </sec>
  </sec>
  <sec id="Sec12" sec-type="results">
    <title>Results</title>
    <sec id="Sec13">
      <title>MHC allele representation model</title>
      <p>We trained our models using two different MHC allele representations: a one-hot system which conveys no relationship between MHC alleles, and an amino acid sequence-based representation that permits inference across alleles. We also tested two entry layer architectures for processing MHC allele’s amino acid sequences: a fully connected layer and a GRU layer. Evaluations based on AUC showed that using a fully connected layer as the entry layer for the sequence-based models gives slightly better overall performance than using a GRU layer (AUC of 0.9910 and 0.9898, respectively). Compared to sequence-based models, the one-hot MHC allele representation model yielded slightly better overall performance with an AUC of 0.9917 and it outperformed the sequence-based models on almost every MHC allele (41 out of 43 alleles tested, Additional file <xref rid="MOESM2" ref-type="media">2</xref>). A closer inspection revealed that the both models achieved similar performance on alleles with large amount of training data. And for MHC alleles with fewer training data points, the performance gap between the one-hot and the sequence-based models tend to be higher. This is likely because the sequence-based model has more parameters and thus requires more data to train.</p>
    </sec>
    <sec id="Sec14">
      <title>Peptide embedding</title>
      <p>The one-hot, 1-gram, and 3-gram peptide representations were pre-trained on three different datasets: Swiss-Prot proteins, simulated human proteasome-cleaved 9-mers, and the combination of the two. We also studied the case where no pre-training is done, and the embedding layer was initialized randomly. Overall, the 1-gram model yielded the best performance with an average AUC of 0.991715, followed by the one-hot model with an average AUC of 0.991680. For the 1-gram model, combining the two amino acid sequence datasets slightly improved the performance over using individual dataset or using no pre-training. Rather unexpectedly, regardless of the adaptation method (see Methods) or the dataset tested, the 3-gram model, which has previously been used to analyzed protein structural family [<xref ref-type="bibr" rid="CR20">20</xref>], consistently performed worse than the other alternatives. We suspected that the large number of parameters in the 3-gram model caused the model to overfit even when adaptation was performed carefully. Nonetheless, significant improvement in AUC for the 3-gram model was achieved with our special adaptation method (from 0.967181 to 0.982490).</p>
    </sec>
    <sec id="Sec15">
      <title>Evaluation using MHC class I binding affinity dataset</title>
      <p>From above results, the 1-gram model trained on the combination of Swiss-Prot proteins and simulated human proteasome-cleaved 9-mers was selected as the peptide embedding layer. For MHC allele representation, we evaluated both the one-hot and the sequence-based models here. The performance of our models, NetMHCPan version 4.0 [<xref ref-type="bibr" rid="CR8">8</xref>], MHCflurry version 1.1.0 [<xref ref-type="bibr" rid="CR9">9</xref>], and the retrained MHCflurry were evaluated on the MHC class I binding affinity dataset using a five-fold cross-validation scheme (see Methods). The dataset was also split so that entries with the same peptide sequences were all assigned to the same cross-validation fold. This revealed that both of our models significantly outperformed NetMHCPan and MHCflurry overall with respect to both AUC and F1 score (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). Analysis of 100 bootstrap samples obtained by sampling 80% of entries in the test set with replacement showed that these AUC estimates are highly stable with coefficients of variation smaller than 0.26<italic>%</italic>. Additionally, the binding probabilities predicted by both of our models strongly distinguish between positive and negative ligands. For positive ligands, the vast majority of predicted binding probabilities are close to 1.0 (Additional file <xref rid="MOESM4" ref-type="media">4</xref>). For negative ligands, the predicted binding probabilities center around 0.2 with the 75th percentile located at around 0.6.
<fig id="Fig2"><label>Fig. 2</label><caption><p>MHCSeqNet achieves the best AUC and F1 scores on MHC class I binding dataset. <bold>a</bold> Bar plots showing the AUC value of each tool when evaluated on the set of MHC alleles it supports (Supported Type) or on the set of MHC alleles supported by all tools (Common Type). <bold>b</bold> Similar bar plots showing F1 values. <bold>c</bold> The ROC plot for all tools when evaluated on the set of MHC alleles supported by all tools. Vertical black line indicates the 5% false discovery rate (FDR). Inset shows the zoomed in ROC plot for the region with ≤5% FDR. <bold>d</bold> Similar ROC plot for the evaluation on MHC alleles supported by individual tools</p></caption><graphic xlink:href="12859_2019_2892_Fig2_HTML" id="MO2"/></fig></p>
      <p>On individual MHC allele level, our one-hot model achieved the highest AUC than all others on 32 out of 41 alleles that are supported by all tools (Additional file <xref rid="MOESM2" ref-type="media">2</xref>). Among 9 alleles where our one-hot model did not yield the best performance, MHCflurry performed better on 8 of them (HLA-A*02:02, HLA-A*02:06, HLA-A*26:01, HLA-A*30:02, HLA-A*33:01, HLA-A*69:01, HLA-B*40:01, and HLA-B*53:01) and NetMHCpan did so on only one allele (HLA-A*68:01). Furthermore, these alleles are mostly alleles with few training data points (8 of these alleles are among the bottom 13 alleles with the least amount of data points). Among NetMHCpan and our sequence-based model – the two approaches that can handle any input MHC allele, our model achieved higher AUC on 32 out of 41 alleles (all alleles except HLA-A*02:02, HLA-A*02:06, HLA-A*23:01, HLA-A*30:02, HLA-A*33:01, HLA-A*68:01, HLA-B*08:01, HLA-B*53:01, and HLA-B*58:01).</p>
    </sec>
    <sec id="Sec16">
      <title>Evaluation using external MHC class I peptidomes</title>
      <p>We further evaluated our models, NetMHCPan, and MHCflurry on MHC class I ligand peptidomes [<xref ref-type="bibr" rid="CR17">17</xref>] which were derived from mass spectrometry analyses of four human individuals whose HLA-A, HLA-B, and HLA-C alleles have been determined (Table <xref rid="Tab1" ref-type="table">1</xref>). This evaluation mimics real use cases where a predicted MHC ligand may bind to any of the MHC class I alleles present in a patient. As it is unclear which MHC allele was bound to each detected peptide, the maximal predicted binding probability or affinity over the set of MHC alleles in each individual was designated as the final prediction for each model. Additionally, to ensure that this test is independent from the evaluation using binding affinity data, all peptidome entries that overlap with our training dataset were removed from consideration. It should be noted that some HLA-C alleles were not supported by NetMHCPan, MHCflurry, and our one-hot model (Table <xref rid="Tab1" ref-type="table">1</xref>), and that the sequence-based model alone could make predictions for these alleles. Again, our models achieved the best overall AUC and F1 scores (Fig. <xref rid="Fig3" ref-type="fig">3</xref>).
<fig id="Fig3"><label>Fig. 3</label><caption><p>MHCSeqNet achieves the best AUC and F1 scores on MHC class I ligand peptidome dataset. <bold>a</bold> The ROC plot for all tools. Vertical black line indicates the 5% FDR. Inset show the zoomed in ROC plot for the region with ≤5% FDR. <bold>b</bold> Bar plots showing the AUC (bars with solid face colors) and F1 (bars with stripes) scores of each tool</p></caption><graphic xlink:href="12859_2019_2892_Fig3_HTML" id="MO3"/></fig>
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Typed MHC alleles of four individuals in the MHC class I ligand peptidome dataset</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Sample ID</th><th align="left">Mel 12</th><th align="left">Mel 15</th><th align="left">Mel 16</th><th align="left">Mel 8</th></tr></thead><tbody><tr><td align="left">HLA-A</td><td align="left">A*01:01</td><td align="left">A*03:01</td><td align="left">A*01:01</td><td align="left">A*01:01</td></tr><tr><td align="left"/><td align="left">-</td><td align="left">A*68:01</td><td align="left">A*24:02</td><td align="left">A*03:01</td></tr><tr><td align="left">HLA-B</td><td align="left">B*08:01</td><td align="left">B*27:05</td><td align="left">B*07:02</td><td align="left">B*07:02</td></tr><tr><td align="left"/><td align="left">-</td><td align="left">B*35:03</td><td align="left">B*08:01</td><td align="left">B*08:01</td></tr><tr><td align="left">HLA-C</td><td align="left">C*07:01<sup>a</sup></td><td align="left">C*02:02<sup>b</sup></td><td align="left">C*07:01<sup>a</sup></td><td align="left">C*07:01<sup>a</sup></td></tr><tr><td align="left"/><td align="left">-</td><td align="left">C*04:01</td><td align="left">C*07:02</td><td align="left">C*07:01<sup>a</sup></td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>Alleles not supported by the original MHCflurry</p><p><sup>b</sup>Allele supported by only our sequence-based model</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec17">
      <title>Prediction for unseen MHC alleles</title>
      <p>To evaluate our sequence-based model’s ability to predict peptide-MHC binding probability for new, unseen MHC alleles, we trained the sequence-based model using data from all-but-one alleles and calculated the model’s AUC using data from the omitted allele. To ensure that the AUC estimates are stable, we repeated the training and AUC calculation process with different random initialization five times for each allele and reported the average AUCs. This revealed that the sequence-based MHC allele representation model clearly outperformed the one-hot MHC allele representation model on 47 out of 60 MHC alleles evaluated (Additional file <xref rid="MOESM5" ref-type="media">5</xref>) with median AUC of 0.7987 versus 0.6159 and a median AUC difference of 0.12 across all alleles.</p>
    </sec>
  </sec>
  <sec id="Sec18" sec-type="discussion">
    <title>Discussion</title>
    <sec id="Sec19">
      <title>Impact of data cleaning</title>
      <p>In addition to removing duplicated entries and entries with ambiguous peptide sequence or MHC allele name as regularly performed in other studies [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR9">9</xref>], we also examined the impact of conflicting entries (entries with the same peptide sequence and same MHC allele but opposite binding affinity classification) and low-confidence entries (Positive-Intermediate and Positive Low) on the prediction performance. Although conflicting entries constitute less than 5% of the raw dataset, the vast majority of them (15,305 out of 17,914 conflicting entries) involve the same source, which reported HLA-B*27 ligands identified in transgenic mice [<xref ref-type="bibr" rid="CR30">30</xref>], and should be entirely excluded or at least carefully scrutinized. The remaining conflicts could be resolved by majority voting which slightly improves the prediction performance. We also found that the exclusion of low-confidence entries slightly improved the prediction performances when tested on all entries or on only high-confidence entries.</p>
    </sec>
    <sec id="Sec20">
      <title>Capability to make prediction for unseen MHC alleles</title>
      <p>The capability to predict binding affinity of a candidate neoepitope against all MHC alleles presented in a patient is highly desirable because neoepitopes that can bind to multiple MHC alleles are likely to be immunogenic. The sequence-based version of MHCSeqNet not only better predicted ligands for unseen MHC alleles than its one-hot counterpart but also improved over existing tools. Curiously, the sequence-based model did not outperform the one-hot model when tested on a peptidome dataset which contains two HLA-C alleles not present in the training dataset (Table <xref rid="Tab1" ref-type="table">1</xref>). We suspected that this is due to the overall lack of HLA-C data (HLA-C entries constitute only 3% of the final training dataset) for the sequence-based model to learn from. Indeed, the sequence-based model performed worse than the one-hot models on 4 out of 9 HLA-C alleles considered when comparing the the two (Additional file <xref rid="MOESM5" ref-type="media">5</xref>). More data on HLA-C epitopes from future experiments should greatly help improve the performance of the sequence-based version of MHCSeqNet.</p>
    </sec>
  </sec>
  <sec id="Sec21" sec-type="conclusion">
    <title>Conclusions</title>
    <p>MHCSeqNet exhibits performance improvement over existing tools for predicting MHC class I ligands on both binding affinity and peptidome datasets. Furthermore, MHCSeqNet retains the flexibility to make prediction for peptide of any length and for any MHC class I allele with known amino acid sequence by utilizing recurrent neural network architectures to handle amino acid sequences. Thus, MHCSeqNet should contribute to the growing interests in MHC ligand prediction, especially to the screening of effective neoepitopes for cancer vaccine development.</p>
  </sec>
  <sec id="Sec22">
    <title>Availability and requirements</title>
    <p><bold>Project name:</bold> MHCSeqNet</p>
    <p>
      <bold>Project home page:</bold>
      <ext-link ext-link-type="uri" xlink:href="https://github.com/cmbcu/MHCSeqNet">https://github.com/cmbcu/MHCSeqNet</ext-link>
    </p>
    <p><bold>Operating systems(s):</bold> Platform independent</p>
    <p><bold>Programming language:</bold> Python 3</p>
    <p><bold>Other requirements:</bold> None</p>
    <p><bold>License:</bold> Apache 2.0</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Additional files</title>
    <sec id="Sec23">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2019_2892_MOESM1_ESM.png">
            <label>Additional file 1</label>
            <caption>
              <p>Figure S1 – Illustration of the two alpha helices (blue and magenta) used to represent an MHC class I allele in our sequence-based model. The structure of HLA-B*35:01 from the Protein Data Bank entry 1A1N is shown here. Amino acid residue positions 50-84 and 140-179 correspond to the two alpha helices in this structure. Inclusion of the beta-sheet (yellow) decreased model performances. (PNG 210 kb)</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="12859_2019_2892_MOESM2_ESM.tsv">
            <label>Additional file 2</label>
            <caption>
              <p>Table S1 – The MHC allele-specific AUC for each software tool evaluated on the binding affinity dataset. (TSV 8 kb)</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="12859_2019_2892_MOESM3_ESM.tsv">
            <label>Additional file 3</label>
            <caption>
              <p>Table S2 – The cleaned peptide-MHC binding affinity dataset. (TSV 8645 kb)</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM4">
          <media xlink:href="12859_2019_2892_MOESM4_ESM.png">
            <label>Additional file 4</label>
            <caption>
              <p>Figure S2 – Boxplots comparing the predicted binding probabilities between positive and negative classes. The orange horizontal lines indicate medians. Black boxes designate the 25<sup>th</sup>–75<sup>th</sup> percentile regions. The whiskers indicate the non-outlier ranges which cover from Q1 - 1.5 * (Q3 - Q1) to Q3 + 1.5 * (Q3 - Q1), where Q1 and Q3 are the values at 25<sup>th</sup> and 75<sup>th</sup> percentiles, respectively. Black circles represent outliers. (PNG 56 kb)</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM5">
          <media xlink:href="12859_2019_2892_MOESM5_ESM.png">
            <label>Additional file 5</label>
            <caption>
              <p>Figure S3 – Scatter plot comparing performances of sequence-based and one-hot models when tested on unseen MHC class I alleles not included in the training dataset. Each circle shows the AUC of one-hot and sequence-based model on each held-out allele. Colors indicate HLA types (A, B, or C). Circle sizes indicate the relative number of data points of the held-out allele. (PNG 79 kb)</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank Tanchanok Wisitponchai for her contribution to the analyses of HLA 3D structure and proteasome-cleaved peptides.</p>
    <sec id="d29e952">
      <title>Funding</title>
      <p>This work was partly supported by the Grant for Special Task Force for Activating Research, Ratchadapisek Sompoch Endowment Fund, Chulalongkorn University [to SS and EC], the Grant for Development of New Faculty Staff, Ratchadaphisek Sompoch Endowment Fund, Chulalongkorn University [to NP], the Grant for New Scholar, Thailand Research Fund [MRG6080087 to NP], the fellowship support from Vidyasirimedhi Institute of Science and Technology [to EC], and the Chulalongkorn Academic Advancement into Its 2nd Century Project.</p>
    </sec>
    <sec id="d29e957" sec-type="data-availability">
      <title>Availability of data and materials</title>
      <p>The MHCSeqNet source code, the cleaned datasets, together with a usage guide are available on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/cmbcu/MHCSeqNet">https://github.com/cmbcu/MHCSeqNet</ext-link>. The cleaned MHC binding dataset is also provided as Additional file <xref rid="MOESM3" ref-type="media">3</xref>.</p>
    </sec>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>PP developed the software. NP, SS, and EC supervised the project and analyzed data. All authors wrote and approved the final manuscript.</p>
  </notes>
  <notes>
    <title>Ethics approval and consent to participate</title>
    <p>Not applicable</p>
  </notes>
  <notes>
    <title>Consent for publication</title>
    <p>Not applicable</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p>The authors declare that they have no competing interests.</p>
  </notes>
  <notes>
    <title>Publisher’s Note</title>
    <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Castle</surname>
            <given-names>J. C.</given-names>
          </name>
          <name>
            <surname>Kreiter</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Diekmann</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Lower</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>van de Roemer</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>de Graaf</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Selmi</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Diken</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Boegel</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Paret</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Koslowski</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Kuhn</surname>
            <given-names>A. N.</given-names>
          </name>
          <name>
            <surname>Britten</surname>
            <given-names>C. M.</given-names>
          </name>
          <name>
            <surname>Huber</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Tureci</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Sahin</surname>
            <given-names>U.</given-names>
          </name>
        </person-group>
        <article-title>Exploiting the Mutanome for Tumor Vaccination</article-title>
        <source>Cancer Research</source>
        <year>2012</year>
        <volume>72</volume>
        <issue>5</issue>
        <fpage>1081</fpage>
        <lpage>1091</lpage>
        <pub-id pub-id-type="doi">10.1158/0008-5472.CAN-11-3722</pub-id>
        <pub-id pub-id-type="pmid">22237626</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schumacher</surname>
            <given-names>TN</given-names>
          </name>
          <name>
            <surname>Schreiber</surname>
            <given-names>RD</given-names>
          </name>
        </person-group>
        <article-title>Realising the Promise: Neoantigens in cancer immunotherapy</article-title>
        <source>Sci Mag</source>
        <year>2015</year>
        <volume>348</volume>
        <issue>6230</issue>
        <fpage>69</fpage>
        <lpage>74</lpage>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Banchereau</surname>
            <given-names>Jacques</given-names>
          </name>
          <name>
            <surname>Palucka</surname>
            <given-names>Karolina</given-names>
          </name>
        </person-group>
        <article-title>Immunotherapy: Cancer vaccines on the move</article-title>
        <source>Nature Reviews Clinical Oncology</source>
        <year>2017</year>
        <volume>15</volume>
        <issue>1</issue>
        <fpage>9</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1038/nrclinonc.2017.149</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sahin</surname>
            <given-names>Ugur</given-names>
          </name>
          <name>
            <surname>Türeci</surname>
            <given-names>Özlem</given-names>
          </name>
        </person-group>
        <article-title>Personalized vaccines for cancer immunotherapy</article-title>
        <source>Science</source>
        <year>2018</year>
        <volume>359</volume>
        <issue>6382</issue>
        <fpage>1355</fpage>
        <lpage>1360</lpage>
        <pub-id pub-id-type="doi">10.1126/science.aar7112</pub-id>
        <pub-id pub-id-type="pmid">29567706</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Engels</surname>
            <given-names>Boris</given-names>
          </name>
          <name>
            <surname>Engelhard</surname>
            <given-names>Victor H.</given-names>
          </name>
          <name>
            <surname>Sidney</surname>
            <given-names>John</given-names>
          </name>
          <name>
            <surname>Sette</surname>
            <given-names>Alessandro</given-names>
          </name>
          <name>
            <surname>Binder</surname>
            <given-names>David C.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Rebecca B.</given-names>
          </name>
          <name>
            <surname>Kranz</surname>
            <given-names>David M.</given-names>
          </name>
          <name>
            <surname>Meredith</surname>
            <given-names>Stephen C.</given-names>
          </name>
          <name>
            <surname>Rowley</surname>
            <given-names>Donald A.</given-names>
          </name>
          <name>
            <surname>Schreiber</surname>
            <given-names>Hans</given-names>
          </name>
        </person-group>
        <article-title>Relapse or Eradication of Cancer Is Predicted by Peptide-Major Histocompatibility Complex Affinity</article-title>
        <source>Cancer Cell</source>
        <year>2013</year>
        <volume>23</volume>
        <issue>4</issue>
        <fpage>516</fpage>
        <lpage>526</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ccr.2013.03.018</pub-id>
        <pub-id pub-id-type="pmid">23597565</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vita</surname>
            <given-names>Randi</given-names>
          </name>
          <name>
            <surname>Overton</surname>
            <given-names>James A.</given-names>
          </name>
          <name>
            <surname>Greenbaum</surname>
            <given-names>Jason A.</given-names>
          </name>
          <name>
            <surname>Ponomarenko</surname>
            <given-names>Julia</given-names>
          </name>
          <name>
            <surname>Clark</surname>
            <given-names>Jason D.</given-names>
          </name>
          <name>
            <surname>Cantrell</surname>
            <given-names>Jason R.</given-names>
          </name>
          <name>
            <surname>Wheeler</surname>
            <given-names>Daniel K.</given-names>
          </name>
          <name>
            <surname>Gabbard</surname>
            <given-names>Joseph L.</given-names>
          </name>
          <name>
            <surname>Hix</surname>
            <given-names>Deborah</given-names>
          </name>
          <name>
            <surname>Sette</surname>
            <given-names>Alessandro</given-names>
          </name>
          <name>
            <surname>Peters</surname>
            <given-names>Bjoern</given-names>
          </name>
        </person-group>
        <article-title>The immune epitope database (IEDB) 3.0</article-title>
        <source>Nucleic Acids Research</source>
        <year>2014</year>
        <volume>43</volume>
        <issue>D1</issue>
        <fpage>D405</fpage>
        <lpage>D412</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gku938</pub-id>
        <pub-id pub-id-type="pmid">25300482</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Abelin</surname>
            <given-names>Jennifer G.</given-names>
          </name>
          <name>
            <surname>Keskin</surname>
            <given-names>Derin B.</given-names>
          </name>
          <name>
            <surname>Sarkizova</surname>
            <given-names>Siranush</given-names>
          </name>
          <name>
            <surname>Hartigan</surname>
            <given-names>Christina R.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Wandi</given-names>
          </name>
          <name>
            <surname>Sidney</surname>
            <given-names>John</given-names>
          </name>
          <name>
            <surname>Stevens</surname>
            <given-names>Jonathan</given-names>
          </name>
          <name>
            <surname>Lane</surname>
            <given-names>William</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Guang Lan</given-names>
          </name>
          <name>
            <surname>Eisenhaure</surname>
            <given-names>Thomas M.</given-names>
          </name>
          <name>
            <surname>Clauser</surname>
            <given-names>Karl R.</given-names>
          </name>
          <name>
            <surname>Hacohen</surname>
            <given-names>Nir</given-names>
          </name>
          <name>
            <surname>Rooney</surname>
            <given-names>Michael S.</given-names>
          </name>
          <name>
            <surname>Carr</surname>
            <given-names>Steven A.</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>Catherine J.</given-names>
          </name>
        </person-group>
        <article-title>Mass Spectrometry Profiling of HLA-Associated Peptidomes in Mono-allelic Cells Enables More Accurate Epitope Prediction</article-title>
        <source>Immunity</source>
        <year>2017</year>
        <volume>46</volume>
        <issue>2</issue>
        <fpage>315</fpage>
        <lpage>326</lpage>
        <pub-id pub-id-type="doi">10.1016/j.immuni.2017.02.007</pub-id>
        <pub-id pub-id-type="pmid">28228285</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jurtz</surname>
            <given-names>Vanessa</given-names>
          </name>
          <name>
            <surname>Paul</surname>
            <given-names>Sinu</given-names>
          </name>
          <name>
            <surname>Andreatta</surname>
            <given-names>Massimo</given-names>
          </name>
          <name>
            <surname>Marcatili</surname>
            <given-names>Paolo</given-names>
          </name>
          <name>
            <surname>Peters</surname>
            <given-names>Bjoern</given-names>
          </name>
          <name>
            <surname>Nielsen</surname>
            <given-names>Morten</given-names>
          </name>
        </person-group>
        <article-title>NetMHCpan-4.0: Improved Peptide–MHC Class I Interaction Predictions Integrating Eluted Ligand and Peptide Binding Affinity Data</article-title>
        <source>The Journal of Immunology</source>
        <year>2017</year>
        <volume>199</volume>
        <issue>9</issue>
        <fpage>3360</fpage>
        <lpage>3368</lpage>
        <pub-id pub-id-type="doi">10.4049/jimmunol.1700893</pub-id>
        <pub-id pub-id-type="pmid">28978689</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>O'Donnell</surname>
            <given-names>Timothy J.</given-names>
          </name>
          <name>
            <surname>Rubinsteyn</surname>
            <given-names>Alex</given-names>
          </name>
          <name>
            <surname>Bonsack</surname>
            <given-names>Maria</given-names>
          </name>
          <name>
            <surname>Riemer</surname>
            <given-names>Angelika B.</given-names>
          </name>
          <name>
            <surname>Laserson</surname>
            <given-names>Uri</given-names>
          </name>
          <name>
            <surname>Hammerbacher</surname>
            <given-names>Jeff</given-names>
          </name>
        </person-group>
        <article-title>MHCflurry: Open-Source Class I MHC Binding Affinity Prediction</article-title>
        <source>Cell Systems</source>
        <year>2018</year>
        <volume>7</volume>
        <issue>1</issue>
        <fpage>129-132.e4</fpage>
        <pub-id pub-id-type="doi">10.1016/j.cels.2018.05.014</pub-id>
        <pub-id pub-id-type="pmid">29960884</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10</label>
      <mixed-citation publication-type="other">Han Y, Kim D. Deep convolutional neural networks for pan-specific peptide-MHC class I binding prediction. BMC Bioinformatics. 2017; 18:585. 10.1186/s12859-017-1997-x.</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11</label>
      <mixed-citation publication-type="other">Graves A, Mohamed A, Hinton G. Speech recognition with deep recurrent neural networks. IEEE Int Conf Acoust Speech Signal Process 2013 (ICASSP). 2013;:6645–9.</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12</label>
      <mixed-citation publication-type="other">Bahdanau D, Cho K, Bengio Y. Neural machine translation by jointly learning to align and translate. 2016. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1409.0473">https://arxiv.org/abs/1409.0473</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Quang</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Xie</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <issue>11</issue>
        <fpage>107</fpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw226</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14</label>
      <mixed-citation publication-type="other">Cho K, Van Merrienboer B, Bahdanau D, Bengio Y. On the properties of neural machine translation: encoder-decoder approaches. 2014. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1409.1259">https://arxiv.org/abs/1409.1259</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15</label>
      <mixed-citation publication-type="other">Chung J, Gulcehre C, Cho K, Bengio Y. Empirical evaluation of gated recurrent neural networks on sequence modeling. 2014. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1412.3555">https://arxiv.org/abs/1412.3555</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16</label>
      <mixed-citation publication-type="other">Tang Z, Shi Y, Wang D, Feng Y, Zhang S. Memory visualization for gated recurrent neural networks in speech recognition. IEEE Int Conf Acoust Speech Signal Process 2017 (ICASSP). 2017;:2736–40.</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17</label>
      <mixed-citation publication-type="other">Bassani-Sternberg M, Braunlein E, Klar R, Engleitner T, Sinitcyn P, Audehm S, Straub M, Weber J, Slotta-Huspenina J, Specht K, Martignoni ME, Werner A, Hein R, Busch DH, Peschel C, Rad R, Cox J, Mann M, Krackhardt AM. Direct identification of clinically relevant neoepitopes presented on native human melanoma tissue by mass spectrometry. Nat Commun. 2016; 7(May). 10.1038/ncomms13404.</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Collobert</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Weston</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bottou</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Karlen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kavukcuoglu</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Kuksa</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Natural language processing (almost) from scratch</article-title>
        <source>J Mach Learn Res</source>
        <year>2011</year>
        <volume>12</volume>
        <issue>Aug</issue>
        <fpage>2493</fpage>
        <lpage>537</lpage>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mikolov</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Corrado</surname>
            <given-names>GS</given-names>
          </name>
          <name>
            <surname>Dean</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Distributed representations of words and phrases and their compositionality</article-title>
        <source>Adv Neural Inf Process Syst</source>
        <year>2013</year>
        <volume>2</volume>
        <fpage>3111</fpage>
        <lpage>9</lpage>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Asgari</surname>
            <given-names>Ehsaneddin</given-names>
          </name>
          <name>
            <surname>Mofrad</surname>
            <given-names>Mohammad R. K.</given-names>
          </name>
        </person-group>
        <article-title>Continuous Distributed Representation of Biological Sequences for Deep Proteomics and Genomics</article-title>
        <source>PLOS ONE</source>
        <year>2015</year>
        <volume>10</volume>
        <issue>11</issue>
        <fpage>e0141287</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0141287</pub-id>
        <pub-id pub-id-type="pmid">26555596</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Felbo</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Mislove</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sogaard</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Rahwan</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Lehmann</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm</article-title>
        <source>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</source>
        <year>2017</year>
        <publisher-loc>Stroudsburg</publisher-loc>
        <publisher-name>The Association for Computational Linguistics</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22</label>
      <mixed-citation publication-type="other">Grezl F, Karafiat M, Vesely K. Adaptation of multilingual stacked bottle-neck neural network structure for new language. IEEE Int Conf Acoust Speech Signal Process 2014 (ICASSP). 2014;:7654–8.</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23</label>
      <element-citation publication-type="book">
        <person-group person-group-type="editor">
          <name>
            <surname>Flower</surname>
            <given-names>Darren D.R.</given-names>
          </name>
          <name>
            <surname>Davies</surname>
            <given-names>Matthew</given-names>
          </name>
          <name>
            <surname>Ranganathan</surname>
            <given-names>Shoba</given-names>
          </name>
        </person-group>
        <source>Bioinformatics for Immunomics</source>
        <year>2010</year>
        <publisher-loc>New York, NY</publisher-loc>
        <publisher-name>Springer New York</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Smith</surname>
            <given-names>Kathrine J.</given-names>
          </name>
          <name>
            <surname>Reid</surname>
            <given-names>Scott W.</given-names>
          </name>
          <name>
            <surname>Stuart</surname>
            <given-names>David I.</given-names>
          </name>
          <name>
            <surname>McMichael</surname>
            <given-names>Andrew J.</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>E.Yvonne</given-names>
          </name>
          <name>
            <surname>Bell</surname>
            <given-names>John I.</given-names>
          </name>
        </person-group>
        <article-title>An Altered Position of the α2 Helix of MHC Class I Is Revealed by the Crystal Structure of HLA-B*3501</article-title>
        <source>Immunity</source>
        <year>1996</year>
        <volume>4</volume>
        <issue>3</issue>
        <fpage>203</fpage>
        <lpage>213</lpage>
        <pub-id pub-id-type="doi">10.1016/S1074-7613(00)80429-X</pub-id>
        <pub-id pub-id-type="pmid">8624811</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Edgar</surname>
            <given-names>R. C.</given-names>
          </name>
        </person-group>
        <article-title>MUSCLE: multiple sequence alignment with high accuracy and high throughput</article-title>
        <source>Nucleic Acids Research</source>
        <year>2004</year>
        <volume>32</volume>
        <issue>5</issue>
        <fpage>1792</fpage>
        <lpage>1797</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkh340</pub-id>
        <pub-id pub-id-type="pmid">15034147</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26</label>
      <mixed-citation publication-type="other">Srivastava N, Hinton G, Krizhevsky A, Sutskever I, Salakhutdinov R. Dropout: A Simple Way to Prevent Neural Networks from Overfitting. J Mach Learn Res. 2014; 15:1929–58.</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27</label>
      <mixed-citation publication-type="other">Kingma DP, Ba J. Adam: a method for stochastic optimization. 2017. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28</label>
      <mixed-citation publication-type="other">The UniProt Consortium. UniProt: The universal protein knowledgebase. Nucleic Acids Res. 2017; 45(D1):158–69. <pub-id pub-id-type="doi">10.1093/nar/gkw1099</pub-id>. 1611.06654.</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Keşmir</surname>
            <given-names>Can</given-names>
          </name>
          <name>
            <surname>Nussbaum</surname>
            <given-names>Alexander K.</given-names>
          </name>
          <name>
            <surname>Schild</surname>
            <given-names>Hansjörg</given-names>
          </name>
          <name>
            <surname>Detours</surname>
            <given-names>Vincent</given-names>
          </name>
          <name>
            <surname>Brunak</surname>
            <given-names>Søren</given-names>
          </name>
        </person-group>
        <article-title>Prediction of proteasome cleavage motifs by neural networks</article-title>
        <source>Protein Engineering, Design and Selection</source>
        <year>2002</year>
        <volume>15</volume>
        <issue>4</issue>
        <fpage>287</fpage>
        <lpage>296</lpage>
        <pub-id pub-id-type="doi">10.1093/protein/15.4.287</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Barnea</surname>
            <given-names>Eilon</given-names>
          </name>
          <name>
            <surname>Melamed Kadosh</surname>
            <given-names>Dganit</given-names>
          </name>
          <name>
            <surname>Haimovich</surname>
            <given-names>Yael</given-names>
          </name>
          <name>
            <surname>Satumtira</surname>
            <given-names>Nimman</given-names>
          </name>
          <name>
            <surname>Dorris</surname>
            <given-names>Martha L.</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>Mylinh T.</given-names>
          </name>
          <name>
            <surname>Hammer</surname>
            <given-names>Robert E.</given-names>
          </name>
          <name>
            <surname>Tran</surname>
            <given-names>Tri M.</given-names>
          </name>
          <name>
            <surname>Colbert</surname>
            <given-names>Robert A.</given-names>
          </name>
          <name>
            <surname>Taurog</surname>
            <given-names>Joel D.</given-names>
          </name>
          <name>
            <surname>Admon</surname>
            <given-names>Arie</given-names>
          </name>
        </person-group>
        <article-title>The Human Leukocyte Antigen (HLA)-B27 Peptidomein Vivo, in Spondyloarthritis-susceptible HLA-B27 Transgenic Rats and the Effect of Erap1 Deletion</article-title>
        <source>Molecular &amp; Cellular Proteomics</source>
        <year>2017</year>
        <volume>16</volume>
        <issue>4</issue>
        <fpage>642</fpage>
        <lpage>662</lpage>
        <pub-id pub-id-type="doi">10.1074/mcp.M116.066241</pub-id>
        <pub-id pub-id-type="pmid">28188227</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
