<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7355265</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa442</article-id>
    <article-id pub-id-type="publisher-id">btaa442</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Studies of Phenotypes and Clinical Applications</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>AITL: Adversarial Inductive Transfer Learning with input and output space adaptation for pharmacogenomics</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Sharifi-Noghabi</surname>
          <given-names>Hossein</given-names>
        </name>
        <xref ref-type="aff" rid="btaa442-aff1">b1</xref>
        <xref ref-type="aff" rid="btaa442-aff2">b2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Peng</surname>
          <given-names>Shuman</given-names>
        </name>
        <xref ref-type="aff" rid="btaa442-aff1">b1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zolotareva</surname>
          <given-names>Olga</given-names>
        </name>
        <xref ref-type="aff" rid="btaa442-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Collins</surname>
          <given-names>Colin C</given-names>
        </name>
        <xref ref-type="aff" rid="btaa442-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa442-aff4">b4</xref>
        <xref ref-type="corresp" rid="btaa442-cor1"/>
        <!--<email>ccollins@prostatecentre.com</email>-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ester</surname>
          <given-names>Martin</given-names>
        </name>
        <xref ref-type="aff" rid="btaa442-aff1">b1</xref>
        <xref ref-type="aff" rid="btaa442-aff2">b2</xref>
        <xref ref-type="corresp" rid="btaa442-cor1"/>
        <!--<email>ester@cs.sfu.ca</email>-->
      </contrib>
    </contrib-group>
    <aff id="btaa442-aff1"><label>b1</label><institution>School of Computing Science, Simon Fraser University</institution>, Burnaby, BC, <country country="CA">Canada</country></aff>
    <aff id="btaa442-aff2"><label>b2</label><institution>Vancouver Prostate Centre</institution>, Vancouver, BC, <country country="CA">Canada</country></aff>
    <aff id="btaa442-aff3"><label>b3</label><institution>International Research Training Group Computational Methods for the Analysis of the Diversity and Dynamics of Genomes and Genome Informatics, Faculty of Technology and Center for Biotechnology, Bielefeld University</institution>, Bielefeld, <country country="DE">Germany</country></aff>
    <aff id="btaa442-aff4"><label>b4</label>Department of Urologic Sciences, <institution>University of British Columbia</institution>, Vancouver, BC, <country country="CA">Canada</country></aff>
    <author-notes>
      <corresp id="btaa442-cor1">To whom correspondence should be addressed. E-mail: <email>ccollins@prostatecentre.com</email> or <email>ester@cs.sfu.ca</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-07-13">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>Suppl 1</issue>
    <issue-title>ISMB 2020 Proceedings</issue-title>
    <fpage>i380</fpage>
    <lpage>i388</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa442.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>The goal of pharmacogenomics is to predict drug response in patients using their single- or multi-omics data. A major challenge is that clinical data (i.e. patients) with drug response outcome is very limited, creating a need for transfer learning to bridge the gap between large pre-clinical pharmacogenomics datasets (e.g. cancer cell lines), as a source domain, and clinical datasets as a target domain. Two major discrepancies exist between pre-clinical and clinical datasets: (i) in the input space, the gene expression data due to difference in the basic biology, and (ii) in the output space, the different measures of the drug response. Therefore, training a computational model on cell lines and testing it on patients violates the i.i.d assumption that train and test data are from the same distribution.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We propose Adversarial Inductive Transfer Learning (AITL), a deep neural network method for addressing discrepancies in input and output space between the pre-clinical and clinical datasets. AITL takes gene expression of patients and cell lines as the input, employs adversarial domain adaptation and multi-task learning to address these discrepancies, and predicts the drug response as the output. To the best of our knowledge, AITL is the first adversarial inductive transfer learning method to address both input and output discrepancies. Experimental results indicate that AITL outperforms state-of-the-art pharmacogenomics and transfer learning baselines and may guide precision oncology more accurately.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p><ext-link ext-link-type="uri" xlink:href="https://github.com/hosseinshn/AITL">https://github.com/hosseinshn/AITL</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Canada Foundation for Innovation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000196</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>33440</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>The Canadian Institutes of Health Research</institution>
          </institution-wrap>
        </funding-source>
        <award-id>PJT-153073</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Terry Fox Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100002655</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>201012TFF</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>The Terry Fox New Frontiers Program Project</institution>
          </institution-wrap>
        </funding-source>
        <award-id>1062</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>DFG Research Training Group GRK</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>1906</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Science and Engineering Research Council of Canada</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>The goal of pharmacogenomics (<xref rid="btaa442-B13" ref-type="bibr">Evans and Relling, 1999</xref>) is to predict response to a drug given some single- or multi-omics data. Since clinical datasets in pharmacogenomics (patients) are small and hard to obtain, it is not feasible to train a computational model only on patients. As a result, many studies have focused on large pre-clinical pharmacogenomics datasets such as cancer cell lines as a proxy to patients (<xref rid="btaa442-B4" ref-type="bibr">Barretina <italic>et al.</italic>, 2012</xref>; <xref rid="btaa442-B24" ref-type="bibr">Iorio <italic>et al.</italic>, 2016</xref>). A majority of the current computational methods are trained on cell line datasets and then tested on other cell line or patient datasets (<xref rid="btaa442-B10" ref-type="bibr">Ding <italic>et al.</italic>, 2018</xref>; <xref rid="btaa442-B17" ref-type="bibr">Geeleher <italic>et al.</italic>, 2014</xref>, <xref rid="btaa442-B18" ref-type="bibr">2017</xref>; <xref rid="btaa442-B21" ref-type="bibr">Güvenç <italic>et al.</italic>, 2019</xref>; <xref rid="btaa442-B28" ref-type="bibr">Mourragui <italic>et al.</italic>, 2019</xref>; <xref rid="btaa442-B33" ref-type="bibr">Rampášek <italic>et al.</italic>, 2019</xref>; <xref rid="btaa442-B34" ref-type="bibr">Sakellaropoulos <italic>et al.</italic>, 2019</xref>; <xref rid="btaa442-B38" ref-type="bibr">Sharifi-Noghabi <italic>et al.</italic>, 2019b</xref>). However, cell lines and patients data, even with the same set of genes, do not have identical distributions due to the lack of an immune system and the tumor microenvironment in cell lines, which means a model cannot be trained on cell lines and then tested on patients (<xref rid="btaa442-B28" ref-type="bibr">Mourragui <italic>et al.</italic>, 2019</xref>). Moreover, in cell lines, the response is often measured by the drug concentration that reduces viability by 50% (IC50), whereas in patients, it is often based on changes in the size of the tumor and measured by metrics such as response evaluation criteria in solid tumors (RECIST; <xref rid="btaa442-B35" ref-type="bibr">Schwartz <italic>et al.</italic>, 2016</xref>). This means that drug response prediction is a regression problem in cell lines but a classification problem in patients. As a result, discrepancies exist in both the input and output spaces in pharmacogenomics datasets. Therefore, a need exists for a novel method to address these discrepancies to utilize cell line and patient data together to build a more accurate model eventually for patients.</p>
    <p>Transfer learning (Pan and Yang, 2009) attempts to solve this challenge by leveraging the knowledge in a <italic>source</italic> domain, a large data-rich dataset, to improve the generalization performance on a small <italic>target</italic> domain. Training a model on the source domain and testing it on the target domain violates the i.i.d assumption that the train and test data are from the same distribution. The discrepancy in the input space decreases the prediction accuracy on the test data, which leads to poor generalization (<xref rid="btaa442-B47" ref-type="bibr">Zhang <italic>et al.</italic>, 2019</xref>). Transductive transfer learning (e.g. domain adaptation) and inductive transfer learning both use a labeled source domain to improve the generalization on a target domain. Transductive transfer learning assumes an unlabeled target domain, whereas inductive transfer learning assumes a labeled target domain where the label spaces of the source and target domain are different (Pan and Yang, 2009). Many methods have been proposed to minimize the discrepancy between the source and the target domains using different distribution metrics such as maximum mean discrepancy (<xref rid="btaa442-B20" ref-type="bibr">Gretton <italic>et al.</italic>, 2012</xref>) In the context of drug response prediction, <xref rid="btaa442-B28" ref-type="bibr">Mourragui <italic>et al.</italic> (2019)</xref> proposed PRECISE, a subspace-centric method based on principal component analysis to minimize the discrepancy in the input space between cell lines and patients. Recently, adversarial domain adaptation has shown great performance in addressing the discrepancy in the input space for different applications, and its performance is comparable to the metric-based and subspace-centric methods in computer vision (<xref rid="btaa442-B9" ref-type="bibr">Chen <italic>et al.</italic>, 2017</xref>; <xref rid="btaa442-B14" ref-type="bibr">Ganin and Lempitsky, 2015</xref>; <xref rid="btaa442-B23" ref-type="bibr">Hosseini-Asl <italic>et al.</italic>, 2018</xref>; <xref rid="btaa442-B26" ref-type="bibr">Long <italic>et al.</italic>, 2018</xref>; <xref rid="btaa442-B32" ref-type="bibr">Pinheiro, 2018</xref>; <xref rid="btaa442-B43" ref-type="bibr">Tsai <italic>et al.</italic>, 2018</xref>; <xref rid="btaa442-B44" ref-type="bibr">Tzeng <italic>et al.</italic>, 2017</xref>; <xref rid="btaa442-B48" ref-type="bibr">Zou <italic>et al.</italic>, 2018</xref>). However, adversarial adaptation that addresses the discrepancies in both the input and output spaces have not yet been explored neither for pharmacogenomics nor for other applications.</p>
    <p>In this article, we propose Adversarial Inductive Transfer Learning (AITL), the first adversarial method of inductive transfer learning. Different from existing methods for inductive transfer learning as well as methods for adversarial transfer learning, AITL adapts not only the input space but also the output space. In pharmacogenomics, the source domain is the gene expression data obtained from the cell lines and the target domain is the gene expression data obtained from patients. Both domains have the same set of genes (i.e. raw feature representation). Discrepancies exist between the gene expression data in the input space, and the measure of the drug response in the output space. AITL learns features for the source and target samples and uses these features as input for a multi-task subnetwork to predict drug response for both the source and the target samples. The output space discrepancy is addressed by the multi-task subnetwork by assigning binary labels, called cross-domain labels, to the source samples which only have continuous labels. The multi-task subnetwork also alleviates the problem of small sample size in the target domain by joint training with the source domain. To address the discrepancy in the input space, AITL performs adversarial domain adaptation. The goal is that features learned for the source samples should be domain-invariant and similar enough to the features learned for the target samples to fool a global discriminator that receives samples from both domains. Moreover, with the cross-domain binary labels available for the source samples, AITL further regularizes the learned features by class-wise discriminators. A class-wise discriminator receives source and target samples from the same class label and should not be able to predict the domain accurately.</p>
    <p>We evaluated the performance of AITL and state-of-the-art pharmacogenomics and transfer learning methods on pharmacogenomics datasets in terms of the area under the receiver operating characteristic curve (AUROC) and the area under the precision-recall curve (AUPR). In our experiments, AITL achieved a substantial improvement compared with the baseline methods, demonstrating the potential of transfer learning for drug response prediction, a crucial task of precision oncology. Finally, we showed that the responses predicted by AITL for The Cancer Genome Atlas (TCGA) patients (without the drug response recorded) for breast, prostate, lung, kidney and bladder cancers had statistically significant associations with the level of expression of some of the annotated target genes for the studied drugs. This shows that AITL captures biological aspects of the response.</p>
  </sec>
  <sec>
    <title>2 Background and related work</title>
    <sec>
      <title>2.1 Transfer learning</title>
      <p>Following the notation of (Pan and Yang, 2009), a domain like <italic>DM</italic> is defined by a raw input feature space (this is different from learned features by the network) <bold>X</bold> and a probability distribution <italic>p</italic>(<italic>X</italic>), where <inline-formula id="IE1"><mml:math id="IM1"><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula><inline-formula id="IE2"><mml:math id="IM2"><mml:mrow><mml:mo>∈</mml:mo><mml:mi mathvariant="bold">X</mml:mi></mml:mrow></mml:math></inline-formula> and <italic>x<sub>i</sub></italic> is the <italic>i</italic>th raw feature vector of <italic>X</italic>. A task <inline-formula id="IE3"><mml:math id="IM3"><mml:mi mathvariant="normal">T</mml:mi></mml:math></inline-formula> is associated with <inline-formula id="IE4"><mml:math id="IM4"><mml:mrow><mml:mi>D</mml:mi><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE5"><mml:math id="IM5"><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi mathvariant="bold">Y</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> is defined by a label space <bold>Y</bold> and a predictive function <inline-formula id="IE6"><mml:math id="IM6"><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> which is learned from training data of the form (<italic>X</italic>, <italic>Y</italic>), where <inline-formula id="IE7"><mml:math id="IM7"><mml:mrow><mml:mi>X</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="bold">X</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE8"><mml:math id="IM8"><mml:mrow><mml:mi>Y</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow></mml:math></inline-formula>. A source task <inline-formula id="IE9"><mml:math id="IM9"><mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> that is associated with a labeled source domain <inline-formula id="IE10"><mml:math id="IM10"><mml:mrow><mml:mi>D</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> is defined as <inline-formula id="IE11"><mml:math id="IM11"><mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi mathvariant="bold">Y</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. <inline-formula id="IE12"><mml:math id="IM12"><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is learned from training data <inline-formula id="IE13"><mml:math id="IM13"><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Similarly, a target task <inline-formula id="IE14"><mml:math id="IM14"><mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> that is associated with a labeled target domain <inline-formula id="IE15"><mml:math id="IM15"><mml:mrow><mml:mi>D</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> is defined as <inline-formula id="IE16"><mml:math id="IM16"><mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi mathvariant="bold">Y</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. <inline-formula id="IE17"><mml:math id="IM17"><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is learned from training data <inline-formula id="IE18"><mml:math id="IM18"><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Since <inline-formula id="IE19"><mml:math id="IM19"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>≪</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, it is challenging to train a model only on the target domain. Transfer learning addresses this challenge with the goal to improve the generalization on a target task <inline-formula id="IE20"><mml:math id="IM20"><mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> using the knowledge in <italic>DM<sub>S</sub></italic> and <italic>DM<sub>T</sub></italic>, as well as their corresponding tasks <inline-formula id="IE21"><mml:math id="IM21"><mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE22"><mml:math id="IM22"><mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Transfer learning addresses this challenge with the goal to improve the generalization on a target task <inline-formula id="IE23"><mml:math id="IM23"><mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> using the knowledge in <italic>DM<sub>S</sub></italic> and <italic>DM<sub>T</sub></italic>, as well as their corresponding tasks <inline-formula id="IE24"><mml:math id="IM24"><mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE25"><mml:math id="IM25"><mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Transfer learning can be categorized into three categories: (i) unsupervised transfer learning, (ii) transductive transfer learning and (iii) inductive transfer learning. In unsupervised transfer learning, there is no label in the source and target domains. In transductive transfer learning, the source domain is labeled, whereas the target domain is unlabeled. In this category, domains can be either the same or different (domain adaptation), but the source and target tasks are the same. In inductive transfer learning, the target domain is labeled and the source domain can be either labeled or unlabeled. In this category, the domains can be the same or different, but the tasks are always different (Pan and Yang, 2009).</p>
    </sec>
    <sec>
      <title>2.2 Inductive transfer learning</title>
      <p>There are three approaches to inductive transfer learning: (i) deep metric learning, (ii) learning and (iii) weight transfer (<xref rid="btaa442-B36" ref-type="bibr">Scott <italic>et al.</italic>, 2018</xref>). Deep metric learning methods are independent of the number of samples in each class of the target domain, denoted as <italic>k</italic>. Few-shot learning methods focus on small <italic>k</italic> (<inline-formula id="IE26"><mml:math id="IM26"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula>). Finally, weight transfer methods require a large <italic>k</italic> (<inline-formula id="IE27"><mml:math id="IM27"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≥</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> or <inline-formula id="IE28"><mml:math id="IM28"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≥</mml:mo><mml:mn>1000</mml:mn></mml:mrow></mml:math></inline-formula>; <xref rid="btaa442-B36" ref-type="bibr">Scott <italic>et al.</italic>, 2018</xref>).</p>
      <p>In drug response prediction, a limited number of samples are for each class is available in the target domain; therefore, few-shot learning is more suitable for such a problem. Few-shot learning involves training a classifier to recognize new classes, provided only a small number of examples from each of these new classes in the training data (<xref rid="btaa442-B41" ref-type="bibr">Snell <italic>et al.</italic>, 2017</xref>). Various methods have been proposed for few-shot learning (<xref rid="btaa442-B8" ref-type="bibr">Chen <italic>et al.</italic>, 2019</xref>; <xref rid="btaa442-B36" ref-type="bibr">Scott <italic>et al.</italic>, 2018</xref>; <xref rid="btaa442-B41" ref-type="bibr">Snell <italic>et al.</italic>, 2017</xref>). For example, ProtoNet (<xref rid="btaa442-B41" ref-type="bibr">Snell <italic>et al.</italic>, 2017</xref>) uses the source domain to learn how to extract features from the input and applies the feature extractor in the target domain. The mean feature of each class, obtained from the source domain, is used as the class prototype to assign labels to the target samples based on the Euclidean distance between a target sample’s feature and class prototypes.</p>
    </sec>
    <sec>
      <title>2.3 Adversarial transfer learning</title>
      <p>Recent advances in adversarial learning leverage deep neural networks to learn transferable representation that disentangles domain- and class-invariant features from different domains and matches them properly (<xref rid="btaa442-B26" ref-type="bibr">Long <italic>et al.</italic>, 2018</xref>; <xref rid="btaa442-B31" ref-type="bibr">Peng <italic>et al.</italic>, 2019</xref>; <xref rid="btaa442-B47" ref-type="bibr">Zhang <italic>et al.</italic>, 2019</xref>). Generative adversarial networks (<xref rid="btaa442-B19" ref-type="bibr">Goodfellow <italic>et al.</italic>, 2014</xref>) attempt to learn the distribution of the input <italic>data</italic> via a minimax framework where two networks are competing: a discriminator <italic>D</italic> and a generator <italic>G</italic>. The generator tries to create fake samples from a randomly sampled latent variable <italic>z</italic> that fool the discriminator, whereas the discriminator tries to catch these fake samples and discriminate them from the real ones. Therefore, the generator wants to minimize its error, whereas the discriminator wants to maximize its accuracy:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mrow><mml:munder><mml:mrow><mml:mtext>Min</mml:mtext></mml:mrow><mml:mi>G</mml:mi></mml:munder><mml:munder><mml:mrow><mml:mtext>Max</mml:mtext></mml:mrow><mml:mi>D</mml:mi></mml:munder><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="italic">data</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mo>⁡</mml:mo></mml:mrow></mml:mrow><mml:mrow/></mml:munder><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="italic">noise</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mo>⁡</mml:mo></mml:mrow></mml:mrow><mml:mrow/></mml:munder><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p>A majority of literature on adversarial transfer learning are for transductive transfer learning, often referred to as domain adaptation, where the source domain is labeled while the target domain is unlabeled. Various methods have been proposed for adversarial transductive transfer learning in different applications such as image segmentation (<xref rid="btaa442-B9" ref-type="bibr">Chen <italic>et al.</italic>, 2017</xref>), image classification (<xref rid="btaa442-B44" ref-type="bibr">Tzeng <italic>et al.</italic>, 2017</xref>), speech recognition (<xref rid="btaa442-B23" ref-type="bibr">Hosseini-Asl <italic>et al.</italic>, 2018</xref>) and adaptation under label-shift (<xref rid="btaa442-B3" ref-type="bibr">Azizzadenesheli <italic>et al.</italic>, 2019</xref>). The idea of these methods is that features extracted from source and target samples should be similar enough to fool a global- (<xref rid="btaa442-B44" ref-type="bibr">Tzeng <italic>et al.</italic>, 2017</xref>) and/or class-wise discriminators (<xref rid="btaa442-B9" ref-type="bibr">Chen <italic>et al.</italic>, 2017</xref>).</p>
    </sec>
  </sec>
  <sec>
    <title>3 Materials and methods</title>
    <sec>
      <title>3.1 Problem definition</title>
      <p>Given a labeled source domain <italic>DM<sub>S</sub></italic> with a learning task <inline-formula id="IE29"><mml:math id="IM29"><mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and a labeled target domain <italic>DM<sub>T</sub></italic> with a learning task <inline-formula id="IE30"><mml:math id="IM30"><mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE31"><mml:math id="IM31"><mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula id="IE32"><mml:math id="IM32"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>≠</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE33"><mml:math id="IM33"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="bold">X</mml:mi></mml:mrow></mml:math></inline-formula>, we assume that the source and the target domains are not the same due to different probability distributions. The goal of AITL is to utilize the source and target domains and their tasks in order to improve the learning of <inline-formula id="IE34"><mml:math id="IM34"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> on <italic>DM<sub>T</sub></italic>.</p>
      <p>In the area of pharmacogenomics, the source domain is the gene expression data obtained from the cell lines, and the source task is to predict the drug response in the form of log (IC50) values. The target domain consists of gene expression data obtained from patients, and the target task is to predict drug response in a different form—often change in the size of tumor after receiving the drug. In this setting, <inline-formula id="IE35"><mml:math id="IM35"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>≠</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> because cell lines are different from patients even with the same set of genes. Additionally, <inline-formula id="IE36"><mml:math id="IM36"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> because for the target task <inline-formula id="IE37"><mml:math id="IM37"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, drug response in patients is a binary outcome, but for the source task <inline-formula id="IE38"><mml:math id="IM38"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>, drug response in cell lines is a continuous outcome. As a result, AITL needs to address these discrepancies in both the input and output spaces.</p>
    </sec>
    <sec>
      <title>3.2 Adversarial Inductive Transfer Learning</title>
      <p>Our proposed AITL method takes input data from the source and target domains, and achieves the following three objectives: first, it makes predictions for the target domain using both of the input domains and their corresponding tasks, second, it addresses the discrepancy in the output space between the source and target tasks and third, it addresses the discrepancy in the input space. AITL is a neural network consisting of four components:
</p>
      <list list-type="bullet">
        <list-item>
          <p>The feature extractor receives the input data from the source and target domains and extracts salient features, which are then sent to the multi-task subnetwork component.</p>
        </list-item>
        <list-item>
          <p>The multi-task subnetwork takes the extracted features of source and target samples and maps them to their corresponding labels and makes predictions for them. This component has a shared layer and two task-specific towers for regression (source task) and classification (target task). Therefore, by training the multi-task subnetwork on the source and target samples, it addresses the small sample size challenge in the target domain. In addition, it also addresses the discrepancy in the output space by assigning cross-domain labels (binary labels in this case) to the source samples (for which only continuous labels are available) using its classification tower.</p>
        </list-item>
        <list-item>
          <p>The global discriminator receives extracted features of source and target samples and predicts if an input sample is from the source or the target domain. To address the discrepancy in the input space, these features should be domain-invariant so that the global discriminator cannot predict their domain labels accurately. This goal is achieved by adversarial learning.</p>
        </list-item>
        <list-item>
          <p>The class-wise discriminators further reduce the discrepancy in the input space by adversarial learning at the level of the different classes, i.e. extracted features of source and target samples from the same class go to the discriminator for that class and this discriminator should not be able to predict if an input sample from a given class is from the source or the target domain.</p>
        </list-item>
      </list>
      <p>The AITL cost function consists of a classification loss, a regression loss, and global- and class-wise discriminator adversarial losses and is optimized end-to-end. An overview of the proposed method is presented in <xref ref-type="fig" rid="btaa442-F1">Figure 1</xref>.
</p>
      <fig id="btaa442-F1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>Schematic overview of AITL: first, the feature extractor receives source and target samples and maps them to a feature space in lower dimensions. Then, the multi-task subnetwork uses these features to make predictions for the source and target samples and also assigns cross-domain labels to the source samples. The multi-task subnetwork addresses the discrepancy in the output space. Finally, to address the input space discrepancy, global- and class-wise discriminators receive the extracted features and regularize the feature extractor to learn domain-invariant features. The feature extractor has one fully connected layer. The multi-task subnetwork has one fully connected shared layer followed by two fully connected layers for the regression task and one fully connected layer for the classification task. All the discriminators are single-layered fully connected subnetworks</p>
        </caption>
        <graphic xlink:href="btaa442f1"/>
      </fig>
      <sec>
        <label>3.2.1</label>
        <title>Feature extractor</title>
        <p>To learn salient features in lower dimensions for the input data, we design a feature extractor component. The feature extractor receives both the source and target samples as input and maps them to a feature space, denoted as <italic>Z</italic>. We denote the feature extractor as <inline-formula id="IE39"><mml:math id="IM39"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>Z</italic> denotes the extracted features for input <italic>X</italic> which is from either the source (<italic>S</italic>) or the target (<italic>T</italic>) domain. In pharmacogenomics, the feature extractor learns features for the cell line and patient data.</p>
      </sec>
      <sec>
        <label>3.2.2</label>
        <title>Multi-task subnetwork</title>
        <p>After extracting features of the input samples, we want to use these learned features to (i) make predictions for target samples, and (ii) address the discrepancy between the source and the target domains in the output space. To achieve these goals, a multi-task subnetwork with a shared layer <inline-formula id="IE40"><mml:math id="IM40"><mml:mrow><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and two task-specific towers, denoted as <inline-formula id="IE41"><mml:math id="IM41"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE42"><mml:math id="IM42"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, is designed, where <italic>M<sub>S</sub></italic> is for regression (the source task) and <italic>M<sub>T</sub></italic> is for classification (the target task):
<disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>The performance of the multi-task subnetwork component is evaluated based on a binary-cross entropy loss for the classification task on the target samples and a mean squared loss for the regression task on the source samples:
<disp-formula id="E4"><label>(4)</label><mml:math id="M4"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">BCE</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="E5"><label>(5)</label><mml:math id="M5"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">MSE</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mrow/></mml:munder></mml:mrow></mml:math></disp-formula>where <italic>Y<sub>S</sub></italic> and <italic>Y<sub>T</sub></italic> are the true labels of the source and the target samples, respectively, and <italic>L<sub>BCE</sub></italic> and <italic>L<sub>MSE</sub></italic> are the corresponding losses for the target and the source domains, respectively. The multi-task subnetwork outputs (i) the predicted continuous labels for the source samples, (ii) the predicted binary labels for the target samples and (iii) the assigned cross-domain binary labels for the source samples. The assigned cross-domain binary labels are obtained via the classification tower in the multi-task subnetwork which assigns binary labels (responder or non-responder) to the source samples because such labels do not exist for the source samples. Therefore, the multi-task subnetwork adapts the output space of the source and the target domains by assigning cross-domain labels to the source domain. In pharmacogenomics, the multi-task subnetwork predicts log (IC50) values for the cell lines and the binary response outcome for the patients. Moreover, it also assigns binary response labels to the cell lines which are similar to those of the patients.</p>
      </sec>
      <sec>
        <label>3.2.3</label>
        <title>Global discriminator</title>
        <p>The goal of this component is to address the discrepancy in the input space by adversarial learning of domain-invariant features. To achieve this goal, a discriminator receives source and target extracted features from the feature extractor and classifies them into their corresponding domain. The feature extractor should learn domain-invariant features to fool the global discriminator. In pharmacogenomics, the global discriminator should not be able to recognize if the extracted features of a sample are from a cell line or a patient. This discriminator is denoted as <inline-formula id="IE43"><mml:math id="IM43"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. The adversarial loss for <inline-formula id="IE44"><mml:math id="IM44"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is as follows:
<disp-formula id="E6"><label>(6)</label><mml:math id="M6"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">adv</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mo>⁡</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      </sec>
      <sec>
        <label>3.2.4</label>
        <title>Class-wise discriminators</title>
        <p>With cross-domain binary labels available for the source domain, AITL further reduces the discrepancy between the input domains via class-wise discriminators. The goal is to learn domain-invariant features with respect to specific class labels such that they fool corresponding class-wise discriminators. Therefore, extracted features of the target samples in class <italic>i</italic>, and those of the source domain which the multi-task subnetwork assigned to class <italic>i</italic>, will go to the discriminator for class <italic>i</italic>. We denote such a class-wise discriminator as <italic>DC<sub>i</sub></italic>. The adversarial loss for <italic>DC<sub>i</sub></italic> is as follows:
<disp-formula id="E7"><label>(7)</label><mml:math id="M7"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">advD</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mo>⁡</mml:mo><mml:mi>D</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
        <p>In pharmacogenomics, the class-wise discriminator for the responder samples should not be able to recognize if the extracted features of a responder sample are from a cell line or a patient (similarly for a non-responder sample).</p>
      </sec>
      <sec>
        <label>3.2.5</label>
        <title>Cost function</title>
        <p>To optimize the entire network in an end-to-end fashion, we design the cost function as follows:
<disp-formula id="E8"><label>(8)</label><mml:math id="M8"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">BCE</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">MSE</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mo>λ</mml:mo><mml:mi>G</mml:mi></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">adv</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mo>λ</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">advD</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>where, <italic>λ<sub>G</sub></italic> and <italic>λ<sub>DC</sub></italic> are adversarial regularization coefficients for the global- and class-wise discriminators, respectively.</p>
      </sec>
      <sec>
        <label>3.2.6</label>
        <title>AITL architecture</title>
        <p>The feature extractor is a one-layer fully-connected subnetwork with batch normalization using the ReLU activation function. The multi-task subnetwork has a shared fully connected layer with batch normalization and the ReLU activation function. The regression tower has two layers (one hidden layer and one output layer) with the ReLU activation function in the first layer and the linear activation function in the second one. The classification tower has one fully-connected layer with the Sigmoid activation function that maps the features to the binary outputs directly. Finally, the global- and class-wise discriminators are one-layer subnetworks with the Sigmoid activation function.</p>
      </sec>
    </sec>
    <sec>
      <title>3.3 Drug response prediction for TCGA patients</title>
      <p>To study AITL’s performance, similar to (<xref rid="btaa442-B18" ref-type="bibr">Geeleher <italic>et al.</italic>, 2017</xref>; <xref rid="btaa442-B38" ref-type="bibr">Sharifi-Noghabi <italic>et al.</italic>, 2019b</xref>), we employ the model trained on Docetaxel, Paclitaxel or Bortezomib to predict the response for patients in several TCGA cohorts for which no drug response was recorded. For each drug, we extract the list of annotated target genes from the PharmacoDB resource (<xref rid="btaa442-B40" ref-type="bibr">Smirnov <italic>et al.</italic>, 2018</xref>). We excluded Cisplatin because there was only one annotated target gene for it in PharmacoDB. To study associations between the level of expression of the extracted genes and the responses predicted by ATIL for each drug in each TCGA cohort, we fit multivariate linear regression models to the gene expression of those genes and the responses to that drug predicted by AITL. We obtain <italic>P</italic>-values for each gene and correct them for multiple hypotheses testing, using the Bonferroni correction (<inline-formula id="IE45"><mml:math id="IM45"><mml:mrow><mml:mo>α</mml:mo><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>). The list of annotated target genes for each drug is available in the <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref>, Section S1.</p>
    </sec>
    <sec>
      <title>3.4 Datasets</title>
      <p>In our experiments, we used the following datasets (see <xref rid="btaa442-T1" ref-type="table">Table 1</xref> for more detail):
</p>
      <table-wrap id="btaa442-T1" orientation="portrait" position="float">
        <label>Table 1.</label>
        <caption>
          <p>Characteristics of the datasets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Dataset</th>
              <th rowspan="1" colspan="1">Resource</th>
              <th rowspan="1" colspan="1">Drug</th>
              <th rowspan="1" colspan="1">Type</th>
              <th rowspan="1" colspan="1">Domain</th>
              <th rowspan="1" colspan="1">Sample size</th>
              <th rowspan="1" colspan="1">Number of genes<xref ref-type="table-fn" rid="tblfn1"><sup>a</sup></xref></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">GSE55145 (<xref rid="btaa442-B2" ref-type="bibr">Amin <italic>et al.</italic>, 2014</xref>)</td>
              <td rowspan="1" colspan="1">Clinical trial</td>
              <td rowspan="1" colspan="1">Bortezomib</td>
              <td rowspan="1" colspan="1">targeted</td>
              <td rowspan="1" colspan="1">Target</td>
              <td rowspan="1" colspan="1">67</td>
              <td rowspan="1" colspan="1">11 609</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GSE9782-GPL96 (<xref rid="btaa442-B29" ref-type="bibr">Mulligan <italic>et al.</italic>, 2007</xref>)</td>
              <td rowspan="1" colspan="1">Clinical trial</td>
              <td rowspan="1" colspan="1">Bortezomib</td>
              <td rowspan="1" colspan="1">targeted</td>
              <td rowspan="1" colspan="1">Target</td>
              <td rowspan="1" colspan="1">169</td>
              <td rowspan="1" colspan="1">11 609</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GDSC (<xref rid="btaa442-B24" ref-type="bibr">Iorio <italic>et al.</italic>, 2016</xref>)</td>
              <td rowspan="1" colspan="1">Cell line</td>
              <td rowspan="1" colspan="1">Bortezomib</td>
              <td rowspan="1" colspan="1">targeted</td>
              <td rowspan="1" colspan="1">Source</td>
              <td rowspan="1" colspan="1">391</td>
              <td rowspan="1" colspan="1">11 609</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GSE18864 (<xref rid="btaa442-B39" ref-type="bibr">Silver <italic>et al.</italic>, 2010</xref>)</td>
              <td rowspan="1" colspan="1">Clinical trial</td>
              <td rowspan="1" colspan="1">Cisplatin</td>
              <td rowspan="1" colspan="1">Chemotherapy</td>
              <td rowspan="1" colspan="1">Target</td>
              <td rowspan="1" colspan="1">24</td>
              <td rowspan="1" colspan="1">11 768</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GSE23554 (<xref rid="btaa442-B27" ref-type="bibr">Marchion <italic>et al.</italic>, 2011</xref>)</td>
              <td rowspan="1" colspan="1">Clinical trial</td>
              <td rowspan="1" colspan="1">Cisplatin</td>
              <td rowspan="1" colspan="1">Chemotherapy</td>
              <td rowspan="1" colspan="1">Target</td>
              <td rowspan="1" colspan="1">28</td>
              <td rowspan="1" colspan="1">11 768</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">TCGA (<xref rid="btaa442-B11" ref-type="bibr">Ding <italic>et al.</italic>, 2016</xref>)</td>
              <td rowspan="1" colspan="1">Patient</td>
              <td rowspan="1" colspan="1">Cisplatin</td>
              <td rowspan="1" colspan="1">Chemotherapy</td>
              <td rowspan="1" colspan="1">Target</td>
              <td rowspan="1" colspan="1">66</td>
              <td rowspan="1" colspan="1">11 768</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GDSC (<xref rid="btaa442-B24" ref-type="bibr">Iorio <italic>et al.</italic>, 2016</xref>)</td>
              <td rowspan="1" colspan="1">Cell line</td>
              <td rowspan="1" colspan="1">Cisplatin</td>
              <td rowspan="1" colspan="1">Chemotherapy</td>
              <td rowspan="1" colspan="1">Source</td>
              <td rowspan="1" colspan="1">829</td>
              <td rowspan="1" colspan="1">11 768</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GSE25065 (<xref rid="btaa442-B22" ref-type="bibr">Hatzis <italic>et al.</italic>, 2011</xref>)</td>
              <td rowspan="1" colspan="1">Clinical trial</td>
              <td rowspan="1" colspan="1">Docetaxel</td>
              <td rowspan="1" colspan="1">Chemotherapy</td>
              <td rowspan="1" colspan="1">Target</td>
              <td rowspan="1" colspan="1">49</td>
              <td rowspan="1" colspan="1">8119</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GSE28796 (<xref rid="btaa442-B25" ref-type="bibr">Lehmann <italic>et al.</italic>, 2011</xref>)</td>
              <td rowspan="1" colspan="1">Clinical trial</td>
              <td rowspan="1" colspan="1">Docetaxel</td>
              <td rowspan="1" colspan="1">Chemotherapy</td>
              <td rowspan="1" colspan="1">Target</td>
              <td rowspan="1" colspan="1">12</td>
              <td rowspan="1" colspan="1">8119</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GSE6434 (<xref rid="btaa442-B6" ref-type="bibr">Chang <italic>et al.</italic>, 2005</xref>)</td>
              <td rowspan="1" colspan="1">Clinical trial</td>
              <td rowspan="1" colspan="1">Docetaxel</td>
              <td rowspan="1" colspan="1">Chemotherapy</td>
              <td rowspan="1" colspan="1">Target</td>
              <td rowspan="1" colspan="1">24</td>
              <td rowspan="1" colspan="1">8119</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">TCGA (<xref rid="btaa442-B11" ref-type="bibr">Ding <italic>et al.</italic>, 2016</xref>)</td>
              <td rowspan="1" colspan="1">Patient</td>
              <td rowspan="1" colspan="1">Docetaxel</td>
              <td rowspan="1" colspan="1">Chemotherapy</td>
              <td rowspan="1" colspan="1">Target</td>
              <td rowspan="1" colspan="1">16</td>
              <td rowspan="1" colspan="1">8119</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GDSC (<xref rid="btaa442-B24" ref-type="bibr">Iorio <italic>et al.</italic>, 2016</xref>)</td>
              <td rowspan="1" colspan="1">Cell line</td>
              <td rowspan="1" colspan="1">Docetaxel</td>
              <td rowspan="1" colspan="1">Chemotherapy</td>
              <td rowspan="1" colspan="1">Source</td>
              <td rowspan="1" colspan="1">829</td>
              <td rowspan="1" colspan="1">8119</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GSE15622 (<xref rid="btaa442-B1" ref-type="bibr">Ahmed <italic>et al.</italic>, 2007</xref>)</td>
              <td rowspan="1" colspan="1">Clinical trial</td>
              <td rowspan="1" colspan="1">Paclitaxel</td>
              <td rowspan="1" colspan="1">Chemotherapy</td>
              <td rowspan="1" colspan="1">Target</td>
              <td rowspan="1" colspan="1">20</td>
              <td rowspan="1" colspan="1">11 731</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GSE22513 (<xref rid="btaa442-B5" ref-type="bibr">Bauer <italic>et al.</italic>, 2010</xref>)</td>
              <td rowspan="1" colspan="1">Clinical trial</td>
              <td rowspan="1" colspan="1">Paclitaxel</td>
              <td rowspan="1" colspan="1">Chemotherapy</td>
              <td rowspan="1" colspan="1">Target</td>
              <td rowspan="1" colspan="1">14</td>
              <td rowspan="1" colspan="1">11 731</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GSE25065 (<xref rid="btaa442-B22" ref-type="bibr">Hatzis <italic>et al.</italic>, 2011</xref>)</td>
              <td rowspan="1" colspan="1">Clinical trial</td>
              <td rowspan="1" colspan="1">Paclitaxel</td>
              <td rowspan="1" colspan="1">Chemotherapy</td>
              <td rowspan="1" colspan="1">Target</td>
              <td rowspan="1" colspan="1">84</td>
              <td rowspan="1" colspan="1">11 731</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PDX (<xref rid="btaa442-B16" ref-type="bibr">Gao <italic>et al.</italic>, 2015</xref>)</td>
              <td rowspan="1" colspan="1">Animal (mouse)</td>
              <td rowspan="1" colspan="1">Paclitaxel</td>
              <td rowspan="1" colspan="1">Chemotherapy</td>
              <td rowspan="1" colspan="1">Target</td>
              <td rowspan="1" colspan="1">43</td>
              <td rowspan="1" colspan="1">11 731</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">TCGA (<xref rid="btaa442-B11" ref-type="bibr">Ding <italic>et al.</italic>, 2016</xref>)</td>
              <td rowspan="1" colspan="1">Patient</td>
              <td rowspan="1" colspan="1">Paclitaxel</td>
              <td rowspan="1" colspan="1">Chemotherapy</td>
              <td rowspan="1" colspan="1">Target</td>
              <td rowspan="1" colspan="1">35</td>
              <td rowspan="1" colspan="1">11 731</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GDSC (<xref rid="btaa442-B24" ref-type="bibr">Iorio <italic>et al.</italic>, 2016</xref>)</td>
              <td rowspan="1" colspan="1">Cell line</td>
              <td rowspan="1" colspan="1">Paclitaxel</td>
              <td rowspan="1" colspan="1">Chemotherapy</td>
              <td rowspan="1" colspan="1">Source</td>
              <td rowspan="1" colspan="1">389</td>
              <td rowspan="1" colspan="1">11 731</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <label>a</label>
            <p>Number of genes in common between the source and all of the target data for each drug.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <list list-type="bullet">
        <list-item>
          <p>The Genomics of Drug Sensitivity in Cancer (GDSC) cell lines dataset, consisting of a thousand cell lines from different cancer types, screened with 265 targeted and chemotherapy drugs (<xref rid="btaa442-B24" ref-type="bibr">Iorio <italic>et al.</italic>, 2016</xref>).</p>
        </list-item>
        <list-item>
          <p>The Patient-Derived Xenograft (PDX) Encyclopedia dataset, consisting of more than 300 PDX samples for different cancer types, screened with 34 targeted and chemotherapy drugs (<xref rid="btaa442-B16" ref-type="bibr">Gao <italic>et al.</italic>, 2015</xref>).</p>
        </list-item>
        <list-item>
          <p>TCGA (<xref rid="btaa442-B45" ref-type="bibr">Weinstein <italic>et al.</italic>, 2013</xref>) containing a total number of 117 patients with diverse cancer types, treated with Cisplatin, Docetaxel or Paclitaxel (<xref rid="btaa442-B11" ref-type="bibr">Ding <italic>et al.</italic>, 2016</xref>).</p>
        </list-item>
        <list-item>
          <p>Patient datasets from nine clinical trial cohorts containing a total number of 491 patients with diverse cancer types, treated with Bortezomib (<xref rid="btaa442-B2" ref-type="bibr">Amin <italic>et al.</italic>, 2014</xref>; <xref rid="btaa442-B29" ref-type="bibr">Mulligan <italic>et al.</italic>, 2007</xref>), Cisplatin (<xref rid="btaa442-B27" ref-type="bibr">Marchion <italic>et al.</italic>, 2011</xref>; <xref rid="btaa442-B39" ref-type="bibr">Silver <italic>et al.</italic>, 2010</xref>), Docetaxel (<xref rid="btaa442-B6" ref-type="bibr">Chang <italic>et al.</italic>, 2005</xref>; <xref rid="btaa442-B22" ref-type="bibr">Hatzis <italic>et al.</italic>, 2011</xref>; <xref rid="btaa442-B25" ref-type="bibr">Lehmann <italic>et al.</italic>, 2011</xref>) or Paclitaxel (<xref rid="btaa442-B1" ref-type="bibr">Ahmed <italic>et al.</italic>, 2007</xref>; <xref rid="btaa442-B5" ref-type="bibr">Bauer <italic>et al.</italic>, 2010</xref>; <xref rid="btaa442-B22" ref-type="bibr">Hatzis <italic>et al.</italic>, 2011</xref>). For the categorical measures of the drug response such as RECIST, we consider complete response and partial response as responder (Class 1) and consider stable disease and progressive disease as non-responder (Class 0).</p>
        </list-item>
        <list-item>
          <p>TCGA cohorts including, breast (BRCA), prostate (PRAD), lung (LUAD), kidney (KIRP) and bladder (BLCA) cancers that do not have the drug response outcome.</p>
        </list-item>
      </list>
      <p>The GDSC dataset was used as the source domain, and all the other datasets were used as the target domain. For the GDSC dataset, raw gene expression data were downloaded from ArrayExpress (E-MTAB-3610) and response outcomes from https:/<ext-link ext-link-type="uri" xlink:href="http://www.cancerrxgene.org">www.cancerrxgene.org</ext-link> release 7.0. Gene expression data of TCGA patients were downloaded from the Firehose Broad GDAC (version published on January 28, 2016) and the response outcome was obtained from (<xref rid="btaa442-B11" ref-type="bibr">Ding <italic>et al.</italic>, 2016</xref>). Patient datasets from clinical trials were obtained from the Gene Expression Omnibus and the PDX dataset was obtained from the <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> of <xref rid="btaa442-B16" ref-type="bibr">Gao <italic>et al.</italic> (2015)</xref>. For each drug, we selected those patient datasets that applied a comparable measure of the drug response. For preprocessing, the same procedure was adopted as described in the <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> of <xref rid="btaa442-B38" ref-type="bibr">Sharifi-Noghabi <italic>et al.</italic> (2019b</xref>) for the raw gene expression data (normalized and z-score transformed) and the drug response data. After the pre-processing, source and target domains had the same number of genes.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Results</title>
    <sec>
      <title>4.1 Experimental design</title>
      <p>We designed our experiments to answer the following four questions:
</p>
      <list list-type="order">
        <list-item>
          <p>Does AITL outperform baselines that are trained only on cell lines and then evaluated on patients (without transfer learning)? To answer this question, we compared AITL against <xref rid="btaa442-B17" ref-type="bibr">Geeleher <italic>et al.</italic> (2014)</xref> and MOLI (<xref rid="btaa442-B38" ref-type="bibr">Sharifi-Noghabi <italic>et al.</italic>, 2019b</xref>) which are state-of-the-art methods of drug response prediction that do not perform domain adaptation. The <xref rid="btaa442-B17" ref-type="bibr">Geeleher <italic>et al.</italic> (2014)</xref> is non-deep learning method based on ridge regression and MOLI is a deep learning-based method. Both of them were originally proposed for pharmacogenomics.</p>
        </list-item>
        <list-item>
          <p>Does AITL outperform baselines that adopt adversarial transductive transfer learning and non-deep learning adaptation (without adaptation of the output space)? To answer this question, we compared AITL against ADDA (<xref rid="btaa442-B44" ref-type="bibr">Tzeng <italic>et al.</italic>, 2017</xref>) and <xref rid="btaa442-B9" ref-type="bibr">Chen <italic>et al.</italic> (2017)</xref>, state-of-the-art methods of adversarial transductive transfer learning with global- and class-wise discriminators, respectively. For the non-deep learning baseline, we compared AITL to PRECISE (<xref rid="btaa442-B28" ref-type="bibr">Mourragui <italic>et al.</italic>, 2019</xref>), a non-deep learning domain adaptation method specifically designed for pharmacogenomics.</p>
        </list-item>
        <list-item>
          <p>Does AITL outperform a baseline for inductive transfer learning? To answer this question, we compared AITL against ProtoNet (<xref rid="btaa442-B41" ref-type="bibr">Snell <italic>et al.</italic>, 2017</xref>) which is a state-of-the-art inductive transfer learning method for small numbers of examples per class.</p>
        </list-item>
        <list-item>
          <p>Finally, do the predicted responses by AITL for TCGA patients have associations with the targets of the studied drug?</p>
        </list-item>
      </list>
      <p>Based on the availability of patient/PDX datasets for a drug, we experimented with four different drugs: Bortezomib, Cisplatin, Docetaxel and Paclitaxel. It is important to note that these drugs have different mechanisms and are being prescribed for different cancers. For example, Docetaxel is a chemotherapy drug mostly known for treating breast cancer patients (<xref rid="btaa442-B6" ref-type="bibr">Chang <italic>et al.</italic>, 2005</xref>), whereas Bortezomib is a targeted drug mostly used for multiple myeloma patients (<xref rid="btaa442-B2" ref-type="bibr">Amin <italic>et al.</italic>, 2014</xref>). Therefore, the datasets we have selected cover different types of anti-cancer drugs.</p>
      <p>In addition to the experimental comparison against published methods, we also performed an ablation study to investigate the impact of the different AITL components separately. AITL-<italic>AD</italic> denotes a version of AITL without the adversarial adaptation components, which means the network only contains the multi-task subnetwork. AITL-<italic>D<sub>G</sub></italic> denotes a version of AITL without the global discriminator, which means the network only employs the multi-task subnetwork and class-wise discriminators. AITL-<italic>D<sub>C</sub></italic> denotes a version of AITL without the class-wise discriminators, which means the network only contains the multi-task subnetwork and the global discriminator.</p>
      <p>All of the baselines were trained on the same data, tested on patients/PDX for these drugs, and eventually compared with AITL in terms of prediction AUROC and AUPR. Since the majority of the studied baselines cannot use the continuous log (IC50) values in the source domain, binarized log (IC50) labels provided by (<xref rid="btaa442-B24" ref-type="bibr">Iorio <italic>et al.</italic>, 2016</xref>) using the Waterfall approach (<xref rid="btaa442-B4" ref-type="bibr">Barretina <italic>et al.</italic>, 2012</xref>) were used to train them. Finally, for the minimax optimization, a gradient reversal layer was employed by AITL and the adversarial baselines (<xref rid="btaa442-B15" ref-type="bibr">Ganin <italic>et al.</italic>, 2016</xref>) which is a well-established approach in domain adaptation (<xref rid="btaa442-B26" ref-type="bibr">Long <italic>et al.</italic>, 2018</xref>; <xref rid="btaa442-B46" ref-type="bibr">You <italic>et al.</italic>, 2019</xref>; <xref rid="btaa442-B47" ref-type="bibr">Zhang <italic>et al.</italic>, 2019</xref>).</p>
      <p>We performed 3-fold cross-validation in the experiments to tune the hyper-parameters of AITL and the baselines based on the AUROC. Two folds of the source samples were used for training and the third fold for validation; similarly, two folds of the target samples were used for training and validation, and the third one for the test. The reported results refer to the average and standard deviation over the test folds. The hyper-parameters tuned for AITL were the number of nodes in the hidden layers, learning rates, mini-batch size, the dropout rate, number of epochs and the regularization coefficients. We considered different ranges for each hyper-parameter and the final selected hyper-parameter settings for each drug and each method are provided in the (<xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref>, Section S2). Finally, each network was re-trained on the selected settings using the train and validation data together for each drug. We used Adagrad for optimizing the parameters of AITL and the baselines (<xref rid="btaa442-B12" ref-type="bibr">Duchi <italic>et al.</italic>, 2011</xref>) implemented in the PyTorch framework, except for <xref rid="btaa442-B17" ref-type="bibr">Geeleher <italic>et al.</italic> (2014)</xref> which was implemented in R. We used the author’s implementations for <xref rid="btaa442-B17" ref-type="bibr">Geeleher <italic>et al.</italic> (2014)</xref>, MOLI, PRECISE and ProtoNet. For ADDA, we used an existing implementation from <ext-link ext-link-type="uri" xlink:href="https://github.com/jvanvugt/pytorch-domain-adaptation">https://github.com/jvanvugt/pytorch-domain-adaptation</ext-link>, and we implemented <xref rid="btaa442-B9" ref-type="bibr">Chen <italic>et al.</italic> (2017)</xref> from scratch.</p>
    </sec>
    <sec>
      <title>4.2 Input and output space adaptation via AITL improves the drug response performance</title>
      <p><xref rid="btaa442-T2" ref-type="table">Table 2</xref> and <xref ref-type="fig" rid="btaa442-F2">Figure 2</xref> report the performance of AITL and the baselines in terms of AUROC and AUPR, respectively. To answer the first experimental question, AITL was compared with the baselines which do not use any adaptation (neither the input nor the output space), i.e. <xref rid="btaa442-B17" ref-type="bibr">Geeleher <italic>et al.</italic> (2014)</xref> and MOLI (<xref rid="btaa442-B38" ref-type="bibr">Sharifi-Noghabi <italic>et al.</italic>, 2019b</xref>), and AITL demonstrated a better performance in both AUROC and AUPR for all of the studied drugs. This indicates that addressing the discrepancies in the input and output spaces leads to better performance compared with training a model on the source domain and testing it on the target domain. To answer the second experimental question, AITL was compared with state-of-the-art methods of adversarial and non-deep learning transductive transfer learning, i.e. ADDA (<xref rid="btaa442-B44" ref-type="bibr">Tzeng <italic>et al.</italic>, 2017</xref>), <xref rid="btaa442-B9" ref-type="bibr">Chen <italic>et al.</italic> (2017)</xref> and PRECISE (<xref rid="btaa442-B28" ref-type="bibr">Mourragui <italic>et al.</italic>, 2019</xref>), which address the discrepancy only in the input space. AITL achieved significantly better performance in AUROC for all of the drugs and for three out of four drugs in AUPR [the results of <xref rid="btaa442-B9" ref-type="bibr">Chen <italic>et al.</italic> (2017)</xref> for Cisplatin were very competitive with AITL]. This indicates that addressing the discrepancies in the both spaces outperforms addressing only the input space discrepancy. Finally, to answer the last experimental question, AITL was compared with ProtoNet (<xref rid="btaa442-B41" ref-type="bibr">Snell <italic>et al.</italic>, 2017</xref>)—a representative of inductive transfer learning with input space adaptation via few-shot learning. AITL outperformed this method in all of the metrics for all of the drugs.
</p>
      <fig id="btaa442-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>Performance of AITL and the baselines in terms of the prediction AUPR</p>
        </caption>
        <graphic xlink:href="btaa442f2"/>
      </fig>
      <table-wrap id="btaa442-T2" orientation="portrait" position="float">
        <label>Table 2.</label>
        <caption>
          <p>Performance of AITL and the baselines in terms of the prediction AUROC</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Method/drug</th>
              <th rowspan="1" colspan="1">Bortezomib</th>
              <th rowspan="1" colspan="1">Cisplatin</th>
              <th rowspan="1" colspan="1">Docetaxel</th>
              <th rowspan="1" colspan="1">Paclitaxel</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">
                <xref rid="btaa442-B17" ref-type="bibr">Geeleher <italic>et al.</italic> (2014)</xref>
              </td>
              <td rowspan="1" colspan="1">0.48</td>
              <td rowspan="1" colspan="1">0.58</td>
              <td rowspan="1" colspan="1">0.55</td>
              <td rowspan="1" colspan="1">0.53</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">MOLI (<xref rid="btaa442-B38" ref-type="bibr">Sharifi-Noghabi <italic>et al.</italic>, 2019b</xref>)</td>
              <td rowspan="1" colspan="1">0.57</td>
              <td rowspan="1" colspan="1">0.54</td>
              <td rowspan="1" colspan="1">0.54</td>
              <td rowspan="1" colspan="1">0.53</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PRECISE (<xref rid="btaa442-B28" ref-type="bibr">Mourragui <italic>et al.</italic>, 2019</xref>)</td>
              <td rowspan="1" colspan="1">0.54</td>
              <td rowspan="1" colspan="1">0.59</td>
              <td rowspan="1" colspan="1">0.52</td>
              <td rowspan="1" colspan="1">0.56</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <xref rid="btaa442-B9" ref-type="bibr">Chen <italic>et al.</italic> (2017)</xref>
              </td>
              <td rowspan="1" colspan="1">0.54 ± 0.07</td>
              <td rowspan="1" colspan="1">0.60 ± 0.14</td>
              <td rowspan="1" colspan="1">0.52 ± 0.02</td>
              <td rowspan="1" colspan="1">0.58 ± 0.04</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ADDA (<xref rid="btaa442-B44" ref-type="bibr">Tzeng <italic>et al.</italic>, 2017</xref>)</td>
              <td rowspan="1" colspan="1">0.51 ± 0.06</td>
              <td rowspan="1" colspan="1">0.56 ± 0.06</td>
              <td rowspan="1" colspan="1">0.48 ± 0.06</td>
              <td rowspan="1" colspan="1">Did not converge</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ProtoNet (<xref rid="btaa442-B41" ref-type="bibr">Snell <italic>et al.</italic>, 2017</xref>)</td>
              <td rowspan="1" colspan="1">0.49 ± 0.01</td>
              <td rowspan="1" colspan="1">0.40 ± 0.003</td>
              <td rowspan="1" colspan="1">0.40 ± 0.01</td>
              <td rowspan="1" colspan="1">Did not converge</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AITL-<italic>AD</italic><xref ref-type="table-fn" rid="tblfn2"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">0.69 ± 0.03</td>
              <td rowspan="1" colspan="1">0.57 ± 0.03</td>
              <td rowspan="1" colspan="1">0.57 ± 0.05</td>
              <td rowspan="1" colspan="1">0.58 ± 0.01</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AITL-D<sub><italic>G</italic></sub><xref ref-type="table-fn" rid="tblfn3"><sup>b</sup></xref></td>
              <td rowspan="1" colspan="1">0.69 ± 0.04</td>
              <td rowspan="1" colspan="1">0.62 ± 0.1</td>
              <td rowspan="1" colspan="1">0.48 ± 0.03</td>
              <td rowspan="1" colspan="1">
                <bold>0.62 ± 0.02</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AITL-<italic>D<sub>C</sub></italic><xref ref-type="table-fn" rid="tblfn4"><sup>c</sup></xref></td>
              <td rowspan="1" colspan="1">0.69 ± 0.03</td>
              <td rowspan="1" colspan="1">0.54 ± 0.1</td>
              <td rowspan="1" colspan="1">0.59 ± 0.07</td>
              <td rowspan="1" colspan="1">0.59 ± 0.03</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AITL</td>
              <td rowspan="1" colspan="1">
                <bold>0.74 ± 0.02</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.66 ± 0.02</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.64 ± 0.04</bold>
              </td>
              <td rowspan="1" colspan="1">0.61 ± 0.04</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <label>a</label>
            <p>AITL with only the multi-task subnetwork (no AD).</p>
          </fn>
          <fn id="tblfn3">
            <label>b</label>
            <p>AITL with only class-wise discriminators and the multi-task subnetwork (no global discriminator).</p>
          </fn>
          <fn id="tblfn4">
            <label>c</label>
            <p>AITL with only the global discriminator and the multi-task subnetwork (no class-wise discriminator). Boldface in the table indicates the best performing of the corresponding drug. </p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>We note that the methods of drug response prediction without adaptation, namely <xref rid="btaa442-B17" ref-type="bibr">Geeleher <italic>et al.</italic> (2014)</xref> and MOLI, outperformed the method of inductive transfer learning based on few-shot learning (ProtoNet). Moreover, these two methods also showed a very competitive performance compared with the methods of transductive transfer learning (ADDA, <xref rid="btaa442-B9" ref-type="bibr">Chen <italic>et al.</italic>, 2017</xref> and PRECISE). For Paclitaxel, ADDA did not converge in the first step (training a classifier on the source domain), which was also observed in another study (<xref rid="btaa442-B38" ref-type="bibr">Sharifi-Noghabi <italic>et al.</italic>, 2019b</xref>). ProtoNet also did not converge for this drug.</p>
      <p>We observed that AITL, when all of its components are used together, outperforms additional baselines with modified versions of AITL. This indicates the importance of both input and output space adaptation. The only exception was for the drug Paclitaxel, where AITL-<italic>D<sub>G</sub></italic> outperforms AITL. We believe the reason for this is that this drug has the most heterogeneous target domain (see <xref rid="btaa442-T1" ref-type="table">Table 1</xref>), and therefore, the global discriminator component of AITL causes a minor decrease in the performance. Our ablation study showed that the global- and the class-wise discriminators are not redundant and, in fact, each of them plays a unique constructive role in learning the domain-invariant representation. All these results indicate that addressing the discrepancies in the input and output spaces between the source and target domains, via the AITL method, leads to a better prediction performance.</p>
    </sec>
    <sec>
      <title>4.3 AITL predictions for TCGA patients have significant associations with target genes</title>
      <p>To answer the last experimental question, we applied AITL models (trained on Docetaxel, Bortezomib and Paclitaxel) to the gene expression data without known drug response from TCGA (breast, prostate, lung, kidney and bladder cancers) and predicted the response for these patients separately. Based on the corrected <italic>P</italic>-values obtained from multiple linear regression, there are a number of statistically significant associations between the target genes of the studied drugs and the responses predicted by AITL. For example, in breast cancer, we observed statistically significant associations in MAP4 (<inline-formula id="IE46"><mml:math id="IM46"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mo>−</mml:mo></mml:msup><mml:msup><mml:mrow/><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) for Doxetaxel, BLC2 (<inline-formula id="IE47"><mml:math id="IM47"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>1.7</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) for Paclitaxel and PSMA4 (<inline-formula id="IE48"><mml:math id="IM48"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>4.7</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) for Bortezomib. In prostate cancer, we observed statistically significant associations in MAP2 (<inline-formula id="IE58"><mml:math id="IM49"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) for Docetaxel, TUBB (<inline-formula id="IE49"><mml:math id="IM50"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) for Paclitaxel, and RELA (<inline-formula id="IE50"><mml:math id="IM51"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>2.2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) for Bortezomib. For bladder cancer, NR1I2 (<italic>P  </italic>= <italic> </italic>0.04) for Docetaxel, MAP4 (<inline-formula id="IE51"><mml:math id="IM52"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) for Paclitaxel and PSMA4 (<italic>P  </italic>= <italic> </italic>0.001) for Bortezomib were significant. In kidney cancer, BLC2 (<inline-formula id="IE52"><mml:math id="IM53"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>5.4</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) for Docetaxel, MAPT (<inline-formula id="IE53"><mml:math id="IM54"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) for Paclitaxel and PSMD2 (<inline-formula id="IE54"><mml:math id="IM55"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) for Bortezomib were significant. Finally, in lung cancer, MAP4 (<inline-formula id="IE55"><mml:math id="IM56"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) for Docetaxel, TUBB (<inline-formula id="IE56"><mml:math id="IM57"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) for Paclitaxel and RELA (<inline-formula id="IE57"><mml:math id="IM58"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) for Bortezomib were significant. The complete list of statistically significant genes and their importance is presented in the <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref>, Sections S3 and S4. All these results suggest that AITL predictions capture biological aspects of the drug response.</p>
    </sec>
    <sec>
      <title>4.4 Discussion</title>
      <p>To our surprise, ProtoNet and ADDA could not outperform <xref rid="btaa442-B17" ref-type="bibr">Geeleher <italic>et al.</italic> (2014)</xref>, MOLI and PRECISE. For ProtoNet, this may be due to the depth of the backbone network. A recent study has shown that a deeper backbone improves ProtoNet performance significantly in image classification <xref rid="btaa442-B8" ref-type="bibr">Chen <italic>et al.</italic> (2019)</xref>. However, in pharmacogenomics, employing a deep backbone is not realistic because of the much smaller sample size compared with an image classification application. Another limitation for ProtoNet is the imbalanced number of training examples in different classes in pharmacogenomics datasets. Specifically, the number of examples per class in the training episodes is limited to the number of samples of the minority class as ProtoNet requires the same number of examples from each class. For ADDA, this lower performance may be due to the lack of end-to-end training of the classifier along with the global discriminator of this method. The reason is that end-to-end training of the classifier along with the discriminators improved the performance of the second adversarial baseline (<xref rid="btaa442-B9" ref-type="bibr">Chen <italic>et al.</italic>, 2017</xref>) in AUROC and AUPR compared with ADDA. Moreover, <xref rid="btaa442-B9" ref-type="bibr">Chen <italic>et al.</italic> (2017)</xref> also showed a relatively better performance in AUPR compared with <xref rid="btaa442-B17" ref-type="bibr">Geeleher <italic>et al.</italic> (2014)</xref> and MOLI.</p>
      <p>In pharmacogenomics, patient datasets with drug response are small or not publicly available due to privacy and/or data sharing issues. We believe including more patient samples and more drugs will increase generalization capability. In addition, recent pharmacogenomics studies have shown that using multi-omics data work better than using only gene expression (<xref rid="btaa442-B38" ref-type="bibr">Sharifi-Noghabi <italic>et al.</italic>, 2019b</xref>). In this work, we did not consider genomic data other than gene expression data due to the lack of patient samples with multi-omics data and drug response data publicly available; however, in principle, AITL can be extended to work with such data by adding separate feature extractors for each omics data type. This approach is particularly crucial if the different data types have different dimensionalities. Last but not least, we used pharmacogenomics as our motivating application for this new problem of transfer learning, but we believe that AITL can also be employed in other applications. For example, in slow progressing cancers such as prostate cancer, large patient datasets with gene expression and short-term clinical data (source domain) are available; however, patient datasets with long-term clinical data (target domain) are small. AITL may be beneficial to learn a model to predict these long-term clinical labels using the source domain and its short-term clinical labels (<xref rid="btaa442-B37" ref-type="bibr">Sharifi-Noghabi <italic>et al.</italic>, 2019a</xref>). Finally, although we designed the multi-task subnetwork for a regression task on the source domain and a classification task on the target domain, in principle, AITL can easily be modified to incorporate different types of outputs.</p>
      <p>We observed that predictions for TCGA samples tend to have a low variance. We believe the reason for that is first, we created target domains by pooling together samples from different patient datasets treated with the same drug; however, in reality each dataset has its own discrepancies compared with the other datasets within each target domain. Second, we trained the model using pan-cancer cell lines, however, the patient samples were cancer specific due to the lack of pan-cancer patient data with drug response which makes the trained model less applicable for pan-cancer resources such as TCGA. For future research directions, we believe that the TCGA dataset consisting of gene expression data of more than 12 000 patients (without drug response outcome) can be incorporated in an unsupervised transfer learning setting to learn better features that are domain-invariant between cell lines and cancer patients. The advantage of this approach is that we can keep the valuable patient datasets with drug response as an independent test set and not use it for training/validation. Another possible future direction is to incorporate domain-expert knowledge into the structure of the model. A recent study has shown that such a structure improves the drug response prediction performance on cell line datasets and, more importantly, provides an explainable model as well (<xref rid="btaa442-B42" ref-type="bibr">Snow <italic>et al.</italic>, 2019</xref>).</p>
    </sec>
  </sec>
  <sec>
    <title>5 Conclusion</title>
    <p>In this article, we introduced a new problem in transfer learning motivated by applications in pharmacogenomics. Unlike domain adaptation that only requires adaptation in the input space, this new problem requires adaptation in both the input and output spaces.</p>
    <p>To address this problem, we proposed AITL, an Adversarial Inductive Transfer Learning method which, to the best of our knowledge, is the first method that addresses the discrepancies in both the input and output spaces. AITL uses a feature extractor to learn features for target and source samples. Then, to address the discrepancy in the output space, AITL utilizes these features as input of a multi-task subnetwork that makes predictions for the target samples and assigns cross-domain labels to the source samples. Finally, to address the input space discrepancy, AITL employs global and class-wise discriminators for learning domain-invariant features. In pharmacogenomics, AITL adapts the gene expression data obtained from cell lines and patients in the input space, and also adapts different measures of the drug response between cell lines and patients in the output space. In addition, AITL can also be employed in other applications such as predicting long-term clinical labels for slow progressing cancers.</p>
    <p>We evaluated AITL on four different drugs and compared it against state-of-the-art baselines in terms of AUROC and AUPR. The empirical results indicated that AITL achieved a significantly better performance compared with the baselines showing the benefits of addressing the discrepancies in both the input and output spaces. Finally, we analyzed AITL’s predictions for the studied drugs on breast, prostate, lung, kidney and bladder cancer patients in TCGA. We showed that AITL’s predictions have statistically significant associations with the level of expression of some of the annotated target genes for the studied drugs. We conclude that AITL may be beneficial in pharmacogenomics, a crucial task in precision oncology.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btaa442_Supplementary_Data</label>
      <media xlink:href="btaa442_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We would like to thank Hossein Asghari, Baraa Orabi and Yen-Yi Lin (the Vancouver Prostate Centre) and Soufiane Mourragui (The Netherlands Cancer Institute) for their support. We also would like to thank the Vancouver Prostate Centre for providing the computational resources for this research.</p>
    <sec>
      <title>Authors’ contributions</title>
      <p>Study concept and design: H.S.N., C.C.C. and M.E. Deep learning design, implementations and analysis: H.S.N. and S.P. Data pre-processing, analysis and interpretation: O.Z. Analysis and interpretation of results: H.S.N., S.P. and O.Z. Drafting of the article: All authors read and approved the final article. Supervision: C.C.C. and M.E.</p>
    </sec>
    <sec>
      <title>Funding</title>
      <p>This work was supported by Canada Foundation for Innovation [33440 to C.C.C.], The Canadian Institutes of Health Research [PJT-153073 to C.C.C.], Terry Fox Foundation [201012TFF to C.C.C.], The Terry Fox New Frontiers Program Project Grants [1062 to C.C.C.], International DFG Research Training Group GRK [1906 to support O.Z.] and a Discovery Grant from the National Science and Engineering Research Council of Canada [to M.E.].</p>
      <p><italic>Conflict of Interests</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa442-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ahmed</surname><given-names>A.A.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>The extracellular matrix protein TGFBI induces microtubule stabilization and sensitizes ovarian cancers to paclitaxel</article-title>. <source>Cancer Cell</source>, <volume>12</volume>, <fpage>514</fpage>–<lpage>527</lpage>.<pub-id pub-id-type="pmid">18068629</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Amin</surname><given-names>S.B.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Gene expression profile alone is inadequate in predicting complete response in multiple myeloma</article-title>. <source>Leukemia</source>, <volume>28</volume>, <fpage>2229</fpage>–<lpage>2234</lpage>.<pub-id pub-id-type="pmid">24732597</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Azizzadenesheli</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>). 
<article-title>Regularized learning for domain adaptation under label shifts</article-title>. <italic>arXiv preprint arXiv: 1903.09734.</italic></mixed-citation>
    </ref>
    <ref id="btaa442-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Barretina</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>The cancer cell line encyclopedia enables predictive modelling of anticancer drug sensitivity</article-title>. <source>Nature</source>, <volume>483</volume>, <fpage>603</fpage>–<lpage>607</lpage>.<pub-id pub-id-type="pmid">22460905</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bauer</surname><given-names>J.A.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Identification of markers of taxane sensitivity using proteomic and genomic analyses of breast tumors from patients receiving neoadjuvant paclitaxel and radiation</article-title>. <source>Clin. Cancer Res</source>., <volume>16</volume>, <fpage>681</fpage>–<lpage>690</lpage>.<pub-id pub-id-type="pmid">20068102</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chang</surname><given-names>J.C.</given-names></name></person-group><etal>et al</etal> (<year>2005</year>) 
<article-title>Patterns of resistance and incomplete response to docetaxel by gene expression profiling in breast cancer patients</article-title>. <source>J. Clin. Oncol</source>., <volume>23</volume>, <fpage>1169</fpage>–<lpage>1177</lpage>.<pub-id pub-id-type="pmid">15718313</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>W.-Y.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>). A closer look at few-shot classification. In: <italic>International Conference on Learning Representations.</italic> New Orleans, USA.</mixed-citation>
    </ref>
    <ref id="btaa442-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>Y.-H.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>). No more discrimination: Cross city adaptation of road scene segmenters. In: <italic>Proceedings of the IEEE International Conference on Computer Vision</italic>, Venice, Italy, pp. <fpage>1992</fpage>–<lpage>2001</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa442-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ding</surname><given-names>M.Q.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Precision oncology beyond targeted therapy: combining omics data with machine learning matches the majority of cancer cells to effective therapeutics</article-title>. <source>Mol. Cancer Res</source>., <volume>16</volume>, <fpage>269</fpage>–<lpage>278</lpage>.<pub-id pub-id-type="pmid">29133589</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ding</surname><given-names>Z.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Evaluating the molecule-based prediction of clinical drug responses in cancer</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>2891</fpage>–<lpage>2895</lpage>.<pub-id pub-id-type="pmid">27354694</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Duchi</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Adaptive subgradient methods for online learning and stochastic optimization</article-title>. <source>J. Mach. Learn. Res</source>., <volume>12</volume>, <fpage>2121</fpage>–<lpage>2159</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa442-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Evans</surname><given-names>W.E.</given-names></name>, <name name-style="western"><surname>Relling</surname><given-names>M.V.</given-names></name></person-group> (<year>1999</year>) 
<article-title>Pharmacogenomics: translating functional genomics into rational therapeutics</article-title>. <source>Science</source>, <volume>286</volume>, <fpage>487</fpage>–<lpage>491</lpage>.<pub-id pub-id-type="pmid">10521338</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Ganin</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Lempitsky</surname><given-names>V.</given-names></name>, </person-group> (<year>2015</year>). 
<article-title>Unsupervised domain adaptation by backpropagation</article-title>. In: <italic>Proceedings of the 32nd International Conference on Machine Learning</italic>, vol. 37. Lille, France.</mixed-citation>
    </ref>
    <ref id="btaa442-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ganin</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Domain-adversarial training of neural networks</article-title>. <source>J. Mach. Learn. Res</source>., <volume>17</volume>, <fpage>2096</fpage>–<lpage>2030</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa442-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gao</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>High-throughput screening using patient-derived tumor xenografts to predict clinical trial drug response</article-title>. <source>Nat. Med</source>., <volume>21</volume>, <fpage>1318</fpage>–<lpage>1325</lpage>.<pub-id pub-id-type="pmid">26479923</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Geeleher</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Clinical drug response can be predicted using baseline gene expression levels and in vitro drug sensitivity in cell lines</article-title>. <source>Genome Biol</source>., <volume>15</volume>, <fpage>R47</fpage>.<pub-id pub-id-type="pmid">24580837</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Geeleher</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Discovering novel pharmacogenomic biomarkers by imputing drug response in cancer patients from large genomics studies</article-title>. <source>Genome Res</source>., <volume>27</volume>, <fpage>1743</fpage>–<lpage>1751</lpage>.<pub-id pub-id-type="pmid">28847918</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B19">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Goodfellow</surname><given-names>I.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>). 
<article-title>Generative adversarial nets</article-title>. In: <italic>Advances in Neural Information Processing Systems</italic>, Montreal, Canada, pp. <fpage>2672</fpage>–<lpage>2680</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa442-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gretton</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>A Kernel two-sample test</article-title>. <source>J. Mach. Learn. Res</source>., <volume>13</volume>, <fpage>723</fpage>–<lpage>773</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa442-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Güvenç</surname><given-names>P.B.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Improving drug response prediction by integrating multiple data sources: matrix factorization, Kernel and network-based approaches</article-title>. <source>Brief. Bioinformatics</source>.</mixed-citation>
    </ref>
    <ref id="btaa442-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hatzis</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>A genomic predictor of response and survival following taxane-anthracycline chemotherapy for invasive breast cancer</article-title>. <source>JAMA</source>, <volume>305</volume>, <fpage>1873</fpage>–<lpage>1881</lpage>.<pub-id pub-id-type="pmid">21558518</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B23">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Hosseini-Asl</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>). 
<article-title>Augmented cyclic adversarial learning for low resource domain adaptation. In:</article-title><italic>International Conference on Learning Representations.</italic> Vancouver, Canada.</mixed-citation>
    </ref>
    <ref id="btaa442-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Iorio</surname><given-names>F.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>A landscape of pharmacogenomic interactions in cancer</article-title>. <source>Cell</source>, <volume>166</volume>, <fpage>740</fpage>–<lpage>754</lpage>.<pub-id pub-id-type="pmid">27397505</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lehmann</surname><given-names>B.D.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Identification of human triple-negative breast cancer subtypes and preclinical models for selection of targeted therapies</article-title>. <source>J. Clin. Invest</source>., <volume>121</volume>, <fpage>2750</fpage>–<lpage>2767</lpage>.<pub-id pub-id-type="pmid">21633166</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B26">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Long</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>). 
<article-title>Conditional adversarial domain adaptation</article-title>. In: Bengio, S. et al. (eds) <italic>Advances in Neural Information Processing Systems</italic>, Montreal, Canada, pp. <fpage>1640</fpage>–<lpage>1650</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa442-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Marchion</surname><given-names>D.C.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Bad phosphorylation determines ovarian cancer chemosensitivity and patient survival</article-title>. <source>Clin. Cancer Res</source>., <volume>17</volume>, <fpage>6356</fpage>–<lpage>6366</lpage>.<pub-id pub-id-type="pmid">21849418</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mourragui</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Precise: a domain adaptation approach to transfer predictors of drug response from pre-clinical models to tumors</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>i510</fpage>–<lpage>i519</lpage>.<pub-id pub-id-type="pmid">31510654</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mulligan</surname><given-names>G.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>Gene expression profiling and correlation with outcome in clinical trials of the proteasome inhibitor bortezomib</article-title>. <source>Blood</source>, <volume>109</volume>, <fpage>3177</fpage>–<lpage>3188</lpage>.<pub-id pub-id-type="pmid">17185464</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pan</surname><given-names>S.J.</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>Q.</given-names></name></person-group> (<year>2010</year>) 
<article-title>A survey on transfer learning</article-title>. <source>IEEE Trans. Knowl. Data Eng</source>., <volume>22</volume>, <fpage>1345</fpage>–<lpage>1359</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa442-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Peng</surname><given-names>X.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>). 
<article-title>Domain agnostic learning with disentangled representations</article-title>. In: <italic>Proceedings of the 36th International Conference on Machine Learning</italic>, vol. <volume>97</volume>, pp. 5102--5112. Long Beach, California, USA.</mixed-citation>
    </ref>
    <ref id="btaa442-B32">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Pinheiro</surname><given-names>P.O.</given-names></name></person-group> (<year>2018</year>). 
<article-title>Unsupervised domain adaptation with similarity learning</article-title>. In: <italic>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic>, New Orleans, US, pp. <fpage>8004</fpage>–<lpage>8013</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa442-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rampášek</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Dr. Vae: improving drug response prediction via modeling of drug perturbation effects</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>3743</fpage>–<lpage>3751</lpage>.<pub-id pub-id-type="pmid">30850846</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sakellaropoulos</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>A deep learning framework for predicting response to therapy in cancer</article-title>. <source>Cell Rep</source>., <volume>29</volume>, <fpage>3367</fpage>–<lpage>3373</lpage>.<pub-id pub-id-type="pmid">31825821</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schwartz</surname><given-names>L.H.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>RECIST 1.1-update and clarification: from the RECIST committee</article-title>. <source>Eur. J. Cancer</source>, <volume>62</volume>, <fpage>132</fpage>–<lpage>137</lpage>.<pub-id pub-id-type="pmid">27189322</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B36">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Scott</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>). 
<article-title>Adapted deep embeddings: a synthesis of methods for k-shot inductive transfer learning</article-title>. In: Bengio, S. et al. (eds) <italic>Advances in Neural Information Processing Systems</italic>, Curran Associates, Inc., Montreal, Canada, pp. <fpage>76</fpage>–<lpage>85</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa442-B37">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Sharifi-Noghabi</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>a). 
<article-title>Deep genomic signature for early metastasis prediction in prostate cancer</article-title>. <italic>BioRxiv</italic>, <fpage>276055</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa442-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sharifi-Noghabi</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>b) 
<article-title>MOLI: multi-omics late integration with deep neural networks for drug response prediction</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>i501</fpage>–<lpage>i509</lpage>.<pub-id pub-id-type="pmid">31510700</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Silver</surname><given-names>D.P.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Efficacy of neoadjuvant cisplatin in triple-negative breast cancer</article-title>. <source>J. Clin. Oncol</source>., <volume>28</volume>, <fpage>1145</fpage>–<lpage>1153</lpage>.<pub-id pub-id-type="pmid">20100965</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Smirnov</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>PharmacoDB: an integrative database for mining in vitro anticancer drug screening studies</article-title>. <source>Nucleic Acids Res</source>., <volume>46</volume>, <fpage>D994</fpage>–<lpage>D1002</lpage>.<pub-id pub-id-type="pmid">30053271</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B41">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Snell</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>). 
<article-title>Prototypical networks for few-shot learning</article-title>. In: Guyon,I. et al. (eds) <italic>Advances in Neural Information Processing Systems</italic>, Curran Associates, Inc., Long Beach, US, pp. <fpage>4077</fpage>–<lpage>4087</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa442-B42">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Snow</surname><given-names>O.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>). 
<article-title>BDKANN-biological domain knowledge-based artificial neural network for drug response prediction</article-title>. <italic>bioRxiv</italic>, <fpage>840553</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa442-B43">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Tsai</surname><given-names>Y.-H.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>). 
<article-title>Learning to adapt structured output space for semantic segmentation</article-title>. In: <italic>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic>, Salt Lake City, US, pp. <fpage>7472</fpage>–<lpage>7481</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa442-B44">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Tzeng</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>). 
<article-title>Adversarial discriminative domain adaptation</article-title>. In: <italic>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic>, Honolulu, US, pp. <fpage>7167</fpage>–<lpage>7176</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa442-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Weinstein</surname><given-names>J.N.</given-names></name></person-group><etal>et al</etal>; The Cancer Genome Atlas Research Network (<year>2013</year>). 
<article-title>The Cancer Genome Atlas pan-cancer analysis project</article-title>. <source>Nat. Genet</source>., <volume>45</volume>, <fpage>1113</fpage>–<lpage>1120</lpage>.<pub-id pub-id-type="pmid">24071849</pub-id></mixed-citation>
    </ref>
    <ref id="btaa442-B46">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>You</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>). 
<article-title>Universal domain adaptation</article-title>. In: <italic><italic>The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).</italic> Long Beach, USA<italic>.</italic></italic></mixed-citation>
    </ref>
    <ref id="btaa442-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>). 
<article-title>Bridging theory and algorithm for domain adaptation</article-title>. In: <italic>Proceedings of the 36th International Conference on Machine Learning, Long Beach</italic>, California, USA, vol. <volume>97</volume>, 7404--7413.</mixed-citation>
    </ref>
    <ref id="btaa442-B48">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Zou</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>). 
<article-title>Unsupervised domain adaptation for semantic segmentation via class-balanced self-training</article-title>. In: <italic>Proceedings of the European Conference on Computer Vision (ECCV)</italic>, Munich, Germany, pp. <fpage>289</fpage>–<lpage>305</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
