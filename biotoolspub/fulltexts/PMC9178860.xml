<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9178860</article-id>
    <article-id pub-id-type="publisher-id">4756</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-022-04756-1</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>EMDLP: Ensemble multiscale deep learning model for RNA methylation site prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Honglei</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Liu</surname>
          <given-names>Hui</given-names>
        </name>
        <address>
          <email>hui.liu@cumt.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Huang</surname>
          <given-names>Tao</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Gangshen</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Lin</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Sun</surname>
          <given-names>Yanjing</given-names>
        </name>
        <address>
          <email>yjsun@cumt.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.411510.0</institution-id><institution-id institution-id-type="ISNI">0000 0000 9030 231X</institution-id><institution>Engineering Research Center of Intelligent Control for Underground Space, Ministry of Education, </institution><institution>China University of Mining and Technology, </institution></institution-wrap>Xuzhou, 221116 China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.411510.0</institution-id><institution-id institution-id-type="ISNI">0000 0000 9030 231X</institution-id><institution>School of Information and Control Engineering, </institution><institution>China University of Mining and Technology, </institution></institution-wrap>Xuzhou, 221116 China </aff>
      <aff id="Aff3"><label>3</label>School of Information Engineering, Xuzhou College of Industrial Technology, Xuzhou, 221400 China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>8</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>8</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <elocation-id>221</elocation-id>
    <history>
      <date date-type="received">
        <day>22</day>
        <month>1</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>27</day>
        <month>5</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Recent research recommends that epi-transcriptome regulation through post-transcriptional RNA modifications is essential for all sorts of RNA. Exact identification of RNA modification is vital for understanding their purposes and regulatory mechanisms. However, traditional experimental methods of identifying RNA modification sites are relatively complicated, time-consuming, and laborious.</p>
        <p id="Par2">Machine learning approaches have been applied in the procedures of RNA sequence features extraction and classification in a computational way, which may supplement experimental approaches more efficiently. Recently, convolutional neural network (CNN) and long short-term memory (LSTM) have been demonstrated achievements in modification site prediction on account of their powerful functions in representation learning. However, CNN can learn the local response from the spatial data but cannot learn sequential correlations. And LSTM is specialized for sequential modeling and can access both the contextual representation but lacks spatial data extraction compared with CNN. There is strong motivation to construct a prediction framework using natural language processing (NLP), deep learning (DL) for these reasons.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par3">This study presents an ensemble multiscale deep learning predictor (EMDLP) to identify RNA methylation sites in an NLP and DL way. It organically combines the dilated convolution and Bidirectional LSTM (BiLSTM), which helps to take better advantage of the local and global information for site prediction.</p>
        <p id="Par4">The first step of EMDLP is to represent the RNA sequences in an NLP way. Thus, three encodings, e.g., RNA word embedding, One-hot encoding, and RGloVe, which is an improved learning method of word vector representation based on GloVe, are adopted to decipher sites from the viewpoints of the local and global information. Then, a dilated convolutional Bidirectional LSTM network (DCB) model is constructed with the dilated convolutional neural network (DCNN) followed by BiLSTM to extract potential contributing features for methylation site prediction. Finally, these three encoding methods are integrated by a soft vote to obtain better predictive performance. Experiment results on m<sup>1</sup>A and m<sup>6</sup>A reveal that the area under the receiver operating characteristic(AUROC) of EMDLP obtains respectively 95.56%, 85.24%, and outperforms the state-of-the-art models. To maximize user convenience, a user-friendly webserver for EMDLP was publicly available at <ext-link ext-link-type="uri" xlink:href="http://www.labiip.net/EMDLP/index.php">http://www.labiip.net/EMDLP/index.php</ext-link> (<ext-link ext-link-type="uri" xlink:href="http://47.104.130.81/EMDLP/index.php">http://47.104.130.81/EMDLP/index.php</ext-link>).</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par5">We developed a predictor for m<sup>1</sup>A and m<sup>6</sup>A methylation sites.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12859-022-04756-1.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>RNA modification site</kwd>
      <kwd>Deep learning</kwd>
      <kwd>Natural language processing</kwd>
      <kwd>Predictor</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par27">RNA molecules’ functional diversity is enriched by post-transcriptional RNA modifications, which regulate all stages of RNA life [<xref ref-type="bibr" rid="CR1">1</xref>]. Up to now, there are around 160 different forms of RNA modifications that have been discovered [<xref ref-type="bibr" rid="CR2">2</xref>], including N<sup>1</sup>-methyladenosine(m<sup>1</sup>A), N<sup>6</sup>-methyladenosine(m<sup>6</sup>A), 5-methylcytosine(m<sup>5</sup>C), N<sup>2</sup>-methylguanosine(m<sup>2</sup>G), 7-methylguanosine(m<sup>7</sup>G) [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR4">4</xref>], etc. Among them, m<sup>1</sup>A modification is a prevalent RNA modification, which occurs on the nitrogen-1 position of the adenine base attached with a methyl group [<xref ref-type="bibr" rid="CR5">5</xref>], as shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>a. It’s linked to problems with the respiratory chain, neurodevelopmental regression, and mediate antibiotic resistance bacteria, etc. [<xref ref-type="bibr" rid="CR6">6</xref>–<xref ref-type="bibr" rid="CR8">8</xref>]. Another modification affecting adenine is m<sup>6</sup>A modification, the most abundant modification in mammals, which occurs on the nitrogen-6 position of the adenosine base [<xref ref-type="bibr" rid="CR9">9</xref>], as shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>b. It has a profound impact on human growth and disease [<xref ref-type="bibr" rid="CR10">10</xref>]. The adenosine usually undergoes m<sup>1</sup>A and m<sup>6</sup>A [<xref ref-type="bibr" rid="CR11">11</xref>]. Interestingly, m<sup>1</sup>A is also known to undergo Dimroth rearrangement to m<sup>6</sup>A under alkaline conditions [<xref ref-type="bibr" rid="CR11">11</xref>]. Therefore, it is important to accurately identify m<sup>1</sup>A and m<sup>6</sup>A modification sites to uncover the mechanisms and functions of those modifications [<xref ref-type="bibr" rid="CR12">12</xref>].<fig id="Fig1"><label>Fig. 1</label><caption><p>Chemical structures of modifications. <bold>a</bold> m<sup>1</sup>A modification. <bold>b</bold> m<sup>6</sup>A modification</p></caption><graphic xlink:href="12859_2022_4756_Fig1_HTML" id="MO1"/></fig></p>
    <p id="Par28">Many experimental methods for identifying m<sup>1</sup>A and m<sup>6</sup>A modification sites have been constructed with the significant advances in high-throughput sequencing technology, such as m<sup>6</sup>A-CLIP [<xref ref-type="bibr" rid="CR13">13</xref>], m<sup>6</sup>A-miCLIP [<xref ref-type="bibr" rid="CR14">14</xref>], m<sup>1</sup>A-seq [<xref ref-type="bibr" rid="CR15">15</xref>], m<sup>1</sup>A-ID-seq [<xref ref-type="bibr" rid="CR11">11</xref>], etc. However, the experimental methods are expensive and time-consuming, which limit their extensive use [<xref ref-type="bibr" rid="CR16">16</xref>]. Fortunately, various computational methods have become powerful supplements in this area.</p>
    <p id="Par29">Most machine learning methods designed for site prediction from sequences usually first extracted features based on human-understood feature methods, followed by a classifier to predict whether the site is a methylation site or not. For example, RAMPred extracted features based on nucleotide chemical properties (NCP), nucleotide composition (NC), and adopted the support vector machine (SVM) to predict the m<sup>1</sup>A methylation site for the first time [<xref ref-type="bibr" rid="CR17">17</xref>]. iRNA-3typeA extracted features based on NCP, accumulated nucleotide frequency(ANF), and adopted SVM to predict m<sup>1</sup>A, m<sup>6</sup>A, and A-to-I modification sites [<xref ref-type="bibr" rid="CR18">18</xref>]. iMRM extracted features based on NCP, NC, One-hot encoding, Dinucleotide Binary Encoding (DBE), Nucleotide Density (ND), Dinucleotide physicochemical properties (DPCP) and adopted eXtreme Gradient Boosting(XGboost) to predict m<sup>1</sup>A, m<sup>6</sup>A, m<sup>5</sup>C, <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\psi$$\end{document}</tex-math><mml:math id="M2"><mml:mi>ψ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq1.gif"/></alternatives></inline-formula> and A-to-I modification sites, whose performance was superior to existing methods [<xref ref-type="bibr" rid="CR19">19</xref>]. M<sup>6</sup>AMRFS extracted features based on DBE, ANF, used the F-score algorithm combined with Sequential Forward Search(SFS) to raise feature representation, and employed XGBoost to predict m<sup>6</sup>A site [<xref ref-type="bibr" rid="CR20">20</xref>]. RNAMethPre extracted the features of the flanking sequences, the local secondary structure data, and the relative position data first, then adopted SVM to predict m<sup>6</sup>A methylation site with satisfactory performance [<xref ref-type="bibr" rid="CR21">21</xref>]. SRAMP combines three random forest classifiers by exploiting One-hot encoding, K-nearest neighbor encoding, and Nucleotide pair spectrum encoding to predict m<sup>6</sup>A sites [<xref ref-type="bibr" rid="CR22">22</xref>]. RFAthM<sup>6</sup>A extracted features based on four encoding methods, including Knucleotide frequencies (KNF), position-specific nucleotide sequence profile (PSNSP), Kspaced nucleotide pair frequencies (KSNPF), and position-specific dinucleotide sequence profile (PSDSP), respectively, then built four random forest models, which were competitive compared with AthMethPre, M<sup>6</sup>ATH, and RAM-NPPS [<xref ref-type="bibr" rid="CR23">23</xref>]. WHISTLE adds 35 genomic features in addition to integrating conventional sequence features and predicts m<sup>6</sup>A methylation by SVM [<xref ref-type="bibr" rid="CR24">24</xref>], which significantly improved compared to other computational approaches. However, genomic features are not always available when only a few RNA sequences are provided to predict m<sup>6</sup>A methylation. These conclusions show that extracted features is extremely critical to the final prediction.</p>
    <p id="Par30">It is well known that RNA-seq contains rich biometric information. Thus, the Rational representation of RNA sequences becomes even more critical. To address this problem, representation learning of sequences by natural language processing (NLP) has attracted a lot of attention [<xref ref-type="bibr" rid="CR25">25</xref>], where an RNA sequence is regarded as a sentence, and a <italic>k</italic>-monomeric unit (<italic>k</italic>-mer) is regarded as a word, has gained great traction [<xref ref-type="bibr" rid="CR26">26</xref>, <xref ref-type="bibr" rid="CR27">27</xref>]. Compared with conventional machine learning methods, most of the deep learning(DL) models can be divided into three parts: first, learning input data representations by NLP models [<xref ref-type="bibr" rid="CR28">28</xref>]; second, composing over the word vectors that have been learned [<xref ref-type="bibr" rid="CR29">29</xref>]; third, classing by a classifier to predict whether or not the site is a methylation site.</p>
    <p id="Par31">By far, some prediction methods using NLP and DL networks have been developed to predict m<sup>6</sup>A or m<sup>1</sup>A sites. Among them, Gene2Vec [<xref ref-type="bibr" rid="CR30">30</xref>], DeepPromise [<xref ref-type="bibr" rid="CR12">12</xref>], and EDLm<sup>6</sup>Apred [<xref ref-type="bibr" rid="CR16">16</xref>] were the most representative and advanced methods for methylation site prediction. Specifically, Gene2Vec was developed to predict m<sup>6</sup>A site based on Word2vec [<xref ref-type="bibr" rid="CR31">31</xref>] and convolutional neural network (CNN). DeepPromise adopted CNN and integrated enhanced nucleic acid content (ENAC) [<xref ref-type="bibr" rid="CR32">32</xref>], RNA word embedding [<xref ref-type="bibr" rid="CR33">33</xref>], and One-hot encoding [<xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR34">34</xref>] features to identify m<sup>1</sup>A and m<sup>6</sup>A sites. EDLm<sup>6</sup>Apred adopted Word2vec, One-hot encoding, RNA word embedding, and BiLSTM to predict m<sup>6</sup>A sites. However, the existing methods have the following shortcomings. As is known, from the perspective of NLP, ENAC, One-hot, and RNA word embedding focused on the local semantic information [<xref ref-type="bibr" rid="CR16">16</xref>] but ignored the context and global information. Word2vec encoding considered the context window information, ignoring the global information [<xref ref-type="bibr" rid="CR35">35</xref>]. From the perspective of DL, CNN can learn the local response from the spatial data [<xref ref-type="bibr" rid="CR25">25</xref>]. The different scale of the convolution kernel impacts the network's learning ability. Gene2Vec [<xref ref-type="bibr" rid="CR30">30</xref>] and DeepPromise [<xref ref-type="bibr" rid="CR12">12</xref>] directly used CNN composed of a single-scale convolution kernel, which might lead to incomplete representation learning of sequences [<xref ref-type="bibr" rid="CR36">36</xref>]. The missing information in both methods may be important to the final site prediction. In addition, CNN has no memory function and lacks the ability to learn sequential correlations [<xref ref-type="bibr" rid="CR25">25</xref>]. On the contrary, EDLm<sup>6</sup>Apred [<xref ref-type="bibr" rid="CR16">16</xref>] presented a deep BiLSTM network to address the above issue, which simultaneously accessed context information. However, BiLSTM lacks spatial data extraction compared with CNN and needs a high training time [<xref ref-type="bibr" rid="CR37">37</xref>, <xref ref-type="bibr" rid="CR38">38</xref>].</p>
    <p id="Par32">Consider the above questions. This paper proposes EMDLP to identify RNA methylation sites in an NLP and DL way. Specifically, One-hot encoding, RNA word embedding, and RGloVe were initially used to encode the sequences. Secondly, the DCB model was constructed with DCNN followed by BiLSTM to extract potential contributing features for methylation site prediction. Third, Three predictors were constructed based on the DCB model by the three feature encoding methods above. Finally, EMDLP was formulated by a soft vote with average predicted probabilities to use the three predictors to obtain better predictive performance. The results showed that the performance of the EMDLP model outperformed the state-of-the-art methods such as DeepPromise [<xref ref-type="bibr" rid="CR12">12</xref>] and EDLm<sup>6</sup>Apred [<xref ref-type="bibr" rid="CR16">16</xref>] in independent tests.</p>
  </sec>
  <sec id="Sec2">
    <title>Results</title>
    <sec id="Sec3">
      <title>Evaluation metrics</title>
      <p id="Par33">To estimate the prediction of the models, we adopted widely used binary classifier evaluation metrics, including Sensitivity(Sn, Recall), Specificity(Sp), Accuracy(Acc), Precision(Pre), F1 score (F1), Matthews correlation coefficient(MCC), Area under the receiver operating characteristic(AUROC), and Area under the precision-recall curve (AUPRC). Sn, Sp, Acc, Pre, F1, MCC are defined as follows:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sn = \frac{TP}{{TP + FN}}$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sp = \frac{TN}{{TN + FP}}$$\end{document}</tex-math><mml:math id="M6" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Acc = \frac{TP + TN}{{TP + TN + FP + FN}}$$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Pre = \frac{TP}{{TP + FP}}$$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F1 = 2 \times \frac{Precision \times Recall}{{Precision + Recall}}$$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MCC = \frac{TP \times TN - FP \times FN}{{\sqrt {(TP + FP) \times (TP + FN) \times (TN + FP) \times (TN + FN)} }}$$\end{document}</tex-math><mml:math id="M14" display="block"><mml:mrow><mml:mi>M</mml:mi><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:msqrt><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>where TP refers to true positive, TN refers to true negative, FP refers to false positive, and FN refers to false negative. In addition, the AUROC and AUPRC values are calculated based on the receiver operation curve (ROC) and the precision-recall curve (PRC), respectively. All the metric values range from 0 to 1 except for the MCC value, which ranges lies in [− 1, + 1], with a higher value indicating better performance.</p>
    </sec>
    <sec id="Sec4">
      <title>Results analysis</title>
      <p id="Par34">This paper first examined the performance of RGloVe and GloVe on different sliding window sizes. Second, the self-built DCB model was compared and analyzed with the CNN, DCNN, and BiLSTM models. Third, this study compared the RGloVe feature encoding with the three others on predicting methylation modification sites. Last, this paper compared the EMDLP model with state-of-the-art methods based on the independent datasets. Our computing device has two NVIDIA RTX2080Ti GPU and 11 GB of GPU device memory. In addition to the GPU, the machine has two 2.3 GHz 16-core Intel(R) Xeon(R) Gold 5218 CPU and 128 GB of RAM. The device is installed with 64-bit Windows10 Professional Edition 20H2, python 3.7.6, Keras 2.2.4, and TensorFlow-gpu 1.14.0.</p>
      <p id="Par35">The size of the sliding window is an important parameter that affects the performance of the encoding scheme. Based on benchmark datasets, this experiment compares the performance of RGloVe and GloVe in predicting m<sup>1</sup>A and m<sup>6</sup>A methylation sites under four different sliding window sizes(i.e., 8, 15, 30, and 60). RGloVe is based on the GloVe model framework and adopts RMSProp instead of Adagrad to minimize the loss function of the global vector model. As a result, RGloVe shows the best prediction performance when the sliding window length = 30, as shown in Table <xref rid="Tab1" ref-type="table">1</xref>. The experiment results show that using RMSProp can train the model more effectively.<table-wrap id="Tab1"><label>Table 1</label><caption><p>AUROC scores of RGloVe and GloVe under different sliding windows sizes based on benchmark datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Modification type</th><th align="left">Encoding</th><th align="left">Window sizes = 8</th><th align="left">Window sizes = 15</th><th align="left">Window sizes = 30</th><th align="left">Window sizes = 60</th></tr></thead><tbody><tr><td align="left" rowspan="2">m<sup>1</sup>A</td><td align="left">RGloVe</td><td char="." align="char">0.9283</td><td char="." align="char">0.9317</td><td char="." align="char"><bold>0.9377</bold></td><td char="." align="char">0.9315</td></tr><tr><td align="left">GloVe</td><td char="." align="char">0.9282</td><td char="." align="char">0.9193</td><td char="." align="char">0.9305</td><td char="." align="char">0.9185</td></tr><tr><td align="left" rowspan="2">m<sup>6</sup>A</td><td align="left">RGloVe</td><td char="." align="char">0.8414</td><td char="." align="char">0.8415</td><td char="." align="char"><bold>0.8432</bold></td><td char="." align="char">0.8407</td></tr><tr><td align="left">GloVe</td><td char="." align="char">0.8399</td><td char="." align="char">0.8420</td><td char="." align="char">0.8414</td><td char="." align="char">0.8372</td></tr></tbody></table><table-wrap-foot><p>The bolded values represent the best results</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec5">
      <title>Comparison with other different learning models</title>
      <p id="Par36">Next, DCB was compared and analyzed with CNN, DCNN, and BiLSTM using the same benchmark datasets. The experiments used RGloVe encoding to describe the RNA sequence, constructed CNN<sub>RGloVe</sub>, DCNN<sub>RGloVe</sub>, BiLSTM<sub>RGloVe</sub>, and DCB<sub>RGloVe</sub>, respectively. Among them, CNN<sub>RGloVe</sub> employed the CNN model in Deeppromise [<xref ref-type="bibr" rid="CR12">12</xref>]. DCB<sub>RGloVe</sub> represented a self-built DCB model, including the DCNN and BiLSTM stage. The DCNN<sub>RGloVed</sub> denoted the DCB<sub>RGloVe</sub> removing the BiLSTM stage, which was substituted by the flatten layer. Similarly, the BiLSTM<sub>RGloVe</sub> represented the DCB<sub>RGloVe</sub> without the DCNN stage.</p>
      <p id="Par37">The fivefold cross-validation evaluation results, the AUROC and AUPRC curves on the m<sup>1</sup>A and m<sup>6</sup>A are shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref> and Table <xref rid="Tab2" ref-type="table">2</xref>. The result shows the AUROC of DCNN<sub>RGloVe</sub> is 0.57% and 0.74% higher than CNN<sub>RGloVe</sub>’s on m<sup>1</sup>A and m<sup>6</sup>A, and the AUPRC of DCNN<sub>RGloVe</sub> is 0.08% and 0.94% higher than CNN<sub>RGloVe</sub>’s. This result.<fig id="Fig2"><label>Fig. 2</label><caption><p>Performance of the different models through fivefold cross-validation. The models are CNN<sub>RGloVe</sub>, DCNN<sub>RGloVe</sub>, BiLSTM<sub>RGloVe</sub>, and DCB<sub>RGloVe,</sub> respectively. "CNN<sub>RGloVe</sub>" employs the CNN model in Deeppromise; "DCB<sub>RGloVe</sub>" represents a self-built DCB model, including the DCNN and the BiLSTM stage; "DCNN<sub>RGloVe</sub>" denotes the DCB<sub>RGloVe</sub> removing the BiLSTM stage; "BiLSTM<sub>RGloVe</sub>" represents the DCB<sub>RGloVe</sub> without the DCNN stage</p></caption><graphic xlink:href="12859_2022_4756_Fig2_HTML" id="MO2"/></fig><table-wrap id="Tab2"><label>Table 2</label><caption><p>Evaluation results of the different models trained on the fivefold cross-validation</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Modification type</th><th align="left">Classifiers</th><th align="left">AUROC</th><th align="left">Acc (%)</th><th align="left">Sn (%)</th><th align="left">Sp (%)</th><th align="left">MCC (%)</th><th align="left">Pre (%)</th><th align="left">F1 (%)</th><th align="left">AUPRC</th><th align="left">Time (s)</th></tr></thead><tbody><tr><td align="left" rowspan="4">m<sup>1</sup>A</td><td align="left">CNN<sub>RGloVe</sub></td><td char="." align="char">0.9248</td><td char="." align="char">94.06</td><td char="." align="char"><bold>66.95</bold></td><td char="." align="char">96.78</td><td char="." align="char">63.97</td><td char="." align="char">67.52</td><td char="." align="char">67.23</td><td char="." align="char">0.7147</td><td align="left">127</td></tr><tr><td align="left">DCNN<sub>RGloVe</sub></td><td char="." align="char">0.9305</td><td char="." align="char">94.22</td><td char="." align="char">58.01</td><td char="." align="char">97.84</td><td char="." align="char">61.97</td><td char="." align="char">72.88</td><td char="." align="char">64.60</td><td char="." align="char">0.7155</td><td align="left">96</td></tr><tr><td align="left">BiLSTM<sub>RGloVe</sub></td><td char="." align="char">0.9260</td><td char="." align="char">93.02</td><td char="." align="char">66.44</td><td char="." align="char">95.68</td><td char="." align="char">59.63</td><td char="." align="char">60.62</td><td char="." align="char">63.40</td><td char="." align="char">0.6980</td><td align="left">2104</td></tr><tr><td align="left">DCB<sub>RGloVe</sub></td><td char="." align="char"><bold>0.9377</bold></td><td char="." align="char"><bold>94.62</bold></td><td char="." align="char">61.72</td><td char="." align="char"><bold>97.91</bold></td><td char="." align="char"><bold>65.04</bold></td><td char="." align="char"><bold>74.69</bold></td><td char="." align="char"><bold>67.59</bold></td><td char="." align="char"><bold>0.7356</bold></td><td align="left">1809</td></tr><tr><td align="left" rowspan="4">m<sup>6</sup>A</td><td align="left">CNN<sub>RGloVe</sub></td><td char="." align="char">0.8281</td><td char="." align="char">74.93</td><td char="." align="char">81.84</td><td char="." align="char">68.22</td><td char="." align="char">50.47</td><td char="." align="char">71.44</td><td char="." align="char">76.29</td><td char="." align="char">0.8009</td><td align="left">5264</td></tr><tr><td align="left">DCNN<sub>RGloVe</sub></td><td char="." align="char">0.8355</td><td char="." align="char">75.79</td><td char="." align="char">82.48</td><td char="." align="char">69.29</td><td char="." align="char">52.18</td><td char="." align="char">72.29</td><td char="." align="char">77.05</td><td char="." align="char">0.8103</td><td align="left">18,732</td></tr><tr><td align="left">BiLSTM<sub>RGloVe</sub></td><td char="." align="char">0.7885</td><td char="." align="char">71.42</td><td char="." align="char"><bold>83.87</bold></td><td char="." align="char">59.33</td><td char="." align="char">44.48</td><td char="." align="char">66.70</td><td char="." align="char">74.31</td><td char="." align="char">0.7564</td><td align="left">131,340</td></tr><tr><td align="left">DCB<sub>RGloVe</sub></td><td char="." align="char"><bold>0.8432</bold></td><td char="." align="char"><bold>76.46</bold></td><td char="." align="char">79.30</td><td char="." align="char"><bold>73.65</bold></td><td char="." align="char"><bold>53.03</bold></td><td char="." align="char"><bold>74.96</bold></td><td char="." align="char"><bold>77.07</bold></td><td char="." align="char"><bold>0.8199</bold></td><td align="left">21,638</td></tr></tbody></table><table-wrap-foot><p>The bolded values represent the best results</p></table-wrap-foot></table-wrap></p>
      <p id="Par38">Verifies that the single-scale convolution kernel in CNN is challenging to learn deep semantics from RNA sequences. On the contrary, the multiscale convolution kernels can extract additional features to provide deep semantics.</p>
      <p id="Par39">In addition, the study compared the performance of DCB<sub>RGloVe</sub> and DCNN<sub>RGloVe</sub>. The AUROC of DCB<sub>RGloVe</sub> is 0.72% and 0.77% higher than DCNN<sub>RGloVe</sub>’s on m<sup>1</sup>A and m<sup>6</sup>A, respectively, and the AUPRC of DCB<sub>RGloVe</sub> is 2.01% and 0.96% higher than DCNN<sub>RGloVe</sub>’s on m<sup>1</sup>A and m<sup>6</sup>A, respectively. The reason may be that DCNN has no memory function and cannot learn sequential correlations. On the contrary, DCB can capture the local correlation of different spatial structures according to DCNN and effectively learn the context of each <italic>k</italic>-mer in the text according to BiLSTM. In summary, DCB can understand sequence semantics more accurately than other methods.</p>
      <p id="Par40">Finally, the study compared the running time of DCB<sub>RGloVe</sub> and BiLSTM<sub>RGloVe</sub>. Although many factors affect the model's training time, the experiment results show that the training time of BiLSTM<sub>RGloVe</sub> is very long, for it is several times that of DCB<sub>RGloVe</sub>. The reason is that the max-pooling layer of the DCNN stage reduces the parameters of the network, which plays an active role in lowering dimensionality and computational complexity.</p>
      <p id="Par41">In conclusion, the DCB<sub>RGloVe</sub> classifier could effectively and quickly capture the sequence details on m<sup>1</sup>A and m<sup>6</sup>A modification sites.</p>
    </sec>
    <sec id="Sec6">
      <title>Comparison with other different feature encoding methods</title>
      <p id="Par42">Besides, the following content compared the prediction performance of the four feature encoding methods. The experiment encoded the sequences by our RGloVe and the three commonly used schemes, RNA word embedding, One-hot encoding, and word2vec, respectively, then applied the same DCB model to predict the modification site on the same independent dataset. The comparison results demonstrate that RGloVe outperforms the other three encoding techniques in predicting AUROC, as shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref> and Table <xref rid="Tab3" ref-type="table">3</xref>. In the sense of exactly, for m<sup>1</sup>A and m<sup>6</sup>A sites, DCB<sub>RGloVe</sub> achieved AUROC 0.9468 and 0.8486 and more accurately than other methods. The reason is that the One-hot encoding and RNA word embedding emphasize local semantic information, and Word2vec encoding highlights the context windows information, but the above three encodings ignore the global information. RGloVe inherits the advantages of GloVe, which combines the benefits of global matrix factorization and local context approaches [<xref ref-type="bibr" rid="CR37">37</xref>]. Therefore, RGloVe can improve the model prediction accuracy according to this advantage.<fig id="Fig3"><label>Fig. 3</label><caption><p>Performance of the DCB model based on One-hot encoding, RNA word embedding, Word2vec, and RGloVe</p></caption><graphic xlink:href="12859_2022_4756_Fig3_HTML" id="MO3"/></fig><table-wrap id="Tab3"><label>Table 3</label><caption><p>Evaluation results of the DCB model based on One-hot encoding, RNA word embedding, Word2vec, and RGloVe</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Modification type</th><th align="left">Classifiers</th><th align="left">AUROC</th><th align="left">Acc (%)</th><th align="left">Sn (%)</th><th align="left">Sp (%)</th><th align="left">MCC (%)</th><th align="left">Pre (%)</th><th align="left">F1 (%)</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left" rowspan="4">m<sup>1</sup>A</td><td align="left">DCB<sub>One-hot</sub></td><td char="." align="char">0.9410</td><td char="." align="char">95.37</td><td char="." align="char">64.04</td><td char="." align="char">98.51</td><td char="." align="char">69.66</td><td char="." align="char">81.11</td><td char="." align="char">71.57</td><td char="." align="char">0.7812</td></tr><tr><td align="left">DCB<sub>Embedding</sub></td><td char="." align="char">0.9409</td><td char="." align="char">95.37</td><td char="." align="char"><bold>65.79</bold></td><td char="." align="char">98.33</td><td char="." align="char">70.0</td><td char="." align="char">79.79</td><td char="." align="char"><bold>72.12</bold></td><td char="." align="char">0.7715</td></tr><tr><td align="left">DCB<sub>word2vec</sub></td><td char="." align="char">0.9316</td><td char="." align="char">95.29</td><td char="." align="char">61.4</td><td char="." align="char"><bold>98.68</bold></td><td char="." align="char">68.72</td><td char="." align="char"><bold>82.35</bold></td><td char="." align="char">70.35</td><td char="." align="char">0.7349</td></tr><tr><td align="left">DCB<sub>RGloVe</sub></td><td char="." align="char"><bold>0.9468</bold></td><td char="." align="char"><bold>95.45</bold></td><td char="." align="char">64.04</td><td char="." align="char">98.6</td><td char="." align="char"><bold>70.12</bold></td><td char="." align="char">82.02</td><td char="." align="char">71.92</td><td char="." align="char"><bold>0.7866</bold></td></tr><tr><td align="left" rowspan="4">m<sup>6</sup>A</td><td align="left">DCB<sub>One-hot</sub></td><td char="." align="char">0.8300</td><td char="." align="char">74.51</td><td char="." align="char">72.25</td><td char="." align="char"><bold>76.76</bold></td><td char="." align="char">49.06</td><td char="." align="char"><bold>75.57</bold></td><td char="." align="char">73.87</td><td char="." align="char">0.8080</td></tr><tr><td align="left">DCB<sub>Embedding</sub></td><td char="." align="char">0.8477</td><td char="." align="char"><bold>76.52</bold></td><td char="." align="char">83.30</td><td char="." align="char">69.79</td><td char="." align="char"><bold>53.56</bold></td><td char="." align="char">73.28</td><td char="." align="char">77.97</td><td char="." align="char">0.8272</td></tr><tr><td align="left">DCB<sub>word2vec</sub></td><td char="." align="char">0.8317</td><td char="." align="char">75.10</td><td char="." align="char">79.60</td><td char="." align="char">70.62</td><td char="." align="char">50.43</td><td char="." align="char">72.95</td><td char="." align="char">76.13</td><td char="." align="char">0.8126</td></tr><tr><td align="left">DCB<sub>RGloVe</sub></td><td char="." align="char"><bold>0.8486</bold></td><td char="." align="char">76.36</td><td char="." align="char"><bold>84.2</bold></td><td char="." align="char">68.57</td><td char="." align="char">53.41</td><td char="." align="char">72.72</td><td char="." align="char"><bold>78.04</bold></td><td char="." align="char"><bold>0.8310</bold></td></tr></tbody></table><table-wrap-foot><p>The bolded values represent the best results</p></table-wrap-foot></table-wrap></p>
      <p id="Par43">In summary, RGloVe shows higher semantic accuracy than the other three commonly used schemes.</p>
    </sec>
    <sec id="Sec7">
      <title>Comparison with state-of-the-art approaches</title>
      <p id="Par44">Finally, EMDLP was compared with other state-of-the-art approaches on the same independent datasets, such as DeepPromise [<xref ref-type="bibr" rid="CR12">12</xref>] and EDLm<sup>6</sup>Apred [<xref ref-type="bibr" rid="CR16">16</xref>]. To make the comparison more illustrative, we built DCB<sub>DeepPromise</sub> by replacing the CNN model in DeepPromise with DCB, and our EMDLP replaced the ENAC encoding in DCB<sub>DeepPromise</sub> with RGloVe.</p>
      <p id="Par45">In order to evaluate the reliability of the model, the EDLm<sup>6</sup>Apred, DeepPromise, DCBDeepPromise, and EMDLP models were performed 100 replicate experiments on the same independent test sets of m<sup>1</sup>A and m<sup>6</sup>A, respectively. In each replicate, new evaluation results were produced. As shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>, Table <xref rid="Tab4" ref-type="table">4</xref>, and Fig. <xref rid="Fig5" ref-type="fig">5</xref>, the AUROC and AUPRC of EMDLP are better than other approaches. The reason may be that ENAC, One-hot, and RNA word embeddings focus on local semantic information, and Word2vec encoding considers context window information, but none of them pay attention to global statistical information. At the same time, RGloVe can represent semantic information sequences more comprehensively than the other four encodings. And DCB is more suitable for extracting the RNA sequence's features than the other methods. Furthermore, We test the statistical significance of AUROC values between different tools by the student’s <italic>t</italic>-test [<xref ref-type="bibr" rid="CR39">39</xref>], as shown in Table <xref rid="Tab5" ref-type="table">5</xref>.<fig id="Fig4"><label>Fig. 4</label><caption><p>Performance of EMDLP and other methods on the independent test</p></caption><graphic xlink:href="12859_2022_4756_Fig4_HTML" id="MO4"/></fig><table-wrap id="Tab4"><label>Table 4</label><caption><p>Compare EMDLP model</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Modification type</th><th align="left">Classifiers</th><th align="left">AUROC</th><th align="left">Acc (%)</th><th align="left">Sn (%)</th><th align="left">Sp (%)</th><th align="left">MCC (%)</th><th align="left">Pre (%)</th><th align="left">F1 (%)</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left" rowspan="4">m<sup>1</sup>A</td><td align="left">EDLm<sup>6</sup>Apred</td><td char="." align="char">0.9494</td><td char="." align="char">95.06</td><td char="." align="char">64.91</td><td char="." align="char">98.07</td><td char="." align="char">68.10</td><td char="." align="char">77.08</td><td char="." align="char">70.47</td><td char="." align="char">0.7773</td></tr><tr><td align="left">DeepPromise</td><td char="." align="char">0.9437</td><td char="." align="char">95.30</td><td char="." align="char">65.79</td><td char="." align="char">98.25</td><td char="." align="char">69.57</td><td char="." align="char">78.95</td><td char="." align="char">71.77</td><td char="." align="char">0.7893</td></tr><tr><td align="left">DCB<sub>DeepPromise</sub></td><td char="." align="char">0.9529</td><td char="." align="char">95.61</td><td char="." align="char"><bold>67.54</bold></td><td char="." align="char">98.42</td><td char="." align="char"><bold>71.67</bold></td><td char="." align="char">81.05</td><td char="." align="char"><bold>73.68</bold></td><td char="." align="char">0.7809</td></tr><tr><td align="left">EMDLP</td><td char="." align="char"><bold>0.9556</bold></td><td char="." align="char"><bold>95.62</bold></td><td char="." align="char">61.40</td><td char="." align="char"><bold>99.04</bold></td><td char="." align="char">70.69</td><td char="." align="char"><bold>86.42</bold></td><td char="." align="char">71.79</td><td char="." align="char"><bold>0.8044</bold></td></tr><tr><td align="left" rowspan="4">m<sup>6</sup>A</td><td align="left">EDLm<sup>6</sup>APred</td><td char="." align="char">0.8085</td><td char="." align="char">73.38</td><td char="." align="char">80.14</td><td char="." align="char">66.66</td><td char="." align="char">47.23</td><td char="." align="char">70.52</td><td char="." align="char">75.02</td><td char="." align="char">0.7905</td></tr><tr><td align="left">DeepPromise</td><td char="." align="char">0.8476</td><td char="." align="char"><bold>77.07</bold></td><td char="." align="char">82.15</td><td char="." align="char">45.00</td><td char="." align="char">54.43</td><td char="." align="char"><bold>74.79</bold></td><td char="." align="char">78.30</td><td char="." align="char">0.8258</td></tr><tr><td align="left">DCB<sub>DeepPromise</sub></td><td char="." align="char">0.8501</td><td char="." align="char">76.76</td><td char="." align="char">81.89</td><td char="." align="char">44.95</td><td char="." align="char">53.81</td><td char="." align="char">74.19</td><td char="." align="char">77.85</td><td char="." align="char">0.8292</td></tr><tr><td align="left">EMDLP</td><td char="." align="char"><bold>0.8524</bold></td><td char="." align="char">76.98</td><td char="." align="char"><bold>84.36</bold></td><td char="." align="char"><bold>69.64</bold></td><td char="." align="char"><bold>54.58</bold></td><td char="." align="char">73.44</td><td char="." align="char"><bold>78.52</bold></td><td char="." align="char"><bold>0.8319</bold></td></tr></tbody></table><table-wrap-foot><p>The bolded values represent the best results</p></table-wrap-foot></table-wrap><fig id="Fig5"><label>Fig. 5</label><caption><p>Boxplot of eight metrics for comparative performance assessment of the four methods based on the pAerformance of 100 replications of four methods. <bold>a</bold> for the m<sup>1</sup>A independent dataset. <bold>b</bold> for the m<sup>6</sup>A independent dataset</p></caption><graphic xlink:href="12859_2022_4756_Fig5_HTML" id="MO5"/></fig><table-wrap id="Tab5"><label>Table 5</label><caption><p>Statistically significant correlation matrix for the difference in the performance of the four classifiers</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Modification type</th><th align="left" rowspan="2">Classifiers</th><th align="left" colspan="4">Classifiers</th></tr><tr><th align="left">EDLm<sup>6</sup>APred</th><th align="left">DeepPromise</th><th align="left">DCB<sub>DeepPromise</sub></th><th align="left">EMDLP</th></tr></thead><tbody><tr><td align="left" rowspan="4">m<sup>1</sup>A</td><td align="left">EDLm<sup>6</sup>APred</td><td align="left"/><td align="left"/><td char="." align="char"/><td align="left"/></tr><tr><td align="left">DeepPromise</td><td align="left">6.80137E-27</td><td align="left"/><td char="." align="char"/><td align="left"/></tr><tr><td align="left">DCB<sub>DeepPromise</sub></td><td align="left">2.14723E-11</td><td align="left">5.22548E-34</td><td char="." align="char"/><td align="left"/></tr><tr><td align="left">EMDLP</td><td align="left">8.734E-20</td><td align="left">4.51535E-37</td><td char="." align="char">0.01606677</td><td align="left"/></tr><tr><td align="left" rowspan="4">m<sup>6</sup>A</td><td align="left">EDLm<sup>6</sup>APred</td><td align="left"/><td align="left"/><td char="." align="char"/><td align="left"/></tr><tr><td align="left">DeepPromise</td><td align="left">1.7731E-122</td><td align="left"/><td char="." align="char"/><td align="left"/></tr><tr><td align="left">DCB<sub>DeepPromise</sub></td><td align="left">3.3248E-133</td><td align="left">2.05181E-42</td><td char="." align="char"/><td align="left"/></tr><tr><td align="left">EMDLP</td><td align="left">8.6672E-142</td><td align="left">6.72773E-87</td><td char="." align="char">3.06352E-20</td><td align="left"/></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec8">
      <title>Webserver</title>
      <p id="Par46">We established an online webserver to simultaneously identify m<sup>1</sup>A and m.<sup>6</sup>A modifications in H. sapiens to facilitate scientific research. The user-friendly webserver for EMDLP was publicly available at <ext-link ext-link-type="uri" xlink:href="http://www.labiip.net/EMDLP/index.php">http://www.labiip.net/EMDLP/index.php</ext-link> (<ext-link ext-link-type="uri" xlink:href="http://47.104.130.81/EMDLP/index.php">http://47.104.130.81/EMDLP/index.php</ext-link>). The usage guide of the webserver for EMDLP is as follows. Open the home page at <ext-link ext-link-type="uri" xlink:href="http://www.labiip.net/EMDLP/index.php">http://www.labiip.net/EMDLP/index.php</ext-link> (<ext-link ext-link-type="uri" xlink:href="http://47.104.130.81/EMDLP/index.php">http://47.104.130.81/EMDLP/index.php</ext-link>). First, clicking the "Prediction" button and selecting the "m<sup>1</sup>A" or"m<sup>6</sup>A" successively, the page will appear, as shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>a. Second, Type or paste an RNA sequence in the input box. Third, leave your email in the input box, clicking the "submit" button, and the predictive results will appear on a new page, as shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>b.<fig id="Fig6"><label>Fig. 6</label><caption><p>Screenshot of EMDLP webserver. <bold>a</bold> Site input interface of EMDLP. <bold>b</bold> The prediction result returned by EMDLP</p></caption><graphic xlink:href="12859_2022_4756_Fig6_HTML" id="MO6"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec9">
    <title>Discussion</title>
    <p id="Par47">This paper proposes EMDLP to identify RNA methylation sites in an NLP and DL way. The specific discussion is as follows:</p>
    <p id="Par48">Firstly, this study compared the performance of predicting m<sup>1</sup>A and m<sup>6</sup>A methylation sites under four different sliding window sizes (i.e., 8, 15, 30, and 60) based on the RGloVe and GloVe encoding methods. The evaluation results show that using RMSProp instead of Adagrad to minimize the loss function of the global vector model can indeed train the model more effectively. This result is consistent with that of Ruder, S. (2017), who pointed out that RMSProp can overcome the weakness of Adagrad. RGloVe shows the best prediction performance when the sliding window length = 30.</p>
    <p id="Par49">Secondly, based on the feature representation of the sequence by the above RGloVe, this study compared the DCB model with the CNN, DCNN, and BiLSTM models for predicting methylation modification sites. The experiment result shows the AUROC of DCNN<sub>RGloVe</sub> is 0.57% and 0.74% higher than CNN<sub>RGloVe</sub>'s on m<sup>1</sup>A and m<sup>6</sup>A. This study confirms that the multiscale convolution kernels can extract different features to provide deep semantics. The experiment results show that the training time of BiLSTM<sub>RGloVe</sub> is very long, and it is several times that of DCB<sub>RGloVe</sub>. That also accords with Min, X.’s conclusion, which showed that the max-pooling layer of the DCNN stage reduces the parameters of the network, which plays an active role in lowering dimensionality and computational complexity. The experimental results show that the DCB<sub>RGloVe</sub> model is superior to other models in predicting m<sup>1</sup>A and m<sup>6</sup>A sites. This study confirms that the combination of DCNN and BiLSTM makes the understanding of sequence semantics more accurate.</p>
    <p id="Par50">Third, based on the above self-built DCB model, this paper compared the prediction performance of RGloVe, RNA word embedding, One-hot encoding, and word2vec. The results reveal that Our RGloVe outperforms the other three encoding schemes in prediction performance. This finding is consistent with Pennington, J (2014), who proposed that GloVe shows higher semantic accuracy than word2vec.</p>
    <p id="Par51">Finally, EMDLP was constructed by a soft vote to use the three predictors to obtain better predictive performance. This paper compared the prediction performance of EMDLP, DeepPromise, DCB<sub>DeepPromise</sub>, and EDLm<sup>6</sup>Apred based on the independent datasets. The results show that the AUROC of EMDLP is significantly better than the three methods. This study further indicates that RGloVe can better represent the semantic information of sequences than the other four encodings, and DCB is more suitable for extracting the RNA sequence's features than the other methods.</p>
  </sec>
  <sec id="Sec10">
    <title>Conclusions</title>
    <p id="Par52">The contribution of this paper proposes a predictor EMDLP to identify RNA methylation sites by NLP and DL way. It organically combines the dilated convolution and BiLSTM, which helps take better advantage of the local and global information for site prediction.</p>
    <p id="Par53">Although EMDLP outperforms state-of-the-art predictors, which is currently limited to humans and has not been extended to other model organisms due to the lack of a sufficient number of single-nucleotide datasets for other species. It is worth looking forward to testing the performance of EMDLP when sufficient other species RNA modification datasets become available in the future.</p>
  </sec>
  <sec id="Sec11">
    <title>Materials and methods</title>
    <sec id="Sec12">
      <title>Datasets</title>
      <p id="Par54">We have extracted two common types of human RNA modification site datasets published at single-nucleotide resolution, including m<sup>1</sup>A and m<sup>6</sup>A. For the m<sup>1</sup>A and m<sup>6</sup>A sites, the datasets in this paper were derived from the previous studies of Chen et al. [<xref ref-type="bibr" rid="CR12">12</xref>] and Zou et al. [<xref ref-type="bibr" rid="CR30">30</xref>], respectively. The only difference is that the Zou validation set was used as the independent test set of this paper on the m<sup>6</sup>A site.</p>
      <p id="Par55">The study divided the dataset into two parts: a benchmark dataset for cross-validation testing and an independent dataset for independent testing. It took the modified/non-modified site as the center for each sample and brought the (2n + 1)-nt partial sequence window. It was worth noting that the "n" for these two modifications was different. Referring to the experimental results in Chen’s paper, the size of the optimal window was 101 and 1001 for m<sup>1</sup>A and m<sup>6</sup>A sites[<xref ref-type="bibr" rid="CR12">12</xref>], respectively. If the length of the original sequences were shorter than 2n + 1, the empty positions would be filled with the character "-" to ensure the sequence length is consistent. The ratio of positive and negative samples of m<sup>1</sup>A sites and m<sup>6</sup>A sites was 1:10 and 1:1, respectively. The statistic of these two RNA modification datasets is shown in Table <xref rid="Tab6" ref-type="table">6</xref>.<table-wrap id="Tab6"><label>Table 6</label><caption><p>A statistical of these two RNA modification datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Modification type</th><th align="left">Dataset</th><th align="left">Window size</th><th align="left">Number of positive samples</th><th align="left">Number of negative samples</th></tr></thead><tbody><tr><td align="left">m<sup>1</sup>A</td><td align="left">m<sup>1</sup>A_BM</td><td align="left">101</td><td align="left">593</td><td align="left">5930</td></tr><tr><td align="left">m<sup>1</sup>A</td><td align="left">m<sup>1</sup>A_IND</td><td align="left">101</td><td align="left">114</td><td align="left">1140</td></tr><tr><td align="left">m<sup>6</sup>A</td><td align="left">m<sup>6</sup>A_ BM</td><td align="left">1001</td><td align="left">26,586</td><td align="left">27,371</td></tr><tr><td align="left">m<sup>6</sup>A</td><td align="left">m<sup>6</sup>A_IND</td><td align="left">1001</td><td align="left">6879</td><td align="left">6914</td></tr></tbody></table><table-wrap-foot><p><italic>BM</italic> benchmark; <italic>IND</italic> independent</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec13">
      <title>Feature encoding representation on different perspectives</title>
      <p id="Par56">As we all know, feature encoding is the key to evaluating the excellent performance of site prediction models. This paper encodes the sequences by RNA word embedding, One-hot encoding, and RGloVe.</p>
      <p id="Par57">One-hot encoding is a sparse binary, high-dimensional word vector, while RNA word embedding is a continuous, low-dimensional dense word vector that captures the local semantic information. RGloVe inherits the principle of GloVe, which captures the global semantic information.</p>
      <p id="Par58">One-hot encoding is a very simple encoding method to describe the nucleotides sequence. The four nucleotides and the the gap symbol "-" are encoded as <inline-formula id="IEq2"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sum { = \{ {\text{A}},{\text{C}},{\text{G}},{\text{T}}, - \} }$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:mo>∑</mml:mo><mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mtext>A</mml:mtext><mml:mo>,</mml:mo><mml:mtext>C</mml:mtext><mml:mo>,</mml:mo><mml:mtext>G</mml:mtext><mml:mo>,</mml:mo><mml:mtext>T</mml:mtext><mml:mo>,</mml:mo><mml:mo>-</mml:mo><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq2.gif"/></alternatives></inline-formula>, where A = (1,0,0,0,0), C = (0,1,0,0,0), G = (0,0,1,0,0), T = (0,0,0,1,0), and "-" = (0,0,0,0,1). Take m<sup>1</sup>A as an example, a sequence of 101nts is transformed to 505-bit vectors.</p>
      <p id="Par59">RNA word embedding is a standard method for encoding RNA sequences. A sliding window of size k slides on the RNA sequence by overlapping an equal length to form a <italic>k</italic>-mer sub-sequence, and these sub-sequences are created as a vocabulary. Take m<sup>1</sup>A as an example. A sequence of 101nts is converted to 99 sub-sequence through a sliding window of size 3. The study obtained 105 different sub-sequences, which are indexed by a unique integer index. Each pre-processed sequence is changed with an integer index and fed into the Keras embedding layer to generate 300-dimension word vectors. Thus, the 101nts sequences are transformed into a matrix of 99 × 300.</p>
      <p id="Par60">RNA word embedding only considers the frequency information but neglects the context and global information. Word2vec only trains independently by information from each local context window, while it does not use the statistical data in the global co-occurrence matrix [<xref ref-type="bibr" rid="CR35">35</xref>]. Pennington et al. [<xref ref-type="bibr" rid="CR40">40</xref>] proposed global vectors(GloVe) that can consider the statistical data in the global co-occurrence matrix and used Adagrad to train GloVe word embeddings [<xref ref-type="bibr" rid="CR41">41</xref>]. But, Adagrad has a primary weakness, which can cause the learning rate of Adagrad to decrease and get extremely small, at which point the algorithm can not learn new information [<xref ref-type="bibr" rid="CR41">41</xref>]. Therefore, the study uses RMSProp instead of Adagrad to minimize the loss function of the global vector model. The word vector trained by this method is called RGloVe. The specific analysis process is as follows.</p>
      <p id="Par61">The statistics of <italic>k</italic>-mer incidence is the most important data source for learning embedding representations. <italic>Y</italic> denotes the matrix of co-occurrence counts, and <italic>Y</italic><sub><italic>ij</italic></sub> records the frequency of the word <italic>k</italic>-mer <inline-formula id="IEq3"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M18"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq3.gif"/></alternatives></inline-formula> appearing in the context sliding windows of the word <italic>k</italic>-mer <italic>i</italic>. <inline-formula id="IEq4"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i,\,j \in \left[ {1,\,W} \right]$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mi>W</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq4.gif"/></alternatives></inline-formula> are two <italic>k</italic>-mer indexes, the vocabulary size <italic>W</italic> = 105. According to the GloVe model, we get the embedding vector by training the cost function under,<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K = \sum\limits_{i,\,j = 1}^{W} {f(Y_{ij} )({\mathbf{e}}_{i}^{T} \widetilde{{\mathbf{e}}}_{j} + b_{i} + \widetilde{b}_{j} - \log Y_{ij} )^{2} }$$\end{document}</tex-math><mml:math id="M22" display="block"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>W</mml:mi></mml:munderover><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="bold">e</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>b</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mo>log</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq5"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e \in \mathbb{R}^{D}$$\end{document}</tex-math><mml:math id="M24"><mml:mrow><mml:mi>e</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq5.gif"/></alternatives></inline-formula> are expected embedding vectors, <inline-formula id="IEq6"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{\tilde{e}}} \in \mathbb{R}^{D}$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq6.gif"/></alternatives></inline-formula> are separate context <italic>k</italic>-mer vectors that help obtain <inline-formula id="IEq7"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{e}}$$\end{document}</tex-math><mml:math id="M28"><mml:mi mathvariant="bold">e</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq7.gif"/></alternatives></inline-formula>, <inline-formula id="IEq8"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b,\,\widetilde{b} \in {\mathbb{R}}$$\end{document}</tex-math><mml:math id="M30"><mml:mrow><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mover accent="true"><mml:mi>b</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq8.gif"/></alternatives></inline-formula> are the biases for <inline-formula id="IEq9"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{e}},\,\widetilde{{\mathbf{e}}}$$\end{document}</tex-math><mml:math id="M32"><mml:mrow><mml:mi mathvariant="bold">e</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq9.gif"/></alternatives></inline-formula> respectively. <inline-formula id="IEq10"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f(y)$$\end{document}</tex-math><mml:math id="M34"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq10.gif"/></alternatives></inline-formula> is a non-decreasing weighting function below<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f(y) = \left\{ {\begin{array}{*{20}c} {(y/y_{\max } )^{\beta } \begin{array}{*{20}c} {} &amp; {if\begin{array}{*{20}c} {} &amp; {y^{{}} { &lt; }^{{}} y_{\max } } \\ \end{array} } \\ \end{array} } \\ {1\begin{array}{*{20}c} {} &amp; {} &amp; {} &amp; {{\text{otherwise}}} \\ \end{array} } \\ \end{array} } \right.$$\end{document}</tex-math><mml:math id="M36" display="block"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mo movablelimits="true">max</mml:mo></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>β</mml:mi></mml:msup><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mrow/></mml:msup><mml:msup><mml:mrow><mml:mo>&lt;</mml:mo></mml:mrow><mml:mrow/></mml:msup><mml:msub><mml:mi>y</mml:mi><mml:mo movablelimits="true">max</mml:mo></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mtext>otherwise</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq11"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_{\max }$$\end{document}</tex-math><mml:math id="M38"><mml:msub><mml:mi>y</mml:mi><mml:mo movablelimits="true">max</mml:mo></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq11.gif"/></alternatives></inline-formula> is a maximum cutoff value and <inline-formula id="IEq12"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\beta$$\end{document}</tex-math><mml:math id="M40"><mml:mi>β</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq12.gif"/></alternatives></inline-formula> denotes the fractional power scaling, which is commonly 0.75.</p>
      <p id="Par62">The original GloVe uses Adagrad [<xref ref-type="bibr" rid="CR42">42</xref>] to minimize Eq. (<xref rid="Equ7" ref-type="">7</xref>). At every time step <inline-formula id="IEq13"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t$$\end{document}</tex-math><mml:math id="M42"><mml:mi>t</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq13.gif"/></alternatives></inline-formula>, the specific iterative rules are as follows:<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$z_{{t,{\kern 1pt} i}} = \nabla_{{\phi_{t} }} F(\phi_{t,\,i} )$$\end{document}</tex-math><mml:math id="M44" display="block"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width="1.0pt"/><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq14"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$z_{t,\,i}$$\end{document}</tex-math><mml:math id="M46"><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq14.gif"/></alternatives></inline-formula> indicates the gradient of the objective function, <inline-formula id="IEq15"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi_{t,\,i}$$\end{document}</tex-math><mml:math id="M48"><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq15.gif"/></alternatives></inline-formula> is the parameter at a time step <inline-formula id="IEq16"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t$$\end{document}</tex-math><mml:math id="M50"><mml:mi>t</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq16.gif"/></alternatives></inline-formula>. The Adagrad update for every parameter <inline-formula id="IEq17"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi_{t,\,i}$$\end{document}</tex-math><mml:math id="M52"><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq17.gif"/></alternatives></inline-formula> at each time step <inline-formula id="IEq18"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t$$\end{document}</tex-math><mml:math id="M54"><mml:mi>t</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq18.gif"/></alternatives></inline-formula> are as follows:<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi_{t + 1,\,i} = \phi_{t,\,i} - \frac{\alpha }{{\sqrt {Z_{t,\,ii} + \delta } }} \cdot z_{t,\,i}$$\end{document}</tex-math><mml:math id="M56" display="block"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mfrac><mml:mi>α</mml:mi><mml:msqrt><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:msqrt></mml:mfrac><mml:mo>·</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq19"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}</tex-math><mml:math id="M58"><mml:mi>α</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq19.gif"/></alternatives></inline-formula> indicates the learning rate, <inline-formula id="IEq20"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Z_{t,\,ii} \in {\mathbb{R}}^{d \times d}$$\end{document}</tex-math><mml:math id="M60"><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq20.gif"/></alternatives></inline-formula> is a diagonal matrix where each diagonal element <italic>i</italic>, <italic>i</italic> is the sum of the gradients' squares. <inline-formula id="IEq21"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi_{t,\,i}$$\end{document}</tex-math><mml:math id="M62"><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq21.gif"/></alternatives></inline-formula> up to time step <italic>t</italic>, δ is commonly 1 <inline-formula id="IEq22"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e$$\end{document}</tex-math><mml:math id="M64"><mml:mi>e</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq22.gif"/></alternatives></inline-formula> − 8.</p>
      <p id="Par63">The primary deficiency of Adagrad is its accumulation of the squared gradients in the denominator, at which point the algorithm stops learning new information [<xref ref-type="bibr" rid="CR41">41</xref>]. The RMSprop algorithm solves this flaw by reducing its monotonically decreasing learning rate. RMSprop does not accumulate all past square gradients but limits the window of accumulated past gradients to a fixed size <inline-formula id="IEq23"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\xi$$\end{document}</tex-math><mml:math id="M66"><mml:mi>ξ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq23.gif"/></alternatives></inline-formula>. The total of gradients is recursively defined as a decaying average of all past square gradients rather than merely keeping <inline-formula id="IEq24"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\xi$$\end{document}</tex-math><mml:math id="M68"><mml:mi>ξ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq24.gif"/></alternatives></inline-formula> previous square gradients [<xref ref-type="bibr" rid="CR41">41</xref>]. At time step <inline-formula id="IEq25"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t$$\end{document}</tex-math><mml:math id="M70"><mml:mi>t</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq25.gif"/></alternatives></inline-formula>, the running average <inline-formula id="IEq26"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$E\left[ {z^{2} } \right]_{t}$$\end{document}</tex-math><mml:math id="M72"><mml:mrow><mml:mi>E</mml:mi><mml:msub><mml:mfenced close="]" open="["><mml:msup><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfenced><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq26.gif"/></alternatives></inline-formula> depends on the previous average <inline-formula id="IEq27"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$E\left[ {z^{2} } \right]_{{t{ - 1}}}$$\end{document}</tex-math><mml:math id="M74"><mml:mrow><mml:mi>E</mml:mi><mml:msub><mml:mfenced close="]" open="["><mml:msup><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfenced><mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq27.gif"/></alternatives></inline-formula> and the current gradient <inline-formula id="IEq28"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$z_{t}^{2}$$\end{document}</tex-math><mml:math id="M76"><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq28.gif"/></alternatives></inline-formula>:<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$E\left[ {z^{2} } \right]_{t} = \lambda E\left[ {z^{2} } \right]_{t - 1} + (1 - \lambda )z_{t}^{2}$$\end{document}</tex-math><mml:math id="M78" display="block"><mml:mrow><mml:mi>E</mml:mi><mml:msub><mml:mfenced close="]" open="["><mml:msup><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfenced><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mi>E</mml:mi><mml:msub><mml:mfenced close="]" open="["><mml:msup><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfenced><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par64">at each time step <inline-formula id="IEq29"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t$$\end{document}</tex-math><mml:math id="M80"><mml:mi>t</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq29.gif"/></alternatives></inline-formula>, the RMSprop update for every parameter <inline-formula id="IEq30"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi_{t}$$\end{document}</tex-math><mml:math id="M82"><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq30.gif"/></alternatives></inline-formula> below:<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi_{t + 1} = \phi_{t} - \frac{\alpha }{{\sqrt {E\left[ {z^{2} } \right]_{t} + \delta } }} \cdot z_{t}$$\end{document}</tex-math><mml:math id="M84" display="block"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mfrac><mml:mi>α</mml:mi><mml:msqrt><mml:mrow><mml:mi>E</mml:mi><mml:msub><mml:mfenced close="]" open="["><mml:msup><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfenced><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:msqrt></mml:mfrac><mml:mo>·</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par65">The momentum term <inline-formula id="IEq31"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M86"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq31.gif"/></alternatives></inline-formula> is usually set to 0.9 or a similar value, while the learning rate of RMSprop <inline-formula id="IEq32"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}</tex-math><mml:math id="M88"><mml:mi>α</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq32.gif"/></alternatives></inline-formula> is 0.001. We use RMSprop to minimize Eq. (<xref rid="Equ7" ref-type="">7</xref>) and obtained the D-dimensional embedding vector representations <inline-formula id="IEq33"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{e}}_{1} ,{\mathbf{e}}_{2} ,{\mathbf{e}}_{3} , \ldots {\mathbf{e}}_{W} \in \mathbb{R}^{D}$$\end{document}</tex-math><mml:math id="M90"><mml:mrow><mml:msub><mml:mi mathvariant="bold">e</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">e</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">e</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:msub><mml:mi mathvariant="bold">e</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq33.gif"/></alternatives></inline-formula>. According to the vectors, the study has completed the embedding encoding of representation learning <inline-formula id="IEq34"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f_{embedding} (x):{\mathbb{C}}^{L} \mapsto {\mathbb{R}}^{L \times D}$$\end{document}</tex-math><mml:math id="M92"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi mathvariant="italic">embedding</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">C</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msup><mml:mo>↦</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq34.gif"/></alternatives></inline-formula> by embedding each <italic>k</italic>-mer into the vector space <inline-formula id="IEq35"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbb{R}}^{D}$$\end{document}</tex-math><mml:math id="M94"><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq35.gif"/></alternatives></inline-formula>:<disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f_{embedding} ({\mathbf{x}}) = [{\mathbf{e}}_{{x_{1} }} ,{\mathbf{e}}_{{x_{2} }} ,{\mathbf{e}}_{{x_{3} }} , \ldots {\mathbf{e}}_{{x_{L} }} ]$$\end{document}</tex-math><mml:math id="M96" display="block"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi mathvariant="italic">embedding</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi mathvariant="bold">e</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">e</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">e</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:msub><mml:mi mathvariant="bold">e</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par66">where <inline-formula id="IEq36"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{x}} = [x_{1} ,x_{2} ,x_{3} , \ldots ,x_{L} ] \in \mathbb{C}^{L}$$\end{document}</tex-math><mml:math id="M98"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">C</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq36.gif"/></alternatives></inline-formula>. We carried out the convolution stage based on the output <inline-formula id="IEq37"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L \times D$$\end{document}</tex-math><mml:math id="M100"><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq37.gif"/></alternatives></inline-formula> matrix.</p>
      <p id="Par67">Take m<sup>1</sup>A as an example. If the dimension is 300, the 101nts sequences are transformed into a matrix of 99 × 300. Three feature encoding input and output formats are in Table <xref rid="Tab7" ref-type="table">7</xref>.<table-wrap id="Tab7"><label>Table 7</label><caption><p>Input and output formats with three kinds of feature encoding</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Modification type</th><th align="left">Encoding method</th><th align="left">Input</th><th align="left">Output</th></tr></thead><tbody><tr><td align="left" rowspan="3">m<sup>1</sup>A</td><td align="left">One-hot</td><td char="×" align="char">101 × 1</td><td char="×" align="char">101 × 5</td></tr><tr><td align="left">RNA word embedding</td><td char="×" align="char">99 × 3</td><td char="×" align="char">99 × 300</td></tr><tr><td align="left">RGloVe</td><td char="×" align="char">99 × 3</td><td char="×" align="char">99 × 300</td></tr><tr><td align="left" rowspan="3">m<sup>6</sup>A</td><td align="left">One-hot</td><td char="×" align="char">1001 × 1</td><td char="×" align="char">1001 × 5</td></tr><tr><td align="left">RNA word embedding</td><td char="×" align="char">999 × 3</td><td char="×" align="char">999 × 300</td></tr><tr><td align="left">RGloVe</td><td char="×" align="char">999 × 3</td><td char="×" align="char">999 × 300</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec14">
      <title>Dilated convolutional neural network</title>
      <p id="Par68">Holschneider et al. [<xref ref-type="bibr" rid="CR43">43</xref>] were the first to develop dilated convolution, which kept the feature map's resolution by introducing holes into the regular convolution [<xref ref-type="bibr" rid="CR44">44</xref>]. Compared to ordinary convolution, dilated convolution adds a hyperparameter named dilation rate(DR), which corresponds to the number of kernel intervals, such as DR = 1 in ordinary convolution.</p>
      <p id="Par69">When applied to a one-dimensional situation, dilated convolution can be calculated as Eq. (<xref rid="Equ14" ref-type="">14</xref>). Different dilution rates can be regarded as inserting varying sizes of blank rows between each kernel of convolution, as shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S1.<disp-formula id="Equ14"><label>14</label><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_{j}^{{}} = f(\sum\limits_{n = 1}^{N} {x_{j + r*n} \omega_{n} } + b)$$\end{document}</tex-math><mml:math id="M102" display="block"><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mi>r</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ω</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ14.gif" position="anchor"/></alternatives></disp-formula>where <italic>x</italic><sub><italic>j</italic></sub> is the <italic>j</italic>th element of input, <italic>y</italic><sub><italic>j</italic></sub> denotes the output of the <italic>j</italic>th element in the DCNN, <inline-formula id="IEq38"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\omega$$\end{document}</tex-math><mml:math id="M104"><mml:mi>ω</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq38.gif"/></alternatives></inline-formula> is the weight of the filter, <italic>N</italic> is the length of the filter, <italic>r</italic> is known as the DR.</p>
      <p id="Par70">In addition to the dilated convolution, the DCNN comprises the pooling and dropout layer. The pooling layer is applied to each feature map and outputs the average or maximum value of the input in a pooling window so that the pooling layer can reduce the number of parameters.</p>
      <p id="Par71">The dropout layer is used to avoid overfitting during model training and is the most commonly used regularization technique. In each training activity during forwarding propagation, some neurons are randomly set to zero, which intuitively leads to the integration of different networks. The dropout rate is the probability of a neuron withdrawing.</p>
      <p id="Par72">In this study, dilated convolutional layers of three dilation rates(DR = 1, 2, and 3, respectively) are concatenated to send to the BiLSTM stage.</p>
    </sec>
    <sec id="Sec15">
      <title>Bidirectional LSTM</title>
      <p id="Par73">BiLSTM is a specific sort of recurrent neural network(RNN) that combines forward LSTM and backward LSTM. Among them, forward LSTM calculates the hidden features in the forward direction and saves the output at each moment <inline-formula id="IEq39"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overrightarrow {{h_{2} ,}} \,\overrightarrow {{h_{{3}} }} ,\,...\overrightarrow {{h_{5} }}$$\end{document}</tex-math><mml:math id="M106"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mspace width="0.166667em"/><mml:mover accent="true"><mml:msub><mml:mi>h</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>h</mml:mi><mml:mn>5</mml:mn></mml:msub><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq39.gif"/></alternatives></inline-formula>. With the same reasoning, backward LSTM calculates the hidden features in the reverse direction and saves the output at each moment <inline-formula id="IEq40"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overleftarrow {{h_{5} }} ,\,\overleftarrow {{h_{4} }} ,\,...\overleftarrow {{h_{2} }}$$\end{document}</tex-math><mml:math id="M108"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>h</mml:mi><mml:mn>5</mml:mn></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mover accent="true"><mml:msub><mml:mi>h</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq40.gif"/></alternatives></inline-formula>, as shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S2. Ultimately, the final result is derived from merging the output values of the forward and backward LSTM layers at each instant.</p>
      <p id="Par74">The LSTM [<xref ref-type="bibr" rid="CR45">45</xref>] framework addresses the exploding or disappearing gradients in RNNs. Commonly, the LSTM unit is defined as a current input <inline-formula id="IEq41"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{t}$$\end{document}</tex-math><mml:math id="M110"><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq41.gif"/></alternatives></inline-formula>, a memory unit <inline-formula id="IEq42"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C_{t}$$\end{document}</tex-math><mml:math id="M112"><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq42.gif"/></alternatives></inline-formula>, an input modulation vector <inline-formula id="IEq43"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde{{C_{t} }}$$\end{document}</tex-math><mml:math id="M114"><mml:mover accent="true"><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq43.gif"/></alternatives></inline-formula>, a hidden state <inline-formula id="IEq44"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{t}$$\end{document}</tex-math><mml:math id="M116"><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq44.gif"/></alternatives></inline-formula>, a forget gate <inline-formula id="IEq45"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f_{t}$$\end{document}</tex-math><mml:math id="M118"><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq45.gif"/></alternatives></inline-formula>, an input gate <inline-formula id="IEq46"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i_{t}$$\end{document}</tex-math><mml:math id="M120"><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq46.gif"/></alternatives></inline-formula>, and an output gate <inline-formula id="IEq47"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$o_{t}$$\end{document}</tex-math><mml:math id="M122"><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq47.gif"/></alternatives></inline-formula> at the moment <inline-formula id="IEq48"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t$$\end{document}</tex-math><mml:math id="M124"><mml:mi>t</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq48.gif"/></alternatives></inline-formula>, as shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S3.</p>
      <p id="Par75">Among them, a memory unit <inline-formula id="IEq49"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C_{t}$$\end{document}</tex-math><mml:math id="M126"><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq49.gif"/></alternatives></inline-formula> is controlled by three "gates": a forget gate <inline-formula id="IEq50"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f_{t}$$\end{document}</tex-math><mml:math id="M128"><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq50.gif"/></alternatives></inline-formula>, an input gate <inline-formula id="IEq51"><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i_{t}$$\end{document}</tex-math><mml:math id="M130"><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq51.gif"/></alternatives></inline-formula>, and an output gate <inline-formula id="IEq52"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$o_{t}$$\end{document}</tex-math><mml:math id="M132"><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq52.gif"/></alternatives></inline-formula>, where their entries are in [0, 1]. The following are the LSTM transition equations:<disp-formula id="Equ15"><label>15</label><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f_{t} = \sigma (W^{f} x_{t} + U^{f} h_{t - 1} + b^{f} )$$\end{document}</tex-math><mml:math id="M134" display="block"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>U</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ15.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ16"><label>16</label><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i_{t} = \sigma (W^{i} x_{t} + U^{i} h_{t - 1} + b^{i} )$$\end{document}</tex-math><mml:math id="M136" display="block"><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>U</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ16.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ17"><label>17</label><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tilde{C}_{t} = \tanh (W^{c} x_{t} + U^{c} h_{t - 1} + b^{c} )$$\end{document}</tex-math><mml:math id="M138" display="block"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>tanh</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mi>c</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>U</mml:mi><mml:mi>c</mml:mi></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mi>c</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ17.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ18"><label>18</label><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C_{t} = f_{t} * C_{t - 1} + i_{t} * \tilde{C}_{t}$$\end{document}</tex-math><mml:math id="M140" display="block"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ18.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ19"><label>19</label><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$o_{t} = \sigma (W^{o} x_{t} + U^{o} h_{t - 1} + b^{o} )$$\end{document}</tex-math><mml:math id="M142" display="block"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mi>o</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>U</mml:mi><mml:mi>o</mml:mi></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mi>o</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ19.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ20"><label>20</label><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{t} = o_{t} * \tanh (C_{t} )$$\end{document}</tex-math><mml:math id="M144" display="block"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:mo>tanh</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ20.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq53"><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W$$\end{document}</tex-math><mml:math id="M146"><mml:mi>W</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq53.gif"/></alternatives></inline-formula> and <inline-formula id="IEq54"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$U$$\end{document}</tex-math><mml:math id="M148"><mml:mi>U</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq54.gif"/></alternatives></inline-formula> are the weight metrics, <inline-formula id="IEq55"><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b$$\end{document}</tex-math><mml:math id="M150"><mml:mi>b</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq55.gif"/></alternatives></inline-formula> represents bias, <inline-formula id="IEq56"><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M152"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq56.gif"/></alternatives></inline-formula> is the logistic Sigmoid function, <inline-formula id="IEq57"><alternatives><tex-math id="M153">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$*$$\end{document}</tex-math><mml:math id="M154"><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq57.gif"/></alternatives></inline-formula> represents element-wise multiplication.</p>
      <p id="Par76">LSTM has been demonstrated significant benefits in modeling time series data attributable to features of its engineer. BiLSTM combines forward and backward LSTM, which overcomes the vanishing or exploding gradients and evaluates the context's meaning [<xref ref-type="bibr" rid="CR25">25</xref>].</p>
    </sec>
    <sec id="Sec16">
      <title>Site prediction based on dilated convolutional Bidirectional LSTM</title>
      <p id="Par77">The study combined the DCB model with three encoding methods: RNA word embedding, one-hot encoding, and RGloVe to create three modification site predictors. Consider the RGloVe predictor, as shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>.<fig id="Fig7"><label>Fig. 7</label><caption><p>structure of our computational framework based on RGloVe, DCNN, and BiLSTM neural network to predict m<sup>1</sup>A methylation site</p></caption><graphic xlink:href="12859_2022_4756_Fig7_HTML" id="MO7"/></fig></p>
      <p id="Par78">Suppose that we have N RNA sequences of <italic>L</italic><sub><italic>0</italic></sub>-length. Each has a binary label indicating whether it is a methylation modification site, meaning <italic>N</italic>-labeled samples <inline-formula id="IEq58"><alternatives><tex-math id="M155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\{ {\mathbf{x}}_{n} ,y_{n} \}_{n = 1}^{N}$$\end{document}</tex-math><mml:math id="M156"><mml:msubsup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq58.gif"/></alternatives></inline-formula>
<inline-formula id="IEq59"><alternatives><tex-math id="M157">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_{n} \in \left\{ {0,\,1} \right\}$$\end{document}</tex-math><mml:math id="M158"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq59.gif"/></alternatives></inline-formula>. For each sequence <inline-formula id="IEq60"><alternatives><tex-math id="M159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{x}}_{n}$$\end{document}</tex-math><mml:math id="M160"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq60.gif"/></alternatives></inline-formula> with A, C, T, G nucleotides, and "-", we split it into sub-sequences by using a split window. Each sub-sequence containing <italic>k</italic> nucleotides is called the <italic>k</italic>-mer motif. We extract the sub-sequence of length <italic>k</italic> with stride <italic>s</italic>, resulting in a <italic>k</italic>-mer motif of length <inline-formula id="IEq61"><alternatives><tex-math id="M161">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L = [(L_{0} - k)/s] + 1$$\end{document}</tex-math><mml:math id="M162"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">/</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq61.gif"/></alternatives></inline-formula>. Take m<sup>1</sup>A as an example. A sequence of <italic>L</italic><sub><italic>0</italic></sub> = 101nts is converted to 99 sub-sequence through a split window of size <italic>k</italic> = 3 and stride <italic>s</italic> = 1, where all these 3-mers have a positive integer index in the set <inline-formula id="IEq62"><alternatives><tex-math id="M163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbb{C}}$$\end{document}</tex-math><mml:math id="M164"><mml:mi mathvariant="double-struck">C</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq62.gif"/></alternatives></inline-formula> = [1, 2, 3, 4…, 105], and sequence data <inline-formula id="IEq63"><alternatives><tex-math id="M165">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{x}} \in \mathbb{C}^{L}$$\end{document}</tex-math><mml:math id="M166"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">C</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq63.gif"/></alternatives></inline-formula>.</p>
      <p id="Par79">The following content will specifically introduce learning a feature map <inline-formula id="IEq64"><alternatives><tex-math id="M167">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f:{\mathbb{C}}^{L} \mapsto {\mathbb{R}}^{d}$$\end{document}</tex-math><mml:math id="M168"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">C</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msup><mml:mo>↦</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq64.gif"/></alternatives></inline-formula> that maps <inline-formula id="IEq65"><alternatives><tex-math id="M169">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{x}} \in \mathbb{C}^{L}$$\end{document}</tex-math><mml:math id="M170"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">C</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq65.gif"/></alternatives></inline-formula> into feature vectors <inline-formula id="IEq66"><alternatives><tex-math id="M171">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{h}} \in \mathbb{R}^{d}$$\end{document}</tex-math><mml:math id="M172"><mml:mrow><mml:mi mathvariant="bold">h</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq66.gif"/></alternatives></inline-formula> useful for DL tasks.</p>
      <p id="Par80">We used DCB with <italic>k</italic>-mer embedding to train the model, as shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>. The representation learning function <inline-formula id="IEq67"><alternatives><tex-math id="M173">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f:{\mathbb{C}}^{L} \mapsto {\mathbb{R}}^{d}$$\end{document}</tex-math><mml:math id="M174"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">C</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msup><mml:mo>↦</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq67.gif"/></alternatives></inline-formula> can be separated into four stages:<disp-formula id="Equ21"><label>21</label><alternatives><tex-math id="M175">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{h}} = f\left( x \right) = f_{BiLSTM} \left( {f_{concat} \left( {f_{DCNN} \left( {f_{embedding} \left( {\mathbf{x}} \right)} \right)} \right)} \right)$$\end{document}</tex-math><mml:math id="M176" display="block"><mml:mrow><mml:mi mathvariant="bold">h</mml:mi><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mfenced close=")" open="("><mml:mi>x</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi mathvariant="italic">BiLSTM</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi mathvariant="italic">concat</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi mathvariant="italic">DCNN</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi mathvariant="italic">embedding</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mi mathvariant="bold">x</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ21.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par81">The embedding stage calculates the co-occurrence statistics of <italic>k</italic>-mers and maps them to the D-dimensional space <inline-formula id="IEq68"><alternatives><tex-math id="M177">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbb{R}}^{D}$$\end{document}</tex-math><mml:math id="M178"><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_4756_Article_IEq68.gif"/></alternatives></inline-formula>.</p>
      <p id="Par82">The DCNN stage has three blocks of DCNNs, and the dilution rate of three DCNNs is 1, 2, and 3, respectively. A dilated convolutional layer with the rectified linear unit (ReLU) as its active function, a max-pooling layer, and a dropout unit are all included in each DCNN block. We used the grid-search strategy for the optimization of hyperparameters. There are 64 convolution kernels with a size of 3 each. For the max-pool layer, the size of the max-pool windows is 2. The drop rate is set at 0.2 to avoid overfitting. The concatenate stage concatenates the three blocks of DCNNs to build a multiscale feature extractor. The BiLSTM stage applies a Bi-direction LSTM network to the input in order to collect long-term data dependency information between the data. The number of neurons is set at 64, and the drop rate is 0.2. After the BiLSTM stage, the data were flattened into one dimension by the flatten layer, followed by a fully connected layer. The fully connected layer consists of three full connections, which contain the number of neurons is 256,128,64, activated by ReLU function, and dropout with a probability of 0.5. Finally, the output layer calculates the probability score to indicate the likelihood of the site being modified with the Sigmoid function as follows:<disp-formula id="Equ22"><label>22</label><alternatives><tex-math id="M179">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overset{\lower0.5em\hbox{$\smash{\scriptscriptstyle\frown}$}}{y} (x) = sigmoid(x) = \frac{1}{{1 + e^{ - x} }}$$\end{document}</tex-math><mml:math id="M180" display="block"><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mstyle displaystyle="false" scriptlevel="2"><mml:mo>⌢</mml:mo></mml:mstyle></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2022_4756_Article_Equ22.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec17">
      <title>Ensemble-based site prediction</title>
      <p id="Par83">Various encoding techniques will observe the sequences from various perspectives. RNA word embedding and One-hot encoding emphasize the local information, while RGlove employs global statistics to learn the global semantics. As a result, different predictors may have complementary impacts on prediction. Based on the DCB model, three predictors are constructed by RNA word embedding, One-hot encoding, and RGloVe. Finally, EMDLP was formulated with the three predictors above by a soft vote, as shown in Fig. <xref rid="Fig8" ref-type="fig">8</xref>.<fig id="Fig8"><label>Fig. 8</label><caption><p>Structure of EMDLP predictor. The diagrams depicted our method's architecture. Three different DL classifiers predicted the methylation sequences and decided the final finding by a soft vote</p></caption><graphic xlink:href="12859_2022_4756_Fig8_HTML" id="MO8"/></fig></p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec18">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2022_4756_MOESM1_ESM.docx">
            <caption>
              <p><bold>Additional file 1.</bold> Supplementary Figures.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>RNA</term>
        <def>
          <p id="Par6">Ribonucleic acid</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>6</sup>A</term>
        <def>
          <p id="Par7">N6-methyladenosine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>1</sup>A</term>
        <def>
          <p id="Par8">N1-methyladenosine</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par9">Convolutional neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>BiLSTM</term>
        <def>
          <p id="Par10">Bidirectional long short-term memory</p>
        </def>
      </def-item>
      <def-item>
        <term>LSTM</term>
        <def>
          <p id="Par11">Long short-term memory</p>
        </def>
      </def-item>
      <def-item>
        <term>RNN</term>
        <def>
          <p id="Par12">Recurrent neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>NLP</term>
        <def>
          <p id="Par13">Natural language processing</p>
        </def>
      </def-item>
      <def-item>
        <term>DL</term>
        <def>
          <p id="Par14">Deep learning</p>
        </def>
      </def-item>
      <def-item>
        <term>EMDLP</term>
        <def>
          <p id="Par15">Ensemble multiscale deep learning model for RNA methylation site prediction</p>
        </def>
      </def-item>
      <def-item>
        <term>DCB</term>
        <def>
          <p id="Par16">Dilated convolutional bidirectional long short-term memory network</p>
        </def>
      </def-item>
      <def-item>
        <term>DCNN</term>
        <def>
          <p id="Par17">Dilated convolutional neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>GloVe</term>
        <def>
          <p id="Par18">Global vectors</p>
        </def>
      </def-item>
      <def-item>
        <term>Sn</term>
        <def>
          <p id="Par19">Sensitivity</p>
        </def>
      </def-item>
      <def-item>
        <term>Sp</term>
        <def>
          <p id="Par20">Specificity</p>
        </def>
      </def-item>
      <def-item>
        <term>ACC</term>
        <def>
          <p id="Par21">Accuracy</p>
        </def>
      </def-item>
      <def-item>
        <term>Pre</term>
        <def>
          <p id="Par22">Precision</p>
        </def>
      </def-item>
      <def-item>
        <term>MCC</term>
        <def>
          <p id="Par23">Matthews correlation coefficient</p>
        </def>
      </def-item>
      <def-item>
        <term>AUROC</term>
        <def>
          <p id="Par24">Area under the receiver operating characteristic</p>
        </def>
      </def-item>
      <def-item>
        <term>AUPRC</term>
        <def>
          <p id="Par25">Area under the precision-recall curve</p>
        </def>
      </def-item>
      <def-item>
        <term>ENAC</term>
        <def>
          <p id="Par26">Enhanced nucleic acid composition</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>HW built the architecture for EMDLP, designed and implemented the experiments, analyzed the result, and wrote the paper. GL and TH conducted the experiments and revised the paper. LZ conducted the experiments, analyzed the result, and revised the paper. HL and YS supervised the project, analyzed the result, and revised the paper. All authors read, critically revised, and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work has been supported by the Fundamental Research Funds for the Central Universities (2014QNA84 to HL), the National Natural Science Foundation of China (31871337 to HL), and the "333 Project" of Jiangsu(BRA2020328 to WHL). The funding body did not play any roles in the design of the study and collection, analysis, and interpretation of data and in writing the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The data supporting the findings of the article is available at the webserver <ext-link ext-link-type="uri" xlink:href="http://www.labiip.net/EMDLP/index.php">http://www.labiip.net/EMDLP/index.php</ext-link> (<ext-link ext-link-type="uri" xlink:href="http://47.104.130.81/EMDLP/index.php">http://47.104.130.81/EMDLP/index.php</ext-link>). The code implemented to perform the analysis is deposited at <ext-link ext-link-type="uri" xlink:href="https://github.com/whl-cumt/EMDLP">https://github.com/whl-cumt/EMDLP</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par84">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par85">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par86">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Song</surname>
            <given-names>ZT</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>DY</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>BW</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>KQ</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>YY</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>de Magalhaes</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Rigden</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Attention-based multi-label neural networks for integrated prediction and interpretation of twelve widely occurring RNA modifications</article-title>
        <source>Nat Commun</source>
        <year>2021</year>
        <volume>12</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>11</lpage>
        <pub-id pub-id-type="doi">10.1038/s41467-020-20314-w</pub-id>
        <pub-id pub-id-type="pmid">33397941</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boccaletto</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Machnicka</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Purta</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Piatkowski</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Baginski</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Wirecki</surname>
            <given-names>TK</given-names>
          </name>
          <name>
            <surname>de Crecy-Lagard</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Ross</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Limbach</surname>
            <given-names>PA</given-names>
          </name>
          <name>
            <surname>Kotter</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MODOMICS: a database of RNA modification pathways 2017 update</article-title>
        <source>Nucleic Acids Res</source>
        <year>2018</year>
        <volume>46</volume>
        <issue>D1</issue>
        <fpage>303</fpage>
        <lpage>307</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkx1030</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sun</surname>
            <given-names>WJ</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>JH</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Qu</surname>
            <given-names>LH</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>JH</given-names>
          </name>
        </person-group>
        <article-title>RMBase: a resource for decoding the landscape of RNA modifications from high-throughput sequencing data</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <issue>D1</issue>
        <fpage>259</fpage>
        <lpage>265</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv1036</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xuan</surname>
            <given-names>JJ</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>WJ</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>PH</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>KR</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>LL</given-names>
          </name>
          <name>
            <surname>Qu</surname>
            <given-names>LH</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>JH</given-names>
          </name>
        </person-group>
        <article-title>RMBase v2.0: deciphering the map of RNA modifications from epitranscriptome sequencing data</article-title>
        <source>Nucleic Acids Res</source>
        <year>2018</year>
        <volume>46</volume>
        <issue>D1</issue>
        <fpage>327</fpage>
        <lpage>334</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkx934</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dunn</surname>
            <given-names>DB</given-names>
          </name>
        </person-group>
        <article-title>The occurence of 1-methyladenine in ribonucleic acid</article-title>
        <source>Biochem Biophys Acta</source>
        <year>1961</year>
        <volume>46</volume>
        <issue>1</issue>
        <fpage>198</fpage>
        <lpage>200</lpage>
        <pub-id pub-id-type="doi">10.1016/0006-3002(61)90668-0</pub-id>
        <?supplied-pmid 13725042?>
        <pub-id pub-id-type="pmid">13725042</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hauenschild</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Tserovski</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Schmid</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Thuring</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Winz</surname>
            <given-names>ML</given-names>
          </name>
          <name>
            <surname>Sharma</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Entian</surname>
            <given-names>KD</given-names>
          </name>
          <name>
            <surname>Wacheul</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Lafontaine</surname>
            <given-names>DL</given-names>
          </name>
          <name>
            <surname>Anderson</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The reverse transcription signature of N-1-methyladenosine in RNA-Seq is sequence dependent</article-title>
        <source>Nucleic Acids Res</source>
        <year>2015</year>
        <volume>43</volume>
        <issue>20</issue>
        <fpage>9950</fpage>
        <lpage>9964</lpage>
        <?supplied-pmid 26365242?>
        <pub-id pub-id-type="pmid">26365242</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>El Allali</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Elhamraoui</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Daoud</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Machine learning applications in RNA modification sites prediction</article-title>
        <source>Comput Struct Biotechnol J</source>
        <year>2021</year>
        <volume>19</volume>
        <fpage>5510</fpage>
        <lpage>5524</lpage>
        <pub-id pub-id-type="doi">10.1016/j.csbj.2021.09.025</pub-id>
        <?supplied-pmid 34712397?>
        <pub-id pub-id-type="pmid">34712397</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ballesta</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Cundliffe</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Site-specific methylation of 16S rRNA caused by pct, a pactamycin resistance determinant from the producing organism, Streptomyces pactum</article-title>
        <source>J Bacteriol</source>
        <year>1991</year>
        <volume>173</volume>
        <issue>22</issue>
        <fpage>7213</fpage>
        <lpage>7218</lpage>
        <pub-id pub-id-type="doi">10.1128/jb.173.22.7213-7218.1991</pub-id>
        <?supplied-pmid 1657884?>
        <pub-id pub-id-type="pmid">1657884</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>GZ</given-names>
          </name>
          <name>
            <surname>Weng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Ji</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Widespread occurrence of N6-methyladenosine in bacterial mRNA</article-title>
        <source>Nucleic Acids Res</source>
        <year>2015</year>
        <volume>43</volume>
        <issue>13</issue>
        <fpage>6557</fpage>
        <lpage>6567</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv596</pub-id>
        <?supplied-pmid 26068471?>
        <pub-id pub-id-type="pmid">26068471</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiao</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Xia</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Deng</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Jia</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>W</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The RNA N(6)-methyladenosine modification landscape of human fetal tissues</article-title>
        <source>Nat Cell Biol</source>
        <year>2019</year>
        <volume>21</volume>
        <issue>5</issue>
        <fpage>651</fpage>
        <lpage>661</lpage>
        <pub-id pub-id-type="doi">10.1038/s41556-019-0315-4</pub-id>
        <?supplied-pmid 31036937?>
        <pub-id pub-id-type="pmid">31036937</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Shu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Yi</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Transcriptome-wide mapping reveals reversible and dynamic N(1)-methyladenosine methylome</article-title>
        <source>Nat Chem Biol</source>
        <year>2016</year>
        <volume>12</volume>
        <issue>5</issue>
        <fpage>311</fpage>
        <lpage>316</lpage>
        <pub-id pub-id-type="doi">10.1038/nchembio.2040</pub-id>
        <?supplied-pmid 26863410?>
        <pub-id pub-id-type="pmid">26863410</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>AI</given-names>
          </name>
          <name>
            <surname>Webb</surname>
            <given-names>GI</given-names>
          </name>
          <name>
            <surname>Akutsu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Baggag</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bensmail</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Comprehensive review and assessment of computational methods for predicting RNA post-transcriptional modification sites from RNA sequences</article-title>
        <source>Brief Bioinform</source>
        <year>2019</year>
        <volume>21</volume>
        <issue>5</issue>
        <fpage>1676</fpage>
        <lpage>1696</lpage>
        <pub-id pub-id-type="doi">10.1093/bib/bbz112</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ke</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Alemu</surname>
            <given-names>EA</given-names>
          </name>
          <name>
            <surname>Mertens</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Gantman</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Darnell</surname>
            <given-names>RB</given-names>
          </name>
        </person-group>
        <article-title>A majority of m6A residues are in the last exons, allowing the potential for 3′ UTR regulation</article-title>
        <source>Genes Dev</source>
        <year>2015</year>
        <volume>29</volume>
        <issue>19</issue>
        <fpage>2037</fpage>
        <lpage>2053</lpage>
        <pub-id pub-id-type="doi">10.1101/gad.269415.115</pub-id>
        <?supplied-pmid 26404942?>
        <pub-id pub-id-type="pmid">26404942</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Linder</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Grozhik</surname>
            <given-names>AV</given-names>
          </name>
          <name>
            <surname>Olarerin-George</surname>
            <given-names>AO</given-names>
          </name>
          <name>
            <surname>Meydan</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Mason</surname>
            <given-names>CE</given-names>
          </name>
          <name>
            <surname>Jaffrey</surname>
            <given-names>SR</given-names>
          </name>
        </person-group>
        <article-title>Single-nucleotide-resolution mapping of m6A and m6Am throughout the transcriptome</article-title>
        <source>Nat Methods</source>
        <year>2015</year>
        <volume>12</volume>
        <issue>8</issue>
        <fpage>767</fpage>
        <lpage>772</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.3453</pub-id>
        <?supplied-pmid 26121403?>
        <pub-id pub-id-type="pmid">26121403</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dominissini</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The dynamic N(1)-methyladenosine methylome in eukaryotic messenger RNA</article-title>
        <source>Nature</source>
        <year>2016</year>
        <volume>530</volume>
        <issue>7591</issue>
        <fpage>1</fpage>
        <lpage>39</lpage>
        <pub-id pub-id-type="doi">10.1038/nature16998</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>GS</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>XY</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>HL</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>ST</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>EDLm(6)APred: ensemble deep learning approach for mRNA m(6)A site prediction</article-title>
        <source>BMC Bioinformatics</source>
        <year>2021</year>
        <volume>22</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>15</lpage>
        <pub-id pub-id-type="doi">10.1186/s12859-020-03881-z</pub-id>
        <pub-id pub-id-type="pmid">33388027</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>RAMPred: identifying the N(1)-methyladenosine sites in eukaryotic transcriptomes</article-title>
        <source>Sci Rep</source>
        <year>2016</year>
        <volume>6</volume>
        <fpage>1</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1038/s41598-016-0001-8</pub-id>
        <pub-id pub-id-type="pmid">28442746</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>iRNA-3typeA: identifying three types of modification at RNA's adenosine sites</article-title>
        <source>Mol Ther Nucleic Acids</source>
        <year>2018</year>
        <volume>11</volume>
        <fpage>468</fpage>
        <lpage>474</lpage>
        <pub-id pub-id-type="doi">10.1016/j.omtn.2018.03.012</pub-id>
        <?supplied-pmid 29858081?>
        <pub-id pub-id-type="pmid">29858081</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>iMRM: a platform for simultaneously identifying multiple kinds of RNA modifications</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>11</issue>
        <fpage>3336</fpage>
        <lpage>3342</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa155</pub-id>
        <?supplied-pmid 32134472?>
        <pub-id pub-id-type="pmid">32134472</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Qiang</surname>
            <given-names>XL</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>HR</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>XC</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>LY</given-names>
          </name>
        </person-group>
        <article-title>M6AMRFS: robust prediction of N6-methyladenosine sites with sequence-based features in multiple species</article-title>
        <source>Front Genet</source>
        <year>2018</year>
        <volume>9</volume>
        <fpage>1</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.3389/fgene.2018.00495</pub-id>
        <pub-id pub-id-type="pmid">29387083</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>RNAMethPre: a web server for the prediction and query of mRNA m6A sites</article-title>
        <source>PLoS ONE</source>
        <year>2016</year>
        <volume>11</volume>
        <issue>10</issue>
        <fpage>1</fpage>
        <lpage>13</lpage>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zeng</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>YH</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>ZD</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>QH</given-names>
          </name>
        </person-group>
        <article-title>SRAMP: prediction of mammalian N-6-methyladenosine (m(6)A) sites based on sequence-derived features</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <issue>10</issue>
        <fpage>e91</fpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw104</pub-id>
        <?supplied-pmid 26896799?>
        <pub-id pub-id-type="pmid">26896799</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>XF</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>RX</given-names>
          </name>
        </person-group>
        <article-title>RFAthM6A: a new tool for predicting m(6)A sites in Arabidopsis thaliana</article-title>
        <source>Plant Mol Biol</source>
        <year>2018</year>
        <volume>96</volume>
        <issue>3</issue>
        <fpage>327</fpage>
        <lpage>337</lpage>
        <pub-id pub-id-type="doi">10.1007/s11103-018-0698-9</pub-id>
        <?supplied-pmid 29340952?>
        <pub-id pub-id-type="pmid">29340952</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>KQ</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>XY</given-names>
          </name>
          <name>
            <surname>Rong</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>ZL</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>de Magalhaes</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Rigden</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>WHISTLE: a high-accuracy map of the human N-6-methyladenosine (m(6)A) epitranscriptome predicted using a machine learning approach</article-title>
        <source>Nucleic Acids Res</source>
        <year>2019</year>
        <volume>47</volume>
        <issue>7</issue>
        <fpage>1</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkz077</pub-id>
        <pub-id pub-id-type="pmid">30629263</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>JB</given-names>
          </name>
        </person-group>
        <article-title>Bidirectional LSTM with attention mechanism and convolutional layer for text classification</article-title>
        <source>Neurocomputing</source>
        <year>2019</year>
        <volume>337</volume>
        <fpage>325</fpage>
        <lpage>338</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neucom.2019.01.078</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Angermueller</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Rnamaa</surname>
            <given-names>PT</given-names>
          </name>
          <name>
            <surname>Parts</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Stegle</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>Deep learning for computational biology</article-title>
        <source>Mol Syst Biol</source>
        <year>2016</year>
        <volume>12</volume>
        <issue>7</issue>
        <fpage>1</fpage>
        <lpage>16</lpage>
        <pub-id pub-id-type="doi">10.15252/msb.20156651</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Huss</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Abid</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Mohammadi</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Torkamani</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Telenti</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>A primer on deep learning in genomics</article-title>
        <source>Nat Genet</source>
        <year>2019</year>
        <volume>51</volume>
        <issue>1</issue>
        <fpage>12</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="doi">10.1038/s41588-018-0295-5</pub-id>
        <?supplied-pmid 30478442?>
        <pub-id pub-id-type="pmid">30478442</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Pang B, Lee L. Seeing stars: exploiting class relationships for sentiment categorization with respect to rating scales. <italic>arXiv</italic> 2005:115–124.</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Collobert</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Weston</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bottou</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Karlen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kavukcuoglu</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Kuksa</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Natural language processing (almost) from scratch</article-title>
        <source>J Mach Learn Res</source>
        <year>2011</year>
        <volume>12</volume>
        <fpage>2493</fpage>
        <lpage>2537</lpage>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zou</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Xing</surname>
            <given-names>PW</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>LY</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Gene2vec: gene subsequence embedding for prediction of mammalian N-6-methyladenosine sites from mRNA</article-title>
        <source>RNA</source>
        <year>2019</year>
        <volume>25</volume>
        <issue>2</issue>
        <fpage>205</fpage>
        <lpage>218</lpage>
        <pub-id pub-id-type="doi">10.1261/rna.069112.118</pub-id>
        <?supplied-pmid 30425123?>
        <pub-id pub-id-type="pmid">30425123</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Church</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Ward: emerging trends word2vec</article-title>
        <source>Nat Lang Eng</source>
        <year>2017</year>
        <volume>23</volume>
        <issue>1</issue>
        <fpage>155</fpage>
        <lpage>162</lpage>
        <pub-id pub-id-type="doi">10.1017/S1351324916000334</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Leier</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Marquez-Lago</surname>
            <given-names>TT</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Webb</surname>
            <given-names>GI</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>AI</given-names>
          </name>
          <name>
            <surname>Daly</surname>
            <given-names>RJ</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>iFeature: a Python package and web server for features extraction and selection from protein and peptide sequences</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>14</issue>
        <fpage>2499</fpage>
        <lpage>2502</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty140</pub-id>
        <?supplied-pmid 29528364?>
        <pub-id pub-id-type="pmid">29528364</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dai</surname>
            <given-names>HJ</given-names>
          </name>
          <name>
            <surname>Umarov</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Kuwahara</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Sequence2Vec: a novel embedding approach for modeling transcription factor binding affinity landscape</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <issue>22</issue>
        <fpage>3575</fpage>
        <lpage>3583</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx480</pub-id>
        <?supplied-pmid 28961686?>
        <pub-id pub-id-type="pmid">28961686</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wei</surname>
            <given-names>LY</given-names>
          </name>
          <name>
            <surname>Luan</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Nagai</surname>
            <given-names>LAE</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Zou</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>Exploring sequence-based features for the improved prediction of DNA N4-methylcytosine sites in multiple species</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <issue>8</issue>
        <fpage>1326</fpage>
        <lpage>1333</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty824</pub-id>
        <?supplied-pmid 30239627?>
        <pub-id pub-id-type="pmid">30239627</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>XQ</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>BX</given-names>
          </name>
          <name>
            <surname>Zeng</surname>
            <given-names>GR</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>QY</given-names>
          </name>
          <name>
            <surname>Ai</surname>
            <given-names>DM</given-names>
          </name>
        </person-group>
        <article-title>Prediction of long non-coding RNAs based on deep learning</article-title>
        <source>Genes (Basel)</source>
        <year>2019</year>
        <volume>10</volume>
        <issue>4</issue>
        <fpage>1</fpage>
        <lpage>16</lpage>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>RY</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>CQ</given-names>
          </name>
        </person-group>
        <article-title>Remaining useful life prediction of rolling bearings based on multiscale convolutional neural network with integrated dilated convolution blocks</article-title>
        <source>Shock Vib</source>
        <year>2021</year>
        <volume>2021</volume>
        <fpage>1</fpage>
        <lpage>11</lpage>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Min</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zeng</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Chromatin accessibility prediction via convolutional long short-term memory networks with k-mer embedding</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>14</volume>
        <fpage>92</fpage>
        <lpage>101</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx234</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhao</surname>
            <given-names>CY</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>XZ</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>YX</given-names>
          </name>
          <name>
            <surname>Iqbal</surname>
            <given-names>MY</given-names>
          </name>
        </person-group>
        <article-title>A double-channel hybrid deep neural network based on CNN and BiLSTM for remaining useful life prediction</article-title>
        <source>Sensors-Basel</source>
        <year>2020</year>
        <volume>20</volume>
        <issue>24</issue>
        <fpage>1</fpage>
        <lpage>15</lpage>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>FY</given-names>
          </name>
          <name>
            <surname>Xiang</surname>
            <given-names>DX</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>YZ</given-names>
          </name>
          <name>
            <surname>Akutsu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Daly</surname>
            <given-names>RJ</given-names>
          </name>
          <name>
            <surname>Webb</surname>
            <given-names>GI</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>QZ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>iLearnPlus: a comprehensive and automated machine-learning platform for nucleic acid and protein sequence analysis, prediction and visualization</article-title>
        <source>Nucleic Acids Res</source>
        <year>2021</year>
        <volume>49</volume>
        <issue>10</issue>
        <fpage>e60</fpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkab122</pub-id>
        <?supplied-pmid 33660783?>
        <pub-id pub-id-type="pmid">33660783</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <mixed-citation publication-type="other">Pennington J, Socher R, Manning C. Glove. Global vectors for word representation. In: conference on empirical methods in natural language processing. 2014. pp. 1532–1543.</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">Ruder S. An overview of gradient descent optimization algorithms. 2017:1–14. <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1609.04747">arXiv:160904747</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Duchi</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hazan</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Singer</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Adaptive subgradient methods for online learning and stochastic optimization</article-title>
        <source>J Mach Learn Res</source>
        <year>2011</year>
        <volume>12</volume>
        <fpage>2121</fpage>
        <lpage>2159</lpage>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Holschneider</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kronland-Martinet</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Morlet</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Combes</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Grossmann</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tchamitchian</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>A real-time algorithm for signal analysis with help of the wavelet transform</article-title>
        <source>Wavelets</source>
        <year>1989</year>
        <publisher-loc>Heidelberg</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>286</fpage>
        <lpage>297</lpage>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ku</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>QR</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Multilevel feature fusion dilated convolutional network for semantic segmentation</article-title>
        <source>Int J Adv Rob Syst</source>
        <year>2021</year>
        <volume>18</volume>
        <issue>2</issue>
        <fpage>1</fpage>
        <lpage>11</lpage>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hochreiter</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schmidhuber</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Long short-term memory</article-title>
        <source>Neural Comput</source>
        <year>1997</year>
        <volume>9</volume>
        <issue>8</issue>
        <fpage>1735</fpage>
        <lpage>1780</lpage>
        <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
        <?supplied-pmid 9377276?>
        <pub-id pub-id-type="pmid">9377276</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
