<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Genome Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">Genome Biol</journal-id>
    <journal-title-group>
      <journal-title>Genome Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1474-7596</issn>
    <issn pub-type="epub">1474-760X</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9575223</article-id>
    <article-id pub-id-type="publisher-id">2780</article-id>
    <article-id pub-id-type="doi">10.1186/s13059-022-02780-1</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Method</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>iDNA-ABF: multi-scale deep biological language learning model for the interpretable prediction of DNA methylations</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Jin</surname>
          <given-names>Junru</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yu</surname>
          <given-names>Yingying</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Ruheng</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zeng</surname>
          <given-names>Xin</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pang</surname>
          <given-names>Chao</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jiang</surname>
          <given-names>Yi</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Zhongshen</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Dai</surname>
          <given-names>Yutong</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Su</surname>
          <given-names>Ran</given-names>
        </name>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zou</surname>
          <given-names>Quan</given-names>
        </name>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Nakai</surname>
          <given-names>Kenta</given-names>
        </name>
        <address>
          <email>knakai@ims.u-tokyo.ac.jp</email>
        </address>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Wei</surname>
          <given-names>Leyi</given-names>
        </name>
        <address>
          <email>weileyi@sdu.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.27255.37</institution-id><institution-id institution-id-type="ISNI">0000 0004 1761 1174</institution-id><institution>School of Software, </institution><institution>Shandong University, </institution></institution-wrap>Jinan, 250101 China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.27255.37</institution-id><institution-id institution-id-type="ISNI">0000 0004 1761 1174</institution-id><institution>Joint SDU-NTU Centre for Artificial Intelligence Research (C-FAIR), </institution><institution>Shandong University, </institution></institution-wrap>Jinan, 250101 China </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.26999.3d</institution-id><institution-id institution-id-type="ISNI">0000 0001 2151 536X</institution-id><institution>Human Genome Center, The Institute of Medical Science, </institution><institution>The University of Tokyo, </institution></institution-wrap>Tokyo, 108-8639 Japan </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.26999.3d</institution-id><institution-id institution-id-type="ISNI">0000 0001 2151 536X</institution-id><institution>Department of Computational Biology and Medical Sciences, </institution><institution>The University of Tokyo, </institution></institution-wrap>Kashiwa, 277-8563 Japan </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="GRID">grid.33763.32</institution-id><institution-id institution-id-type="ISNI">0000 0004 1761 2484</institution-id><institution>College of Intelligence and Computing, </institution><institution>Tianjin University, </institution></institution-wrap>Tianjin, 300350 China </aff>
      <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="GRID">grid.54549.39</institution-id><institution-id institution-id-type="ISNI">0000 0004 0369 4060</institution-id><institution>Institute of Fundamental and Frontier Sciences, </institution><institution>University of Electronic Science and Technology of China, </institution></institution-wrap>Chengdu, 610054 China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>17</day>
      <month>10</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>17</day>
      <month>10</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <elocation-id>219</elocation-id>
    <history>
      <date date-type="received">
        <day>22</day>
        <month>2</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>3</day>
        <month>10</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">In this study, we propose iDNA-ABF, a multi-scale deep biological language learning model that enables the interpretable prediction of DNA methylations based on genomic sequences only. Benchmarking comparisons show that our iDNA-ABF outperforms state-of-the-art methods for different methylation predictions. Importantly, we show the power of deep language learning in capturing both sequential and functional semantics information from background genomes. Moreover, by integrating the interpretable analysis mechanism, we well explain what the model learns, helping us build the mapping from the discovery of important sequential determinants to the in-depth analysis of their biological functions.</p>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s13059-022-02780-1.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>DNA methylation</kwd>
      <kwd>Deep learning</kwd>
      <kwd>Multi-scale information processing</kwd>
      <kwd>Interpretable analysis</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Natural Science Foundation of China</institution>
        </funding-source>
        <award-id>62072329</award-id>
        <award-id>62071278</award-id>
        <principal-award-recipient>
          <name>
            <surname>Wei</surname>
            <given-names>Leyi</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par2">DNA methylation is significant for the development and plays an important role in gene silencing, protection against spurious repetitive element activity, genomic stability during mitosis, and parent-of-origin imprinting [<xref ref-type="bibr" rid="CR1">1</xref>]. Moreover, alteration of the DNA methylation pattern caused by the environment and aging may contribute to the development of disease, especially cancer [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>]. Currently, 5-methylcytosine (5mC), N6-methyladenosine (6mA), and 4-methylcytosine (4mC) are three main DNA methylation types, named according to the type of nucleotide, the type of molecule added, and the position of modification within the nucleotide [<xref ref-type="bibr" rid="CR4">4</xref>]. Different methylations have diverse functional mechanisms. For example, among them, 5mC is generated by binding methyl groups at the fifth site of cytosine (C). It is associated with transcriptional inhibition, and thus with classical epigenetic phenomena such as genomic imprinting and X chromosome inactivation [<xref ref-type="bibr" rid="CR5">5</xref>]. 6mA, usually with methylation at the sixth position in adenosine (A), plays a crucial role in chromosome replication, cell defense, cell-cycle regulation, and transcription [<xref ref-type="bibr" rid="CR6">6</xref>]. It has been extensively detected in viruses, bacteria, protists, fungi, algae, etc. As the other important epigenetic modification, 4mC protects host DNA from the degradation of restriction enzymes and corrects prokaryotic DNA replication errors, and controls the DNA replication and cell cycle of prokaryotes [<xref ref-type="bibr" rid="CR7">7</xref>]. Therefore, DNA methylation identification is fundamentally essential for revealing the functional mechanisms.</p>
    <p id="Par3">DNA methylation can be determined experimentally through next-generation sequencing (NGS) approaches such as whole-genome bisulfite sequencing (WGBS) [<xref ref-type="bibr" rid="CR8">8</xref>] or reduced-representation bisulfite sequencing (RRBS) [<xref ref-type="bibr" rid="CR9">9</xref>]. The techniques can determine the global genomic distribution of DNA methylations at the nucleotide level and provide golden standard datasets for DNA methylation-related downstream task analysis. However, the detection of DNA methylation using traditional experimental techniques is often costly and time-consuming [<xref ref-type="bibr" rid="CR10">10</xref>]. In addition, bisulfite sequencing cannot profile DNA methylation in repetitive genomic areas due to short-read sequencing [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR12">12</xref>]. Thus, recent research is more focused on developing computational approaches, particularly machine learning-based approaches, to detect DNA methylations directly using genomic sequences. These methods formulate DNA methylation identification as a binary prediction task and train machine learning models to distinguish true methylation sites from non-methylation sites.</p>
    <p id="Par4">Over the last few decades, a series of sequence-based approaches using either traditional machine learning or deep learning are well developed for the prediction of DNA methylations. Taking 4mC methylation prediction as an example, Tang et al. proposed DNA4mC-LIP, an ensemble learning method by combining six existing predictors through a linear integration strategy to make predictions [<xref ref-type="bibr" rid="CR13">13</xref>]. DeepTorrent [<xref ref-type="bibr" rid="CR14">14</xref>] is a deep learning-based predictor that integrates inception module, attention module, and transfer learning to improve the predictive performance of 4mC sites. As the prediction of 6mA sites, MM-6mAPred [<xref ref-type="bibr" rid="CR15">15</xref>] makes use of the transition probability between adjacent nucleotides based on a Markov model. To simplify the model construction, SNNRice6mA [<xref ref-type="bibr" rid="CR16">16</xref>] builds a simple and lightweight deep learning model using Convolutional Neural Network (CNN) to identify 6mA sites in the rice genome. Later on, Li et al. proposed Deep6mA [<xref ref-type="bibr" rid="CR17">17</xref>], a hybrid deep learning network of CNN and Long Short-Term Memory (LSTM), with more accurate 6mA prediction. BERT6mA [<xref ref-type="bibr" rid="CR18">18</xref>] is a similar model but uses transformer to build predictive models, demonstrating the effectiveness of natural language processing techniques with applications in 6mA prediction. As for 5mC site detection, iPromoter-5mC fuses the results of several models that predict the one-hot encoded sequence through full connection layers [<xref ref-type="bibr" rid="CR19">19</xref>]. BiLSTM-5mC mainly uses Bidirectional Long Short-Term Memory (BiLSTM) to extract features of sequences encoded by nucleotide property and frequency for the 5mC prediction [<xref ref-type="bibr" rid="CR20">20</xref>]. However, most existing approaches can only distinguish one single type of DNA methylation. They are difficult to generalize to other methylation types. iDNA-MS [<xref ref-type="bibr" rid="CR21">21</xref>] is the first machine learning predictor, which is designed for generic detection of different methylations across different species. The iDNA-MS utilizes manual features such as K-tuple nucleotide frequency component and mono-nucleotide binary encoding with traditional machine learning algorithms like support vector machine (SVM) and random forest (RF). The shortcoming of iDNA-MS is that the feature design highly requires a lot of prior knowledge and meanwhile lacks adaptability among different methylation prediction tasks. To address this problem, in our previous work, we designed a deep learning model, namely iDNA-ABT [<xref ref-type="bibr" rid="CR22">22</xref>] that uses the architecture of Bidirectional Encoder Representations from Transformers [<xref ref-type="bibr" rid="CR23">23</xref>] (BERT) to automatically and adaptively learn distinguishable features and make relatively accurate predictions for different methylation types in different species.</p>
    <p id="Par5">As seen above, more and more research efforts attempt to explore the potential of deep learning in the prediction of DNA methylations, and certain progress has been made in the improvement of predictive performance. However, existing deep learning predictors have not fully explored the power of feature representation learning, especially in the discovery of key sequential patterns that are important for elucidating the DNA methylation mechanisms. This also results in the deep learning models with poor interpretation and not being able to dig out the important influence of sequence-based models in DNA methylation prediction. On the other hand, existing approaches fail to answer other important questions: (1) whether background genomic sequences contain extra distinguishable information that can guide the development of DNA methylations, and (2) whether DNA methylation occurring exists the conservation and specificity of sequential patterns across species or cell lines from computational perspectives is also a key problem.</p>
    <p id="Par6">With the development of natural language processing, there are some advanced techniques such as BERT [<xref ref-type="bibr" rid="CR24">24</xref>] that are capable of sufficiently exploring and learning high-latent contextual information in natural language texts. Inspired by this, we here consider genomic sequences as “biological texts” and take different-scale sequential determinants as different “biological words”. Therefore, we propose iDNA-ABF, a multi-scale biological language learning model to successfully build the mapping from natural language to biological language, and the mapping from methylation-related sequential determinants to their functions. Specifically, we introduce a model well pretrained with large-scale genomic sequences to learn biological contextual semantics and propose a multi-scale processing strategy to capture discriminative methylation information from different scales. We further utilize adversarial training and transfer learning to improve the predictive performance and enhance the robustness of our model. Benchmarking results on seventeen datasets across different methylations and species show that our model significantly outperforms the state-of-the-art sequence-based methods. Importantly, our model provides interpretable prediction and analysis at sequence level by exploring the local sequential characteristics based on attention mechanisms. The results reveal that our model can accurately and adaptively locate the sequential regions that are closely associated with methylations, demonstrating that there might exist “biological language grammars” that are participating in functional regulations in cellular progress.</p>
  </sec>
  <sec id="Sec2">
    <title>Results</title>
    <sec id="Sec3">
      <title>The proposed iDNA-ABF outperforms the state-of-the-art methods</title>
      <p id="Par7">To evaluate the performance of our proposed iDNA-ABF, we compared it with four state-of-the-art predictors, including iDNA-ABT, iDNA-MS, BERT6mA, and Deep6mA. Of the four predictors, the former two (iDNA-ABT and iDNA-MS) are generic predictors for different methylation predictions while the other two (BERT6mA and Deep6mA) are originally designed for 6mA site prediction. The reason to include the two 6mA predictors for performance comparison is that they are the state-of-the-art predictors based on deep learning. Moreover, their models are flexible and can be well extended for other methylation predictions like 5hmC and 4mC, not only for 6mA. All the compared predictors were respectively trained on seventeen training datasets across different species and different methylation types, and evaluated on the corresponding independent testing datasets (see “<xref rid="Sec15" ref-type="sec">Datasets</xref>” section for details). The evaluation results in terms of ACC and MCC are shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>A and B, respectively. The detailed results in other metrics such as SN and SP are presented in Additional file (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1). As clearly seen in Fig. <xref rid="Fig1" ref-type="fig">1</xref>A and B, our model outperforms the four existing predictors on 15 out of 17 datasets (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1), with only two exceptions—<italic>5hmC_M.musculus</italic> and <italic>6mA_A.thaliana</italic>, in which our model is actually comparable with the best predictors as well. To be specific, the average ACC of our model on all datasets is higher than that of two runner-up predictors iDNA-ABT by 1.34% and BERT6mA by 3.73%, respectively. In particular, on the three datasets (<italic>4mC_C.equisetifolia</italic>, <italic>4mC_S.cerevisiae</italic>, and <italic>6mA_S.cerevisiae</italic>), our iDNA-ABF performs better than the existing predictors with a relatively large margin, leading by 3.28–14.75%, 1.88–3.59%, and 1.48–4.23% in ACC, respectively. Similar results are observed in terms of MCC. To this end, the results demonstrate that our iDNA-ABF is superior to the state-of-the-art approaches for the generic prediction of DNA methylations. More importantly, it shows robust performance across species under the three methylation types.<fig id="Fig1"><label>Fig. 1</label><caption><p>Performance comparison between iDNA-ABF and other existing methods. <bold>A</bold> and <bold>B</bold> represent the ACC and MCC values of our proposed iDNA-ABF and other existing methods including iDNA-ABT, iDNA-MS, BERT6mA, and Deep6mA on 17 benchmark independent datasets, respectively. <bold>C</bold> The ROC and PR curves of our proposed iDNA-ABF and other existing methods in <italic>5hmC_M.musculus</italic>. <bold>D</bold> The ROC and PR curves of our proposed method and other existing methods in <italic>4mC_C.equisetifolia</italic>. <bold>E</bold> The ROC and PR curves of our proposed iDNA-ABF and other existing methods in <italic>6mA_C.equisetifolia</italic>. <bold>F</bold> The ROC and PR curves of our iDNA-ABF and other existing methods in <italic>6mA_F.vesca</italic>. <bold>G</bold> and <bold>H</bold> represent the feature space distribution (with UMAP visualization) of iDNA-ABF and iDNA-ABT in <italic>5hmC_M.musculus, 4mC_C.equisetifolia, 6mA_C.equisetifolia</italic>, and <italic>6mA_F.vesca</italic>, respectively. Negative (in red color) and positive (in blue color) represent non-methylation and true methylation samples, respectively. <bold>I</bold> The MCCs and ACCs of the models with and without adversarial training on 17 benchmark independent datasets, respectively; each point in the figure represents each dataset. <bold>J</bold> Learning curves of the model with and without the use of adversarial training on <italic>5hmC_M.musculus,</italic> and <italic>6mA_F.vesca</italic></p></caption><graphic xlink:href="13059_2022_2780_Fig1_HTML" id="MO1"/></fig></p>
      <p id="Par8">To validate the robustness of our model, we further illustrated the ROC and PR curves of the predictors on four datasets (<italic>4mC_C.equisetifolia, 5hmC_M.musculus, 6mA_C.equisetifolia</italic>, and <italic>6mA_F.vesca</italic>) as presented in Fig. <xref rid="Fig1" ref-type="fig">1</xref>C–F, respectively. We can see that our iDNA-ABF has the highest AUC and AP in all four datasets. Specifically, the average AUC and AP values of our model on the four datasets increase by about 1.39–2.81% and 0.1–13.8% as compared to the other predictors, respectively. The results further demonstrate the robust performance of our model in DNA methylation prediction tasks. The ROC and PR curves on the other datasets can be found in Additional file (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S1 and Fig. S2). To intuitively discuss why our iDNA-ABF performs better than the other approaches, we further visualized the distribution of feature representation space of our iDNA-ABF and the second-best predictor iDNA-ABT on the above four datasets (<italic>4mC_C.equisetifolia, 5hmC_M.musculus, 6mA_C.equisetifolia</italic>, and <italic>6mA_F.vesca</italic>) using Uniform Manifold Approximation and Projection (UMAP) [<xref ref-type="bibr" rid="CR25">25</xref>], a widely used visualization tool that reveals the essential data characteristics through dimensionality reduction. Note that the UMAP visualization results on the other datasets can be found in Additional file (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S3). Figure <xref rid="Fig1" ref-type="fig">1</xref>G and H illustrate the feature space distribution of our iDNA-ABF and iDNA-ABT, respectively, in which each point represents each sample; methylation sites (positive samples) are annotated with red color while non-methylation sites (negative samples) with blue color. As seen from Fig. <xref rid="Fig1" ref-type="fig">1</xref>G, our model separates the positive and negative samples clearly and every class clusters together rather than disperse, while in Fig. <xref rid="Fig1" ref-type="fig">1</xref>H, the positive and negative samples in the feature space of the iDNA-ABT are distributed almost connected, which is not easy to circle the boundary for each class. By comparing Fig. <xref rid="Fig1" ref-type="fig">1</xref>G and H, we found that the two classes are distributed more clearly in the feature space of our iDNA-ABF as compared to the state-of-the-art iDNA-ABT. This demonstrates that our model learns better feature representations from different class samples, possibly due to the well pretrained model in our model construction, helping us capture more high-latent contextual semantics information from millions of background genomic sequences.</p>
    </sec>
    <sec id="Sec4">
      <title>Adversarial training enhances the predictive performance and the robustness of iDNA-ABF</title>
      <p id="Par9">Adversarial training is an important component of our iDNA-ABF. To investigate the effectiveness of the adversarial training, we compared our original iDNA-ABF with the model without the use of adversarial training. The results of the 17 independent datasets are illustrated in Fig. <xref rid="Fig1" ref-type="fig">1</xref>I where each dot represents each dataset. As seen, our original iDNA-ABF (with adversarial training) generally achieves better performance than that without adversarial training. To be specific, by introducing adversarial training, the performance improvement in ACC and MCC can be observed on 14 out of 17 datasets, and 15 out of 17 datasets, respectively. This indicates that adversarial training can enhance prediction performance. The results on other metrics (SN, SP, and AUC) can be found in Additional file (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S4). What is more, to intuitively show the importance of adversarial training in model optimization, we further analyzed the learning curves during the training process. Figure <xref rid="Fig1" ref-type="fig">1</xref>J shows the curves of the models with and without adversarial training on two datasets (<italic>5hmC_M.musculus</italic> and <italic>6mA_F.vesca</italic>), randomly selected from the datasets. From Fig. <xref rid="Fig1" ref-type="fig">1</xref>J, we can see that the models with adversarial training achieve lower test loss than that without adversarial training although the loss reduction rate decreases more slowly than the models without adversarial training. Furthermore, using adversarial training the models maintain lower test loss in the later period of the training process while the models without adversarial training gradually begin to overfit, demonstrating that adversarial training enhances the robustness of our model in the DNA methylation prediction.</p>
    </sec>
    <sec id="Sec5">
      <title>Our iDNA-ABF reveals the methylation conservation across species at sequential level</title>
      <p id="Par10">To investigate whether the methylated sequential patterns across different species are conserved or not, we firstly constructed the evolutionary tree for different species in the same methylation type using Lifemap [<xref ref-type="bibr" rid="CR26">26</xref>]. As for 4mC methylation, Fig. <xref rid="Fig2" ref-type="fig">2</xref>A illustrates the evolutionary relationship of four species. It can be clearly seen that <italic>Fragaria vesca</italic> and <italic>Casuarina equisetifolia</italic> are evolutionary taxonomies, belonging to the common <italic>Fabids</italic>, while the other two species belong to <italic>Saccharomyces</italic>. An interesting observation is that our model exhibited similar performance in the species with evolutionary taxonomies. In <italic>F. vesca</italic> and <italic>C. equisetifolia</italic>, the ACCs of our model are 0.852 and 0.858, respectively; while in the other, their ACCs are 0.743 and 0.723. Next, we further analyzed the methylation sequential patterns of the four species using the probability-based motif visualization tool—kpLogo [<xref ref-type="bibr" rid="CR27">27</xref>]. Figure <xref rid="Fig2" ref-type="fig">2</xref>B illustrates the sequential patterns in two evolutionarily close species (<italic>F. vesca</italic> and <italic>C. equisetifolia</italic>) while Fig. <xref rid="Fig2" ref-type="fig">2</xref>C shows that in the other two species. From Fig. <xref rid="Fig2" ref-type="fig">2</xref>B, we can see that the methylated sequential regions in the species are very similar, particularly enriched with CG content. From Fig. <xref rid="Fig2" ref-type="fig">2</xref>C, the similar results in the other two species can be observed. As for the 6mA methylation, we also found the similar conclusion with 4mC methylation (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S5). Overall, the results demonstrate that the methylated sequential patterns in species with evolutionary taxonomies might be conserved, thus contributing to the similar predictive performance; on the other hand, the methylation patterns in the species with far evolutionary relationship would be quite different.<fig id="Fig2"><label>Fig. 2</label><caption><p>The relationship between methylation conservation and model accuracy across species. <bold>A</bold> Taxonomy tree and accuracy for four species in 4mC dataset. Two species (i.e., <italic>F. vesca</italic> and <italic>C. equisetifolia</italic>) with higher accuracy are grouped in red, while the other two species (i.e., <italic>S. cerevisiae</italic> and <italic>Tolypocladium</italic>) with lower accuracy are grouped in blue. <bold>B</bold> The motif logo analysis on <italic>F. vesca</italic> and <italic>C. equisetifolia</italic>. <bold>C</bold> The motif logo analysis on <italic>S. cerevisiae</italic> and <italic>Tolypocladium</italic>. <bold>D</bold> The accuracy heatmap of cross-species validation on 4mC dataset</p></caption><graphic xlink:href="13059_2022_2780_Fig2_HTML" id="MO2"/></fig></p>
      <p id="Par11">Next, we further investigated the cross-species performance of our model to study their interrelationships between species; that is, we trained our model in one species and tested on the other. To avoid the problem of insufficient learning, we only trained our models on large datasets and tested on small datasets. The cross-species performances are illustrated in Fig. <xref rid="Fig2" ref-type="fig">2</xref>D, from which we can see that the performances within evolutionary taxonomies are significantly better than that without evolutionary taxonomies. The results further demonstrate that the methylation conservation at sequential level is positively correlated with evolutionary taxonomies.</p>
    </sec>
    <sec id="Sec6">
      <title>Multi-scale sequential design choice is more appropriate to elucidate methylation mechanisms</title>
      <p id="Par12">In our model, we proposed a multi-scale information processing strategy via using different <italic>k</italic>-mers to represent different “biological words” for feature representation learning. Therefore, we firstly validated how single-scale <italic>k</italic>-mers impact the predictive performance of our model. We compared different <italic>k</italic>-mers, ranging from 3-mer to 6-mer. The comparative results are illustrated in Fig. <xref rid="Fig3" ref-type="fig">3</xref>A, in which we can see that different <italic>k</italic>-mers indeed have their advantages on different datasets, respectively. There is no consistent result observed. It might be that the methylated sequential regions vary across species and methylation types in length. Therefore, using single-scale sequential patterns for feature representations cannot adaptively and sufficiently capture the inherent characteristics of methylations. To address this problem, we integrated different scales of <italic>k</italic>-mers as our model input, such as 3-mer + 6-mer, 4-mer + 6-mer, and 5-mer + 6-mer, and compared their performance as illustrated in Fig. <xref rid="Fig3" ref-type="fig">3</xref>B. It can be observed that the multi-scale <italic>k</italic>-mer integration (i.e., 3-mer + 6-mer) improves the model performance as compared to the single-scale <italic>k</italic>-mers (i.e., 3-mer, and 6-mer). To be specific, the model using the integration of 3-mer and 6-mer achieved the highest performance with the average ACC of 85.95% on all the datasets, which is 2.53 and 1.01% higher than that using 3-mer and 6-mer, respectively. This demonstrates that the information from different scales is complementary to each other for learning better feature representations.<fig id="Fig3"><label>Fig. 3</label><caption><p>Interpretable analysis of multi-scale information processing. <bold>A</bold> The comparison of single scales including 3-mer, 4-mer, 5-mer, and 6-mer, respectively. <bold>B</bold> The comparison of multi-scale combinations. <bold>C</bold> The attention map to illustrate the information captured at 3-mer scale on one randomly selected sequence. Two sub-figures visualize the change of information captured before and after training, respectively. <bold>D</bold> The attention map to illustrate the information captured at 6-mer scale. <bold>E–G</bold> Interpretable illustrations of the motifs learnt by our model in three species covering three methylation types, including <italic>4mC_Tolypocladium, 5hmC_H.sapiens</italic>, and <italic>6mA_C.equisetifolia,</italic> respectively. The left part figure clearly shows which region the model is more focused on by using heatmap from 0 to 1. The closer the score is to 1, the darker the color and the more important the region considered by the model. The <italic>p</italic>-value was calculated using TOMTOM by comparing our iDNA-ABF learnt motifs with STREME motifs. The <italic>p</italic>-value in STREME was calculated by a one-sided binomial test. The motifs within the gray dashed anchor boxes were extracted for pair comparisons</p></caption><graphic xlink:href="13059_2022_2780_Fig3_HTML" id="MO3"/></fig></p>
      <p id="Par13">Next, we further investigated why using multi-scale <italic>k</italic>-mer integration is more appropriate for discriminative information capturing. For this, we utilized attention mechanism to intuitively interpret the information our model learnt from two sequential scales—3-mer and 6-mer. We visualized the attention heatmap of the two scales in Fig. <xref rid="Fig3" ref-type="fig">3</xref>C and D, respectively. Note that the element in the heatmap represents the correlation degree of two positions along the sequences. Figure <xref rid="Fig3" ref-type="fig">3</xref>C shows the information our model learnt before and after training at 3-mer scale. As we can see, as compared to the initial model, the attention mechanism is more focused on the diagonal of the heatmap after training. This indicates that our model learns more local discriminative information as compared to that before training. Similarly, Fig. <xref rid="Fig3" ref-type="fig">3</xref>D illustrates the information our model learnt before and after training on the other sequential scale—6-mer. In contrast, this scale is more focused on global information after training. To this end, we can conclude that different scales of sequential patterns learn both local and global information, which might be complementary for the performance improvement.</p>
      <p id="Par14">In order to clearly demonstrate which sequential region is the most important for methylation prediction, we randomly selected three sequences from three species with different DNA methylation types, and applied the attention mechanism to identify key regions from these sequences. As can be seen in Fig. <xref rid="Fig3" ref-type="fig">3</xref>E–G (in left), for each sequence, our model identified different regions under different sequential scales. This further confirms that different scales capture different important information. For those identified regions, we further extracted and visualized the corresponding motifs using attention scores. Figure <xref rid="Fig3" ref-type="fig">3</xref>E–G (in right) shows the motifs learnt by our iDNA-ABF and that discovered by the conventional tool—STREME [<xref ref-type="bibr" rid="CR28">28</xref>], respectively. As seen, our learnt motifs (highlighted with a gray-color window) almost match the STREME’s motifs in each species. To quantitatively compare the motif similarity, we adopted TOMTOM [<xref ref-type="bibr" rid="CR29">29</xref>] to calculate the similarity degree of two motifs, which is measured by <italic>p</italic>-value. The lower <italic>p</italic>-value indicates a higher degree of motif consistency. As can be seen in Fig. <xref rid="Fig3" ref-type="fig">3</xref>E–G, our motifs are highly similar to the STREME’s motifs, suggesting that our model can learn conserved sequential characteristics.</p>
    </sec>
    <sec id="Sec7">
      <title>Our iDNA-ABF sufficiently explores genomic information in 5mC prediction across human cell lines</title>
      <p id="Par15">In this section, we analyzed how well our iDNA-ABF performs the methylation prediction across human cell lines. Since 5mC is one of the most well-studied methylation types in human genome, we selected the 5mC methylation to perform our method. We therefore constructed three new 5mC datasets corresponding to three human cell lines, including GM12878, K562, and HepG2, respectively. The details of the datasets can be seen in section “<xref rid="Sec15" ref-type="sec">Datasets</xref>”.</p>
      <p id="Par16">First, we discussed the impact of the length of methylated sequential regions for the 5mC methylation prediction. Therefore, for each cell line, we constructed four 5mC datasets, in each of which the 5mC sequences are 11, 41, 71, and 101 bp (base pairs) long, respectively. The details of the datasets are summarized in Additional file (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S2, Table S3, and Table S4). Figure <xref rid="Fig4" ref-type="fig">4</xref>A shows the model performance varied with different sequence lengths in the three cell lines. In the beginning, the model performance significantly improves as the sequence length increases, demonstrating that a longer sequence brings the model extra genomic contextual information. The peak is reached when the length is 71 bp. After that, the model performance gradually declines. Notably, the model trained with the sequences 11 bp long exhibits extremely poor performance, with the ACC of around 55%. The reason is that methylation-centered regions with the range of 11 bases are very similar between negative and positive samples. This further demonstrates that the methylations are strongly correlated with the upstream and downstream from the methylated regions.<fig id="Fig4"><label>Fig. 4</label><caption><p>The 5mC prediction performance of our model on three human cell lines. <bold>A</bold> The ACC and AUC results of different human cell line datasets with different sequence lengths. <bold>B–D</bold> Performance of sequence data, ChIP-seq data, and integration of sequence and ChIP-seq data under different sequence lengths in three human cell lines, respectively. <bold>E</bold> The 5mC distributions predicted by our model and annotated by WGBS in a randomly selected genomic region (Chr1: 187000 - 192000, GRCh38). Note that the 5mC distribution is derived from HepG2 cell line</p></caption><graphic xlink:href="13059_2022_2780_Fig4_HTML" id="MO4"/></fig></p>
      <p id="Par17">As well known, 5mC methylation is one of the well-studied methylation types, backing supported by many NGS data, such as ChIP-seq data, and ATAC-seq data, etc. [<xref ref-type="bibr" rid="CR30">30</xref>]. An interesting question is whether integrating the NGS data with sequence data can contribute to more accurate prediction. For this, we chose two histone modifications (HM) data, H3k4me3 and H3k36me3, which are reported to be closely associated with 5mC [<xref ref-type="bibr" rid="CR31">31</xref>]. We trained and tested the models using (1) Sequence data only, (2) ChIP-seq data only, and (3) Sequence + ChIP-seq data on the three cell lines, respectively. The comparative results are shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>B–D. As we can see, the model trained with sequence data achieved remarkably better performance as compared to that trained with ChIP-seq data, leading by 10.4, 10.9, and 21.1% in the average ACC, AUC, and MCC in three cell lines under different sequence lengths. When combining ChIP-seq data with sequence data for model training, all the performance metrics are further improved, achieving the highest scores, with the improvement of 3.8, 5.2, and 8.1% on the average ACC, AUC, and MCC over the model trained with sequence data, demonstrating that the ChIP-seq data and sequence data are complementary to each other for the improved 5mC prediction.</p>
    </sec>
    <sec id="Sec8">
      <title>Application of iDNA-ABF for the 5mC methylation detection at genome scale</title>
      <p id="Par18">Considering real application scenario, it is important to measure the performance of our iDNA-ABF in detecting the 5mC distribution from the whole-genome scale. Thus, we predicted the methylation probability on a 5k-bp-long genomic region (Chr1: 187,000–192,000) from human genome (GRCh38) based on our iDNA-ABF model trained on HepG2. The prediction procedure is as follows. Firstly, we used a 71-bp-long window to screen the region. Secondly, the sequences that meet the following two requirements: (1) centered with base C and (2) centered with CPG patterns were picked out. Ultimately, the resulting sequences were submitted to our iDNA-ABF for prediction. Our model gives the predicted confidence of each site candidate.</p>
      <p id="Par19">Figure <xref rid="Fig4" ref-type="fig">4</xref>E illustrates two HM data distributions, the 5mC distribution predicted by our model, and the true 5mC distribution annotated by WGBS, respectively. As we can see from Fig. <xref rid="Fig4" ref-type="fig">4</xref>E, our predicted 5mC distribution is generally overlapped with the true 5mC site distribution. Moreover, the predicted 5mCs basically match with the two HM data, demonstrating that our predictions have the functional significance. Notably, we found that our model identified some regions (with blue frame, Fig. <xref rid="Fig4" ref-type="fig">4</xref>E) that are not identified by WGBS, but they matched well with the signal of H3K4me3 data. This implies that our model might discover potentially novel functional regions. Although our model also produces some false positives, from the perspective of sequential bins (here, we considered 100-bp region as a bin), the predicted 5mC region distribution is almost the same with the true 5mC region distribution. The results at least demonstrate that our model can perform well in locating 5mC regions. This could also be helpful for methylation research.</p>
    </sec>
    <sec id="Sec9">
      <title>Our iDNA-ABF has robust performance in 5mC prediction on unseen human cell lines</title>
      <p id="Par20">To analyze the predictive performance of iDNA-ABF in unseen cell lines, we conducted the cross-cell line validation. To be specific, we trained our model on one cell line and evaluated it on the other. Figure <xref rid="Fig5" ref-type="fig">5</xref>A shows the heatmap results in terms of four metrics, including ACC, MCC, SN, and SP, respectively. The vertical axis denotes training cell lines, while horizontal axis shows testing cell lines. As shown in Fig. <xref rid="Fig5" ref-type="fig">5</xref>A, our model achieved relatively stable ACC and MCC under the cross-cell line validation. Moreover, we can also see that when evaluated on the K562, our model trained on the GM12878 achieved the highest SN, yielding a relative improvement of 16% compared to the model trained on the HepG2. For better explanation, we introduced the probability distribution analysis in methylated central regions of three human cell lines. Figure <xref rid="Fig5" ref-type="fig">5</xref>B and C show the probability distribution in the positive and negative samples in three cell lines, respectively. On the one hand, it can be seen from Fig. <xref rid="Fig5" ref-type="fig">5</xref>B that the positive motif logos of K562 are more similar to the GM12878 than HepG2 in position from −1 to 1. On the other hand, we observed from Fig. <xref rid="Fig5" ref-type="fig">5</xref>C that the negative motif logos of K562 are the same as the positive motif logos of GM12878 in position from −1 to 1, which can explain the lowest SP of our model trained on GM12878 while tested on K562. Furthermore, we found in Fig. <xref rid="Fig5" ref-type="fig">5</xref>A that our model in the heatmap of cross-cell line validation performs not that well in terms of SP. This might be that the negative motif logos among all three cell lines are quite different. To this end, via the cross-cell line validation results, we can conclude that our model has robust performance even for the unseen cell lines. This further explores the application value of our model.<fig id="Fig5"><label>Fig. 5</label><caption><p>Performance in 5mC prediction on unseen cell lines. <bold>A</bold> The heatmap of cross-cell line validation in terms of different metrics, including ACC, MCC, SN, and SP, respectively. <bold>B</bold> Motif logos in central sequential regions of the positive datasets in three human cell lines, respectively. <bold>C</bold> Motif logos in central sequential regions of the negative datasets in three human cell lines, respectively</p></caption><graphic xlink:href="13059_2022_2780_Fig5_HTML" id="MO5"/></fig></p>
    </sec>
    <sec id="Sec10">
      <title>Our iDNA-ABF has good transfer learning ability to capture the specificity of methylated sequential patterns</title>
      <p id="Par21">The 5mC methylations mainly occur within the sequences with CpG patterns in human genome; actually in a few cases, the methylations are also detected within the CHH and CHG patterns (where H = A, C, or T). In order to find out whether different methylated sequential patterns are correlated with each other, we constructed extra CHG and CHH datasets for the three cell lines, respectively. It is worth noting that the number of sequences in CpG dataset is far more than that in CHG or CHH datasets. The details of the datasets are presented in Additional file (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S5).</p>
      <p id="Par22">To see whether our model has good transfer learning ability in detection of different methylation patterns, we firstly pretrained a model on the CpG dataset and fine-tuned it on the CHG or CHH datasets, yielding another model denoted as “transfer learning model”. Moreover, we also trained a model directly with the CHG or CHH datasets for comparison, denoted as “baseline model”. Both models were then evaluated with the same testing datasets of the CHG or CHH datasets. The performance on the two datasets is shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>A and B, respectively. As we can see, the performance of the “transfer learning model” is always superior to the baseline model, with the average AUC and AP increasing by 3.1 and 3.3% in three cell lines. The results demonstrate that our model has a good transfer learning ability; the pre-training mechanism can bring extra discriminative information from one specific pattern to benefit the prediction of the target patterns, thus improving the predictive performance.<fig id="Fig6"><label>Fig. 6</label><caption><p>Transfer learning results and analysis of our model. <bold>A</bold> The ROC and PR curves of the baseline model and the transfer learning model on CHG dataset in HepG2 cell line. Note that the baseline model is trained with the CHG dataset while the transfer learning model is pretrained with CpG dataset and fine-tuned on the CHG dataset. <bold>B</bold> The ROC and PR curves of the baseline model and the transfer learning model in CHH dataset in HepG2 cell line. Note that the baseline model is trained with the CHH dataset while the transfer learning model is pretrained with the CpG dataset and fine-tuned on the CHH dataset. <bold>C</bold> The motifs learnt from three models, including baseline model, pretrained model, and transfer learning model, respectively. <bold>D</bold> The searching results using our learnt motifs against the topEnriched.MM database</p></caption><graphic xlink:href="13059_2022_2780_Fig6_HTML" id="MO6"/></fig></p>
      <p id="Par23">To in-depth explain the possible reason regarding the performance improvement using transfer learning, we further analyzed and compared the motifs that were learned from the three models, including baseline model, transfer learning model, and pretrained model which is trained on CpG dataset only, respectively. The motif comparison results in HepG2 cell line are illustrated in Fig. <xref rid="Fig6" ref-type="fig">6</xref>C. Taking the 1st, 5th, and 9th motif figures as an example, we observed that the transfer learning model not only keeps some CpG patterns inherited from the pretrained model but also captures the specificity of the CHG patterns learned by baseline model. In addition, the transfer learning model can also discover some new patterns such as the 7th motif figure, which does not share similar patterns from the baseline model in the 3th motif figure.</p>
    </sec>
    <sec id="Sec11">
      <title>The motifs learnt from our models are biologically meaningful</title>
      <p id="Par24">Next, we further explored whether the motifs (or sequential patterns) learnt from our above three models (baseline model, pretrained model, and transfer learning model) are biologically meaningful. Accordingly, we searched the learnt motifs against topEnriched.MM, a public methylation database [<xref ref-type="bibr" rid="CR32">32</xref>]. Interestingly, from Fig. <xref rid="Fig6" ref-type="fig">6</xref>D, we found that the motifs learnt by our models can significantly match with some functional motifs in the database, which were previously reported to be closely associated with methylation mechanisms. The results demonstrate that our model can accurately mine functional sequential characteristics; on the other hand, the newly discovered sequential motifs are also biologically meaningful, indicating the strong ability of our model in learning functional semantics between different sequential patterns.</p>
    </sec>
  </sec>
  <sec id="Sec12">
    <title>Discussions</title>
    <p id="Par25">We presented iDNA-ABF, a novel method for identifying DNA methylation by biological language learning solely based on genomic sequences. Our iDNA-ABF not only enables relatively accurate methylation prediction across species and across cell lines, but also builds the mapping from the sequential level to the functional level using explainable attention mechanism to study the in-depth DNA methylation mechanisms.</p>
    <p id="Par26">First, we investigated the predictive performance of our model to see how well and how stable it performs. Experimental results in 17 benchmark datasets covering three methylation types (4mC, 5hmC, and 6mA) in multiple species show that our model exhibits the consistently superior and robust performance as compared with the state-of-the-art sequence-based approaches. The ablation analyses reveal the importance of the adversarial training in the model performance. Particularly, the adversarial training in our training process alleviates the impact of large-scale parameters particularly on some small datasets and improves the generalization ability of our model across different species and methylation types. In addition, we also studied the impact of sequence length on the methylation prediction. The results show that the model performance generally improves with the increase of the input sequence length, demonstrating the upstream and downstream surrounding the methylated sequential regions are crucial to identifying DNA methylation sites. They might contain some degree of specificity information from the sequential perspective to help our model distinguish the methylation sites from non-methylation sites; on the other hand, we adopted DNABERT [<xref ref-type="bibr" rid="CR33">33</xref>] for model construction, a powerful natural language learning model that was pretrained with million-scale genomic sequence data. It enables our model to capture more sequential semantics from background genomes. The feature space visualization analysis results prove that our model learns more distinguishable feature representations as compared with existing predictors. Interestingly, by integrating ChIP-seq data such as histone modification data (e.g., H3K4me3 and H3K36me3) into our model, we observed that the performances are further improved, indicating that biological signals and sequence data are complementary for the improved prediction. The result could show the great potential of sequence data for DNA methylation prediction and other genomic functional analysis. We can imagine that, as for new cell line data, the NGS data is limited so that we cannot train an effective model. At least, the analyses provide a new way to build a more accurate and robust model by integrating the sequence data.</p>
    <p id="Par27">Secondly, the main feature of our iDNA-ABF is that we provide the interpretable analysis for DNA methylation prediction. The major problem of existing deep learning-based approaches is that they cannot well explain why their models are effective for the methylation prediction, since deep learning works as “black box”. To address this problem, we did two major improvements for model construction. One is proposing the multi-scale sequence processing strategy for model training, and the other is introducing the attention mechanism for model analysis. Inspired by word segmentation in natural language learning, we utilized the multi-scale sequence processing strategy by segmenting DNA sequences with different scales (3mer and 6mer) of sequential patterns to represent “biological words”. Furthermore, we adopted the attention mechanism to interpret what information our model learned from different scales of “biological words”. Analyses demonstrate that the multi-scale strategy is capable of bringing more discriminative semantics information from both local and global levels, effectively overcoming the information lack at one single-scale and the information over-redundancy at all scales. Importantly, different sequential scales lead our model to learn different motifs. The results show that our learnt motifs from different scales are highly consistent with that by the conventional motif finding tool—STREME, demonstrating that our model is capable of discovering conserved sequential patterns. Next, the natural question is whether the sequential patterns learnt by our model are biologically meaningful or correlated with the methylations. To answer this question, we applied our model to the prediction of 5mC methylation across human cell lines. The reason to choose human 5mC methylation is that it has conserved methylated sequential patterns, such as CpG, CHH, and CHG; on the other hand, it is back supported by many NGS data, facilitating further functional validation analysis. We investigated the transfer learning ability of our model and the experimental results show that learning the knowledge from CpG methylation patterns can help the improved prediction of the other two methylation patterns (i.e., CHH, and CHG). This demonstrates that our model has a strong ability in learning the specificity of different methylation patterns. The results also imply the potential of our model in the discovery of other rarely occurred methylation patterns. Importantly, we found that by using transfer learning, our model can learn some new motifs and meanwhile keep the motifs in original methylation patterns. By searching our learnt motifs against a well-known methylation database—topEnriched.MM, we found that our motifs are significantly similar to some known methylation-related functional motifs (see Fig. <xref rid="Fig6" ref-type="fig">6</xref>D). This also demonstrates that our model can learn different biological semantic information under different methylation patterns.</p>
    <p id="Par28">Ultimately, to verify the performance of our model in real application scenarios, we further applied our model to the detection of 5mC methylation within human genome. The experimental results in a randomly selected genomic region show that our model is capable of accurately detecting true DNA methylation regions (annotated by WGBS). Importantly, our model discovered some potential methylation regions, which are not detected by WGBS but are highly overlapped with the methylation-related histone modification data (e.g., H3K4me3). This demonstrates the strong ability of our model in the discovery of biologically meaningful sequential regions. It might be that the deep pretrained model helps us learn functional semantics from millions of background genome sequences.</p>
  </sec>
  <sec id="Sec13">
    <title>Conclusion</title>
    <p id="Par29">Altogether, our proposed deep biological language learning model achieves satisfactory performances in DNA methylation prediction. Importantly, we show the power of deep language learning in capturing both sequential and functional semantics information from background genomes. Moreover, by integrating the interpretable analysis mechanism, we have well explained what we learned, helping us build the mapping from the discovery of important sequential determinants to the in-depth analysis of their biological functions. However, there is still much room to improve. For example, in the construction of methylation prediction models, we only considered local sequential regions surrounding the methylation sites, in which the discriminative information might be limited to some extent. Studies [<xref ref-type="bibr" rid="CR34">34</xref>] have demonstrated that there is a long-range interactive impact of gene regulations in genome, such as enhancer-promoter interaction. Therefore, exploring how the long-range sequence integrative information affects DNA methylation levels could be an important direction in future work.</p>
  </sec>
  <sec id="Sec14">
    <title>Methods</title>
    <sec id="Sec15">
      <title>Datasets</title>
      <sec id="Sec16">
        <title>Different species datasets</title>
        <p id="Par30">A stringent dataset is fundamentally crucial for training effective and promising predictors. To further evaluate our proposed method with state-of-the-art methods, we choose the same benchmark datasets originally proposed by iDNA-MS [<xref ref-type="bibr" rid="CR21">21</xref>]. The datasets consist of three main DNA methylation types, including seventeen datasets totally. Among seventeen datasets, <italic>C. equisetifolia</italic> (<italic>4mC_C.equisetifolia</italic>), <italic>F. vesca</italic> (<italic>4mC_F.vesca</italic>), <italic>S. cerevisiae</italic> (<italic>4mC_S.cerevisiae</italic>), and <italic>Ts. SUP5-1</italic> (<italic>4mC_Ts.SUP5-1</italic>) belong to 4mC. The 6mA contains <italic>Arabidopsis thaliana</italic> (<italic>6mA_A.thaliana</italic>), <italic>Caenorhabditis elegans</italic> (<italic>6mA_C.elegans</italic>), <italic>Casuarina equisetifolia</italic> (<italic>6mA_C.equisetifolia</italic>), <italic>Drosophila melanogaster</italic> (<italic>6mA_D.melanogaster</italic>), <italic>Fragaria vesca</italic> (<italic>6mA_F.vesca</italic>), <italic>Homo sapiens</italic> (<italic>6mA_H.sapiens</italic>), <italic>Rosa chinensis</italic> (<italic>6mA_R.chinensis</italic>), <italic>Saccharomyces cerevisiae</italic> (<italic>6mA_S.cerevisiae</italic>), <italic>Tolypocladium sp SUP5-1</italic> (<italic>6mA_Tolypocladium</italic>), <italic>Tetrahymena thermophile</italic> (<italic>6mA_T.thermophile</italic>), and <italic>Xanthomonas oryzae PV. Oryzicola</italic> (<italic>Xoc</italic>) <italic>BLS256</italic> (<italic>6mA_Xoc.BLS256</italic>). What is more, there are two 5hmC datasets from two species, including <italic>H. sapiens</italic> (<italic>5hmC_H.sapiens</italic>) and <italic>M. musculus</italic> (<italic>5hmC_M.musculus</italic>). It should be noted that both positives and negatives are 41-base pair (bp) long and the sequence identity of the datasets is less than 80% using the CD-HIT [<xref ref-type="bibr" rid="CR35">35</xref>] program, which is shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>A. The details of the training dataset and the validation dataset from seventeen species are given in Additional file (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S6).<fig id="Fig7"><label>Fig. 7</label><caption><p>Overview of the proposed iDNA-ABF. <bold>A</bold> shows the DNA methylation dataset collection where different datasets belonging to three main DNA methylation types are reorganized into their training datasets and independent datasets. The overall architecture of our iDNA-ABF is presented in <bold>B–E</bold>. <bold>B</bold> Multi-scale information processing module, exploiting two scales (3-mer and 6-mer) of tokenizers separately to process the input sequence and adaptively obtain corresponding embeddings. <bold>C</bold> BERT encode module, using BERT encoders to extract high-latent feature representations. <bold>D</bold> Multi-scale extraction module, generating final output feature representations based on multi-scale embeddings. <bold>E</bold> Classification module, integrating binary classification probability values to make prediction. <bold>F</bold> The workflow of the interpretable analysis. In brief, our model uses attention mechanisms to extract and learn sequential motifs from query sequences</p></caption><graphic xlink:href="13059_2022_2780_Fig7_HTML" id="MO7"/></fig></p>
      </sec>
      <sec id="Sec17">
        <title>Human cell lines datasets</title>
        <p id="Par31">The 5mC methylation data of three human cell lines (K562, GM12878, hepG2) were collected from ENCODE portal (ENCSR765JPC, ENCSR890UQO, and ENCSR786DCL) [<xref ref-type="bibr" rid="CR36">36</xref>], which provides the location information of three methylation patterns (CpG, CHG, and CHH) experimented by whole-genome bisulfite sequencing (WGBS). To construct a high-quality dataset, methylation sites with 100% methylated and 10–200× sequencing coverage were kept for positive samples, whereas methylation sites with 0% methylated and 0 sequencing coverage were selected as negative samples. The processed methylation sites located in promoter and gene body region were further mapped using annotation from GENECODE GRCh38. A promoter region is defined as the 1000-bp region upstream from the transcription start site (TSS) of a gene. The number of each cell line processed dataset is shown in Additional file (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S7, Table S8, and Table S9). To evaluate the impact of sequence length on the prediction of methylations, the DNA sequences that 11, 41, 71, and 101-bp-long flanking the methylation sites were extracted from GRCh38, respectively. Similar to the different species datasets, the sequence identity of the human cell line datasets is also less than 80% with using the CD-HIT program.</p>
      </sec>
    </sec>
    <sec id="Sec18">
      <title>Description of the proposed iDNA-ABF</title>
      <p id="Par32">Figure <xref rid="Fig7" ref-type="fig">7</xref> illustrates the overall architecture of our iDNA-ABF. Figure <xref rid="Fig7" ref-type="fig">7</xref>A shows the data set collection procedure, which is described in “<xref rid="Sec15" ref-type="sec">Datasets</xref>” section. The workflow of iDNA-ABF is clearly seen in Fig. <xref rid="Fig7" ref-type="fig">7</xref>B–E, mainly consisting of four modules: (B) Multi-scale data processing module, (C) BERT encoder module, (D) Feature fusion module, and (E) Classification module. The prediction procedure is described as follows. In module B (see Fig. <xref rid="Fig7" ref-type="fig">7</xref>B), we exploit two scales of tokenizers (3-mer and 6-mer) separately to process the input sequence and adaptively learn corresponding embeddings. Due to the input sequences containing multifaceted features of various scales, we design a multi-scale architecture rather than using a single simple tokenizer, which may result in information loss. Afterwards, in module C (see Fig. <xref rid="Fig7" ref-type="fig">7</xref>C), the iDNA-ABF uses BERT encoders individually to extract different embeddings processed by tokenization. The iDNA-ABF then combines multi-scale embeddings based on BERT output in module D to generate the final evolutionary output feature. After that, in module E (see Fig. <xref rid="Fig7" ref-type="fig">7</xref>E), the model uses fully connected layers to predict whether the input sequence is methylated or not. Notably, we adopt adversarial training to enhance the robustness of the model and prevent early overfitting, which can be separated into two components: (1) adversarial perturbation, using cross-entropy loss from this propagation as the adversarial perturbation back to the network, and (2) adversarial optimization, obtaining the adversarial loss which is used to make backpropagation and optimize our model. Note that we describe the details of the four modules as follows.</p>
    </sec>
    <sec id="Sec19">
      <title>Multi-scale information processing module</title>
      <p id="Par33">In our model, we tokenize a DNA sequence with <italic>k</italic>-mer representations. In this way, each token is represented by <italic>k</italic> bases, thus integrating richer contextual information for each nucleotide. For example, a given DNA sequence “ATGGCTG” can be tokenized to a sequence of two 6-mers: ATGGCT and TGGCTG. Different <italic>k</italic> results in different token representations. In our work, we set <italic>k</italic> as 3 or 6, and thus obtain two scales of token representations. The whole token table has 4<sup><italic>k</italic></sup>+5 tokens, consisting of all the permutations of <italic>k</italic>-mer as well as 5 special tokens: [CLS], [PAD], [UNK], [SEP], and [MASK], which stand for classification token, padding token, unknown token, separation token, and masked token, respectively.</p>
    </sec>
    <sec id="Sec20">
      <title>BERT-based encoder module</title>
      <sec id="Sec21">
        <title>Pre-training of the BERT model</title>
        <p id="Par34">BERT is the first bidirectional language representation model based on the transformer proposed by [<xref ref-type="bibr" rid="CR24">24</xref>]. Due to its powerful performance in language understanding against many kinds of large corpus, BERT has been widely used in lots of NLP tasks. To better play the role of BERT, it generally will first be trained on a large background-related corpus with two pre-training tasks namely the masked language model and the next sentence prediction. Here we use a pretrained BERT model namely DNABERT [<xref ref-type="bibr" rid="CR33">33</xref>], using the same architecture as the BERT base, which consists of 12 Transformer layers with 768 hidden units and 12 attention heads in each layer. Notably, since there is no direct semantic logic between DNA sequences, this domain pre-training adjusts the sequence length and enables the model to predict contiguous <italic>k</italic> tokens adapting to a DNA sequence. Also, it uses the masked language model technique similar to the original BERT.</p>
      </sec>
      <sec id="Sec22">
        <title>Encoding process of the BERT</title>
        <p id="Par35">BERT is a transformer-based contextualized language representation model, which has been applied to many aspects of biology and has achieved many outstanding performances. The basic component of BERT consists of a multi-head attention mechanism, a feed-forward network, and the residual connection technique. To capture contextual information, BERT performs the multi-head attention mechanism based on the self-attention mechanism, which is described as follows:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{\begin{array}{c}Q=X{W}^Q\\ {}K=X{W}^K\\ {}V=X{W}^V\end{array}\right.$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mi>X</mml:mi><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mrow/><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mi>X</mml:mi><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mrow/><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mi>X</mml:mi><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="13059_2022_2780_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Self-Attention\left(Q,K,V\right)=softmax\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>f</mml:mi><mml:mo>-</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:mi>Q</mml:mi><mml:msup><mml:mi>K</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:mfenced><mml:mi>V</mml:mi></mml:mrow></mml:math><graphic xlink:href="13059_2022_2780_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
        <p id="Par36">where <inline-formula id="IEq1"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X\in {R}^{L\times {d}_m}$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mi>X</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="13059_2022_2780_Article_IEq1.gif"/></alternatives></inline-formula> is the output of the sequence embedding module. What is more, according to respectively linear layers <inline-formula id="IEq2"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}^Q,{W}^K,{W}^V\in {\textrm{R}}^{d_m\times {d}_k}$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mtext>R</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="13059_2022_2780_Article_IEq2.gif"/></alternatives></inline-formula>, <italic>X</italic> is transformed to the query matrix <inline-formula id="IEq3"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Q\in {R}^{L\times {d}_k}$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="13059_2022_2780_Article_IEq3.gif"/></alternatives></inline-formula>, key matrix <inline-formula id="IEq4"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K\in {R}^{L\times {d}_k}$$\end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="13059_2022_2780_Article_IEq4.gif"/></alternatives></inline-formula>, and value matrix <inline-formula id="IEq5"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V\in {R}^{L\times {d}_k}$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:mi>V</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="13059_2022_2780_Article_IEq5.gif"/></alternatives></inline-formula>, in which <italic>L</italic> is the length of the input protein sequence, <italic>d</italic><sub><italic>m</italic></sub> is the initial embedding dimension, and <italic>d</italic><sub><italic>k</italic></sub> is the dimension of matrix <italic>Q</italic>, <italic>K</italic>, and <italic>V</italic>.</p>
        <p id="Par37">From the above base unit, the multi-head attention mechanism can be expressed as follows:<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{\begin{array}{c}Head_i=Self-Attention\left(XW_i^Q,XW_i^K,XW_i^V\right),i=1,\dots,h\\MultiHead-Attention\left(Q,K,V\right)=\left[head_1,head_2,\cdots,head_h\right]\;W^O\end{array}\right.$$\end{document}</tex-math><mml:math id="M16" display="block"><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>H</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>f</mml:mi><mml:mo>-</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mi>X</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mi>Q</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mi>K</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mi>V</mml:mi></mml:msubsup></mml:mfenced><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mi>M</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>H</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mo>-</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mfenced><mml:mspace width="0.277778em"/><mml:msup><mml:mi>W</mml:mi><mml:mi>O</mml:mi></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="13059_2022_2780_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq6"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}_i^Q,{W}_i^K,{W}_i^V\in {R}^{d_m\times {d}_k}$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mi>Q</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mi>K</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mi>V</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="13059_2022_2780_Article_IEq6.gif"/></alternatives></inline-formula> are the query, key, and value linear transformation layers of the <italic>i</italic><sup>th</sup> head while <italic>h</italic> is the number of heads. Then multi-head concatenates results of <italic>h</italic> independent head with different sets of <inline-formula id="IEq7"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{{W}_i^Q,{W}_i^K,{W}_i^V\right\}$$\end{document}</tex-math><mml:math id="M20"><mml:mfenced close="}" open="{"><mml:msubsup><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mi>Q</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mi>K</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mi>V</mml:mi></mml:msubsup></mml:mfenced></mml:math><inline-graphic xlink:href="13059_2022_2780_Article_IEq7.gif"/></alternatives></inline-formula> and use a linear conversion layer <italic>W</italic><sup><italic>O</italic></sup> to map the output dimension of the multi-head attention to the initial embedding dimension of the embedding module. The entire procedure is performed <italic>L</italic> times, where <italic>L</italic> represents the number of layers.</p>
      </sec>
    </sec>
    <sec id="Sec23">
      <title>Feature fusion module</title>
      <p id="Par38">In order to obtain the final output <italic>h</italic><sub><italic>M</italic></sub> of two BERT parts, we combine the output <italic>h</italic><sub><italic>kmer1</italic></sub> from the first scale input format layer and <italic>h</italic><sub><italic>kmer2</italic></sub> from the second scale input format layer through a dimensional-wise fusion gate <italic>F</italic>. <italic>F</italic> is accomplished by the sigmoid activation function to encode two parts of representation:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F=sigmoid\left(\;W_1\cdot h_{kmer1}+W_2\cdot h_{kmer2}\right)$$\end{document}</tex-math><mml:math id="M22" display="block"><mml:mrow><mml:mi>F</mml:mi><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mfenced close=")" open="("><mml:mspace width="0.277778em"/><mml:msub><mml:mi>W</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="13059_2022_2780_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where <italic>W</italic><sub>1</sub> and <italic>W</italic><sub>2</sub> are trainable parameters of the fusion gate. Then the final vector representation output of a specific molecule <italic>h</italic><sub><italic>M</italic></sub> is generated through F:<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_M=F\cdot h_{kmer1}+\left(1-F\right)\cdot h_{kmer2}$$\end{document}</tex-math><mml:math id="M24" display="block"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mo>·</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfenced close=")" open="("><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>F</mml:mi></mml:mfenced><mml:mo>·</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><graphic xlink:href="13059_2022_2780_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec24">
      <title>Classification module</title>
      <p id="Par39">Adversarial training [<xref ref-type="bibr" rid="CR37">37</xref>] is a novel regularization method for classifiers to improve robustness to small, approximately worst-case perturbations. Here, because of the large parameters that BERT has, we use this strategy to prevent models from overfitting. Among lots of adversarial training methods, we use a variant of Fast Gradient Method (FGM) specific for text classification [<xref ref-type="bibr" rid="CR38">38</xref>]. The cross-entropy loss function <inline-formula id="IEq8"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{\textrm{CE}}$$\end{document}</tex-math><mml:math id="M26"><mml:msub><mml:mi>L</mml:mi><mml:mtext>CE</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="13059_2022_2780_Article_IEq8.gif"/></alternatives></inline-formula> is used to train the output module to improve the prediction performance as our base loss function. We define <italic>p</italic> as the prediction probability, <italic>y</italic> as the true label, <italic>x</italic> as the input, <italic>θ</italic> as the parameters of the model, and <italic>ε</italic> as one additional parameter. When applying this method, adversarial training adds the following term to the cost function:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{\begin{array}{c}{L}_{CE}\left(p,y|x,\theta \right)=-y\log p-\left(1-y\right)\log \left(1-p\right)\\ {}\ {L}_{CE}\left(p,y|x+{r}_{adv},\theta \right)\ {where}\ {r}_{adv}=\arg \underset{r,\left|\left|r\right|\right|\preccurlyeq \varepsilon }{\min }\ {L}_{CE}\left(p,y|x,\hat{\theta}\right)\end{array}\right.$$\end{document}</tex-math><mml:math id="M28" display="block"><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">CE</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mi>y</mml:mi><mml:mo>log</mml:mo><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mfenced close=")" open="("><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>y</mml:mi></mml:mfenced><mml:mo>log</mml:mo><mml:mfenced close=")" open="("><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>p</mml:mi></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mrow/><mml:mspace width="4pt"/><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">CE</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="italic">adv</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mfenced><mml:mspace width="4pt"/><mml:mrow><mml:mi mathvariant="italic">where</mml:mi></mml:mrow><mml:mspace width="4pt"/><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="italic">adv</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>arg</mml:mo><mml:munder><mml:mo movablelimits="false">min</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mfenced close="|" open="|"><mml:mfenced close="|" open="|"><mml:mi>r</mml:mi></mml:mfenced></mml:mfenced><mml:mo>≼</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:munder><mml:mspace width="4pt"/><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">CE</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo></mml:mrow><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="13059_2022_2780_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>where <italic>r</italic> is a perturbation on the input and <inline-formula id="IEq9"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{\theta}$$\end{document}</tex-math><mml:math id="M30"><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="13059_2022_2780_Article_IEq9.gif"/></alternatives></inline-formula> is a constant set to the current parameters of the model. Backpropagation algorithm should not be used to propagate gradients through the adversarial example construction process which means <inline-formula id="IEq10"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{\theta}$$\end{document}</tex-math><mml:math id="M32"><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="13059_2022_2780_Article_IEq10.gif"/></alternatives></inline-formula> is not consistent with <italic>θ</italic> in the Eq. (<xref rid="Equ6" ref-type="">6</xref>). Then, in the training process, we minimize Eq. (<xref rid="Equ6" ref-type="">6</xref>) for <italic>θ</italic> to obtain the worst-case perturbations <italic>r</italic><sub>adv</sub> against the current model.</p>
      <p id="Par40">In the FGM method, we apply the adversarial perturbation to the extracted sequence embedding, rather than directly to the input. To define adversarial perturbation on the word embeddings, we denote relevant embedding of <italic>k</italic>-mer as <italic>s</italic>. Then we define the adversarial perturbation <italic>r</italic><sub><italic>adv</italic></sub> on <italic>s</italic> as<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${r}_{adv}=-\varepsilon\ \frac{g}{{\left|\left|g\right|\right|}_2}where\ g={\nabla}_s\ {L}_{CE}\left(p,y|s,\theta \right)$$\end{document}</tex-math><mml:math id="M34" display="block"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="italic">adv</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mi>ε</mml:mi><mml:mspace width="4pt"/><mml:mfrac><mml:mi>g</mml:mi><mml:msub><mml:mfenced close="|" open="|"><mml:mfenced close="|" open="|"><mml:mi>g</mml:mi></mml:mfenced></mml:mfenced><mml:mn>2</mml:mn></mml:msub></mml:mfrac><mml:mi>w</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="4pt"/><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mspace width="4pt"/><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">CE</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="13059_2022_2780_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par41">To train a robust model, we define a new adversarial loss based on the adversarial perturbation defined in Eq. (<xref rid="Equ6" ref-type="">6</xref>), which is formulated as follows:<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{adv}\left(\theta \right)=-\frac{1}{N}\ \sum_{n=1}^N{L}_{CE}\left({p}_n,y|{s}_n+{r}_{adv,n},\theta \right)$$\end{document}</tex-math><mml:math id="M36" display="block"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">adv</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mi>θ</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mspace width="4pt"/><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">CE</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="13059_2022_2780_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>where <italic>N</italic> is the number of batch size. In our work, adversarial training is to minimize the <italic>L</italic><sub><italic>adv</italic></sub> based on cross-entropy loss with stochastic gradient descent.</p>
    </sec>
    <sec id="Sec25">
      <title>Performance metrics</title>
      <p id="Par42">In this study, we evaluate the performance of our iDNA-ABF and other existing methods with the following four commonly used metrics: Accuracy (ACC), Matthews’ correlation coefficient (MCC), Sensitivity (SN), and Specificity (SP). The formulas of these metrics are described as follows:<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{\begin{array}{c}\begin{array}{c}ACC=\frac{TP+TN}{TP+FN+TN+FP}\\MCC=\frac{TP\times TN-FP\times FN}{\sqrt{\left(TP+FP\right)\left(TP+FN\right)\left(TN+FP\right)\left(TN+FN\right)}}\end{array}\\Sensitivity\left(SN\right)=\frac{TP}{TP+FN}\\Specificity\left(SP\right)=\frac{TN}{TN+FP}\end{array}\right.$$\end{document}</tex-math><mml:math id="M38" display="block"><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mi>M</mml:mi><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:msqrt><mml:mrow><mml:mfenced close=")" open="("><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mfenced><mml:mfenced close=")" open="("><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mfenced><mml:mfenced close=")" open="("><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mfenced><mml:mfenced close=")" open="("><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mfenced></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mfenced close=")" open="("><mml:mi>S</mml:mi><mml:mi>N</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mfenced close=")" open="("><mml:mi>S</mml:mi><mml:mi>P</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="13059_2022_2780_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>where TP, FN, TN, and FP represent the number of true positive, false negative, true negative, and false positive samples, respectively. ACC and MCC are both used to measure the overall performance of the model. SN refers to the proportion of true methylated samples correctly predicted by a predictive model, and SP measures the proportion of non-methylated samples correctly predicted by the model. Moreover, the ROC (receiver operating characteristic) curve and PR (precision-recall) curve [<xref ref-type="bibr" rid="CR39">39</xref>] are used to intuitively evaluate the overall predictive performance of the model. AUC and AP denote the area under ROC curve and that under the PR curve, respectively [<xref ref-type="bibr" rid="CR39">39</xref>]. They are further used to quantitatively measure the overall performance of the model. Altogether, the higher these metrics are, the better the model is.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec26">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="13059_2022_2780_MOESM1_ESM.pdf">
            <caption>
              <p>Additional file 1: Table S1. Performances of iDNA-ABF and the state-of-the-art methods on 17 benchmark datasets across species and methylation types. Table S2. Performance of our iDNA-ABF under various methylation patterns varied with different sequence lengths in three human cell lines. Table S3. Performance of our iDNA-ABF using ChIP-seq data varied with different sequence lengths in three human cell lines. Table S4. Performance of iDNA-ABF using ChIP-seq data + sequence data varied with different sequence lengths in three human cell lines. Table S5. The transfer learning performance of our model varied with different sequence lengths in three human cell lines. Table S6. The statistics of 17 benchmark datasets with three methylation types in various species. Table S7. The statistics of raw data with different methylation patterns in three human cell lines. Table S8. The statistics of the data in three human cell lines after sequence similarity reduction using CD-HIT. Table S9. The statistics of training and testing data under different methylation patterns in three human cell lines. Table S10. Performance comparison of different scales as the input to train the model in various species. Table S11. Performance comparison with the 5mC methods on cancer cell line Encyclopedia (CCLE). Table S12. Performance of iPromoter-5mC in three human cell lines. Table S13. Training parameters of our model on 17 benchmark datasets. Table S14. Performance of our iDNA-ABF for the SNP classification. Table S15. Performance of the multi-task model. Table S16. Performance of the regression model built on ChIP-seq data. Figure S1. The ROC curves on benchmark datasets. Figure S2. The PR curves on benchmark datasets. Figure S3. The UMAP visualization results on benchmark datasets. Figure S4. The SN, SP, and AUC of the models with and without adversarial training on 17 benchmark datasets with the independent test. Figure S5. Taxonomy tree and accuracy for eleven species in 6mA dataset. Figure S6. The ROC and PR curves of our baseline model and our model transferring from CpG pattern on the other two pattern datasets (i.e., CHG, CHH) in the cell line GM12878 and K562. Figure S7. The regression result of signal prediction in the regression model built on ChIP-seq data. Supplementary methods.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="13059_2022_2780_MOESM2_ESM.pdf">
            <caption>
              <p>Additional file 2. Review history.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <sec id="FPar1">
      <title>Review history</title>
      <p id="Par43">The review history is available as Additional file <xref rid="MOESM2" ref-type="media">2</xref>.</p>
    </sec>
    <sec id="FPar2">
      <title>Peer review information</title>
      <p id="Par44">Andrew Cosgrove was the primary editor of this article and managed its editorial process and peer review in collaboration with the rest of the editorial team.</p>
    </sec>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>J.J. conceived iDNA-ABF. J.J., Y.Y., and Z.L. performed the experiments and data analysis. X.Z. and Y.D. constructed the cell line datasets. Y.J. constructed the web server. J.J., R.W., Y.Y., C.P., R.S., Q.Z., K.N., and L.W. wrote, revised, and contributed to the final manuscript. L.W. and K.N. designed the study and supervised the project. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>The work was supported by the Natural Science Foundation of China (Nos. 62071278, and 62072329). K.N. is supported by grants-in-aid for scientific research (22K06189), JSPS.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The 5hmC site containing sequences for <italic>H. sapiens</italic> and <italic>M. musculus</italic> were collected from NCBI Gene Expression Omnibus (GEO) database under accession number GSE127906 [<xref ref-type="bibr" rid="CR40">40</xref>].</p>
    <p>The 6mA site data for 11 species (<italic>Arabidopsis thaliana</italic> (<italic>A. thaliana</italic>), <italic>Caenorhabditis elegans</italic> (<italic>C. elegans</italic>), <italic>Casuarina equisetifolia</italic> (<italic>C. equisetifolia</italic>), <italic>Drosophila melanogaster</italic> (<italic>D. melanogaster</italic>), <italic>Fragaria vesca</italic> (<italic>F. vesca</italic>), <italic>H. sapiens</italic>, <italic>Rosa chinensis</italic> (<italic>R. chinensis</italic>), <italic>Saccharomyces cerevisiae</italic> (<italic>S. cerevisiae</italic>), <italic>Tolypocladium sp SUP5-1</italic> (<italic>Ts. SUP5-1</italic>), <italic>Tetrahymena thermophile</italic> (<italic>T. thermophile</italic>), and <italic>Xanthomonas oryzae pv. Oryzicola</italic> (<italic>Xoc</italic>) <italic>BLS256</italic> (<italic>Xoc. BLS256</italic>)) were obtained from the MethSMRT database (<ext-link ext-link-type="uri" xlink:href="http://sysbio.gzzoc.com/methsmrt/">http://sysbio.gzzoc.com/methsmrt/</ext-link>) with accession numbers SRP145409 [<xref ref-type="bibr" rid="CR41">41</xref>] under BioProject PRJNA450482, MDR database (<ext-link ext-link-type="uri" xlink:href="http://mdr.xieslab.org">http://mdr.xieslab.org</ext-link>), GEO database under the accession number GSE104475 [<xref ref-type="bibr" rid="CR42">42</xref>] and NCBI Genome database SRA: SRX1424851 and SRX1423750 in NCBI project SRA: PRJNA301527 [<xref ref-type="bibr" rid="CR43">43</xref>], respectively.</p>
    <p>The 4mC site data for 4 species (<italic>C. equisetifolia</italic>, <italic>F. vesca</italic>, <italic>S. cerevisiae</italic>, and <italic>Ts. SUP5-1</italic>) were obtained from the MDR database (<ext-link ext-link-type="uri" xlink:href="http://mdr.xieslab.org">http://mdr.xieslab.org</ext-link>) and MethSMRT database (<ext-link ext-link-type="uri" xlink:href="http://sysbio.gzzoc.com/methsmrt/">http://sysbio.gzzoc.com/methsmrt/</ext-link>).</p>
    <p>The human cell line dataset GM12878, K562, and HepG2 were obtained from ENCODE portal (ENCSR765JPC, ENCSR890UQO, and ENCSR786DCL) [<xref ref-type="bibr" rid="CR36">36</xref>, <xref ref-type="bibr" rid="CR44">44</xref>]. The ChIP-seq data H3K4me3 and H3K36me3 were also obtained from ENCODE portal (ENCSR668LDD, ENCSR000DWB, ENCSR057BWO, ENCSR000DRW, ENCSR575RRX, ENCSR000DUD) [<xref ref-type="bibr" rid="CR36">36</xref>].</p>
    <p>To facilitate the use of our method, we established a code-free, interactive, and non-programmatic web interface of iDNA-ABF at <ext-link ext-link-type="uri" xlink:href="https://server.wei-group.net/idnaabf">https://server.wei-group.net/idnaabf</ext-link>, which can lessen the programming burden biological and biomedical researchers. Besides, the benchmarking datasets and our source code were also available at this server. In addition, our source code is also available at <ext-link ext-link-type="uri" xlink:href="https://github.com/FakeEnd/iDNA_ABF">https://github.com/FakeEnd/iDNA_ABF</ext-link> under MIT license and at Zenodo [<xref ref-type="bibr" rid="CR45">45</xref>, <xref ref-type="bibr" rid="CR46">46</xref>].</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar3">
      <title>Ethics approval and consent to participate</title>
      <p id="Par45">Not applicable.</p>
    </notes>
    <notes id="FPar4">
      <title>Consent for publication</title>
      <p id="Par46">Not applicable.</p>
    </notes>
    <notes id="FPar5" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par47">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Smith</surname>
            <given-names>ZD</given-names>
          </name>
          <name>
            <surname>Meissner</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>DNA methylation: roles in mammalian development</article-title>
        <source>Nat Rev Genet</source>
        <year>2013</year>
        <volume>14</volume>
        <fpage>204</fpage>
        <lpage>220</lpage>
        <pub-id pub-id-type="doi">10.1038/nrg3354</pub-id>
        <pub-id pub-id-type="pmid">23400093</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bergman</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Cedar</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>DNA methylation dynamics in health and disease</article-title>
        <source>Nat Struct Mol Biol</source>
        <year>2013</year>
        <volume>20</volume>
        <fpage>274</fpage>
        <lpage>281</lpage>
        <pub-id pub-id-type="doi">10.1038/nsmb.2518</pub-id>
        <pub-id pub-id-type="pmid">23463312</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Maegawa</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Hinkal</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>HS</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Donehower</surname>
            <given-names>LA</given-names>
          </name>
          <name>
            <surname>Issa</surname>
            <given-names>JP</given-names>
          </name>
        </person-group>
        <article-title>Widespread and tissue specific age-related DNA methylation changes in mice</article-title>
        <source>Genome Res</source>
        <year>2010</year>
        <volume>20</volume>
        <fpage>332</fpage>
        <lpage>340</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.096826.109</pub-id>
        <pub-id pub-id-type="pmid">20107151</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Bai</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>JY</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>SH</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>ZD</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>HG</given-names>
          </name>
          <name>
            <surname>Ling</surname>
            <given-names>ZQ</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Tumor development is associated with decrease of TET gene expression and 5-methylcytosine hydroxylation</article-title>
        <source>Oncogene</source>
        <year>2013</year>
        <volume>32</volume>
        <fpage>663</fpage>
        <lpage>669</lpage>
        <pub-id pub-id-type="doi">10.1038/onc.2012.67</pub-id>
        <pub-id pub-id-type="pmid">22391558</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Greenberg</surname>
            <given-names>MV</given-names>
          </name>
          <name>
            <surname>Bourc’his</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>The diverse roles of DNA methylation in mammalian development and disease</article-title>
        <source>Nat Rev Mol Cell Biol</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>590</fpage>
        <lpage>607</lpage>
        <pub-id pub-id-type="doi">10.1038/s41580-019-0159-6</pub-id>
        <pub-id pub-id-type="pmid">31399642</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>GZ</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Deng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hao</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Dore</surname>
            <given-names>LC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>N6-methyldeoxyadenosine marks active transcription start sites in Chlamydomonas</article-title>
        <source>Cell</source>
        <year>2015</year>
        <volume>161</volume>
        <fpage>879</fpage>
        <lpage>892</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2015.04.010</pub-id>
        <pub-id pub-id-type="pmid">25936837</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhao</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Accurate prediction of DNA N 4-methylcytosine sites via boost-learning various types of sequence features</article-title>
        <source>BMC Genomics</source>
        <year>2020</year>
        <volume>21</volume>
        <fpage>1</fpage>
        <lpage>11</lpage>
        <pub-id pub-id-type="doi">10.1186/s12864-020-07033-8</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lister</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Pelizzola</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dowen</surname>
            <given-names>RH</given-names>
          </name>
          <name>
            <surname>Hawkins</surname>
            <given-names>RD</given-names>
          </name>
          <name>
            <surname>Hon</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Tonti-Filippini</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Nery</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Ngo</surname>
            <given-names>Q-M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Human DNA methylomes at base resolution show widespread epigenomic differences</article-title>
        <source>Nature</source>
        <year>2009</year>
        <volume>462</volume>
        <fpage>315</fpage>
        <lpage>322</lpage>
        <pub-id pub-id-type="doi">10.1038/nature08514</pub-id>
        <pub-id pub-id-type="pmid">19829295</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meissner</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Gnirke</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bell</surname>
            <given-names>GW</given-names>
          </name>
          <name>
            <surname>Ramsahoye</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Lander</surname>
            <given-names>ES</given-names>
          </name>
          <name>
            <surname>Jaenisch</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Reduced representation bisulfite sequencing for comparative high-resolution DNA methylation analysis</article-title>
        <source>Nucleic Acids Res</source>
        <year>2005</year>
        <volume>33</volume>
        <fpage>5868</fpage>
        <lpage>5877</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gki901</pub-id>
        <pub-id pub-id-type="pmid">16224102</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Flusberg</surname>
            <given-names>BA</given-names>
          </name>
          <name>
            <surname>Webster</surname>
            <given-names>DR</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>JH</given-names>
          </name>
          <name>
            <surname>Travers</surname>
            <given-names>KJ</given-names>
          </name>
          <name>
            <surname>Olivares</surname>
            <given-names>EC</given-names>
          </name>
          <name>
            <surname>Clark</surname>
            <given-names>TA</given-names>
          </name>
          <name>
            <surname>Korlach</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Turner</surname>
            <given-names>SW</given-names>
          </name>
        </person-group>
        <article-title>Direct detection of DNA methylation during single-molecule, real-time sequencing</article-title>
        <source>Nat Methods</source>
        <year>2010</year>
        <volume>7</volume>
        <fpage>461</fpage>
        <lpage>465</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.1459</pub-id>
        <pub-id pub-id-type="pmid">20453866</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Landan</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Cohen</surname>
            <given-names>NM</given-names>
          </name>
          <name>
            <surname>Mukamel</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Bar</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Molchadsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Brosh</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Horn-Saban</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zalcenstein</surname>
            <given-names>DA</given-names>
          </name>
          <name>
            <surname>Goldfinger</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Zundelevich</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Epigenetic polymorphism and the stochastic formation of differentially methylated regions in normal and cancerous tissues</article-title>
        <source>Nat Genet</source>
        <year>2012</year>
        <volume>44</volume>
        <fpage>1207</fpage>
        <lpage>1214</lpage>
        <pub-id pub-id-type="doi">10.1038/ng.2442</pub-id>
        <pub-id pub-id-type="pmid">23064413</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Treangen</surname>
            <given-names>TJ</given-names>
          </name>
          <name>
            <surname>Salzberg</surname>
            <given-names>SL</given-names>
          </name>
        </person-group>
        <article-title>Repetitive DNA and next-generation sequencing: computational challenges and solutions</article-title>
        <source>Nat Rev Genet</source>
        <year>2012</year>
        <volume>13</volume>
        <fpage>36</fpage>
        <lpage>46</lpage>
        <pub-id pub-id-type="doi">10.1038/nrg3117</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tang</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Kang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>DNA4mC-LIP: a linear integration method to identify N4-methylcytosine site in multiple species</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <fpage>3327</fpage>
        <lpage>3335</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa143</pub-id>
        <pub-id pub-id-type="pmid">32108866</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Liu Q, Chen J, Wang Y, Li S, Jia C, Song J, et al. DeepTorrent: a deep learning-based approach for predicting DNA N4-methylcytosine sites. Brief Bioinform. 2021. 10.1093/bib/bbaa124.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pian</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Fan</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>MM-6mAPred: identifying DNA N6-methyladenine sites based on Markov model</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <fpage>388</fpage>
        <lpage>392</lpage>
        <?supplied-pmid 31297537?>
        <pub-id pub-id-type="pmid">31297537</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>SNNRice6mA: a deep learning method for predicting DNA N6-methyladenine sites in rice genome</article-title>
        <source>Front Genet</source>
        <year>2019</year>
        <volume>10</volume>
        <fpage>1071</fpage>
        <pub-id pub-id-type="doi">10.3389/fgene.2019.01071</pub-id>
        <pub-id pub-id-type="pmid">31681441</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Kong</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Lang</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Fan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Pian</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Deep6mA: a deep learning framework for exploring similar patterns in DNA N6-methyladenine sites across different species</article-title>
        <source>PLoS Comput Biol</source>
        <year>2021</year>
        <volume>17</volume>
        <fpage>e1008767</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1008767</pub-id>
        <pub-id pub-id-type="pmid">33600435</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Tsukiyama S, Hasan MM, Deng H-W, Kurata H. BERT6mA: prediction of DNA N6-methyladenine site using deep learning-based approaches. Brief Bioinform. 2022. 
10.1093/bib/bbac053.</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>ZC</given-names>
          </name>
        </person-group>
        <article-title>iPromoter-5mC: a novel fusion decision predictor for the identification of 5-methylcytosine sites in genome-wide DNA promoters</article-title>
        <source>Front Cell Dev Biol</source>
        <year>2020</year>
        <volume>8</volume>
        <fpage>614</fpage>
        <pub-id pub-id-type="doi">10.3389/fcell.2020.00614</pub-id>
        <pub-id pub-id-type="pmid">32850787</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Cheng X, Wang J, Li Q, Liu T. BiLSTM-5mC: A Bidirectional Long Short-Term Memory-Based Approach for Predicting 5-Methylcytosine Sites in Genome-Wide DNA Promoters. Molecules. 2021;26:7414.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lv</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Dao</surname>
            <given-names>F-Y</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Guan</surname>
            <given-names>Z-X</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>M-L</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>iDNA-MS: an integrated computational tool for detecting DNA modification sites in multiple genomes</article-title>
        <source>Iscience</source>
        <year>2020</year>
        <volume>23</volume>
        <fpage>100991</fpage>
        <pub-id pub-id-type="doi">10.1016/j.isci.2020.100991</pub-id>
        <pub-id pub-id-type="pmid">32240948</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">Yu Y, He W, Jin J, Xiao G, Cui L, Zeng R, Wei L. iDNA-ABT: advanced deep learning model for detecting DNA methylation with adaptive features and transductive information maximization. Bioinformatics. 2021;37:4603-10.</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Vaswani</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Shazeer</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Parmar</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Uszkoreit</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Gomez</surname>
            <given-names>AN</given-names>
          </name>
          <name>
            <surname>Kaiser</surname>
            <given-names>Ł</given-names>
          </name>
          <name>
            <surname>Polosukhin</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Attention is all you need</article-title>
        <source>Advances in neural information processing systems</source>
        <year>2017</year>
        <fpage>5998</fpage>
        <lpage>6008</lpage>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">Devlin J, Chang M-W, Lee K, Toutanova K. Bert: pre-training of deep bidirectional transformers for language understanding. arXiv preprint. 2018. 10.48550/arXiv.1810.04805.</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>McInnes</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Healy</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Melville</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <source>UMAP: uniform manifold approximation and projection for dimension reduction</source>
        <year>2020</year>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de Vienne</surname>
            <given-names>DM</given-names>
          </name>
        </person-group>
        <article-title>Lifemap: exploring the entire tree of life</article-title>
        <source>PLoS Biol</source>
        <year>2016</year>
        <volume>14</volume>
        <fpage>e2001624</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pbio.2001624</pub-id>
        <pub-id pub-id-type="pmid">28005907</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Bartel</surname>
            <given-names>DP</given-names>
          </name>
        </person-group>
        <article-title>kpLogo: positional k-mer analysis reveals hidden specificity in biological sequences</article-title>
        <source>Nucleic Acids Res</source>
        <year>2017</year>
        <volume>45</volume>
        <fpage>W534</fpage>
        <lpage>W538</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkx323</pub-id>
        <pub-id pub-id-type="pmid">28460012</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bailey</surname>
            <given-names>TL</given-names>
          </name>
        </person-group>
        <article-title>STREME: accurate and versatile sequence motif discovery</article-title>
        <source>Bioinformatics</source>
        <year>2021</year>
        <volume>37</volume>
        <fpage>2834</fpage>
        <lpage>2840</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btab203</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gupta</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Stamatoyannopoulos</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Bailey</surname>
            <given-names>TL</given-names>
          </name>
          <name>
            <surname>Noble</surname>
            <given-names>WS</given-names>
          </name>
        </person-group>
        <article-title>Quantifying similarity between motifs</article-title>
        <source>Genome Biol</source>
        <year>2007</year>
        <volume>8</volume>
        <fpage>1</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1186/gb-2007-8-2-r24</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Spektor</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Tippens</surname>
            <given-names>ND</given-names>
          </name>
          <name>
            <surname>Mimoso</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Soloway</surname>
            <given-names>PD</given-names>
          </name>
        </person-group>
        <article-title>methyl-ATAC-seq measures DNA methylation at accessible chromatin</article-title>
        <source>Genome Res</source>
        <year>2019</year>
        <volume>29</volume>
        <fpage>969</fpage>
        <lpage>977</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.245399.118</pub-id>
        <pub-id pub-id-type="pmid">31160376</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Putiri</surname>
            <given-names>EL</given-names>
          </name>
          <name>
            <surname>Tiedemann</surname>
            <given-names>RL</given-names>
          </name>
          <name>
            <surname>Thompson</surname>
            <given-names>JJ</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ho</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Choi</surname>
            <given-names>J-H</given-names>
          </name>
          <name>
            <surname>Robertson</surname>
            <given-names>KD</given-names>
          </name>
        </person-group>
        <article-title>Distinct and overlapping control of 5-methylcytosine and 5-hydroxymethylcytosine by the TET proteins in human cancer cells</article-title>
        <source>Genome Biol</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>1</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="doi">10.1186/gb-2014-15-6-r81</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Ngo</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Fan</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Whitaker</surname>
            <given-names>JW</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ai</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Identification of DNA motifs that regulate DNA methylation</article-title>
        <source>Nucleic Acids Res</source>
        <year>2019</year>
        <volume>47</volume>
        <fpage>6753</fpage>
        <lpage>6768</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkz483</pub-id>
        <pub-id pub-id-type="pmid">31334813</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ji</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Davuluri</surname>
            <given-names>RV</given-names>
          </name>
        </person-group>
        <article-title>DNABERT: pre-trained bidirectional encoder representations from transformers model for DNA-language in genome</article-title>
        <source>Bioinformatics</source>
        <year>2021</year>
        <volume>37</volume>
        <fpage>2112</fpage>
        <lpage>2120</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btab083</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schoenfelder</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Fraser</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Long-range enhancer–promoter contacts in gene expression control</article-title>
        <source>Nat Rev Genet</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>437</fpage>
        <lpage>455</lpage>
        <pub-id pub-id-type="doi">10.1038/s41576-019-0128-0</pub-id>
        <pub-id pub-id-type="pmid">31086298</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Godzik</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences</article-title>
        <source>Bioinformatics</source>
        <year>2006</year>
        <volume>22</volume>
        <fpage>1658</fpage>
        <lpage>1659</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btl158</pub-id>
        <pub-id pub-id-type="pmid">16731699</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luo</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hitz</surname>
            <given-names>BC</given-names>
          </name>
          <name>
            <surname>Gabdank</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Hilton</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Kagda</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Lam</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Myers</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Sud</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Jou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>New developments on the Encyclopedia of DNA Elements (ENCODE) data portal</article-title>
        <source>Nucleic Acids Res</source>
        <year>2020</year>
        <volume>48</volume>
        <fpage>D882</fpage>
        <lpage>D889</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkz1062</pub-id>
        <pub-id pub-id-type="pmid">31713622</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Goodfellow IJ, Shlens J, Szegedy C. Explaining and harnessing adversarial examples. arXiv preprint. 2014. 10.48550/arXiv.1412.6572.</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Miyato T, Dai AM, Goodfellow I. Adversarial training methods for semi-supervised text classification. arXiv preprint. 2016. 10.48550/arXiv.1605.07725.</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kumar</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Indrayan</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Receiver operating characteristic (ROC) curve for medical researchers</article-title>
        <source>Indian Pediatr</source>
        <year>2011</year>
        <volume>48</volume>
        <fpage>277</fpage>
        <lpage>287</lpage>
        <pub-id pub-id-type="doi">10.1007/s13312-011-0055-4</pub-id>
        <pub-id pub-id-type="pmid">21532099</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <mixed-citation publication-type="other">Hu L, Liu Y, Han S, Yang L, Cui X, Gao Y, Dai Q, Lu X, Kou X, Zhao Y, et al. Jump-seq: Genome-Wide Capture and Amplification of 5-Hydroxymethylcytosine Sites. Journal of the American Chemical Society. 2019;141:8694-7.</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">Ye G, Zhang H, Chen B, Nie S, Liu H, Gao W, Wang H, Gao Y, Gu L. De novo genome assembly of the stress tolerant forest species Casuarina equisetifolia provides insight into secondary growth. The Plant Journal. 2019;97:779-94.</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <mixed-citation publication-type="other">Xiao C-L, Zhu S, He M-H, Chen Y, Yu G-L, De Chen S-QX, et al. N6-methyladenine DNA modification in human genome. Gene Expression Omnibus. 2018. 10.1101/176958.</mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">Shi L, Guo Y, Dong C, Huddleston J, Yang H, Han X, et al. Long-read sequencing and de novo assembly of a Chinese genome. Datasets Gene Expression Omnibus. 2016. 10.1038/ncomms12065.</mixed-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <mixed-citation publication-type="other">Jing Zhang, Donghoon Lee, Vineet Dhiman, Peng Jiang, Jie Xu, Patrick McGillivray, Hongbo Yang et al. An integrative ENCODE resource for cancer genomics. Datasets. ENCODE portal. 2020. <ext-link ext-link-type="uri" xlink:href="https://doi.org/doi:10.1038/s41467-020-14743-w">https://doi.org/doi:10.1038%2Fs41467-020-14743-w</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <mixed-citation publication-type="other">Jin J, Yu Y, Wang R, Zeng X, Pang C, Jiang Y, et al. iDNA-ABF: multi-scale deep biological language learning model for the interpretable prediction of DNA methylations. Github; 2022. <ext-link ext-link-type="uri" xlink:href="https://github.com/FakeEnd/iDNA_ABF">https://github.com/FakeEnd/iDNA_ABF</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <mixed-citation publication-type="other">Jin J, Yu Y, Wang R, Zeng X, Pang C, Jiang Y, et al. FakeEnd/iDNA_ABF: V0.0.0. Zenodo. 2022. 10.5281/ZENODO.7018276.</mixed-citation>
    </ref>
  </ref-list>
</back>
