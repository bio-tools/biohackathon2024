<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Database (Oxford)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Database (Oxford)</journal-id>
    <journal-id journal-id-type="publisher-id">databa</journal-id>
    <journal-title-group>
      <journal-title>Database: The Journal of Biological Databases and Curation</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1758-0463</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6787548</article-id>
    <article-id pub-id-type="doi">10.1093/database/baz084</article-id>
    <article-id pub-id-type="publisher-id">baz084</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>The extraction of complex relationships and their conversion to biological expression language (BEL) overview of the BioCreative VI (2017) BEL track</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Madan</surname>
          <given-names>Sumit</given-names>
        </name>
        <!--<email>sumit.madan@scai.fraunhofer.de</email>-->
        <xref ref-type="aff" rid="aff1">1</xref>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Szostak</surname>
          <given-names>Justyna</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Komandur Elayavilli</surname>
          <given-names>Ravikumar</given-names>
        </name>
        <!--<email>komandurelayavilli.ravikumar@mayo.edu</email>-->
        <xref ref-type="aff" rid="aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tsai</surname>
          <given-names>Richard Tzong-Han</given-names>
        </name>
        <!--<email>thtsai@csie.ncu.edu.tw</email>-->
        <xref ref-type="aff" rid="aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ali</surname>
          <given-names>Mehdi</given-names>
        </name>
        <!--<email>alim@informatik.uni-bonn.de</email>-->
        <xref ref-type="aff" rid="aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Qian</surname>
          <given-names>Longhua</given-names>
        </name>
        <!--<email>qianlonghua@suda.edu.cn</email>-->
        <xref ref-type="aff" rid="aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rastegar-Mojarad</surname>
          <given-names>Majid</given-names>
        </name>
        <!--<email>rastegar.83@gmail.com</email>-->
        <xref ref-type="aff" rid="aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hoeng</surname>
          <given-names>Julia</given-names>
        </name>
        <!--<email>julia.hoeng@pmi.com</email>-->
        <xref ref-type="aff" rid="aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fluck</surname>
          <given-names>Juliane</given-names>
        </name>
        <!--<email>juliane.fluck@scai.fraunhofer.de</email>-->
        <xref ref-type="aff" rid="aff1">1</xref>
      </contrib>
    </contrib-group>
    <aff id="aff1"><label>1</label><institution>Fraunhofer Institute for Algorithms and Scientific Computing</institution>, Schloss Birlinghoven, 53754 Sankt Augustin, <country country="DE">Germany</country></aff>
    <aff id="aff2"><label>2</label><institution>Philip Morris International R&amp;D</institution>, Philip Morris Products S.A., Quai Jeanrenaud 5, 2000 Neuchatel, <country country="CH">Switzerland</country></aff>
    <aff id="aff3"><label>3</label><institution>Department of Health Sciences Research</institution>, Mayo Clinic, 200 First St. SW, Rochester, MN 55905, USA</aff>
    <aff id="aff4"><label>4</label><institution>Department of Computer Science and Information Engineering</institution>, National Central University, Taiwan, R.O.C., Taiwan 320</aff>
    <aff id="aff5"><label>5</label><institution>NLP Lab</institution>, School of Computer Science and Technology, Soochow University, Suzhou, 215006 Suzhou, <country country="CN">China</country></aff>
    <aff id="aff6"><label>6</label><institution>Friedrich Wilhelm University of Bonn</institution>, 53012 Bonn, <country country="DE">Germany</country></aff>
    <author-notes>
      <corresp id="cor1">Corresponding author: Tel: +49 2241 14-2997; Fax: +49 2241 14-2656; Email: <email>sumit.madan@scai.fraunhofer.de</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-10-11">
      <day>11</day>
      <month>10</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>11</day>
      <month>10</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>2019</volume>
    <elocation-id>baz084</elocation-id>
    <history>
      <date date-type="received">
        <day>27</day>
        <month>11</month>
        <year>2018</year>
      </date>
      <date date-type="rev-recd">
        <day>22</day>
        <month>5</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>31</day>
        <month>5</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="cc-by" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="baz084.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>Knowledge of the molecular interactions of biological and chemical entities and their involvement in biological processes or clinical phenotypes is important for data interpretation. Unfortunately, this knowledge is mostly embedded in the literature in such a way that it is unavailable for automated data analysis procedures. Biological expression language (BEL) is a syntax representation allowing for the structured representation of a broad range of biological relationships. It is used in various situations to extract such knowledge and transform it into BEL networks. To support the tedious and time-intensive extraction work of curators with automated methods, we developed the BEL track within the framework of BioCreative Challenges. Within the BEL track, we provide training data and an evaluation environment to encourage the text mining community to tackle the automatic extraction of complex BEL relationships. In 2017 BioCreative VI, the 2015 BEL track was repeated with new test data. Although only minor improvements in text snippet retrieval for given statements were achieved during this second BEL task iteration, a significant increase of BEL statement extraction performance from provided sentences could be seen. The best performing system reached a 32% F-score for the extraction of complete BEL statements and with the given named entities this increased to 49%. This time, besides rule-based systems, new methods involving hierarchical sequence labeling and neural networks were applied for BEL statement extraction.</p>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Philip Morris International R&amp;D</named-content>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="17"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>Introduction</title>
    <p>Identifying the molecular mechanisms influencing disease development and therapeutic responses is currently one of the most promising ways of identifying better treatments for non-responders to traditional treatments. There is an increasing amount of research with large-scale biological data sets produced to identify those mechanisms, and the results are mainly published in the scientific literature. To use this data for further analysis, it needs to be in a computer-readable format. To achieve this, availability of a syntax and the conversion of the biological data and knowledge to this syntax are required. For dynamic models, systems biology markup language (SBML) is the main format (<xref rid="ref1" ref-type="bibr">1</xref>) used, and for traditional pathway information, the exchange format BioPAX (<xref rid="ref2" ref-type="bibr">2</xref>) is useful. Both formats contain representations of biological mechanisms or models rather than findings from literature. Also, most relationships described in the literature are difficult to convert directly to these representations. Furthermore, they are not easily accessible to humans without a user interface. As an alternative, biological expression language (BEL) has been developed to allow the representation of the huge variety of causal relationships expressed in the literature (<xref rid="ref3" ref-type="bibr">3</xref>). BEL is better suited for biocuration to encode findings or observations from the literature compared to other representation formats. Additionally, BEL follows the principles of FAIR (findable, accessible, interoperable and reusable) data, providing the necessary metadata to make it findable and enabling interoperability using standardized terminologies and external data sources for all biological entities. Using further metadata, BEL also allows for the fine granular annotation of data. Additionally, it is well suited to integration into knowledge graphs or graphical network analyses (<xref rid="ref4" ref-type="bibr">4</xref>).</p>
    <p>However, it is labor-intensive to extract the relevant information from the primary literature and convert the free text data into structured relationships using controlled vocabularies (<xref rid="ref5" ref-type="bibr">5</xref>). In recent years, research has been conducted to enable the automatic extraction of biological relationships and their translation into BEL. First, a syntax for BEL conversion was developed from the text mining-focused representation of relationships provided by Biomedical Natural Language Processing shared tasks (<xref rid="ref6" ref-type="bibr">6</xref>). These tasks provide fined grained and linguistically motivated annotations for biologically relevant extractions (<ext-link ext-link-type="uri" xlink:href="http://2016.bionlp-st.org/">http://2016.bionlp-st.org/</ext-link>). Second, to enable a broader text mining community to extract relationships in BEL format, BEL was introduced within BioCreative 2015 as a new track (<xref rid="ref7" ref-type="bibr">7</xref>, <xref rid="ref8" ref-type="bibr">8</xref>). For this track, a subset of relationships containing genes, proteins, chemical compounds, biological processes and diseases was used (<xref rid="ref9" ref-type="bibr">9</xref>). In the first BioCreative BEL track, the best performing system reached an F-score of 22% for the extraction of complete BEL statements (<xref rid="ref8" ref-type="bibr">8</xref>). Despite the low F-score for complete relationships, core relationships containing relationship partners were extracted with an F-score of up to 49% (<xref rid="ref8" ref-type="bibr">8</xref>). These results support the possibility of the semi-automatic extraction of relationships, supporting curation experts with the facility of automated extraction. BEL information extraction workflow (BELIEF) supports such semi-automatic curation (<xref rid="ref10" ref-type="bibr">10</xref>). BELIEF (<ext-link ext-link-type="uri" xlink:href="http://belief.scai.fraunhofer.de/BeliefDashboard">http://belief.scai.fraunhofer.de/BeliefDashboard</ext-link>) is a public web service with underlying text mining workflows and a curation interface that enables the semi-automatic extraction of complex relationships, and their coding, in BEL.</p>
    <p>In 2017, the BEL track was conducted a second time in the context of BioCreative VI. Experiences in other areas have demonstrated that repetitions of tasks tend to result in increased performance. For the 2017 BEL track, novel, and yet unpublished, test data from the disease ulcerative colitis (<xref rid="ref11" ref-type="bibr">11</xref>, <xref rid="ref12" ref-type="bibr">12</xref>) was created. The BioCreative 2015 test set and 2015 annotated result set are available for the participating groups (<ext-link ext-link-type="uri" xlink:href="https://wiki.openbel.org/display/BIOC/Datasets">https://wiki.openbel.org/display/BIOC/Datasets</ext-link>). Here, the track details, relevant resources and newly created test set are described. Furthermore, the participating systems present their solutions and performance results from the new BEL track.</p>
  </sec>
  <sec id="sec2">
    <title>BEL track overview</title>
    <sec id="sec3">
      <title>BEL and used namespaces</title>
      <p>BEL statements encode semantic triples with subject, relationship and object. An example BEL statement and its corresponding sentence are shown in <xref rid="f1" ref-type="fig">Figure 1</xref>. For the BEL track, we focused on two causal relationship types: increase and decrease. Using normalized entities from so-called namespaces for subject and objects, the resulting statements can be integrated and merged into networks as well as aligned to other data. These namespaces are generated from database entries {e.g. human genes from HGNC [HGNC stands for HUGO Gene Nomenclature Committee (<ext-link ext-link-type="uri" xlink:href="http://www.genenames.org">http://www.genenames.org</ext-link>)], mouse genes from MGI [MGI stands for Mouse Genome Informatics (<ext-link ext-link-type="uri" xlink:href="http://www.informatics.jax.org/">http://www.informatics.jax.org/</ext-link>)] and chemical entities from the ChEBI [ChEBI stands for Chemical Entities of Biological Interest (<ext-link ext-link-type="uri" xlink:href="https://www.ebi.ac.uk/chebi/">https://www.ebi.ac.uk/chebi/</ext-link>)] database}. In our example in <xref rid="f1" ref-type="fig">Figure 1</xref>, textual references such as IL1-ß and ATF-2 are normalized to the HGNC database entries IL1B and ATF2, respectively. The reference to the chosen namespace is given using a prefix with the database short name separated by a colon, ‘HGNC’ in our example. Other namespaces originate either from ontologies, such as the biological processes subtree (GO:0008150) of the Gene Ontology for GOBP (GOBP stands for Gene Ontology Biological Process) or from terminologies, such as the diseases namespace MESHD (MESH disease subtree is available at <ext-link ext-link-type="uri" xlink:href="https://meshb.nlm.nih.gov/treeView">https://meshb.nlm.nih.gov/treeView</ext-link>.) from the Medical Subject Headings diseases subtree.</p>
      <fig id="f1" orientation="portrait" position="float">
        <label>Figure 1</label>
        <caption>
          <p>Example of a BEL statement extracted from the sentence ‘IL-1β caused a time-dependent increase in Caco-2 ATF-2 phosphorylation, starting at 10 min of treatment (<xref rid="f3" ref-type="fig">Fig. 3A</xref>).’ (<xref rid="ref46" ref-type="bibr">46</xref>) (PMID: 23656735) (BEL:201720027; identifier in BEL corpus). The BEL statement consists of two protein abundances [<italic>p (HGNC:IL1B)</italic> and <italic>p (HGNC:ATF2)</italic>], one protein modification function representing a phosphorylation event [<italic>pmod(P)</italic>] and a relationship type (<italic>increases</italic>).</p>
        </caption>
        <graphic xlink:href="baz084f1"/>
      </fig>
      <p>For the different entities, different class abundances are assigned: the abundance function <italic>a()</italic> is assigned to chemicals, <italic>bp()</italic> for biological processes and <italic>path()</italic> (pathology) for diseases. For genes, different abundances <italic>g()</italic> (gene), <italic>r()</italic> (mRNA) or <italic>p()</italic> (protein) are possible, but to reduce complexity only <italic>p()</italic> is used in the BEL track. In our example in <xref rid="f1" ref-type="fig">Figure 1</xref>, we used the protein abundance function for both entities. In addition to class abundances, different functions can also be assigned to the biological entities. For the BEL track, we focused on the protein phosphorylation function <italic>pmod(P)</italic>, the protein activity function <italic>act()</italic>, the translocation function <italic>tloc()</italic>, the protein degradation function <italic>deg()</italic> and finally the <italic>complex()</italic> function, to describe protein complexes. For a more detailed description of this, see Rinaldi <italic>et al.</italic> (<xref rid="ref8" ref-type="bibr">8</xref>). In <xref rid="f1" ref-type="fig">Figure 1</xref>, the syntax for describing a phosphorylated protein is: <italic>p (HGNC:ATF2, pmod(P))</italic>.</p>
    </sec>
  </sec>
  <sec id="sec4">
    <title>Task description and evaluation</title>
    <p>The BEL track challenge was organized into two tasks evaluating the complementary aspects of the problem:</p>
    <list list-type="order">
      <list-item>
        <p>(i) Task 1: given textual evidence for a BEL statement, generate the corresponding BEL statement.</p>
      </list-item>
      <list-item>
        <p>(ii) Task 2: given a BEL statement, provide a maximum of 10 additional evidence sentences.</p>
      </list-item>
    </list>
    <p>The extraction of relationships and their coding in BEL is a complex task as a multitude of entity, relationship and function types can be involved in a single relationship. Therefore, we made a number of simplifications for the evaluation. Briefly, for genes and proteins, HGNC, EntrezGene or mouse orthologous (MGI) identifiers were accepted. For the abundance functions of these namespaces, all correct abundances were accepted. Furthermore, for the modification function <italic>pmod()</italic> and the translocation function <italic>tloc()</italic>, the number of arguments was reduced. The details of all simplifications are provided online (<ext-link ext-link-type="uri" xlink:href="http://wiki.openbel.org/display/BIOC/All+Functions+Evaluation+Overview">http://wiki.openbel.org/display/BIOC/All+Functions+Evaluation+Overview</ext-link>).</p>
    <p>A cascade evaluation model with different levels of success rates was performed for syntactically valid statements, whereas invalid statements were ignored. A submitted full BEL statement was automatically cut into its fragments to enable evaluations on lower levels. On the term level, only the correctness of BEL terms was assessed. Furthermore, the correctness of the discovered entities, the associated namespaces and the associated abundance and process functions were measured.</p>
    <p>The correctness of the discovered function was evaluated on the function level. Functions were only accepted together with their argument, the BEL term. As a simplification, a complex function was only valid if at least one of its arguments was correct. On the secondary function level, the correctness of a function alone was measured, regardless of the correctness of its term-arguments.</p>
    <p>In the relationship level evaluation, only the terms and relationships were considered. Functions that were part of a BEL statement were not taken into account on this level. Yet again, two levels of evaluation were considered. To obtain a full score relationship, subject, object and the relationship type had to be correct. For the secondary relationship level, partial relationships containing two out of three correct units (subject, object and relationship type) were considered fulfilled. This level was introduced in order to give weighting to the results, which although were partially correct, could still be useful as suggestions to a human curator in the context of a semi-automated approach. Finally, we evaluated how many BEL statements were entirely correct. The cascade evaluation model is depicted in <xref rid="f2" ref-type="fig">Figure 2</xref> and described in detail by Rinaldi <italic>et al.</italic> (<xref rid="ref8" ref-type="bibr">8</xref>).</p>
    <fig id="f2" orientation="portrait" position="float">
      <label>Figure 2</label>
      <caption>
        <p>An example of a candidate evaluation. The example shows the candidate sentence, the gold standard and predicted statements. The scores are provided for all primary and secondary levels (<xref rid="ref8" ref-type="bibr">8</xref>). Abbreviations: PMID (PubMed identifier), true positive (TP), false positive (FP), false negative (FN), recall (R), precision (P). Adapted and reprinted with permission from Fluck <italic>et al.</italic> (<xref rid="ref7" ref-type="bibr">7</xref>).</p>
      </caption>
      <graphic xlink:href="baz084f2"/>
    </fig>
    <p>For task 2, up to 10 evidence sentences for each BEL statement were accepted from the participating systems. Those statements were evaluated on two levels: on the ‘fully supportive level’, the sentence had to contain all necessary information for a biologist to create the BEL statement; and on the ‘partially supportive level’, the sentence was correct when relevant context information from surrounding sentences contained the additional information required. For more detailed information on the evaluation criteria, see Rinaldi <italic>et al.</italic> (<xref rid="ref8" ref-type="bibr">8</xref>).</p>
  </sec>
  <sec id="sec8">
    <title>Materials and methods</title>
    <sec id="sec9">
      <title>Training data and preparation of new test set</title>
      <p>The training data and test data from BioCreative V (2015) are available online (<ext-link ext-link-type="uri" xlink:href="https://wiki.openbel.org/display/BIOC/Datasets">https://wiki.openbel.org/display/BIOC/Datasets</ext-link>). The description of the training set selection and curation are described in detail by Fluck <italic>et al.</italic> (<xref rid="ref9" ref-type="bibr">9</xref>). For the generation of the 2017 BEL track task 1 test set, we used a real-world case and extracted new data in the disease context of ulcerative colitis. For the test set, we restricted the named entity classes to those that could be normalized to the gene and protein namespaces HGNC and MGI, including ChEBI for chemical names, MESHD for disease names and GOBP for biological processes. We also used a restricted set of relationship types and functions as defined above. For the extraction, we used automatic support in the form of BELIEF (<xref rid="ref10" ref-type="bibr">10</xref>). This workflow pre-annotated and normalized the named entities and suggested BEL statements in a user-friendly curation environment. At the front-end, the curator could browse through the text, search for unrecognized named entities and edit or add statements. Only user-selected statements were exported by the system.</p>
      <p>In the first step, two curators independently extracted the information from the same full texts. In the comparison of results, it became clear that it is very tedious to extract all possible statements from a document. Especially, since we would extract repetitively very similar statements only with different experimental settings, which was irrelevant for task 1. It was also not feasible for independent curators to select the same sentences for curation in the full text. Therefore, we decided to take a more straightforward approach. One person selected the relevant sentences and extracted all of the BEL statements from this sentence. Then, the second curator analyzed and edited this set. Finally, differences were discussed in an annotation jamboree.</p>
      <p>An overview of the number of different entities, functions and relationship types of the task 1 test set is given in <xref rid="TB1" ref-type="table">Table 1</xref>. For task 2, BEL statements were curated from PubMed abstracts to make sure that at least one sentence could be found for every BEL statement.</p>
      <table-wrap id="TB1" orientation="portrait" position="float">
        <label>Table 1</label>
        <caption>
          <p>Distribution of term, function and relationship types in the training and test corpora</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">
                <bold>Type</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>Training</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>Test 2015</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>Test 2017</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>
                  <italic>Terms</italic>
                </bold>
              </td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">p()</td>
              <td align="left" rowspan="1" colspan="1">19.918</td>
              <td align="left" rowspan="1" colspan="1">346</td>
              <td align="left" rowspan="1" colspan="1">328</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">a()</td>
              <td align="left" rowspan="1" colspan="1">1.927</td>
              <td align="left" rowspan="1" colspan="1">37</td>
              <td align="left" rowspan="1" colspan="1">52</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">bp()</td>
              <td align="left" rowspan="1" colspan="1">877</td>
              <td align="left" rowspan="1" colspan="1">31</td>
              <td align="left" rowspan="1" colspan="1">23</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">path()</td>
              <td align="left" rowspan="1" colspan="1">244</td>
              <td align="left" rowspan="1" colspan="1">15</td>
              <td align="left" rowspan="1" colspan="1">2</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>
                  <italic>Functions</italic>
                </bold>
              </td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">act()</td>
              <td align="left" rowspan="1" colspan="1">6.332</td>
              <td align="left" rowspan="1" colspan="1">36</td>
              <td align="left" rowspan="1" colspan="1">79</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">pmod()</td>
              <td align="left" rowspan="1" colspan="1">1.411</td>
              <td align="left" rowspan="1" colspan="1">9</td>
              <td align="left" rowspan="1" colspan="1">36</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">complex()</td>
              <td align="left" rowspan="1" colspan="1">750</td>
              <td align="left" rowspan="1" colspan="1">15</td>
              <td align="left" rowspan="1" colspan="1">5</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">tloc()</td>
              <td align="left" rowspan="1" colspan="1">406</td>
              <td align="left" rowspan="1" colspan="1">13</td>
              <td align="left" rowspan="1" colspan="1">10</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">deg()</td>
              <td align="left" rowspan="1" colspan="1">205</td>
              <td align="left" rowspan="1" colspan="1">6</td>
              <td align="left" rowspan="1" colspan="1">4</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">sub()</td>
              <td align="left" rowspan="1" colspan="1">23</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">trunc()</td>
              <td align="left" rowspan="1" colspan="1">6</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>
                  <italic>Relationships</italic>
                </bold>
              </td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">increases</td>
              <td align="left" rowspan="1" colspan="1">8.112</td>
              <td align="left" rowspan="1" colspan="1">155</td>
              <td align="left" rowspan="1" colspan="1">130</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">decreases</td>
              <td align="left" rowspan="1" colspan="1">2.956</td>
              <td align="left" rowspan="1" colspan="1">53</td>
              <td align="left" rowspan="1" colspan="1">68</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>For task 1 stage 1, we also provided the normalized names of all biological processes occurring in the test set, as extracting such concepts remains a non-trivial task. Finally, for task 1 stage 2, we provided a file with entity information and offsets and the associated normalized concept with the namespace.</p>
    </sec>
    <sec id="sec10">
      <title>Supporting material</title>
      <p>The participants were provided with a range of supporting resources and comprehensive documentation (<ext-link ext-link-type="uri" xlink:href="https://wiki.openbel.org/display/BIOC/BioCreative+BEL+Task+Challenges">https://wiki.openbel.org/display/BIOC/BioCreative+BEL+Task+Challenges</ext-link>), containing a description of the formats and a detailed explanation of the evaluation process. The evaluation of the different levels of a single BEL statement was illustrated using a set of concrete example submissions as reference. Additionally, validation and evaluation interfaces (<ext-link ext-link-type="uri" xlink:href="http://bio-eval.scai.fraunhofer.de/cgi-bin/General_server.rc">http://bio-eval.scai.fraunhofer.de/cgi-bin/General_server.rc</ext-link>
) were provided for the participants to validate and test their generated statements during the development phase. The BEL statement validator checks the user-provided BEL statements with respect to formal correctness and provides specific error messages for invalid BEL statements. For the sample, training and 2015 test sets, the evaluation interface evaluated the input BEL statements based on evaluation criteria such as term, function, relationship and full statement level. For a more detailed description of the candidate evaluation, see Rinaldi <italic>et al.</italic> (<xref rid="ref8" ref-type="bibr">8</xref>).</p>
      <p>Resources for further support included BEL statements from the training, sample and 2015 test sets in BioC format. A tab-separated format that contained all fragments of the BEL statements (terms, functions and relations) was automatically generated from the sample, training and 2015 test sets. These were provided to the participants as supporting material [c.f. (<xref rid="ref8" ref-type="bibr">8</xref>)] (<ext-link ext-link-type="uri" xlink:href="https://wiki.openbel.org/display/BIOC/Datasets">https://wiki.openbel.org/display/BIOC/Datasets</ext-link>).</p>
    </sec>
    <sec id="sec11">
      <title>Participating systems</title>
      <p>All participating systems can be compartmentalized in at least two main parts—a first part that is composed of a number of named entity recognition (NER) components for the recognition and normalization of the entities and a second part for relationship extraction and BEL translation. In NER, the systems use different tools that utilize various algorithmic approaches such as dictionary, rule-based and machine learning. The second part is dedicated to relationship extraction. Here, three approaches use a dependency parser as a preprocess step. BELMiner 2.0 uses graph traversal and BelSmile extracts relationships using predicate argument structures. After the extraction, all systems have a final component to transform extracted relationships to BEL statements.</p>
      <p>Two systems, the graph-based traversal system BELMiner 2.0 and the semantic role labeling approach BelSmile, participated in the BEL track for the second time. The newly participating systems used either hierarchical sequence labeling or deep neural networks for relationship extraction. Finally, one system, BelTracker, participated in task 2 of the BEL track, using a pre-annotated corpus for the different named entities and integrating a ranking component to order the resulting sentences by relevance. All systems are described in the following sections.</p>
      <sec id="sec12">
        <title>BELMiner 2.0—information extraction system to extract BEL relationships from biomedical literature</title>
        <p>BELMiner 2.0 (<xref rid="ref13" ref-type="bibr">13</xref>) is a generic graph-based traversal on the dependency graphs constructed from entity-normalized sentences. The following components are executed in sequence to process the evidence statement, with each component incrementally contributing towards BEL statement extraction: (i) extraction of normalized entities, (ii) identification of dependency structure, (iii) graph-based traversal to extract causal relationships, (iv) formalization of causal relations into BEL statements and (v) filtering out of irrelevant BEL statements.</p>
        <p><xref rid="f3" ref-type="fig">Figure 3</xref> outlines the overall architecture of BELMiner 2.0. It consists of an ensemble of state-of-the-art entity normalization tools to extract normalized entities from the evidence sentences provided for each NER task. TaggerOne (<xref rid="ref14" ref-type="bibr">14</xref>), a machine-learning toolkit, was adapted for BEL entity recognition and supplemented with annotations from other external tools such as beCAS (<xref rid="ref15" ref-type="bibr">15</xref>) and Reach (<xref rid="ref16" ref-type="bibr">16</xref>).</p>
        <fig id="f3" orientation="portrait" position="float">
          <label>Figure 3</label>
          <caption>
            <p>BELMiner 2.0 architecture.</p>
          </caption>
          <graphic xlink:href="baz084f3"/>
        </fig>
        <p>Within BelMiner2.0, the Stanford Parser 3.8 (<xref rid="ref17" ref-type="bibr">17</xref>) is applied to identify extended dependencies such as anaphora and co-references, and appositives and dependencies that occur beyond clausal boundaries. The identification of appropriate arguments for functions and relations involves a graph-based traversal (<xref rid="ref18" ref-type="bibr">18</xref>). The system first identifies the event or activity and phrase or term in the sentence and, using that as an anchor, traverses bi-directionally along the dependency graph to identify the arguments. During graph traversal, the system considers certain properties of the node, such as the semantic type of the node and properties such as negations. It also identifies the successive double negation of events along the traversal path to correctly identify the type of main event.</p>
      </sec>
      <sec id="sec13">
        <title>BelSmile—a semantic role labeling approach for extracting BEL statements</title>
        <p>BelSmile (<xref rid="ref19" ref-type="bibr">19</xref>) contains two main natural language processing (NLP) stages: NER and semantic role labeling (SRL). <xref rid="f4" ref-type="fig">Figure 4</xref> shows the workflow of the system. In the NER stage, BelSmile consists of an ensemble system composed of three approaches: statistical principle, conditional random fields (CRF) and dictionary-based. The statistical principle-based approach is used to identify protein mentions and achieved the highest score in terms of the second evaluation metric of the BioCreative V.5 Gene and protein related object recognition (GPRO) task (<xref rid="ref20" ref-type="bibr">20</xref>). The CRF-based NERChem (<xref rid="ref21" ref-type="bibr">21</xref>) is used to identify chemical mentions. Finally, the dictionary-based approach is used to recognize disease and biological process mentions by using external dictionaries including Entrez, ChEBI and BEL official dictionaries, which are also used to normalize each recognized NE mention to its database identifier.</p>
        <fig id="f4" orientation="portrait" position="float">
          <label>Figure 4</label>
          <caption>
            <p>BelSmile workflow.</p>
          </caption>
          <graphic xlink:href="baz084f4"/>
        </fig>
        <p>In the SRL stage, two systems, RCBiosmile (<xref rid="ref22" ref-type="bibr">22</xref>) and Enju (<xref rid="ref23" ref-type="bibr">23</xref>), are employed. Enju covers some predicates (verbs) not recognized by RCBiosmile, which is trained on the BioProp corpus (<xref rid="ref24" ref-type="bibr">24</xref>). In the configuration achieving the highest score, predicate argument structures (PASs) extracted from both systems are used.</p>
        <p>After the two NLP stages, BelSmile’s nominal patterns (<xref rid="ref25" ref-type="bibr">25</xref>) and newly-compiled verbal patterns are used to generate the BEL function markup for each named entity mention. These verbal patterns refer to elements in a PAS. Finally, BelSmile generates BEL-level statement(s) by feeding the PASs and named entities with functions into the BelSmile’s statement generation module.</p>
      </sec>
      <sec id="sec14">
        <title>A hierarchical sequence labeling system for the BioCreative VI BEL task</title>
        <p>The hierarchical sequence labeling system (<xref rid="ref26" ref-type="bibr">26</xref>) pipeline consists of five components: preprocessing, NER and mapping, parallel corpus construction, training corpus generation and model training and testing. <xref rid="f5" ref-type="fig">Figure 5</xref> illustrates the framework of the system.</p>
        <fig id="f5" orientation="portrait" position="float">
          <label>Figure 5</label>
          <caption>
            <p>Hierarchical sequence labeling system pipeline.</p>
          </caption>
          <graphic xlink:href="baz084f5"/>
        </fig>
        <p><italic>Preprocessing:</italic> Preprocessing the training corpus includes two steps: rule-based sentence tokenization and BEL statement serialization. The latter step also reduces BEL statement redundancy and inconsistencies and elevates the hierarchical level of some protein modification functions.</p>
        <p><italic>NER and mapping:</italic> Three NER tools are used to identify biomedical entities, including GNormplus (<xref rid="ref27" ref-type="bibr">27</xref>), tmChem (<xref rid="ref28" ref-type="bibr">28</xref>) and DNorm (<xref rid="ref29" ref-type="bibr">29</xref>). Additionally, a dictionary-based search method is employed to promote the recall rate of entities. For the training corpus, the identified entities are mapped to those in BEL statements.</p>
        <fig id="f6" orientation="portrait" position="float">
          <label>Figure 6</label>
          <caption>
            <p>Architecture of the neural network-based system.</p>
          </caption>
          <graphic xlink:href="baz084f6"/>
        </fig>
        <p><italic>Parallel corpus construction:</italic> In order to obtain the alignments between entities, functions and relationships in the BEL statement and the words in the sentence, we recast this problem as the word alignment problem between the source language (text sentence) and the target language (serial representation of the BEL statement). The target language is generated through three stages: (i) BEL tree generation, (ii) BEL tree unification and (iii) BEL tree serialization. To obtain the source language, the sentences are tokenized and then simplified by extracting the minimal subtree containing all the entities in the BEL statement. In a further step, words are serialized in the subtree according to their original order.</p>
        <p><italic>Training corpus generation:</italic> Generating a training corpus from the aforementioned parallel corpus follows two steps: initially, a word alignment tool GIZA++ (<xref rid="ref30" ref-type="bibr">30</xref>) is utilized to obtain alignments between words and BEL nodes. A hierarchically tagged corpus is then generated based on the alignment results between the nodes in the BEL statement and the words in the sentence. The corpus is annotated using the ‘BIESO’ (B-beginning, I-intermediate, E-end, S-single entity, O-outside) labeling scheme.</p>
        <p><italic>Training and testing:</italic> The open source CRF package CRF++ (<xref rid="ref31" ref-type="bibr">31</xref>) is used to train hierarchical sequence labeling models from the hierarchically tagged corpus. The first level sequence labeling model is trained on words and entities. When training the k-th level model, the lower k-1 layers are treated as features and the top-level model is reached recursively.</p>
        <p>In the testing stage, the trained <italic>L</italic> models are employed to label the test examples. In contrast to during training, when labeling the k-th layer the labels automatically recognized in the lower k-1 layers are treated as features. After labeling all the layers, the labeling results are converted into BEL statements. This process is basically the reverse of training example generation and can be divided into three steps, that is, BEL tree generation, unified tree splitting and BEL statement generation.</p>
      </sec>
      <sec id="sec15">
        <title>A neural network-based system to extract BEL statements</title>
        <p>BEL statement extraction through the neural network-based system (<xref rid="ref32" ref-type="bibr">32</xref>) is divided into four subtasks (c.f. <xref rid="f6" ref-type="fig">Figure 6</xref>): (i) NER, (ii) association detection, (iii) subject and object detection and (iv) relationship type detection. In the following, we discuss how we solved each subtask and present the network architecture that we used.</p>
        <p><italic>NER:</italic> For NER, the rule- and dictionary-based software ProMiner (<xref rid="ref33" ref-type="bibr">33</xref>) was used. It contains several terminologies to detect named entities. For the training set, we used ProMiner to find the offsets of the annotated entities. For the test set, we considered all detected entities for further predictions.</p>
        <p><italic>Association detection model:</italic> The second subtask was to decide whether a sentence describes an association between two entities or not (independently from any information about subject and object and the relationship type). In order to create artificial negative examples, a pair of entities was annotated as a negative example when no relationship was annotated in the training set. This strategy can produce false positives as shown in (<xref rid="ref9" ref-type="bibr">9</xref>) but can be realized with very low effort. The model was trained based on 6389 instances comprising 4633 positive and 1756 negative examples.</p>
        <p><italic>Subject and object detection model:</italic> The third subtask was to assign the subject and object within an entity pair. If the subject appears before the object, the instance is assigned to the class ‘Subject First’, otherwise it is assigned to the class ‘Object First’. This training set consists of 4633 examples from which 3156 instances belong to the class ‘Subject First’ and 1477 instances to the class ‘Object First’.</p>
        <p><italic>Relationship type detection model</italic>: The last subtask was to determine the type of relationship of an entity pair participating in an association. After mapping the relationship types ‘directly increases’ to ‘increases’ and ‘directly decreases’ to ‘decreases’, a neural network for this task was trained based on 4325 instances consisting of 3103 ‘increases’ and 1222 ‘decreases’ examples.</p>
        <p><italic>Architecture of the multichannel convolutional neural networks (CNN):</italic> For all three models described, B-D multichannel CNNs were trained (<xref rid="ref32" ref-type="bibr">32</xref>). The system development is based on the work of Quan <italic>et al.</italic> (<xref rid="ref34" ref-type="bibr">34</xref>) and Hua <italic>et al.</italic> (<xref rid="ref35" ref-type="bibr">35</xref>). The embedding layer contains the representations of the input sentence. The multichannel CNN uses different input channels for different representations of the sentence. Four Word2Vec models trained by Pyysalo <italic>et al.</italic> (<xref rid="ref36" ref-type="bibr">36</xref>), which are based on PubMed, PubMed Central and Wikipedia, are used to transform each word of the sentence into a vector representation. Based on these word vectors, a sentence-matrix is generated and passed to the network as input. In the sentence-matrix, each column represents a word, and the number of rows indicates the dimension of each word vector.</p>
        <p>In the convolutional layer, local features are computed by applying a convolutional operation on each sentence representation (<xref rid="ref32" ref-type="bibr">32</xref>). For each sentence representation, we retrieved a scalar value every time the sliding window of the convolution operation shifted. The scalar values of each shift were summed and passed to the activation function. The rows of a new matrix represent the results of the convolutions created by different kernels/filters (in this case four filters). At the end of the convolutional layer, a max-pooling operation created a feature vector by extracting the most significant features, taking the biggest value for each row. The feature vector was passed to a fully connected layer and the result given as input to a softmax classifier producing the predictions. In the convolutional layer and in the fully connected layer, the exponential linear unit was used as the non-linear activation function.</p>
      </sec>
      <sec id="sec16">
        <title>BELTracker—a system for semantic sentence retrieval</title>
        <p>The BELTracker (<xref rid="ref37" ref-type="bibr">37</xref>) is focused on the second task of the BEL track, in which evidence sentences for given BEL statements are requested. The system has three main components: indexing, retrieval and ranking. In the first component, we retrieved ‘informative sentences’ from MEDLINE abstracts and indexed them in a text search engine, called Elasticsearch (<ext-link ext-link-type="uri" xlink:href="https://www.elastic.co/de/products/elasticsearch">https://www.elastic.co/de/products/elasticsearch</ext-link>
). To identify such sentences, the system relied on the Semantic Medline Database (SemMedDB) (<xref rid="ref38" ref-type="bibr">38</xref>), which is a relational database that stores all sentences from MEDLINE abstracts containing at least two biomedical entities and a relationship between them.</p>
        <p>The retrieval component in this system was the same as in our previous system (<xref rid="ref39" ref-type="bibr">39</xref>). All elements (e.g. entities, functions and relationships) in the given BEL statement were identified, synonyms were added and a query for the index was generated. Elasticsearch retrieves these sentences based on co-occurrence returns and, at most, 1000 evidence sentences for a given BEL statement.</p>
        <p>In order to rank the retrieved sentences, the ranking component applies three classifiers: entity–entity (EE) classifier, function–entity (FE) classifier and relationship classifier. The EE classifier examines the relationship between the entities and classifies sentences into ‘positive’ (existence of a relationship) and ‘negative’ (no relation; only co-occurrence). To obtain negative instances, sentences from SemMedDB that contain two biomedical entities with a ‘co-exist’ relationship type (meaning there is not any specific type of relationship between the entities and they only co-occur in corresponding sentences) were retrieved. Unigrams, bigrams and word embedding of terms between entities were used as features for the EE classifier.</p>
        <p>The ‘function–entity classifier’ calculated the probability of a relationship between functions and entities in the retrieved sentences. For example, the BEL statement ‘catalyticActivity (HGNC:XIAP) decreases catalyticActivity (HGNC:CASP9)’ contains two FE relationships: ‘cat-XIAP’ and ‘cat-CASP9’. We trained a set of FE classifiers, where each classifier targeted one BEL function. To train FE classifiers, both positive and negative instances were available in the training data provided by the organizers. Unigrams and bigrams of the words surrounding an entity (a window of three–five words) were utilized as features for FE classifiers. Beside lexical features, we used word embedding, dependency-based word embedding and abstract meaning representation embedding (<xref rid="ref40" ref-type="bibr">40</xref>) as other features for FE classifiers.</p>
        <fig id="f7" orientation="portrait" position="float">
          <label>Figure 7</label>
          <caption>
            <p>Best results of each system of BioCreative VI (2017) and BioCreative V (2015) in each structured level of task 1.</p>
          </caption>
          <graphic xlink:href="baz084f7"/>
        </fig>
        <p>The last classifier categorized the retrieved sentences based on two BEL relationship types: ‘increase’ and ‘decrease’. More details about this classifier, such as list of the features, are explained in our previous publication (<xref rid="ref39" ref-type="bibr">39</xref>).</p>
        <p>The final score was calculated using the following equation:</p>
        <p>Score<sub>sentence</sub> = W<sub>EE</sub> * P<sub>EE</sub> + W<sub>FE</sub> * P<sub>FE</sub> + W<sub>R</sub> * P<sub>R</sub>.</p>
        <p><italic>P</italic> represents the probability produced by the classifiers and <italic>W</italic> indicates the weight assigned to each classifier. We assigned weight to each classifier based on its importance and the accuracy of the training data set. The weights were: W<sub>EE</sub> = 0.4, W<sub>FE</sub> = 0.5 and W<sub>Relation</sub> = 0.1. The FE classifier had the highest weight because the data used to train this classifier had less noise compared with the EE classifier. The relation classifier had a lower weight compared with the others, because we observed that rarely did two sentences contain all elements of a BEL statement, but they did often convey two different relationship types. That is, if entities and functions of a given BEL statement appear in a sentence, it is likely that the sentence has the relationship type mentioned in the BEL statement.</p>
      </sec>
    </sec>
  </sec>
  <sec id="sec17">
    <title>Results</title>
    <p>Here, we describe the achieved performance scores of the participating systems for each BEL track task.</p>
    <sec id="sec18">
      <title>Task 1: given textual evidence for a BEL statement, generate the corresponding BEL statement</title>
      <p>Thirteen teams registered for the first task of the BEL track; however, four teams contributed results of their BEL extraction systems. The task was performed in two stages. In the first stage, teams had to provide their own NER and normalization to the defined namespaces, whereas in the second stage, the entities of the relationships were given. In each stage, a maximum number of three submissions were permitted. As described in the methods section, the evaluation of the submitted BEL statements was performed in a number of subsiding steps. This allowed for the identification of the challenges on each different structural level.</p>
      <p>A summary of the best F-scores for all participants of stage 1 is shown in <xref rid="f7" ref-type="fig">Figure 7</xref>, along with the best scores of the BioCreative V (2015) evaluation. Although different test sets were used in the BioCreative V (2015) and VI (2017) BEL tracks, their characteristics, such as the size of the datasets, the included entity types, BEL functions and the relationships, were similar. It is therefore reasonable to compare the results of both assessments. Overall, <xref rid="f7" ref-type="fig">Figure 7</xref> illustrates several trends: firstly, prediction scores of the secondary level are significantly higher than their specific primary level scores; secondly, the complexity of the extraction process increases from term, relation and function to BEL statement extraction level. Compared with BioCreative V, a clear performance gain was achieved at the functional and full statement levels.</p>
      <p>The detailed results of each individual run of stage 1 are provided in <xref rid="TB2" ref-type="table">Table 2</xref>. The results are color-coded according to F-score values (F), the main evaluation criterion, and supplemented by the values for precision (P) and recall (R). The best results for each evaluation metric are marked in bold. In general, all teams took part on all structural levels except the neural network-based system, which excluded the function level.</p>
      <table-wrap id="TB2" orientation="portrait" position="float">
        <label>Table 2</label>
        <caption>
          <p>Evaluation of stage 1 of task 1 (prediction of BEL statements without gold standard entities). F, P and R stand for F-score, precision and recall, respectively</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">
                <bold>System</bold>
              </th>
              <th rowspan="1" colspan="1"/>
              <th colspan="3" align="left" rowspan="1">
                <bold>Terms</bold>
              </th>
              <th colspan="3" align="left" rowspan="1">
                <bold>Function</bold>
              </th>
              <th colspan="3" align="left" rowspan="1">
                <bold>Function-Second</bold>
              </th>
              <th colspan="3" align="left" rowspan="1">
                <bold>Relation</bold>
              </th>
              <th colspan="3" align="left" rowspan="1">
                <bold>Relation-Second</bold>
              </th>
              <th colspan="3" align="left" rowspan="1">
                <bold>Statement</bold>
              </th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th align="left" rowspan="1" colspan="1">
                <bold>Run</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>F</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>P</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>R</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>F</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>P</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>R</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>F</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>P</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>R</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>F</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>P</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>R</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>F</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>P</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>R</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>F</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>P</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>R</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>BEL-</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">r1</td>
              <td align="center" rowspan="1" colspan="1">63.24</td>
              <td align="center" rowspan="1" colspan="1">84.62</td>
              <td align="center" rowspan="1" colspan="1">50.49</td>
              <td align="center" rowspan="1" colspan="1">33.99</td>
              <td align="center" rowspan="1" colspan="1">44.83</td>
              <td align="center" rowspan="1" colspan="1">27.37</td>
              <td align="center" rowspan="1" colspan="1">51.24</td>
              <td align="center" rowspan="1" colspan="1">67.39</td>
              <td align="center" rowspan="1" colspan="1">41.33</td>
              <td align="center" rowspan="1" colspan="1">40.22</td>
              <td align="center" rowspan="1" colspan="1">55.38</td>
              <td align="center" rowspan="1" colspan="1">31.58</td>
              <td align="center" rowspan="1" colspan="1">62.92</td>
              <td align="center" rowspan="1" colspan="1">88.19</td>
              <td align="center" rowspan="1" colspan="1">48.91</td>
              <td align="center" rowspan="1" colspan="1">22.99</td>
              <td align="center" rowspan="1" colspan="1">33.33</td>
              <td align="center" rowspan="1" colspan="1">17.54</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>smile</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">r2</td>
              <td align="center" rowspan="1" colspan="1">57.75</td>
              <td align="center" rowspan="1" colspan="1">81.93</td>
              <td align="center" rowspan="1" colspan="1">44.59</td>
              <td align="center" rowspan="1" colspan="1">31.08</td>
              <td align="center" rowspan="1" colspan="1">43.4</td>
              <td align="center" rowspan="1" colspan="1">24.21</td>
              <td align="center" rowspan="1" colspan="1">38.67</td>
              <td align="center" rowspan="1" colspan="1">69.05</td>
              <td align="center" rowspan="1" colspan="1">38.67</td>
              <td align="center" rowspan="1" colspan="1">36.78</td>
              <td align="center" rowspan="1" colspan="1">53.33</td>
              <td align="center" rowspan="1" colspan="1">28.07</td>
              <td align="center" rowspan="1" colspan="1">57.73</td>
              <td align="center" rowspan="1" colspan="1">86.84</td>
              <td align="center" rowspan="1" colspan="1">43.23</td>
              <td align="center" rowspan="1" colspan="1">20.71</td>
              <td align="center" rowspan="1" colspan="1">31.82</td>
              <td align="center" rowspan="1" colspan="1">15.35</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">r3</td>
              <td align="center" rowspan="1" colspan="1">61.24</td>
              <td align="center" rowspan="1" colspan="1">88.27</td>
              <td align="center" rowspan="1" colspan="1">46.89</td>
              <td align="center" rowspan="1" colspan="1">32.88</td>
              <td align="center" rowspan="1" colspan="1">47.06</td>
              <td align="center" rowspan="1" colspan="1">25.26</td>
              <td align="center" rowspan="1" colspan="1">46.15</td>
              <td align="center" rowspan="1" colspan="1">64.29</td>
              <td align="left" rowspan="1" colspan="1">36</td>
              <td align="center" rowspan="1" colspan="1">37.43</td>
              <td align="center" rowspan="1" colspan="1">56.14</td>
              <td align="center" rowspan="1" colspan="1">28.07</td>
              <td align="center" rowspan="1" colspan="1">62.03</td>
              <td align="center" rowspan="1" colspan="1">92.24</td>
              <td align="center" rowspan="1" colspan="1">46.72</td>
              <td align="center" rowspan="1" colspan="1">21.15</td>
              <td align="center" rowspan="1" colspan="1">33.98</td>
              <td align="center" rowspan="1" colspan="1">15.35</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>HSL-</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">r1</td>
              <td align="center" rowspan="1" colspan="1">50.88</td>
              <td align="center" rowspan="1" colspan="1">76.82</td>
              <td align="center" rowspan="1" colspan="1">38.03</td>
              <td align="left" rowspan="1" colspan="1">6</td>
              <td align="left" rowspan="1" colspan="1">60</td>
              <td align="left" rowspan="1" colspan="1">3.16</td>
              <td align="left" rowspan="1" colspan="1">7.5</td>
              <td align="left" rowspan="1" colspan="1">60</td>
              <td align="left" rowspan="1" colspan="1">4</td>
              <td align="center" rowspan="1" colspan="1">16.77</td>
              <td align="center" rowspan="1" colspan="1">31.71</td>
              <td align="left" rowspan="1" colspan="1">11.4</td>
              <td align="center" rowspan="1" colspan="1">45.14</td>
              <td align="left" rowspan="1" colspan="1">80</td>
              <td align="center" rowspan="1" colspan="1">31.44</td>
              <td align="left" rowspan="1" colspan="1">7.38</td>
              <td align="center" rowspan="1" colspan="1">15.71</td>
              <td align="left" rowspan="1" colspan="1">4.82</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>based</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">r2</td>
              <td align="center" rowspan="1" colspan="1">55.29</td>
              <td align="center" rowspan="1" colspan="1">81.01</td>
              <td align="center" rowspan="1" colspan="1">41.97</td>
              <td align="left" rowspan="1" colspan="1">6.06</td>
              <td align="left" rowspan="1" colspan="1">75</td>
              <td align="left" rowspan="1" colspan="1">3.16</td>
              <td align="left" rowspan="1" colspan="1">7.59</td>
              <td align="left" rowspan="1" colspan="1">75</td>
              <td align="left" rowspan="1" colspan="1">4</td>
              <td align="center" rowspan="1" colspan="1">21.52</td>
              <td align="center" rowspan="1" colspan="1">38.64</td>
              <td align="center" rowspan="1" colspan="1">14.91</td>
              <td align="center" rowspan="1" colspan="1">51.06</td>
              <td align="left" rowspan="1" colspan="1">84</td>
              <td align="center" rowspan="1" colspan="1">36.68</td>
              <td align="center" rowspan="1" colspan="1">10.67</td>
              <td align="center" rowspan="1" colspan="1">22.22</td>
              <td align="left" rowspan="1" colspan="1">7.02</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">r3</td>
              <td align="center" rowspan="1" colspan="1">67.83</td>
              <td align="center" rowspan="1" colspan="1">72.22</td>
              <td align="center" rowspan="1" colspan="1">63.93</td>
              <td align="center" rowspan="1" colspan="1">20.17</td>
              <td align="left" rowspan="1" colspan="1">50</td>
              <td align="center" rowspan="1" colspan="1">12.63</td>
              <td align="center" rowspan="1" colspan="1">31.25</td>
              <td align="center" rowspan="1" colspan="1">71.43</td>
              <td align="left" rowspan="1" colspan="1">20</td>
              <td align="center" rowspan="1" colspan="1">24.69</td>
              <td align="center" rowspan="1" colspan="1">28.25</td>
              <td align="center" rowspan="1" colspan="1">21.93</td>
              <td align="center" rowspan="1" colspan="1">62.25</td>
              <td align="center" rowspan="1" colspan="1">70.95</td>
              <td align="center" rowspan="1" colspan="1">55.46</td>
              <td align="center" rowspan="1" colspan="1">10.44</td>
              <td align="left" rowspan="1" colspan="1">12.9</td>
              <td align="left" rowspan="1" colspan="1">8.77</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>BEL-</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">r1</td>
              <td align="center" rowspan="1" colspan="1">74.14</td>
              <td align="center" rowspan="1" colspan="1">78.18</td>
              <td align="center" rowspan="1" colspan="1">70.49</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>40.54</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">56.6</td>
              <td align="center" rowspan="1" colspan="1">31.58</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>55.28</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">70.83</td>
              <td align="center" rowspan="1" colspan="1">45.33</td>
              <td align="center" rowspan="1" colspan="1">43.65</td>
              <td align="center" rowspan="1" colspan="1">51.81</td>
              <td align="center" rowspan="1" colspan="1">37.72</td>
              <td align="center" rowspan="1" colspan="1">86.17</td>
              <td align="center" rowspan="1" colspan="1">89.62</td>
              <td align="center" rowspan="1" colspan="1">82.97</td>
              <td align="center" rowspan="1" colspan="1">32.28</td>
              <td align="center" rowspan="1" colspan="1">40.67</td>
              <td align="center" rowspan="1" colspan="1">26.75</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>miner</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">
                <bold>r2</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">72.89</td>
              <td align="center" rowspan="1" colspan="1">78.71</td>
              <td align="center" rowspan="1" colspan="1">67.87</td>
              <td align="center" rowspan="1" colspan="1">40.29</td>
              <td align="center" rowspan="1" colspan="1">63.64</td>
              <td align="center" rowspan="1" colspan="1">29.47</td>
              <td align="center" rowspan="1" colspan="1">54.39</td>
              <td align="center" rowspan="1" colspan="1">79.49</td>
              <td align="center" rowspan="1" colspan="1">41.33</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>43.77</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">52.12</td>
              <td align="center" rowspan="1" colspan="1">37.72</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>86.71</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">93</td>
              <td align="center" rowspan="1" colspan="1">81.22</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>32.45</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">41.22</td>
              <td align="center" rowspan="1" colspan="1">26.75</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>NN-</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">r1</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>76.39</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">81.18</td>
              <td align="center" rowspan="1" colspan="1">72.13</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="center" rowspan="1" colspan="1">29.87</td>
              <td align="center" rowspan="1" colspan="1">25.55</td>
              <td align="center" rowspan="1" colspan="1">35.96</td>
              <td align="center" rowspan="1" colspan="1">65.19</td>
              <td align="center" rowspan="1" colspan="1">60.45</td>
              <td align="center" rowspan="1" colspan="1">70.74</td>
              <td align="center" rowspan="1" colspan="1">18.08</td>
              <td align="left" rowspan="1" colspan="1">16.1</td>
              <td align="center" rowspan="1" colspan="1">20.61</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>based</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">r2</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>76.39</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">81.18</td>
              <td align="center" rowspan="1" colspan="1">72.13</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="center" rowspan="1" colspan="1">28.92</td>
              <td align="center" rowspan="1" colspan="1">24.19</td>
              <td align="center" rowspan="1" colspan="1">35.96</td>
              <td align="center" rowspan="1" colspan="1">65.23</td>
              <td align="center" rowspan="1" colspan="1">59.29</td>
              <td align="center" rowspan="1" colspan="1">72.49</td>
              <td align="center" rowspan="1" colspan="1">17.88</td>
              <td align="center" rowspan="1" colspan="1">15.53</td>
              <td align="center" rowspan="1" colspan="1">21.05</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>Overall, the two systems participating the second time performed best in almost all categories: the BELMiner system, in particular, outperformed all other systems. Analysis of the different steps revealed that NER performance in stage 1 reached F-scores between 63% and 76.39% for the best performing runs. The function extraction seemed to be more difficult than relationship extraction and produced the greatest differences. BELMiner could extract function information in stage 1 with an F-score of 40.54% and BelSmile with a best performance of 33.99%. The hierarchical sequence labeling system could recognize correct functions with an F-score of only 20%, and the neural network-based system did not predict any functions at all.</p>
      <p>At the relationship level, BELMiner and BelSmile achieved similar F-score performances of 43.77% and 40.22%, respectively. This is a large difference with the other systems with F-scores of 29.8% and 24.6% for the neural network-based system and the hierarchical sequence labeling system, respectively. At the secondary relationship level, where only two thirds of the relationship (subject, object and relation type) needed to be correct, BELMiner achieved an impressive F-score of 87%. All other systems reached F-scores only between 62% and 65%.</p>
      <p>Finally, the best full BEL statement extraction score for BELMiner was 32.45% at stage 1. This illustrates the difficulty of this highly structured prediction task. Despite similar values for relationship extraction, BelSmile lost performance in comparison with BELMiner and achieved an F-score of only 22.99%. Surprisingly, despite no function recognition and low relationship extraction performance, the neural network-based system obtained an F-score for full statement extraction of 18%. The hierarchical sequence labeling system reached only 10.6% and shows the difficulty of sentence to BEL statement alignment.</p>
      <p>The detailed results for task 1 stage 2 are shown in <xref rid="TB3" ref-type="table">Table 3</xref>, and a summary is illustrated in <xref rid="f7" ref-type="fig">Figure 7</xref>. In this stage, the gold standard concepts, together with their specific text spans, were made available to the teams. All teams could significantly benefit and improve on the level of the full statements. These results show the importance of high-quality term recognition for further higher-level recognition tasks. NER was enhanced to 83–91% in the second stage. Because NER was not evaluated independently, but only when full statements were provided by the systems, no system could reach an F-score of 100%.</p>
      <table-wrap id="TB3" orientation="portrait" position="float">
        <label>Table 3</label>
        <caption>
          <p>Evaluation of stage 2 of task 1 (prediction of BEL statements with gold standard entities)</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">
                <bold>System</bold>
              </th>
              <th rowspan="1" colspan="1"/>
              <th colspan="3" align="left" rowspan="1">
                <bold>Terms</bold>
              </th>
              <th colspan="3" align="left" rowspan="1">
                <bold>Function</bold>
              </th>
              <th colspan="3" align="left" rowspan="1">
                <bold>Function-second</bold>
              </th>
              <th colspan="3" align="left" rowspan="1">
                <bold>Relation</bold>
              </th>
              <th colspan="3" align="left" rowspan="1">
                <bold>Relation-second</bold>
              </th>
              <th colspan="3" align="left" rowspan="1">
                <bold>Statement</bold>
              </th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th align="left" rowspan="1" colspan="1">
                <bold>Run</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>F</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>P</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>R</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>F</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>P</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>R</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>F</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>P</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>R</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>F</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>P</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>R</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>F</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>P</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>R</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>F</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>P</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>R</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>BEL-</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">r1</td>
              <td align="center" rowspan="1" colspan="1">83.93</td>
              <td align="center" rowspan="1" colspan="1">99.11</td>
              <td align="center" rowspan="1" colspan="1">72.79</td>
              <td align="center" rowspan="1" colspan="1">36.36</td>
              <td align="center" rowspan="1" colspan="1">47.46</td>
              <td align="center" rowspan="1" colspan="1">29.47</td>
              <td align="center" rowspan="1" colspan="1">46.77</td>
              <td align="center" rowspan="1" colspan="1">59.18</td>
              <td align="center" rowspan="1" colspan="1">38.67</td>
              <td align="center" rowspan="1" colspan="1">57.22</td>
              <td align="center" rowspan="1" colspan="1">73.29</td>
              <td align="center" rowspan="1" colspan="1">46.93</td>
              <td align="center" rowspan="1" colspan="1">83.33</td>
              <td align="left" rowspan="1" colspan="1">98.8</td>
              <td align="center" rowspan="1" colspan="1">72.05</td>
              <td align="center" rowspan="1" colspan="1">31.30</td>
              <td align="center" rowspan="1" colspan="1">46.15</td>
              <td align="center" rowspan="1" colspan="1">23.68</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>smile</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">r2</td>
              <td align="center" rowspan="1" colspan="1">86.09</td>
              <td align="center" rowspan="1" colspan="1">99.15</td>
              <td align="center" rowspan="1" colspan="1">76.07</td>
              <td align="center" rowspan="1" colspan="1">40.51</td>
              <td align="center" rowspan="1" colspan="1">50.79</td>
              <td align="center" rowspan="1" colspan="1">33.68</td>
              <td align="center" rowspan="1" colspan="1">51.16</td>
              <td align="center" rowspan="1" colspan="1">61.11</td>
              <td align="left" rowspan="1" colspan="1">44</td>
              <td align="center" rowspan="1" colspan="1">56.08</td>
              <td align="center" rowspan="1" colspan="1">70.67</td>
              <td align="center" rowspan="1" colspan="1">46.49</td>
              <td align="center" rowspan="1" colspan="1">83.92</td>
              <td align="center" rowspan="1" colspan="1">98.82</td>
              <td align="center" rowspan="1" colspan="1">72.93</td>
              <td align="center" rowspan="1" colspan="1">30.95</td>
              <td align="center" rowspan="1" colspan="1">44.63</td>
              <td align="center" rowspan="1" colspan="1">23.68</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">r3</td>
              <td align="center" rowspan="1" colspan="1">85.45</td>
              <td align="center" rowspan="1" colspan="1">99.13</td>
              <td align="center" rowspan="1" colspan="1">75.08</td>
              <td align="center" rowspan="1" colspan="1">39.24</td>
              <td align="center" rowspan="1" colspan="1">49.21</td>
              <td align="center" rowspan="1" colspan="1">32.63</td>
              <td align="left" rowspan="1" colspan="1">50</td>
              <td align="center" rowspan="1" colspan="1">60.38</td>
              <td align="center" rowspan="1" colspan="1">42.67</td>
              <td align="center" rowspan="1" colspan="1">57.6</td>
              <td align="center" rowspan="1" colspan="1">73.47</td>
              <td align="center" rowspan="1" colspan="1">47.37</td>
              <td align="center" rowspan="1" colspan="1">83.63</td>
              <td align="center" rowspan="1" colspan="1">98.81</td>
              <td align="center" rowspan="1" colspan="1">72.49</td>
              <td align="center" rowspan="1" colspan="1">31.79</td>
              <td align="center" rowspan="1" colspan="1">46.61</td>
              <td align="center" rowspan="1" colspan="1">24.12</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>HSL-</bold>
                <break/>
                <bold>based</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">r1</td>
              <td align="center" rowspan="1" colspan="1">90.20</td>
              <td align="center" rowspan="1" colspan="1">98.83</td>
              <td align="center" rowspan="1" colspan="1">82.95</td>
              <td align="center" rowspan="1" colspan="1">12.39</td>
              <td align="center" rowspan="1" colspan="1">38.89</td>
              <td align="center" rowspan="1" colspan="1">7.37</td>
              <td align="center" rowspan="1" colspan="1">21.74</td>
              <td align="center" rowspan="1" colspan="1">58.82</td>
              <td align="center" rowspan="1" colspan="1">13.33</td>
              <td align="center" rowspan="1" colspan="1">42.52</td>
              <td align="center" rowspan="1" colspan="1">52.94</td>
              <td align="center" rowspan="1" colspan="1">35.53</td>
              <td align="center" rowspan="1" colspan="1">84.24</td>
              <td align="center" rowspan="1" colspan="1">96.61</td>
              <td align="center" rowspan="1" colspan="1">74.67</td>
              <td align="center" rowspan="1" colspan="1">22.66</td>
              <td align="left" rowspan="1" colspan="1">32</td>
              <td align="center" rowspan="1" colspan="1">17.54</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>BEL-</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">r1</td>
              <td align="center" rowspan="1" colspan="1">87.65</td>
              <td align="center" rowspan="1" colspan="1">90.56</td>
              <td align="center" rowspan="1" colspan="1">84.92</td>
              <td align="center" rowspan="1" colspan="1">51.75</td>
              <td align="center" rowspan="1" colspan="1">77.08</td>
              <td align="center" rowspan="1" colspan="1">38.95</td>
              <td align="center" rowspan="1" colspan="1">57.63</td>
              <td align="center" rowspan="1" colspan="1">79.07</td>
              <td align="center" rowspan="1" colspan="1">45.33</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>66.83</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">76.7</td>
              <td align="center" rowspan="1" colspan="1">59.21</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>92.06</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">95.75</td>
              <td align="center" rowspan="1" colspan="1">88.65</td>
              <td align="left" rowspan="1" colspan="1">49.2</td>
              <td align="center" rowspan="1" colspan="1">63.01</td>
              <td align="center" rowspan="1" colspan="1">40.35</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>miner</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">
                <bold>r2</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">86.4</td>
              <td align="center" rowspan="1" colspan="1">90.94</td>
              <td align="left" rowspan="1" colspan="1">82.3</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>52.55</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">85.71</td>
              <td align="center" rowspan="1" colspan="1">37.89</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>58.93</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">89.19</td>
              <td align="left" rowspan="1" colspan="1">44</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>66.83</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">76.7</td>
              <td align="center" rowspan="1" colspan="1">59.21</td>
              <td align="center" rowspan="1" colspan="1">91.92</td>
              <td align="center" rowspan="1" colspan="1">97.55</td>
              <td align="left" rowspan="1" colspan="1">86.9</td>
              <td align="left" rowspan="1" colspan="1">
                <bold>49.6</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">64.34</td>
              <td align="center" rowspan="1" colspan="1">40.35</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">r3</td>
              <td align="center" rowspan="1" colspan="1">87.41</td>
              <td align="center" rowspan="1" colspan="1">90.81</td>
              <td align="center" rowspan="1" colspan="1">84.26</td>
              <td align="center" rowspan="1" colspan="1">51.75</td>
              <td align="center" rowspan="1" colspan="1">77.08</td>
              <td align="center" rowspan="1" colspan="1">38.95</td>
              <td align="center" rowspan="1" colspan="1">57.63</td>
              <td align="center" rowspan="1" colspan="1">79.07</td>
              <td align="center" rowspan="1" colspan="1">45.33</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>66.83</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">76.7</td>
              <td align="center" rowspan="1" colspan="1">59.21</td>
              <td align="center" rowspan="1" colspan="1">91.99</td>
              <td align="center" rowspan="1" colspan="1">96.63</td>
              <td align="center" rowspan="1" colspan="1">87.77</td>
              <td align="left" rowspan="1" colspan="1">49.2</td>
              <td align="center" rowspan="1" colspan="1">63.01</td>
              <td align="center" rowspan="1" colspan="1">40.35</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>NN-</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">r1</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>91.33</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">99.23</td>
              <td align="center" rowspan="1" colspan="1">84.59</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="center" rowspan="1" colspan="1">43.51</td>
              <td align="center" rowspan="1" colspan="1">41.6</td>
              <td align="center" rowspan="1" colspan="1">45.61</td>
              <td align="center" rowspan="1" colspan="1">86.36</td>
              <td align="center" rowspan="1" colspan="1">90.05</td>
              <td align="center" rowspan="1" colspan="1">82.97</td>
              <td align="center" rowspan="1" colspan="1">23.61</td>
              <td align="left" rowspan="1" colspan="1">25</td>
              <td align="center" rowspan="1" colspan="1">22.37</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>based</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">r2</td>
              <td align="center" rowspan="1" colspan="1">88.36</td>
              <td align="center" rowspan="1" colspan="1">99.18</td>
              <td align="center" rowspan="1" colspan="1">79.67</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="center" rowspan="1" colspan="1">42.47</td>
              <td align="center" rowspan="1" colspan="1">44.29</td>
              <td align="center" rowspan="1" colspan="1">40.79</td>
              <td align="center" rowspan="1" colspan="1">83.41</td>
              <td align="center" rowspan="1" colspan="1">91.19</td>
              <td align="center" rowspan="1" colspan="1">76.86</td>
              <td align="center" rowspan="1" colspan="1">24.06</td>
              <td align="center" rowspan="1" colspan="1">28.07</td>
              <td align="center" rowspan="1" colspan="1">21.05</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">r3</td>
              <td align="center" rowspan="1" colspan="1">76.71</td>
              <td align="center" rowspan="1" colspan="1">98.96</td>
              <td align="center" rowspan="1" colspan="1">62.62</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="left" rowspan="1" colspan="1">0</td>
              <td align="center" rowspan="1" colspan="1">25.68</td>
              <td align="center" rowspan="1" colspan="1">29.38</td>
              <td align="center" rowspan="1" colspan="1">22.81</td>
              <td align="center" rowspan="1" colspan="1">71.76</td>
              <td align="center" rowspan="1" colspan="1">85.98</td>
              <td align="center" rowspan="1" colspan="1">61.57</td>
              <td align="center" rowspan="1" colspan="1">15.06</td>
              <td align="center" rowspan="1" colspan="1">18.47</td>
              <td align="center" rowspan="1" colspan="1">12.72</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>Performance increases can be seen on all evaluation levels for all teams. Again, BELMiner improved the most on all levels. For full statement level, it reached the highest F-score of 49.6% with the provided terms. In comparison to stage 1, the score was increased up to 17% on the same test set. Similar performance increases were seen on the function and relationship levels too. In summary, the comparison of all teams shows that most teams, except for the neural network-based system, built systems that focused more on precision rather than recall. Furthermore, high scores on the relationship level do not necessarily correlate with high scores on the full statement level. This is because the full statement level combines all structural levels.</p>
      <p>To evaluate whether some information is more difficult to extract than others, we identified the information for which not a single correct prediction was produced. <xref rid="f8" ref-type="fig">Figure 8</xref> shows the number of sentences for which no run of any participant system provided any valid prediction for each structured level. On the term level, only two sentences with no true term predictions were found. In stage 1, on the relationship-secondary and relationship level, no correct predictions were made for 6 and 15 sentences, respectively. In stage 2, where the terms were provided, this was reduced significantly. A high number of sentences with no valid predictions for function-secondary and function level in both stages could be identified (36 and 39 in stage 1, 33 and 35 in stage 2). Here, the given entity information in stage 2 only slightly reduced the amount of non-prediction sentences. The analysis of the different functions showed that around 23% (18/79) of the activity functions and 50% of the <italic>tloc()</italic> (5/10) functions were not predicted from any system. For the activity functions, <italic>tloc()</italic> is also the most ambiguous in curator annotation and is also most difficult to recognize because biological interpretation is necessary. An example is the statement ‘p (HGNC:TNF) increases tloc(p (HGNC:KHDRBS1), GOCC:cytoplasm, GOCC:nucleus)’ that was extracted from the following sentence: ‘The results showed Sam68 levels decreased in the cytoplasm following TNF-a stimulation for 1 h, which was paralleled by a corresponding increase in its nuclear level showing that Sam68 is a TNF-a responsive protein (<xref rid="f7" ref-type="fig">Fig. 7d</xref>)’ (<xref rid="ref41" ref-type="bibr">41</xref>).</p>
      <fig id="f8" orientation="portrait" position="float">
        <label>Figure 8</label>
        <caption>
          <p>Number of sentences for each structured level on each stage for which no correct prediction was produced by any run of any participant system.</p>
        </caption>
        <graphic xlink:href="baz084f8"/>
      </fig>
      <p><xref rid="f8" ref-type="fig">Figure 8</xref> also clearly shows that entity information also improved performance on the statement level. In stage 1, 40 sentences lacked a correct prediction, whereas in stage 2, only 23 sentences had no valid prediction. A typical relationship that the automatic systems could not extract was the BEL statement ‘act(p (HGNC:EDNRA)) increases a (CHEBI:“calcium(2+)”)’ from the sentence ‘This ET-1-induced cell proliferation and [Ca2+] increase were completely abolished by BQ123, a selective ETAR antagonist, but not by BQ788, a selective ETBR antagonist’ (<xref rid="ref42" ref-type="bibr">42</xref>). For the extraction of such statements, an understanding of biological experiments and reasoning, as well as interpretation of their results, is necessary. For the example provided, it can be reasoned that activity is necessary for the read-out if the removal of a protein activity [in this case <italic>act(p (HGNC:EDNRA))</italic> through its antagonist <italic>BQ123</italic>] leads to the abolishment of the read-out (in this case an increase of <italic>[Ca2+]</italic>).</p>
    </sec>
    <sec id="sec19">
      <title>Task 2: given a BEL statement, provide a maximum of 10 additional evidence sentences</title>
      <p>Only one system, BELTracker, participated in this task. In agreement with the organizers, two runs with two different configurations and only five ranked sentences for each run were submitted. The correctness of the provided evidence sentences was evaluated manually and rated on two different levels of strictness:</p>
      <p><italic>(i) Fully supportive</italic>: Relationship is fully expressed in the sentence.</p>
      <p><italic>(ii) Partially supportive</italic>: Relationship can be extracted from the sentence if context sentences or biological background knowledge are taken into account.</p>
      <p>To evaluate the quality of the curation results, we calculated an inter-annotator agreement. For this task, part of the manual curation was performed by two different curators. For 150 entries, we observed a high agreement of 93% (kappa statistic: 0.75) and 91% (kappa statistic: 0.79) for the categories fully and partially supportive, respectively.</p>
      <p>As shown in <xref rid="TB4" ref-type="table">Table 4</xref> the system provided 382 evidence sentences for 98 BEL statements in each run (mean 3.9 sentences per statement). In run 1, for 55 BEL statements, there was at least one entirely correct evidence sentence; for 71 statements, there was at least one sentence meeting the partially supportive evaluation condition; and in run 2, 58 and 70 BEL statements satisfied the fully and partially supportive evaluation conditions, respectively.</p>
      <table-wrap id="TB4" orientation="portrait" position="float">
        <label>Table 4</label>
        <caption>
          <p>Evaluation results of task 2 including MAP</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">
                <bold>Runs</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>Criterion</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>TP</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>FP</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>Precision</bold>
              </th>
              <th align="left" rowspan="1" colspan="1">
                <bold>MAP</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">Run 1</td>
              <td align="left" rowspan="1" colspan="1">Full</td>
              <td align="left" rowspan="1" colspan="1">117</td>
              <td align="left" rowspan="1" colspan="1">265</td>
              <td align="left" rowspan="1" colspan="1">30.6%</td>
              <td align="left" rowspan="1" colspan="1">59.6%</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Partial</td>
              <td align="left" rowspan="1" colspan="1">175</td>
              <td align="left" rowspan="1" colspan="1">207</td>
              <td align="left" rowspan="1" colspan="1">45.8%</td>
              <td align="left" rowspan="1" colspan="1">77.5%</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Run 2</td>
              <td align="left" rowspan="1" colspan="1">Full</td>
              <td align="left" rowspan="1" colspan="1">121</td>
              <td align="left" rowspan="1" colspan="1">261</td>
              <td align="left" rowspan="1" colspan="1">31.7%</td>
              <td align="left" rowspan="1" colspan="1">50.2%</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Partial</td>
              <td align="left" rowspan="1" colspan="1">192</td>
              <td align="left" rowspan="1" colspan="1">190</td>
              <td align="left" rowspan="1" colspan="1">50.3%</td>
              <td align="left" rowspan="1" colspan="1">76.7%</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p><xref rid="TB4" ref-type="table">Table 4</xref> also shows the detailed numbers for true positives (TP), false positives (FP) and the resulting precision at the micro level. Around one-third of all sentences fully expressed the desired relationship. To assess the ranking quality of the system, we computed the mean average precision (MAP). Although the first run had a slightly lower precision compared with the second run, the MAP was considerably higher, especially for full supportive sentences. Overall, based on the results and the low number of participants, task 2 appeared to be as difficult as task 1. For some statements, only a few references could be extracted by curators and no prediction was provided by the automatic system. One example is the statement ‘p (MGI:Tmsb4x) decreases path (MESHD:Colitis)’. Only the abstract with the PMID, <italic>28127198,</italic> could be found containing these entities and also this relation. A second example is the statement ‘p (HGNC:CXCL8) increases p (HGNC:BCL2)’<italic>,</italic> where numerous abstracts could be found with those co-occurring genes but not the relationship. For this example, BELTracker made only false predictions.</p>
      <p>Placeholder for <xref rid="TB4" ref-type="table">Table 4.</xref></p>
    </sec>
  </sec>
  <sec id="sec20">
    <title>Discussion</title>
    <p>The results of biomedical analyses are complex and are often associated with several experimental settings including inhibitors, silencing or knock-out experiments. For understanding and interpreting these results, and encoding the findings as relationships, biological background knowledge is often necessary. Biologists encoding such relationships most likely select evidence sentences on the basis of the detailed experimental information included. All this leads to a high complexity for relationship extraction. Furthermore, results are reported not only on a molecular level but often on biological process or disease levels as well. The BEL corpora created for the BioCreative VI track 4 added a new resource for use in the training and evaluation of biological relationship extraction methods. In contrast with other published corpora, BEL includes multimodal relationships spanning from molecular protein–protein or protein–chemical entity relationships to higher-level causal relationships including biological processes or diseases, which are common in real-world data, to tackle real-world use cases. There are already a number of publicly available corpora addressing different relationship types (<xref rid="ref43" ref-type="bibr">43–45</xref>). In contrast with the BEL corpora, they mostly address only one or two types of entity.</p>
    <p>Consequently, the BEL track remains the most complex task within the BioCreative challenge, even after our attempts to simplify the BEL statements and the evaluation. In this track, four different entity types, gene and protein names, small chemicals, disease names and biological processes have to be recognized and normalized for the term-level evaluation. The performance of term detection ranges between F-scores of 50.88% and 76.39%. This scale of NER performance dramatically influences the results of subsequent higher levels. By providing the term information in the second stage of task 1, the NER performance within submitted BEL statements increased to F-score values between 83.93% and 91.33%. Hence, all other extraction steps for function, relationship type and full statement extraction improved drastically because of the provided name entities. For example, the best system, BELMiner 2.0, improved the BEL statement extraction performance from an F-score of 32.45% to an F-score of 49.6%. Primary researchers could support information extraction tremendously in using standardized terminology in their publications.</p>
    <p>The second most influential factor was the past experience of the team that utilized the systems created for the past 2015 BEL track. BelSmile and BELMiner 2.0 participated again this second time. Furthermore, both systems rely on dependency parsed text as well as rules applied on dependencies. Rules can be more easily learned on smaller training sets and do not need in depth annotation of the training data. In direct comparison, BELMiner 2.0, using graph-based traversal, outperformed BelSmile, which is based on SRL for relation extraction. Performance differences for these systems can be seen on all levels: term recognition, function recognition and, to a lesser extent, relationship extraction. The other newly introduced methods are more dependent on positional information and the size of the training set. The system based on hierarchical sequence labeling aligned the BEL statements and the sentence to generate the corpus. Also, the neural network-based system relies on positional information, as do most currently available machine learning algorithms. Both approaches would most likely gain performance with exhaustive positional annotations and larger training sets.</p>
    <p>The biological research community needs highly precise data for their analyses to further understand biological mechanisms. Therefore, most of the biological databases that provide research and experimental data focus mainly on manual curation for relationship extraction to meet the quality needs of the research community. The comparison of the secondary and primary levels of task 1 shows that the precision and recall values of secondary levels are high enough to use as recommendations for manual curation. Therefore, we believe that migrating from manual to semi-automatic curation workflows, by using the BEL extraction systems mentioned here, is worth consideration to still produce high quality curation data while at the same time raising curation efficiency and reducing time effort.</p>
    <p>Another important aspect of scientific research is the reproducibility of findings. In general, reproducibility increases the confidence in findings, and is reused by other researchers for their own studies. Finding reproduced evidence from the scientific literature is a challenging text mining problem. Task 2 tried to tackle this challenge by providing a platform for building systems that can find further evidence for a given BEL-encoded relationship. The evaluation of task 2 was split into two levels: fully and partially supportive. The only system participating in this task performed with around 30% precision for finding up to five instances of evidence for a single relationship. As the size of databases is rising enormously, we think this will become more important to the research community in the future.</p>
    <p>Most current and popular methods used by NLP system developers and applicants are based on machine learning. For those methods, larger training sets and positional annotation information needs to be available. Therefore, for future track development for BEL extraction, we plan to focus on three different areas. Firstly, we would like to further reduce the complexity of the task and focus on certain subtypes of entities and relationships. Secondly, we will attempt to increase the size of training data and, in particular, provide further positional annotations. Also, the data produced by previous BioCreative challenges might represent a useful resource that can be utilized in the future as training data for the BEL track. Finally, we need to provide tools that reduce the time needed for participants to build complex BEL-related workflows so that they can focus more on the mining tasks.</p>
    <p>A mixture of automatic and manual post-processing steps is still necessary for the generation of high-quality data. Better alignment of curators with unambiguous annotation guidelines and more interdisciplinary work of both text miners and curators are necessary to overcome some of this additional work. This will hopefully lead to better training corpora, as well as methods supporting efficient curation in the future.</p>
  </sec>
  <sec id="sec21">
    <title>Conclusion</title>
    <p>The extraction of molecular mechanism information with a fully automatic relationship extraction is a complex task. Through the second round of the BEL track and the provision of training data, the performance of participating systems increased drastically. When entity annotation was given, an F-score of up to 49% could be reached. Nevertheless, NER is the most relevant information extraction task to accomplish such an F-score. An increase in further training data and terminology resources is necessary to improve performance. Additionally, to enhance participation in such a complex track, we have to consider subdividing the task further, find automatic ways to increase the amount of training data and provide more supportive tools for each individual subtask. Nevertheless, we are positive that the investment (task definitions, data sets, documentation, evaluation framework and participating systems) made so far in the BEL track shows the need for BEL-related text mining in the scientific community.</p>
  </sec>
</body>
<back>
  <ack id="baz084-ack">
    <title>Acknowledgments</title>
    <p>We would like to thank Lisa Langnickel for her support in the generation of the test data and for her evaluation of the task 2 data. Also our special thanks to Jens Dörpinghaus who kindly helped to create the curation interface. Furthermore, we would like to thank all participants of the BioCreative BEL track. In this overview, we have only included the main principal investigator for each system.</p>
  </ack>
  <sec id="sec22">
    <title>Funding</title>
    <p>We acknowledge support for our research from Philip Morris International R&amp;D (PMI).</p>
    <p><italic>Conflict of interest</italic>. None declared.</p>
  </sec>
  <notes id="an1">
    <p><italic>Availability</italic>: The BEL track resources are available at <ext-link ext-link-type="uri" xlink:href="https://wiki.openbel.org/display/BIOC/BioCreative+BEL+Task+Challenges">https://wiki.openbel.org/display/BIOC/BioCreative+BEL+Task+Challenges</ext-link>. The participating systems are not publicly accessible.</p>
    <p><bold>Database URL</bold>: <ext-link ext-link-type="uri" xlink:href="https://wiki.openbel.org/display/BIOC/BioCreative+BEL+Task+Challenges">https://wiki.openbel.org/display/BIOC/BioCreative+BEL+Task+Challenges</ext-link></p>
  </notes>
  <ref-list id="bib1">
    <title>References</title>
    <ref id="ref1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hucka</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Finney</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Sauro</surname><given-names>H.M.</given-names></name><etal>et al.</etal></person-group> (<year>2003</year>) <article-title>The systems biology markup language (SBML): a medium for representation and exchange of biochemical network models</article-title>. <source>Bioinformatics</source>, <volume>19</volume>, <fpage>524</fpage>–<lpage>531</lpage>.<pub-id pub-id-type="pmid">12611808</pub-id></mixed-citation>
    </ref>
    <ref id="ref2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Demir</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Cary</surname><given-names>M.P.</given-names></name>, <name name-style="western"><surname>Paley</surname><given-names>S.</given-names></name><etal>et al.</etal></person-group> (<year>2010</year>) <article-title>The BioPAX community standard for pathway data sharing</article-title>. <source>Nat. Biotechnol.</source>, <volume>28</volume>, <fpage>935</fpage>–<lpage>942</lpage>.<pub-id pub-id-type="pmid">20829833</pub-id></mixed-citation>
    </ref>
    <ref id="ref3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Slater</surname><given-names>T.</given-names></name> and <name name-style="western"><surname>Song</surname><given-names>D.</given-names></name></person-group> (<year>2012</year>) <article-title>Saved by the BEL: ringing in a common language for the life sciences</article-title>, <volume>Fall 2012</volume>, <fpage>75</fpage>–<lpage>80</lpage>.</mixed-citation>
    </ref>
    <ref id="ref4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Martin</surname><given-names>F.</given-names></name>, <name name-style="western"><surname>Sewer</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Talikka</surname><given-names>M.</given-names></name><etal>et al.</etal></person-group> (<year>2014</year>) <article-title>Quantification of biological network perturbations for mechanistic insight and diagnostics using two-layer causal models</article-title>. <source>BMC Bioinformatics</source>, <volume>15</volume>, <fpage>238</fpage>.<pub-id pub-id-type="pmid">25015298</pub-id></mixed-citation>
    </ref>
    <ref id="ref5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ansari</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Binder</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Boué</surname><given-names>S.</given-names></name><etal>et al.</etal></person-group> (<year>2013</year>) <article-title>On crowd-verification of biological networks</article-title>. <source>Bioinform. Biol. Insights</source>, <volume>7</volume>, <fpage>307</fpage>–<lpage>325</lpage>.<pub-id pub-id-type="pmid">24151423</pub-id></mixed-citation>
    </ref>
    <ref id="ref6">
      <label>6.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Fluck</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Klenner</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Madan</surname><given-names>S.</given-names></name><etal>et al.</etal></person-group> (<year>2013</year>) <article-title>BEL networks derived from qualitative translations of BioNLP shared task annotations</article-title>. <source>Proceedings of the 2013 Workshop on Biomedical Natural Language Processing</source>. <publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>Sofia, Bulgaria</publisher-loc>, <volume>2013</volume>, <fpage>80</fpage>–<lpage>88</lpage>.</mixed-citation>
    </ref>
    <ref id="ref7">
      <label>7.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Fluck</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Madan</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Ellendorff</surname><given-names>T.R.</given-names></name><etal>et al.</etal></person-group> (<year>2015</year>) <article-title>Track 4 overview: extraction of causal network information in biological expression language (BEL)</article-title>. <source>Proceedings of the Fifth BioCreative Challenge Evaluation Workshop</source>. <publisher-name>University of Delaware</publisher-name>, <publisher-loc>Sevilla, Spain</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="ref8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rinaldi</surname><given-names>F.</given-names></name>, <name name-style="western"><surname>Ellendorff</surname><given-names>T.R.</given-names></name>, <name name-style="western"><surname>Madan</surname><given-names>S.</given-names></name><etal>et al.</etal></person-group> (<year>2016</year>) <article-title>BioCreative V track 4: a shared task for the extraction of causal network information using the biological expression language</article-title>. <source>Database (Oxford)</source>, <volume>2016</volume>.</mixed-citation>
    </ref>
    <ref id="ref9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fluck</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Madan</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Ansari</surname><given-names>S.</given-names></name><etal>et al.</etal></person-group> (<year>2016</year>) <article-title>Training and evaluation corpora for the extraction of causal relationships encoded in biological expression language (BEL)</article-title>. <source>Database (Oxford)</source>, <volume>2016</volume>.</mixed-citation>
    </ref>
    <ref id="ref10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Madan</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Hodapp</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Senger</surname><given-names>P.</given-names></name><etal>et al.</etal></person-group> (<year>2016</year>) <article-title>The BEL information extraction workflow (BELIEF): evaluation in the BioCreative V BEL and IAT track</article-title>. <source>Database</source>, <volume>2016</volume>, <fpage>baw136</fpage>.<pub-id pub-id-type="pmid">27694210</pub-id></mixed-citation>
    </ref>
    <ref id="ref11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sartor</surname><given-names>R.B.</given-names></name></person-group> (<year>2006</year>) <article-title>Mechanisms of disease: pathogenesis of Crohn’s disease and ulcerative colitis</article-title>. <source>Nat. Clin. Pract. Gastroenterol. Hepatol.</source>, <volume>3</volume>, <fpage>390</fpage>–<lpage>407</lpage>.<pub-id pub-id-type="pmid">16819502</pub-id></mixed-citation>
    </ref>
    <ref id="ref12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kaistha</surname><given-names>A.</given-names></name> and <name name-style="western"><surname>Levine</surname><given-names>J.</given-names></name></person-group> (<year>2014</year>) <article-title>Inflammatory bowel disease: the classic gastrointestinal autoimmune disease</article-title>. <source>Curr. Probl. Pediatr. Adolesc. Health Care</source>, <volume>44</volume>, <fpage>328</fpage>–<lpage>334</lpage>.<pub-id pub-id-type="pmid">25499459</pub-id></mixed-citation>
    </ref>
    <ref id="ref13">
      <label>13.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Elayavilli</surname><given-names>R.K.</given-names></name>, <name name-style="western"><surname>Rastegar-Mojarad</surname><given-names>M.</given-names></name> and <name name-style="western"><surname>Liu</surname><given-names>H.</given-names></name></person-group> (<year>2017</year>) <article-title>BELMiner-information extraction system to extract BEL relationships</article-title>. <source>Proceedings of the BioCreative VI</source>. <publisher-name>BioCreative VI Committees</publisher-name>, <publisher-loc>Bethesda, Maryland, USA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="ref14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Leaman</surname><given-names>R.</given-names></name> and <name name-style="western"><surname>Lu</surname><given-names>Z.</given-names></name></person-group> (<year>2016</year>) <article-title>TaggerOne: joint named entity recognition and normalization with semi-Markov models</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>2839</fpage>–<lpage>2846</lpage>.<pub-id pub-id-type="pmid">27283952</pub-id></mixed-citation>
    </ref>
    <ref id="ref15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nunes</surname><given-names>T.</given-names></name>, <name name-style="western"><surname>Campos</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Matos</surname><given-names>S.</given-names></name><etal>et al.</etal></person-group> (<year>2013</year>) <article-title>BeCAS: biomedical concept recognition services and visualization</article-title>. <source>Bioinformatics</source>, <volume>29</volume>, <fpage>1915</fpage>–<lpage>1916</lpage>.<pub-id pub-id-type="pmid">23736528</pub-id></mixed-citation>
    </ref>
    <ref id="ref16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Valenzuela-Escárcega</surname><given-names>M.A.</given-names></name>, <name name-style="western"><surname>Hahn-Powell</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Hicks</surname><given-names>T.</given-names></name><etal>et al.</etal></person-group> (<year>2015</year>) <article-title>A domain-independent rule-based framework for event extraction, <italic>Assoc</italic></article-title>. <source>Comput. Linguist</source>. Proceedings of ACL-IJCNLP 2015 System Demonstrations (pp. 127-132).</mixed-citation>
    </ref>
    <ref id="ref17">
      <label>17.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Manning</surname><given-names>C.</given-names></name>, <name name-style="western"><surname>Surdeanu</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Bauer</surname><given-names>J.</given-names></name><etal>et al.</etal></person-group> (<year>2014</year>) <article-title>The Stanford CoreNLP natural language processing toolkit</article-title>. <source>Proceedings of 52nd Annual Meeting of the Association for Computational Linguistic: Systems Demonstrations</source>, <publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>Baltimore, USA</publisher-loc>, pp. <fpage>55</fpage>–<lpage>60</lpage>.</mixed-citation>
    </ref>
    <ref id="ref18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ravikumar</surname><given-names>K.E.</given-names></name>, <name name-style="western"><surname>Wagholikar</surname><given-names>K.B.</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>D.</given-names></name><etal>et al.</etal></person-group> (<year>2015</year>) <article-title>Text mining facilitates database curation-extraction of mutation-disease associations from bio-medical literature</article-title>. <source>BMC Bioinformatics</source>, <volume>16</volume>, <fpage>185</fpage>.<pub-id pub-id-type="pmid">26047637</pub-id></mixed-citation>
    </ref>
    <ref id="ref19">
      <label>19.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Lai</surname><given-names>P.-T.</given-names></name>, <name name-style="western"><surname>Huang</surname><given-names>M.-S.</given-names></name>, <name name-style="western"><surname>Hsu</surname><given-names>W.-L.</given-names></name><etal>et al.</etal></person-group> (<year>2017</year>) <article-title>Generating biological expression language statements with pipeline approach and different parsers</article-title>. <source>Proceedings of the BioCreative VI Challenge Workshop</source>. <publisher-name>BioCreative VI Committees</publisher-name>, <publisher-loc>Bethesda, Maryland, USA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="ref20">
      <label>20.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Lai</surname><given-names>P.-T.</given-names></name>, <name name-style="western"><surname>Huang</surname><given-names>M.-S.</given-names></name>, <name name-style="western"><surname>Su</surname><given-names>C.-H.</given-names></name><etal>et al.</etal></person-group> (<year>2017</year>) <article-title>Statistical principle-based approach for gene and Protein related object recognition</article-title>. <source>Proceedings of the BioCreative V.5 Challenge Evaluation Workshop</source>. <publisher-name>University of Delaware</publisher-name>, <publisher-loc>Sevilla, Spain</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="ref21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tsai</surname><given-names>R.T.H.</given-names></name>, <name name-style="western"><surname>Hsiao</surname><given-names>Y.C.</given-names></name> and <name name-style="western"><surname>Lai</surname><given-names>P.T.</given-names></name></person-group> (<year>2016</year>) <article-title>NERChem: adapting NERBio to chemical patents via full-token features and named entity feature with chemical sub-class composition</article-title>. <source>Database</source>, <volume>2016</volume>.</mixed-citation>
    </ref>
    <ref id="ref22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tsai</surname><given-names>R.T.H.</given-names></name> and <name name-style="western"><surname>Lai</surname><given-names>P.T.</given-names></name></person-group> (<year>2014</year>) <article-title>A resource-saving collective approach to biomedical semantic role labeling</article-title>. <source>BMC Bioinformatics</source>, <volume>15</volume>, <fpage>160</fpage>.<pub-id pub-id-type="pmid">24884358</pub-id></mixed-citation>
    </ref>
    <ref id="ref23">
      <label>23.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Matsuzaki</surname><given-names>T.</given-names></name>, <name name-style="western"><surname>Miyao</surname><given-names>Y.</given-names></name> and <name name-style="western"><surname>Tsujii</surname><given-names>J.</given-names></name></person-group> (<year>2007</year>) <article-title>Efficient HPSG parsing with supertagging and CFG-filtering</article-title>. <source>Internation Joint Conferences on Artificial Intelligence</source>, <publisher-name>Morgan Kaufmann Publishers Inc.</publisher-name>, <publisher-loc>Hyderabad, India</publisher-loc>, <fpage>1671</fpage>–<lpage>1676</lpage>.</mixed-citation>
    </ref>
    <ref id="ref24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tsai</surname><given-names>R.T.H.</given-names></name>, <name name-style="western"><surname>Dai</surname><given-names>H.J.</given-names></name>, <name name-style="western"><surname>Huang</surname><given-names>C.H.</given-names></name><etal>et al.</etal></person-group> (<year>2008</year>) <article-title>Semi-automatic conversion of BioProp semantic annotation to PASBio annotation</article-title>. <source>BMC Bioinformatics</source>, <volume>9</volume>, <fpage>S18</fpage>.</mixed-citation>
    </ref>
    <ref id="ref25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lai</surname><given-names>P.T.</given-names></name>, <name name-style="western"><surname>Lo</surname><given-names>Y.Y.</given-names></name>, <name name-style="western"><surname>Huang</surname><given-names>M.S.</given-names></name><etal>et al.</etal></person-group> (<year>2016</year>) <article-title>BelSmile: a biomedical semantic role labeling approach for extracting biological expression language from text</article-title>. <source>Database (Oxford)</source>, <volume>2016</volume>.</mixed-citation>
    </ref>
    <ref id="ref26">
      <label>26.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>He</surname><given-names>Y.</given-names></name><etal>et al.</etal></person-group> (<year>2017</year>) <article-title>A hierarchical sequence labeling system for BioCreative VI BEL task</article-title>. <source>Proceedings of the BioCreative VI Challenge Workshop</source>. <publisher-name>BioCreative VI Committees</publisher-name>, <publisher-loc>Bethesda, Maryland, USA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="ref27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wei</surname><given-names>C.H.</given-names></name>, <name name-style="western"><surname>Kao</surname><given-names>H.Y.</given-names></name> and <name name-style="western"><surname>Lu</surname><given-names>Z.</given-names></name></person-group> (<year>2015</year>) <article-title>GNormPlus: an integrative approach for tagging genes, gene families, and protein domains</article-title>. <source>Biomed. Res. Int.</source>, <volume>2015</volume>, <fpage>7</fpage>.</mixed-citation>
    </ref>
    <ref id="ref28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Leaman</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Wei</surname><given-names>C.H.</given-names></name> and <name name-style="western"><surname>Lu</surname><given-names>Z.</given-names></name></person-group> (<year>2015</year>) <article-title>TmChem: a high performance approach for chemical named entity recognition and normalization</article-title>. <source>J. Cheminform.</source>, <volume>7</volume>, <fpage>S3</fpage>, <comment><ext-link ext-link-type="uri" xlink:href="https://jcheminf.biomedcentral.com/articles/10.1186/1758-2946-7-S1-S3">https://jcheminf.biomedcentral.com/articles/10.1186/1758-2946-7-S1-S3</ext-link></comment>.<pub-id pub-id-type="pmid">25810774</pub-id></mixed-citation>
    </ref>
    <ref id="ref29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Leaman</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Doğan</surname><given-names>R.I.</given-names></name> and <name name-style="western"><surname>Lu</surname><given-names>Z.</given-names></name></person-group> (<year>2013</year>) <article-title>DNorm: disease name normalization with pairwise learning to rank</article-title>. <source>Bioinformatics</source>, <volume>29</volume>, <fpage>2909</fpage>–<lpage>2917</lpage>.<pub-id pub-id-type="pmid">23969135</pub-id></mixed-citation>
    </ref>
    <ref id="ref30">
      <label>30.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Casacuberta</surname><given-names>F.</given-names></name> and <name name-style="western"><surname>Vidal</surname><given-names>E.</given-names></name></person-group> (<year>2007</year>) <source>GIZA++: Training of statistical translation models</source>. <publisher-name>Polytechnic University of Valencia</publisher-name>, <publisher-loc>Valencia, Spain</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="ref31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kudo</surname><given-names>T.</given-names></name></person-group> (<year>2005</year>) <article-title>CRF++: yet another CRF toolkit</article-title>. <comment>Softw. available http//crfpp. sourceforge. net</comment>
<volume>130</volume> (<comment>15 July 2019, date last accessed</comment>).</mixed-citation>
    </ref>
    <ref id="ref32">
      <label>32.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Ali</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Madan</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Fischer</surname><given-names>A.</given-names></name><etal>et al.</etal></person-group> (<year>2017</year>) <article-title>Automatic extraction of BEL-statements based on neural networks</article-title>. <source>Proceedings of the BioCreative VI Challenge Workshop</source><italic>.</italic><publisher-name>BioCreative VI Committees</publisher-name>, <publisher-loc>Bethesda, Maryland, USA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="ref33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hanisch</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Fundel</surname><given-names>K.</given-names></name>, <name name-style="western"><surname>Mevissen</surname><given-names>H.-T.</given-names></name><etal>et al.</etal></person-group> (<year>2005</year>) <article-title>ProMiner: rule-based protein and gene entity recognition</article-title>. <source>BMC Bioinformatics</source>, <volume>6</volume>, <fpage>S14</fpage>.</mixed-citation>
    </ref>
    <ref id="ref34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Quan</surname><given-names>C.</given-names></name>, <name name-style="western"><surname>Hua</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Sun</surname><given-names>X.</given-names></name><etal>et al.</etal></person-group> (<year>2016</year>) <article-title>Multi-channel convolutional neural network for biological relation extraction</article-title>. <source>Biomed. Res. Int.</source>, <volume>2016</volume>, <fpage>1</fpage>–<lpage>10</lpage>.</mixed-citation>
    </ref>
    <ref id="ref35">
      <label>35.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hua</surname><given-names>L.</given-names></name> and <name name-style="western"><surname>Quan</surname><given-names>C.</given-names></name></person-group> (<year>2016</year>) <article-title>A shortest dependency path based convolutional neural network for protein–protein relation extraction</article-title>. <source>Biomed. Res. Int.</source>, <volume>2016</volume>, <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="ref36">
      <label>36.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Pyysalo</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Ginter</surname><given-names>F.</given-names></name>, <name name-style="western"><surname>Moen</surname><given-names>H.</given-names></name><etal>et al.</etal></person-group> (<year>2013</year>) <article-title>Distributional semantics resources for biomedical text processing</article-title>. <source>Proceedings of Languages in Biology and Medicine 2013</source>. <publisher-name>University of Tokyo</publisher-name>, <publisher-loc>Tokyo, Japan</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="ref37">
      <label>37.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Rastegar-Mojarad</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Elayavilli</surname><given-names>R.K.</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name><etal>et al.</etal></person-group> (<year>2017</year>) <article-title>Semantic information retrieval: exploring dependency and word embedding features in biomedical information retrieval</article-title>. <source>Proceedings of the BioCreative VI</source>. <publisher-name>BioCreative VI Committees</publisher-name>, <publisher-loc>Bethesda, Maryland, USA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="ref38">
      <label>38.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kilicoglu</surname><given-names>H.</given-names></name>, <name name-style="western"><surname>Shin</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Fiszman</surname><given-names>M.</given-names></name><etal>et al.</etal></person-group> (<year>2012</year>) <article-title>SemMedDB: a PubMed-scale repository of biomedical semantic predications</article-title>. <source>Bioinformatics</source>, <volume>28</volume>, <fpage>3158</fpage>–<lpage>3160</lpage>.<pub-id pub-id-type="pmid">23044550</pub-id></mixed-citation>
    </ref>
    <ref id="ref39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rastegar-Mojarad</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Komandur Elayavilli</surname><given-names>R.</given-names></name> and <name name-style="western"><surname>Liu</surname><given-names>H.</given-names></name></person-group> (<year>2016</year>) <article-title>BELTracker: evidence sentence retrieval for BEL statements</article-title>. <source>Database (Oxford)</source>, <volume>2016</volume>.</mixed-citation>
    </ref>
    <ref id="ref40">
      <label>40.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Rastegar-Mojarad</surname><given-names>M.</given-names></name><etal>et al.</etal></person-group> (<year>2017</year>) <chapter-title>Dependency and AMR embeddings for drug–drug interaction extraction from biomedical literature</chapter-title>
<source>Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics—ACM-BCB’17</source>, <publisher-name>ACM</publisher-name>, <publisher-loc>Boston, MA</publisher-loc>, pp. <fpage>36</fpage>–<lpage>43</lpage>.</mixed-citation>
    </ref>
    <ref id="ref41">
      <label>41.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Qian</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Zhao</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Miao</surname><given-names>X.</given-names></name><etal>et al.</etal></person-group> (<year>2016</year>) <article-title>Sam68 modulates apoptosis of intestinal epithelial cells via mediating NF-κB activation in ulcerative colitis</article-title>. <source>Mol. Immunol.</source>. <volume>75</volume>, <fpage>48</fpage>–<lpage>59</lpage>.<pub-id pub-id-type="pmid">27235792</pub-id></mixed-citation>
    </ref>
    <ref id="ref42">
      <label>42.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>W.-M.</given-names></name>, <name name-style="western"><surname>Zhou</surname><given-names>J.</given-names></name> and <name name-style="western"><surname>Ye</surname><given-names>Q.-J.</given-names></name></person-group> (<year>2008</year>) <article-title>Endothelin-1 enhances proliferation of lung cancer cells by increasing intracellular free Ca2+</article-title>. <source>Life Sci</source>. <volume>82</volume>, <fpage>764</fpage>–<lpage>771</lpage>.<pub-id pub-id-type="pmid">18294657</pub-id></mixed-citation>
    </ref>
    <ref id="ref43">
      <label>43.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>De León</surname><given-names>H.</given-names></name>, <name name-style="western"><surname>Boué</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Schlage</surname><given-names>W.K.</given-names></name><etal>et al.</etal></person-group> (<year>2014</year>) <article-title>A vascular biology network model focused on inflammatory processes to investigate atherogenesis and plaque instability</article-title>. <source>J. Transl. Med.</source>, <volume>12</volume>, <fpage>185</fpage>.<pub-id pub-id-type="pmid">24965703</pub-id></mixed-citation>
    </ref>
    <ref id="ref44">
      <label>44.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Boué</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Talikka</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Westra</surname><given-names>J.W.</given-names></name><etal>et al.</etal></person-group> (<year>2015</year>) <article-title>Causal biological network database: a comprehensive platform of causal biological network models focused on the pulmonary and vascular systems</article-title>. <source>Database (Oxford)</source>, <volume>2015</volume>, <fpage>bav030</fpage>.<pub-id pub-id-type="pmid">25887162</pub-id></mixed-citation>
    </ref>
    <ref id="ref45">
      <label>45.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gebel</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Lichtner</surname><given-names>R.B.</given-names></name>, <name name-style="western"><surname>Frushour</surname><given-names>B.</given-names></name><etal>et al.</etal></person-group> (<year>2013</year>) <article-title>Construction of a computable network model for DNA damage, autophagy, cell death, and senescence</article-title>. <source>Bioinform. Biol. Insights</source>, <volume>7</volume>, <fpage>97</fpage>–<lpage>117</lpage>.<pub-id pub-id-type="pmid">23515068</pub-id></mixed-citation>
    </ref>
    <ref id="ref46">
      <label>46.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Al-Sadi</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Guo</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Ye</surname><given-names>D.</given-names></name><etal>et al.</etal></person-group> (<year>2013</year>) <article-title>Mechanism of IL-1 modulation of intestinal epithelial barrier involves p38 kinase and activating transcription factor-2 activation</article-title>. <source>J. Immunol.</source>, <volume>190</volume>, <fpage>6596</fpage>–<lpage>6606</lpage>.<pub-id pub-id-type="pmid">23656735</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
