<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8336442</article-id>
    <article-id pub-id-type="pmid">34252965</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btab271</article-id>
    <article-id pub-id-type="publisher-id">btab271</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Systems Biology and Networks</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>KG4SL: knowledge graph neural network for synthetic lethality prediction in human cancers</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Shike</given-names>
        </name>
        <aff><institution>School of Information Science and Technology, ShanghaiTech University</institution>, Shanghai 201210, <country country="CN">China</country></aff>
        <xref rid="btab271-FM2" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xu</surname>
          <given-names>Fan</given-names>
        </name>
        <aff><institution>School of Information Science and Technology, ShanghaiTech University</institution>, Shanghai 201210, <country country="CN">China</country></aff>
        <xref rid="btab271-FM2" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Yunyang</given-names>
        </name>
        <aff><institution>School of Life Science and Technology, ShanghaiTech University</institution>, Shanghai 201210, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Jie</given-names>
        </name>
        <aff><institution>School of Information Science and Technology, ShanghaiTech University</institution>, Shanghai 201210, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Ke</given-names>
        </name>
        <aff><institution>School of Information Science and Technology, ShanghaiTech University</institution>, Shanghai 201210, <country country="CN">China</country></aff>
        <aff><institution>Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences</institution>, Shanghai 200050, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Yong</given-names>
        </name>
        <aff><institution>Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly, Nanyang Technological University</institution>, Singapore 639798, <country country="SG">Singapore</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-0977-3600</contrib-id>
        <name>
          <surname>Wu</surname>
          <given-names>Min</given-names>
        </name>
        <aff><institution>Institute for Infocomm Research, Agency for Science, Technology and Research (A*STAR)</institution>, Singapore 138632, <country country="SG">Singapore</country></aff>
        <xref rid="btab271-cor1" ref-type="corresp"/>
        <!--wumin@i2r.a-star.edu.sg-->
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Zheng</surname>
          <given-names>Jie</given-names>
        </name>
        <aff><institution>School of Information Science and Technology, ShanghaiTech University</institution>, Shanghai 201210, <country country="CN">China</country></aff>
        <aff><institution>Shanghai Engineering Research Center of Intelligent Vision and Imaging</institution>, Shanghai, 201210, <country country="CN">China</country></aff>
        <xref rid="btab271-cor1" ref-type="corresp"/>
        <!--zhengjie@shanghaitech.edu.cn-->
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btab271-cor1">To whom correspondence should be addressed. <email>wumin@i2r.a-star.edu.sg</email>; <email>zhengjie@shanghaitech.edu.cn</email>.</corresp>
      <fn id="btab271-FM2">
        <p>The authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint Authors.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="collection">
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-07-12">
      <day>12</day>
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>12</day>
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <volume>37</volume>
    <issue>Suppl 1</issue>
    <issue-title>ISMB/ECCB 2021 Proceedings</issue-title>
    <fpage>i418</fpage>
    <lpage>i425</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2021. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btab271.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Synthetic lethality (SL) is a promising gold mine for the discovery of anti-cancer drug targets. Wet-lab screening of SL pairs is afflicted with high cost, batch-effect, and off-target problems. Current computational methods for SL prediction include gene knock-out simulation, knowledge-based data mining and machine learning methods. Most of the existing methods tend to assume that SL pairs are independent of each other, without taking into account the shared biological mechanisms underlying the SL pairs. Although several methods have incorporated genomic and proteomic data to aid SL prediction, these methods involve manual feature engineering that heavily relies on domain knowledge.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Here, we propose a novel graph neural network (GNN)-based model, named KG4SL, by incorporating knowledge graph (KG) message-passing into SL prediction. The KG was constructed using 11 kinds of entities including genes, compounds, diseases, biological processes and 24 kinds of relationships that could be pertinent to SL. The integration of KG can help harness the independence issue and circumvent manual feature engineering by conducting message-passing on the KG. Our model outperformed all the state-of-the-art baselines in area under the curve, area under precision-recall curve and F1. Extensive experiments, including the comparison of our model with an unsupervised TransE model, a vanilla graph convolutional network model, and their combination, demonstrated the significant impact of incorporating KG into GNN for SL prediction.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>: KG4SL is freely available at <ext-link xlink:href="https://github.com/JieZheng-ShanghaiTech/KG4SL" ext-link-type="uri">https://github.com/JieZheng-ShanghaiTech/KG4SL</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p>Supplementary data are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Complex biological systems cannot be composed by a large number of genes acting independently, but rely on the interactions between genes which can be further classified into enhancing and suppressive effects (<xref rid="btab271-B7" ref-type="bibr">Dhabhar, 2009</xref>). The suppressive effects characterize the situation that, when mutations occur simultaneously in a pair of genes, some important functions will be deactivated which seriously decrease cell viability, whereas the mutation in a single gene might not affect the cell viability. A common type of suppressive effect is synthetic lethality (SL; <xref rid="btab271-B8" ref-type="bibr">Dobzhansky, 1946</xref>), which has been a promising strategy for cancer medicine (<xref rid="btab271-B1" ref-type="bibr">Ashworth <italic toggle="yes">et al.</italic>, 2011</xref>). If a specific gene is found to be inactivated in tumor cells, drugs that suppress its SL partner gene can cause tumor cells to die but spare normal cells (<xref rid="btab271-B16" ref-type="bibr">Hartwell <italic toggle="yes">et al.</italic>, 1997</xref>). Hence, SL is a gold mine of anti-cancer drug targets, and intensive efforts have been exerted to identify SL gene pairs. High-throughput wet-lab screening methods, including chemical liraries (<xref rid="btab271-B33" ref-type="bibr">Simons <italic toggle="yes">et al.</italic>, 2001</xref>), pooled RNAi screening (<xref rid="btab271-B27" ref-type="bibr">Luo <italic toggle="yes">et al.</italic>, 2009</xref>) and CRISPR-based genome editing technology (<xref rid="btab271-B9" ref-type="bibr">Du <italic toggle="yes">et al.</italic>, 2017</xref>) have been used to find SLs, but they are thwarted by varius barriers such as high cost, off-target effects, and batch effects (<xref rid="btab271-B25" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2020</xref>). Hence, it is compelling to devise efficient computational methods to complement the downsides of the wet-lab screening techniques.</p>
    <p>A spectrum of computational methods has been proposed for SL prediction. These methods can be categorized into three classes. The first class involves simulating <italic toggle="yes">in silico</italic> knockouts using metabolic network models. <xref rid="btab271-B10" ref-type="bibr">Folger <italic toggle="yes">et al.</italic> (2011)</xref> proposed to characterize SLs by modeling effects of the single- and double-knockouts of candidate genes in those networks. The second class, referred to as knowledge-oriented methods, is mostly conducted by feature engineering with domain-specific knowledge. To predict SL pairs, these methods employ network topology features such as graph centrality (<xref rid="btab271-B21" ref-type="bibr">Kranthi <italic toggle="yes">et al.</italic>, 2013</xref>), network flow (<xref rid="btab271-B44" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2015</xref>), connectivity homology (<xref rid="btab271-B18" ref-type="bibr">Jacunski <italic toggle="yes">et al.</italic>, 2015</xref>) and features derived from genomic data including somatic copy number alteration (<xref rid="btab271-B19" ref-type="bibr">Jerby-Arnon <italic toggle="yes">et al.</italic>, 2014</xref>), short hairpin RNA profiles (<xref rid="btab271-B19" ref-type="bibr">Jerby-Arnon <italic toggle="yes">et al.</italic>, 2014</xref>), and gene expression profiles (<xref rid="btab271-B19" ref-type="bibr">Jerby-Arnon <italic toggle="yes">et al.</italic>, 2014</xref>). However, the two classes mentioned above rely heavily on the metabolic network models, domain knowledge and genomic data, without fully exploiting the valuable information of known SL pairs.</p>
    <p>To exploit the exiting SL data, the third class of methods apply machine learning algorithms, where features are engineered based on both domain knowledge and heuristic functions. <xref rid="btab271-B30" ref-type="bibr">Paladugu <italic toggle="yes">et al.</italic> (2008)</xref> proposed to train a support vector machine (SVM) for SL prediction where the features were extracted from a protein–protein interaction (PPI) network. MetaSL (<xref rid="btab271-B43" ref-type="bibr">Wu <italic toggle="yes">et al.</italic>, 2014</xref>) integrated 17 features and weighted outputs of 10 classifiers to predict SLs. Aside from the traditional machine learning methods, graph representation learning approaches have been proposed, which mostly adopt an encoder–decoder paradigm. In this paradigm, an encoder tries to map the nodes into a low-dimensional embedding, whereas a decoder takes the embedding and utilizes it to reconstruct the node similarities in the original graph (<xref rid="btab271-B15" ref-type="bibr">Hamilton, 2020</xref>), thereby recovering missing links. This paradigm can be generalized to matrix factorization (MF)-based methods and graph neural network (GNN)-based methods. Those methods use distinct designs of encoders, but resemble each other in the choices of decoders (mostly taking the form of inner product predictor or its normalized variants). MF methods adopt a MF encoder. SL<sup>2</sup>MF (<xref rid="btab271-B25" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2020</xref>) proposed a MF encoder which decomposes the SL matrix, gene ontology (GO) similarity matrix, and PPI matrix to a low-dimensional latent space. GRSMF (<xref rid="btab271-B17" ref-type="bibr">Huang <italic toggle="yes">et al.</italic>, 2019</xref>) introduced a self-representative MF encoder which focuses on learning a representation matrix from known SL pairs and further integrates the functional similarities among genes derived from GO. <xref rid="btab271-B23" ref-type="bibr">Liany <italic toggle="yes">et al.</italic> (2020)</xref> adopted Collective Matrix Factorization (CMF) based methods to integrate data from heterogeneous sources to predict SLs.</p>
    <p>The MF-based encoders are just shallow embedding methods, which simply optimize a unique embedding vector for each node, without sharing any parameter between nodes or leveraging node features (<xref rid="btab271-B15" ref-type="bibr">Hamilton, 2020</xref>). GNN, a state-of-the-art framework for deep learning on graphs, enhances the aforementioned methods by adopting a different embedding strategy. GNN defines a message-passing (MP) process on the original graph, i.e. at each iteration, each node aggregates all the embeddings from its local neighborhood as a message which is combined with its previous embedding to generate a new embedding. Based on GNN, <xref rid="btab271-B5" ref-type="bibr">Cai <italic toggle="yes">et al.</italic> (2020)</xref> adopted a novel regularization technique called dual dropout to address the sparsity of SL networks.</p>
    <p>However, the existing GNN-based methods often regard each SL pair as an independent sample, and make no attempt to take their underlying biological mechanisms into account. However, some shared factors (such as biological processes, pathways, cellular components etc.) might latently invalidate the assumption of independency. For instance, poly (adenosine diphosphate-ribose) polymerase 1 (PARP1) and breast cancer 1 (BRCA1) are a famous SL gene pair, leading to the first clinically approved SL-based cancer drug, PARP inhibitor (<xref rid="btab271-B26" ref-type="bibr">Lord and Ashworth, 2017</xref>). PARP1 and BRCA1 are both key players in DNA repair process. Meanwhile, ATM and TP53 are another widely known SL pair (<xref rid="btab271-B22" ref-type="bibr">Kwok <italic toggle="yes">et al.</italic>, 2016</xref>), and ATM is also a key instrument in DNA repair process (<xref rid="btab271-B32" ref-type="bibr">Sanders <italic toggle="yes">et al.</italic>, 2020</xref>). Here, the DNA repair process might be the common mechanism underlying the two SL pairs.</p>
    <p>A subset of existing methods [e.g. SVM, random forests (RFs), SL<sup>2</sup>MF and GRSMF] have injected some genomic and proteomic data to facilitate the SL prediction, and the results of these studies have underscored the significance of integrating additional information. Meanwhile, GNN-based methods can also encode such information as input features. However, these methods extracted features manually based on domain knowledge and some features might be left out. Therefore, to attain a more comprehensive set of features to improve the performance of SL prediction, we need a new method capable of automatic knowledge integration and feature extraction.</p>
    <p>Knowledge graphs (KGs) are a type of multi-relational graph, where nodes and edges have different types. A KG is denoted by <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where edges in set <italic toggle="yes">E</italic> are defined as triplets <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mo>τ</mml:mo><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> indicating a particular relationship <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mo>τ</mml:mo><mml:mo>∈</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:math></inline-formula> between two nodes (<xref rid="btab271-B15" ref-type="bibr">Hamilton, 2020</xref>). By incorporating a KG into a GNN, one can mitigate the aforementioned independency issue by directly introducing those latent factors as nodes in the graph. <xref rid="btab271-B24" ref-type="bibr">Lin <italic toggle="yes">et al.</italic> (2020)</xref> proposed an end-to-end knowledge GNN (KGNN) and achieved good performance in drug–drug interaction prediction.</p>
    <p>Here, we propose a novel KGNN-based method for SL prediction, named KG4SL, which utilizes KG MP as a back-end. We approach the independency issue by injecting various factors including biological processes, diseases, compounds etc. that could be pertinent to SL, into our KG. Our model comprises three parts. In the first part, we derive a gene-specific subgraph from the original KG for each gene. In the second part, we conduct MP on the gene-specific subgraph, to automatically associate genes with factors that could be decisive in identifying an SL pair. In the third part, we define a decoder to reconstruct gene–gene similarity in a supervised fashion. To the best of our knowledge, this is the first framework to integrate KG with GNN for SL prediction. We compared our model with 10 state-of-the-art methods for SL prediction, and our model outperformed all the baselines in area under ROC curve (AUC), area under precision-recall curve (AUPR) and F1. Another contribution of our work is that we studied the impact of KG, which suggests that introducing a KG combined with MP process in GNN can significantly improve the performance of SL prediction.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <p>In this section, we first introduce the data and the problem of SL prediction. Then, we present the details of the proposed KG4SL model.</p>
    <sec>
      <title>2.1 Data Collection</title>
      <p>SynLethDB (<ext-link xlink:href="http://synlethdb.sist.shanghaitech.edu.cn/v2/#/" ext-link-type="uri">http://synlethdb.sist.shanghaitech.edu.cn/v2/#/</ext-link>; <xref rid="btab271-B13" ref-type="bibr">Guo <italic toggle="yes">et al.</italic>, 2016</xref>) is a comprehensive database of synthetic lethal gene pairs. Its latest version includes a set of 36,402 human SL pairs, as well as a KG with 11 kinds of entities and 24 kinds of relationships as shown in <xref rid="btab271-T1" ref-type="table">Table 1</xref>. SynLethDB also includes negative SL pairs, i.e. Non-SL and synthetic rescue pairs. However, there are much less known negative SL pairs than known positive ones. To obtain a balance between the positive and negative samples, we randomly pick up unknown pairs as negative pairs so that there are equal numbers of positive and negative SL pairs. Hence, the final SL dataset contains 72 804 gene pairs between 10 004 genes.</p>
      <table-wrap position="float" id="btab271-T1">
        <label>Table 1.</label>
        <caption>
          <p>Details about the SL data and KG SynLethKG</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th rowspan="1" colspan="1">SL data</th>
              <th rowspan="1" colspan="1">No. of genes</th>
              <th rowspan="1" colspan="1">10 004</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">No. of interactions</td>
              <td rowspan="1" colspan="1">72 804</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Density</td>
              <td rowspan="1" colspan="1">0.14%</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SynLethKG</td>
              <td rowspan="1" colspan="1">No. of entity types</td>
              <td rowspan="1" colspan="1">11</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">No. of relationship types</td>
              <td rowspan="1" colspan="1">24</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">No. of nodes</td>
              <td rowspan="1" colspan="1">54 012</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">No. of edges</td>
              <td rowspan="1" colspan="1">2 231 921</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>The KG, denoted as SynLethKG, includes 24 kinds of relationships between 11 entities. Among 24 kinds of relationships, 16 of them are related to genes directly, e.g. (gene, regulates, gene), (gene, interacts, gene) and (gene, co-varies, gene). And the other 8 relationships are associated with drug and compounds. Besides, 7 out of 11 kinds of entities are directly related to genes, i.e. pathway, cellular component, biological process, molecular function, disease, compound and anatomy. They are in the format of (gene, relationship, entity). These entities can be reached from genes in one hop, whereas the other three kinds of entities (pharmacologic class, side effect and symptom) can be reached from genes in two hops. After removing isolated nodes, the final graph of SynLethKG contains 54 012 nodes and 2 231 921 edges as shown in <xref rid="btab271-T1" ref-type="table">Table 1</xref>. <xref rid="btab271-T2" ref-type="table">Tables 2</xref> and <xref rid="btab271-T3" ref-type="table">3</xref> show the details about the entities and relationships in SynLethKG. Users can access the SynLethKG through searching the names of the genes that they want to study in SynLethDB.</p>
      <table-wrap position="float" id="btab271-T2">
        <label>Table 2.</label>
        <caption>
          <p>Details about the entities in SynLethKG</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Type</th>
              <th rowspan="1" colspan="1">Sample size</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Cellular component</td>
              <td rowspan="1" colspan="1">1670</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Gene</td>
              <td rowspan="1" colspan="1">67 062</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Biological process</td>
              <td rowspan="1" colspan="1">12 703</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Side effect</td>
              <td rowspan="1" colspan="1">5726</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Molecular function</td>
              <td rowspan="1" colspan="1">3203</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Pathway</td>
              <td rowspan="1" colspan="1">2069</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Disease</td>
              <td rowspan="1" colspan="1">137</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Compound</td>
              <td rowspan="1" colspan="1">2595</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Pharmacologic class</td>
              <td rowspan="1" colspan="1">377</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Anatomy</td>
              <td rowspan="1" colspan="1">402</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Symptom</td>
              <td rowspan="1" colspan="1">453</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap position="float" id="btab271-T3">
        <label>Table 3.</label>
        <caption>
          <p>Details about the relationships in SynLethKG</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Type</th>
              <th rowspan="1" colspan="1">No. of edges</th>
              <th rowspan="1" colspan="1">No. of source <break/>nodes</th>
              <th rowspan="1" colspan="1">No. of target <break/>nodes</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">(Anatomy, downregulates, gene)</td>
              <td rowspan="1" colspan="1">31</td>
              <td rowspan="1" colspan="1">4</td>
              <td rowspan="1" colspan="1">24</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Anatomy, expresses, gene)</td>
              <td rowspan="1" colspan="1">617 175</td>
              <td rowspan="1" colspan="1">241</td>
              <td rowspan="1" colspan="1">23 881</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Anatomy, upregulates, gene)</td>
              <td rowspan="1" colspan="1">26</td>
              <td rowspan="1" colspan="1">5</td>
              <td rowspan="1" colspan="1">22</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Compound, binds, gene)</td>
              <td rowspan="1" colspan="1">16 323</td>
              <td rowspan="1" colspan="1">1922</td>
              <td rowspan="1" colspan="1">2306</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Compound, causes, side effect)</td>
              <td rowspan="1" colspan="1">139 428</td>
              <td rowspan="1" colspan="1">1079</td>
              <td rowspan="1" colspan="1">5702</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Compound, downregulates, gene)</td>
              <td rowspan="1" colspan="1">21 526</td>
              <td rowspan="1" colspan="1">747</td>
              <td rowspan="1" colspan="1">2847</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Compound, palliates, disease)</td>
              <td rowspan="1" colspan="1">384</td>
              <td rowspan="1" colspan="1">215</td>
              <td rowspan="1" colspan="1">50</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Compound, resembles, compound)</td>
              <td rowspan="1" colspan="1">6266</td>
              <td rowspan="1" colspan="1">1034</td>
              <td rowspan="1" colspan="1">1055</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Compound, treats, disease)</td>
              <td rowspan="1" colspan="1">752</td>
              <td rowspan="1" colspan="1">385</td>
              <td rowspan="1" colspan="1">77</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Compound, upregulates, gene)</td>
              <td rowspan="1" colspan="1">19 200</td>
              <td rowspan="1" colspan="1">721</td>
              <td rowspan="1" colspan="1">3205</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Disease, associates, gene)</td>
              <td rowspan="1" colspan="1">24 328</td>
              <td rowspan="1" colspan="1">135</td>
              <td rowspan="1" colspan="1">6572</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Disease, downregulates, gene)</td>
              <td rowspan="1" colspan="1">7616</td>
              <td rowspan="1" colspan="1">44</td>
              <td rowspan="1" colspan="1">5730</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Disease, localizes, anatomy)</td>
              <td rowspan="1" colspan="1">3373</td>
              <td rowspan="1" colspan="1">123</td>
              <td rowspan="1" colspan="1">398</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Disease, presents, symptom)</td>
              <td rowspan="1" colspan="1">3401</td>
              <td rowspan="1" colspan="1">122</td>
              <td rowspan="1" colspan="1">427</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Disease, resembles, disease)</td>
              <td rowspan="1" colspan="1">404</td>
              <td rowspan="1" colspan="1">100</td>
              <td rowspan="1" colspan="1">98</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Disease, upregulates, gene)</td>
              <td rowspan="1" colspan="1">7730</td>
              <td rowspan="1" colspan="1">44</td>
              <td rowspan="1" colspan="1">5614</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Gene, covaries, gene)</td>
              <td rowspan="1" colspan="1">62 987</td>
              <td rowspan="1" colspan="1">9174</td>
              <td rowspan="1" colspan="1">9706</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Gene, interacts, gene)</td>
              <td rowspan="1" colspan="1">148 379</td>
              <td rowspan="1" colspan="1">9633</td>
              <td rowspan="1" colspan="1">14 275</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Gene, participates, biological process)</td>
              <td rowspan="1" colspan="1">619 712</td>
              <td rowspan="1" colspan="1">16 608</td>
              <td rowspan="1" colspan="1">12 703</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Gene, participates, cellular component)</td>
              <td rowspan="1" colspan="1">97 652</td>
              <td rowspan="1" colspan="1">11 916</td>
              <td rowspan="1" colspan="1">1670</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Gene, participates, molecular function)</td>
              <td rowspan="1" colspan="1">110 042</td>
              <td rowspan="1" colspan="1">14 404</td>
              <td rowspan="1" colspan="1">3203</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Gene, participates, pathway)</td>
              <td rowspan="1" colspan="1">57 441</td>
              <td rowspan="1" colspan="1">11 519</td>
              <td rowspan="1" colspan="1">2069</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Gene, regulates, gene)</td>
              <td rowspan="1" colspan="1">267 791</td>
              <td rowspan="1" colspan="1">4649</td>
              <td rowspan="1" colspan="1">7105</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">(Pharmacologic class, includes, compound)</td>
              <td rowspan="1" colspan="1">1205</td>
              <td rowspan="1" colspan="1">377</td>
              <td rowspan="1" colspan="1">837</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>The 24 relationships in <xref rid="btab271-T3" ref-type="table">Table 3</xref> describe the features of genes, drugs and compounds. These relationships are collected from Genbank, GO, Drugbank, DrugCental, PubMed, Bgee, String, LINCS L1000, SIDER4, STARGEO, Uberon and BioGRID. The specific number of each type of relationship and the number of associated nodes are also shown in <xref rid="btab271-T3" ref-type="table">Table 3</xref>. Besides, the types of the entities in SynLethKG and the number of each entity are shown in <xref rid="btab271-T2" ref-type="table">Table 2</xref>.</p>
    </sec>
    <sec>
      <title>2.2 Problem statement</title>
      <p>Formally, the SL data can be modeled as a matrix <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mi>S</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">n</italic> is the number of genes involved in the SL pairs. In this SL matrix <italic toggle="yes">S</italic>, an entry <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is 1 if there is an SL interaction between gene <italic toggle="yes">e<sub>i</sub></italic> and gene <italic toggle="yes">e<sub>j</sub></italic>, and 0 otherwise. Note that gene pairs with entry value 0 are unknown pairs, some of which could be potential SL pairs not yet discovered. The KG SynLethKG is denoted by <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, which contains a set of entities <italic toggle="yes">V<sub>e</sub></italic> and a set of relationships <italic toggle="yes">V<sub>r</sub></italic>. Each edge in the KG is defined as a triplet <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, which shows a relationship of type <italic toggle="yes">r</italic> between head entity <italic toggle="yes">h</italic> and tail entity <italic toggle="yes">t</italic>, where <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mi>r</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p>
      <p>Given the SL matrix <italic toggle="yes">S</italic> and the KG <italic toggle="yes">G</italic>, the problem we aim to solve is to predict the SL relationship between gene <italic toggle="yes">e<sub>i</sub></italic> and gene <italic toggle="yes">e<sub>j</sub></italic>. To achieve this goal, we propose a GNN-based model to learn a scoring function <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> that estimates how likely gene <italic toggle="yes">e<sub>i</sub></italic> and gene <italic toggle="yes">e<sub>j</sub></italic> is an SL pair, where <bold>W</bold>, <bold>A</bold> and <bold>b</bold> denote the learnable parameters in function <italic toggle="yes">F</italic>.</p>
    </sec>
    <sec>
      <title>2.3 Overview of KG4SL</title>
      <p>The overall framework of KG4SL is laid out in <xref rid="btab271-T1" ref-type="table">Table 1</xref>. KG4SL utilizes a GNN to encode the gene features from KG for SL prediction in three steps. First, we derive a gene-specific weighted subgraph for each SL-related gene from the KG. Specifically, the weight of every edge is defined by a gene-specific relation scoring function to depict the importance of the relation for its target gene. Second, we design an aggregation layer to update the representation for a given gene by aggregating the representations of its neighbors in the gene-specific weighted subgraph. Third, we assign a score for each gene pair computed by the normalized inner product based on their learned representations. Next, we introduce these three steps in details.</p>
      <sec>
        <label>2.3.1</label>
        <title>Gene-specific weighted subgraph</title>
        <p>Given an SL-related gene, we first construct a weighted subgraph from the KG. Identifying relevant nodes and determining the edge weights are two key operations to construct the gene-specific weighted subgraph.</p>
        <p>Assume that <italic toggle="yes">e</italic> is the central node/entity and <italic toggle="yes">N</italic>(<italic toggle="yes">e</italic>) is the set of neighbors of <italic toggle="yes">e</italic> (i.e. entities directly connected to <italic toggle="yes">e</italic>). In SynLethKG, the size of <italic toggle="yes">N</italic>(<italic toggle="yes">e</italic>) varies greatly among the entities. For example, network hubs may have thousands of relations, whereas some nodes are less studied and thus have a limited number of neighbors. In this work, we sample a fixed number of <italic toggle="yes">k</italic> neighbors for each entity to characterize its local structure and we repeat this process for <italic toggle="yes">H</italic> hops (<inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mi>H</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>). In particular, if a node has less than <italic toggle="yes">k</italic> neighbors, we sample duplicates, i.e. a neighbor may be sampled more than once. The set of sampled <italic toggle="yes">k</italic> neighbors is denoted as <italic toggle="yes">P</italic>(<italic toggle="yes">e</italic>). An example of 2-hop subgraph with neighbor sampling size <italic toggle="yes">k </italic>=<italic toggle="yes"> </italic>4 in each hop can be seen in <xref rid="btab271-F1" ref-type="fig">Figure 1</xref>.</p>
        <fig position="float" id="btab271-F1">
          <label>Fig. 1.</label>
          <caption>
            <p>The framework of KG4SL. The workflow of KG4SL can be divided into three modules, including gene-specific weighted subgraph module, aggregation module and score computation module. (1) Gene-specific weighted subgraph: First, we construct a weighted subgraph from the KG. (2) Aggregation: Second, for each SL pair, we select the entities and relationships that are directly related to the nodes. Besides, we believe the biological information can flow between nodes through edges. Thus, we also aggregate the information of indirectly connected entities and relationships. Considering the problem of computing power, only two layers of entities and relationships are included. (3) Score computation: Third, the results of aggregation for two genes are used to compute their SL score through inner product. The loss function of KG4SL is composed of two kinds of losses, i.e. the base loss computed based on the truth label and the gene–gene score, and the <italic toggle="yes">L2</italic> loss computed using the entity embedding, relation embedding and aggregation weights</p>
          </caption>
          <graphic xlink:href="btab271f1" position="float"/>
        </fig>
        <p>In a gene-specific subgraph, we can assign different weights for edges to describe the importance of the relations. For an SL pair (<italic toggle="yes">e<sub>i</sub></italic>, <italic toggle="yes">e<sub>j</sub></italic>), the weight for an edge <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> in <italic toggle="yes">e<sub>i’</sub></italic>s subgraph is computed by <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>ω</mml:mo></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>′</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">e</italic> is one of the entities in the subgraph of <italic toggle="yes">e<sub>i</sub></italic>, and <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mi>e</mml:mi><mml:mo>′</mml:mo><mml:mo>∈</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Besides, <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are the feature embeddings of gene <italic toggle="yes">e<sub>j</sub></italic> and relation <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, respectively. <italic toggle="yes">g</italic> is an inner product function. Here, <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>ω</mml:mo></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>′</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> characterizes the importance of relation <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> to gene <italic toggle="yes">e<sub>j</sub></italic>.</p>
      </sec>
      <sec>
        <label>2.3.2</label>
        <title>Aggregation of node representations</title>
        <p>For any central entity <italic toggle="yes">e</italic> in the subgraph of gene <italic toggle="yes">e<sub>i</sub></italic>, we aggregate the representations of all its picked neighbors to update its own representation. To show the topological neighborhood structure of entity <italic toggle="yes">e</italic> in the KG, we compute the weighted average combination of <italic toggle="yes">e’</italic>s neighborhood:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mo>′</mml:mo><mml:mo>∈</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>ω</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>′</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mi mathvariant="bold">e</mml:mi><mml:mo>′</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <bold>e</bold> is the representation of entity <italic toggle="yes">e</italic>, gene <italic toggle="yes">e<sub>i</sub></italic> and gene <italic toggle="yes">e<sub>j</sub></italic> are a pair in the SL matrix, and <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>ω</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is the normalized gene-relation score by applying a softmax function:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:msubsup><mml:mover accent="true"><mml:mi>ω</mml:mi><mml:mo>~</mml:mo></mml:mover><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>`</mml:mo></mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo> </mml:mo><mml:mtext>exp</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mo>ω</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>`</mml:mo></mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>`</mml:mo><mml:mo>∈</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:munder><mml:mo> </mml:mo><mml:mtext>exp</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mo>ω</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>`</mml:mo></mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math></disp-formula></p>
        <p>After obtaining the picked neighbors’ representation <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> of a central entity in one hop, similar to (<xref rid="btab271-B40" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2019a</xref>), it integrates the entity representation <bold>e</bold> into a single vector to update <bold>e</bold>:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>h</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mo>ϕ</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula> where <bold>W</bold> and <bold>b</bold> are the linear transformation weight and bias, respectively, and <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula> is an activation function such as <italic toggle="yes">ReLU</italic>. After aggregating neighbors’ information through <italic toggle="yes">H</italic> hops, the final feature representation of gene <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mi mathvariant="bold">e</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>H</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo mathvariant="bold">.</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> is obtained in the same way.</p>
      </sec>
      <sec>
        <label>2.3.3</label>
        <title>SL prediction score</title>
        <p>Finally, by passing information from two subgraphs of KG, we attain the final representations <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for the two genes in the SL matrix. The predicted interaction probability between gene <italic toggle="yes">e<sub>i</sub></italic> and gene <italic toggle="yes">e<sub>j</sub></italic> is calculated by <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>ϕ</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">f</italic> is the inner product function and <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula> is a sigmoid function, squashing the output to a range between 0 and 1. Furthermore, this link prediction can be viewed as a binary classification problem, by setting the threshold to 0.5. <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is 1 or 0, which indicates whether an SL relation exists between a candidate pair of genes.</p>
      </sec>
    </sec>
    <sec>
      <title>2.4 Overall loss and optimization</title>
      <p>Two kinds of losses are designed for our model, including base loss and <italic toggle="yes">L2</italic> loss. The base loss <italic toggle="yes">J</italic> is computed through cross-entropy of the truth label and the predicted label for the edges, represented as follows.
<disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mi>J</mml:mi></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mi>max</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext>exp</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the predicted label and <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the truth label for the edge. We also add an <italic toggle="yes">L2</italic>-regularizer defined as:
<disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo>Γ</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">e</mml:mi><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">r</mml:mi><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo>·</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> represents the <italic toggle="yes">L2</italic> norm for entity embedding, relation embedding and aggregation weights.</p>
      <p>The final loss combines the two kinds of loss functions described above as follows:
<disp-formula id="E6"><label>(6)</label><mml:math id="M6" display="block" overflow="scroll"><mml:msub><mml:munder><mml:mi>min</mml:mi><mml:mrow><mml:mi mathvariant="bold">W</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="bold">b</mml:mi></mml:mrow></mml:munder><mml:mrow/></mml:msub><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:munder><mml:mi>min</mml:mi><mml:mrow><mml:mi mathvariant="bold">W</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="bold">b</mml:mi></mml:mrow></mml:munder><mml:mrow/></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mi>J</mml:mi><mml:mo>+</mml:mo><mml:mo>α</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo>Γ</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo>,</mml:mo></mml:math></disp-formula>where <bold>A</bold> is the trainable weighted matrix in which each element represents the gene-relation score and <italic toggle="yes">L2</italic> weight <italic toggle="yes">α</italic> is a balancing hyper-parameter. Here <italic toggle="yes">α</italic> was set to 0.0039. The first term corresponds to the part of GNN that learns the linear transformation weight <bold>W</bold>, gene-relation score weight <bold>A</bold> and bias <bold>b</bold> simultaneously. The second term added the <italic toggle="yes">L2</italic>-regularizer. Adam algorithm is used to minimize the final loss and the learning rate is set to 0.002. The framework of KG4SL is outlined in Algorithim 1.</p>
      <p>
        <boxed-text id="btab271-BOX1" position="float">
          <sec>
            <title>Algorithm 1 KG4SL</title>
            <p><bold>Input:</bold> SL matrix <italic toggle="yes">S</italic>; KG <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>; neighborhood field  <italic toggle="yes">P</italic>(<italic toggle="yes">e</italic>); hyper-parameters <italic toggle="yes">α</italic>,<italic toggle="yes">d</italic>, <italic toggle="yes">k</italic>, <italic toggle="yes">h</italic> and epoch;</p>
            <p><bold>Output:</bold>  <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></p>
            <list list-type="simple">
              <list-item>
                <p>
                  <bold>1: Initialization:</bold>
                </p>
              </list-item>
              <list-item>
                <p>2: entity embedding matrix <italic toggle="yes">W<sub>e</sub></italic>;</p>
              </list-item>
              <list-item>
                <p>3: relation embedding matrix <italic toggle="yes">W<sub>r</sub></italic>;</p>
              </list-item>
              <list-item>
                <p>4: step ← 0;</p>
              </list-item>
              <list-item>
                <p><bold>5: while</bold> step &lt; epoch <bold>do</bold></p>
              </list-item>
              <list-item>
                <p><bold>6:   for</bold>  <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:math></inline-formula>  <bold>do</bold></p>
              </list-item>
              <list-item>
                <p>7:    <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>H</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> ← <bold>G</bold>ene-specific <bold>S</bold>ubgraph(<italic toggle="yes">e<sub>i</sub></italic>);</p>
              </list-item>
              <list-item>
                <p>8:    <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>H</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> ← <bold>G</bold>ene-specific <bold>S</bold>ubgraph(<italic toggle="yes">e<sub>j</sub></italic>);</p>
              </list-item>
              <list-item>
                <p><bold>9:    for</bold> <italic toggle="yes">m</italic> <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>  <bold>do</bold></p>
              </list-item>
              <list-item>
                <p>10:     <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:mi>e</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mo>←</mml:mo><mml:mi>G</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>;</p>
              </list-item>
              <list-item>
                <p><bold>11:     for</bold> <italic toggle="yes">h</italic> = 1,2,…,H <bold>do</bold></p>
              </list-item>
              <list-item>
                <p><bold>12:      for</bold>  <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mrow><mml:mi>e</mml:mi><mml:mo>∈</mml:mo><mml:mi>G</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>  <bold>do</bold></p>
              </list-item>
              <list-item>
                <p>13:       <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>h</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mo>←</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mo>′</mml:mo><mml:mo>∈</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>ω</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>′</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mi mathvariant="bold">e</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:math></inline-formula>;</p>
              </list-item>
              <list-item>
                <p>14:       <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>←</mml:mo><mml:mo>ϕ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>h</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>h</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="bold">b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>;</p>
              </list-item>
              <list-item>
                <p>
                  <bold>15:      end for</bold>
                </p>
              </list-item>
              <list-item>
                <p>
                  <bold>16:     end for</bold>
                </p>
              </list-item>
              <list-item>
                <p>17:     <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mo>←</mml:mo><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>;</p>
              </list-item>
              <list-item>
                <p>
                  <bold>18:    end for</bold>
                </p>
              </list-item>
              <list-item>
                <p>19:    Compute the predicted probability <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:mo>ϕ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>;</p>
              </list-item>
              <list-item>
                <p>20:    Compute the loss <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mi>ℓ</mml:mi></mml:math></inline-formula>;</p>
              </list-item>
              <list-item>
                <p>
                  <bold>21:   end for</bold>
                </p>
              </list-item>
              <list-item>
                <p>22:   step ← step + 1;</p>
              </list-item>
              <list-item>
                <p>
                  <bold>23:  end while</bold>
                </p>
              </list-item>
            </list>
          </sec>
        </boxed-text>
      </p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <p>In this section, we first introduce the state-of-the-art baseline methods and their implementation details, and then we compare our model with the baselines, followed by an analysis of the influence of the KG. The KG4SL model was implemented with Python 3.6 and Tensorflow 1.15.0. We adopt AUC, AUPR and F1 as the evaluation metrics.</p>
    <sec>
      <title>3.1 Performance evaluation</title>
      <sec>
        <label>3.1.1</label>
        <title>Baselines</title>
        <p>We compare KG4SL with the following baselines:
</p>
        <list list-type="bullet">
          <list-item>
            <p><bold>SL<sup>2</sup>MF</bold> (<xref rid="btab271-B25" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2020</xref>) integrates gene similarities based on GO biological pathway annotations with SL matrix to predict SL pairs.</p>
          </list-item>
          <list-item>
            <p><bold>GRSMF</bold> (<xref rid="btab271-B17" ref-type="bibr">Huang <italic toggle="yes">et al.</italic>, 2019</xref>) is a graph regularized self-representative MF model which also uses known SL pairs and GO-based gene similarities to predict SL pairs.</p>
          </list-item>
          <list-item>
            <p><bold>HOPE</bold> (<xref rid="btab271-B29" ref-type="bibr">Ou <italic toggle="yes">et al.</italic>, 2016</xref>) is scalable to preserve high-order proximity of graphs and capable of capturing the asymmetric transitivity.</p>
          </list-item>
          <list-item>
            <p><bold>DeepWalk</bold> (<xref rid="btab271-B31" ref-type="bibr">Perozzi <italic toggle="yes">et al.</italic>, 2014</xref>) is a graph embedding method which uses short random walks (RWs) to learn representations for nodes in graphs.</p>
          </list-item>
          <list-item>
            <p><bold>Node2Vec</bold> (<xref rid="btab271-B12" ref-type="bibr">Grover and Leskovec, 2016</xref>) also learns feature representations for node in graphs but adds flexibility in exploring neighborhoods.</p>
          </list-item>
          <list-item>
            <p><bold>LINE</bold> (<xref rid="btab271-B34" ref-type="bibr">Tang <italic toggle="yes">et al.</italic>, 2015</xref>) uses an effective edge-sampling method for model inference and preserves both the first- and second-order proximities by a fine-grained objective function.</p>
          </list-item>
          <list-item>
            <p><bold>Convolutional network (GCN)</bold> (<xref rid="btab271-B20" ref-type="bibr">Kipf and Welling, 2016</xref>) is the most popular GNN architecture, which employs the symmetric-normalized aggregation as well as the self-loop update approach.</p>
          </list-item>
          <list-item>
            <p><bold>GraphSAGE</bold> (<xref rid="btab271-B14" ref-type="bibr">Hamilton <italic toggle="yes">et al.</italic>, 2017</xref>) introduces the idea of generalized neighborhood aggregation.</p>
          </list-item>
          <list-item>
            <p><bold>GAT</bold> (<xref rid="btab271-B38" ref-type="bibr">Veličković <italic toggle="yes">et al.</italic>, 2017</xref>) introduces the attention mechanisms to GNN.</p>
          </list-item>
          <list-item>
            <p><bold>DDGCN</bold> (<xref rid="btab271-B5" ref-type="bibr">Cai <italic toggle="yes">et al.</italic>, 2020</xref>) is built to adapt to the sparsity of SL network, which includes a dual form drop out.</p>
          </list-item>
        </list>
        <p>These baselines can be divided into three categories, MF-based baselines (SL<sup>2</sup>MF, GRSMF and HOPE), RW-based baselines (DeepWalk, Node2Vec and LINE) and GNN-based baselines (GraphSAGE, GAT, GCN and DDGCN). We evaluated DeepWalk, Node2Vec, LINE using CogDL (<xref rid="btab271-B35" ref-type="bibr">THUDM, 2020</xref>), GraphSage, GCN and GAT via graph convolution layer in DGL (<xref rid="btab271-B41" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2019b</xref>). Note that all the baselines do not utilize KG as inputs, so they are only trained on the SL interaction matrix. In addition to the SL interaction matrix, SL<sup>2</sup>MF and GRSMF also utilize GO semantic similarity matrices for SL prediction.</p>
      </sec>
      <sec>
        <label>3.1.2</label>
        <title>Implementation details</title>
        <p>All the baselines were evaluated at 5-fold cross validation which makes the best use of the available data. We viewed the input graph as an unweighted and undirected graph. For SL<sup>2</sup>MF and GRSMF, we utilized all the default parameters in the origin papers. For HOPE, the parameter beta was set to 0.02. For RW-based methods, the number of walks to start at each node was set to 5, the length of the RW start at each node was set to 10, the window size was set to 3. For node2vec, <italic toggle="yes">p</italic> and <italic toggle="yes">q</italic> were both set to 1, which respectively control how fast the walk explores and how fast the walk leaves the neighborhood of starting. For LINE, the alpha was set to 0.1 and other was set to 2. For DDGCN, we use the same setting of the origin paper. For GCN, GAT and GraphSage, we all used two convolution layers, and the dimensionality of the latent spaces in the first and second layers were chosen to be 5 and 16. The number of training epochs was decided via the early stopping strategy. KG4SL was evaluated using the ratio of training, validation and testing data as 8:1:1. In order to improve the stability of results, we randomly split dataset into 10 pieces and took one of them as the testing set. Early stopping strategy is used to control the number of training epochs.</p>
      </sec>
      <sec>
        <label>3.1.3</label>
        <title>Comparison with baselines</title>
        <p>On SynLethKG, KG4SL outperforms all baselines as shown in <xref rid="btab271-T4" ref-type="table">Table 4</xref>. When compared with the second best model GRSMF, KG4SL improves the performance on AUC, AUPR and F1 by 3.11%, 2.16% and 6.4%, respectively.</p>
        <table-wrap position="float" id="btab271-T4">
          <label>Table 4.</label>
          <caption>
            <p>Metrics of KG4SL against baselines in AUC, AUPR and F1</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Categories</th>
                <th rowspan="1" colspan="1">Methods</th>
                <th rowspan="1" colspan="1">AUC</th>
                <th rowspan="1" colspan="1">AUPR</th>
                <th rowspan="1" colspan="1">F1</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">MF</td>
                <td rowspan="1" colspan="1">SL<sup>2</sup>MF</td>
                <td rowspan="1" colspan="1">0.7811 ± 0.0035</td>
                <td rowspan="1" colspan="1">0.8635 ± 0.0021</td>
                <td rowspan="1" colspan="1">0.7446 ± 0.0074</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">GRSMF</td>
                <td rowspan="1" colspan="1">0.9184 ± 0.0039</td>
                <td rowspan="1" colspan="1">0.9362 ± 0.0023</td>
                <td rowspan="1" colspan="1">0.8339 ± 0.0049</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">HOPE</td>
                <td rowspan="1" colspan="1">0.7776 ± 0.0005</td>
                <td rowspan="1" colspan="1">0.7410 ± 0.0006</td>
                <td rowspan="1" colspan="1">0.7089 ± 0.0010</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">RW</td>
                <td rowspan="1" colspan="1">DeepWalk</td>
                <td rowspan="1" colspan="1">0.8451 ± 0.0024</td>
                <td rowspan="1" colspan="1">0.8600 ± 0.0013</td>
                <td rowspan="1" colspan="1">0.7562 ± 0.0027</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">node2vec</td>
                <td rowspan="1" colspan="1">0.8362 ± 0.0010</td>
                <td rowspan="1" colspan="1">0.8523 ± 0.0014</td>
                <td rowspan="1" colspan="1">0.7503 ± 0.0031</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">LINE</td>
                <td rowspan="1" colspan="1">0.8233 ± 0.0028</td>
                <td rowspan="1" colspan="1">0.8327 ± 0.0023</td>
                <td rowspan="1" colspan="1">0.7380 ± 0.0056</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">GNN</td>
                <td rowspan="1" colspan="1">GCN</td>
                <td rowspan="1" colspan="1">0.8329 ± 0.0172</td>
                <td rowspan="1" colspan="1">0.8727 ± 0.0110</td>
                <td rowspan="1" colspan="1">0.8508 ± 0.0136</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">GraphSAGE</td>
                <td rowspan="1" colspan="1">0.8398 ± 0.0291</td>
                <td rowspan="1" colspan="1">0.8775 ± 0.0188</td>
                <td rowspan="1" colspan="1">0.8569 ± 0.0236</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">GAT</td>
                <td rowspan="1" colspan="1">0.7914 ± 0.0182</td>
                <td rowspan="1" colspan="1">0.8462 ± 0.0103</td>
                <td rowspan="1" colspan="1">0.8152 ± 0.0129</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">DDGCN</td>
                <td rowspan="1" colspan="1">0.8491 ± 0.0106</td>
                <td rowspan="1" colspan="1">0.8998 ± 0.0056</td>
                <td rowspan="1" colspan="1">0.8154 ± 0.0074</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">KG4SL</td>
                <td rowspan="1" colspan="1"><bold>0.9470 </bold>±<bold> </bold>0.0003</td>
                <td rowspan="1" colspan="1"><bold>0.9564 </bold>±<bold> </bold>0.0005</td>
                <td rowspan="1" colspan="1"><bold>0.8877 </bold>±<bold> </bold>0.0017</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <p><italic toggle="yes">Note</italic>: The best results for each index are in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>In general, GNN-based models achieve better performance than shallow embedding methods like MF-based and RW-based models. This may because GNN-based models can learn from the similarity between SLs and enrich the embedding of genes for SL prediction. DDGCN represents the state-of-art model for SL prediction, and it achieves the best performance among the GNN-based baselines. MF-based method GRSMF is second only to KG4SL, which shows that the combination of GO gene similarity information and self-representation matrix decomposition is very effective for SL prediction. The performance of KG4SL is even higher, which shows that learning gene representations from the KG including GO information and other gene features can further improve SL prediction.</p>
      </sec>
    </sec>
    <sec>
      <title>3.2 Model Analysis</title>
      <sec>
        <label>3.2.1</label>
        <title>Parameter sensitivity</title>
        <p>We present the sensitivity analysis for some key hyperparameters in our KG4SL, including the neighbor sampling size <italic toggle="yes">k</italic> and the dimension of entity embedding <italic toggle="yes">d</italic>, as shown in <xref rid="btab271-F2" ref-type="fig">Figure 2</xref>.</p>
        <fig position="float" id="btab271-F2">
          <label>Fig. 2.</label>
          <caption>
            <p>Parameter sensitivity analysis with varying <italic toggle="yes">k</italic> and <italic toggle="yes">d</italic> for KG4SL. Left: AUC, AUPR, and F1 at different neighbor sampling sizes <italic toggle="yes">k</italic>, ranging from 2 to 128. Right: AUC, AUPR and F1 at different node embedding dimensions <italic toggle="yes">d</italic>, ranging from 8 to 512</p>
          </caption>
          <graphic xlink:href="btab271f2" position="float"/>
        </fig>
        <p>First, we change the number of samples for neighbor <italic toggle="yes">k</italic> and observe the model performance. KG4SL achieves the best AUC, F1 and AUPR when the neighbor sampling size <italic toggle="yes">k </italic>=<italic toggle="yes"> </italic>64. When sampling more neighbors with higher value of <italic toggle="yes">k</italic>, the information sampled may become redundant, and thus the model performance slightly decreases when <italic toggle="yes">k</italic> is 128. Next, we also investigate the influence of the dimension of embedding <italic toggle="yes">d</italic>. The KG4SL model already has a good performance when the dimension of embedding is 256. Too large dimension of embedding is a burden on memory and computation. Eventually, we set the neighbor sampling size as 64 and the dimension of embedding as 256 for our KG4SL model.</p>
      </sec>
      <sec>
        <label>3.2.2</label>
        <title>Convergence analysis</title>
        <p>With the above parameters set, we observe the convergence of the model. <xref rid="btab271-F3" ref-type="fig">Figure 3</xref> displays the change of loss and three metrics with the increase of epochs. The blue-dotted, red-dashed and green dash-dot lines represent the metrics of training data, validation data and testing data, respectively. The orange line shows the change of loss. We find that loss falls rapidly within the first 10 epochs and begins to converge gradually at the 20th epoch. Under the constraint of the <italic toggle="yes">L2</italic>-regularizer, loss converges to 0.3111 and the results of the three metrics in the training set, validation set and test set have the similar variation trend which shows that the proposed method can alleviate the problem of overfitting.</p>
        <fig position="float" id="btab271-F3">
          <label>Fig. 3.</label>
          <caption>
            <p>Convergence analysis of KG4SL. In the first subgraph, the orange line represents the change of training loss during the training process. In the other three subgraphs, the blue-dotted line represents the variation trend of three metrics (AUC, F1 and AUPR) during the training process. The red-dashed line displays the values of the above metrics for validation set as the increase of epochs. The green dash-dot line denotes the results for test set. At the first 10 epochs, the training loss drops rapidly and the three metrics for training set, validation set and test set increase with a uniform trend. Although at the 20th epoch, the training loss and three metrics begin to converge</p>
          </caption>
          <graphic xlink:href="btab271f3" position="float"/>
        </fig>
      </sec>
    </sec>
    <sec>
      <title>3.3 Impact of KG</title>
      <p>While automatically integrating the KG into the node feature construction is crucial in our work, we wonder whether the KG is really important for the task of SL prediction. To investigate this problem, we test the SL prediction performance with and without the SynLethKG separately.</p>
      <p><xref rid="btab271-T5" ref-type="table">Table 5</xref> shows the prediction performance of several machine learning models on SynLethKG, SL graph and the combination of both. KG-based methods intend to learn low-dimensional embeddings of entities and relations in SynLethKG automatically. We take TransE (<xref rid="btab271-B3" ref-type="bibr">Bordes <italic toggle="yes">et al.</italic>, 2013</xref>), a popular unsupervised KG embedding learning method as an example, which is trained based solely on SynLethKG. We also compare the contributions of a single SL graph, which is called SL-based method, whose performance is exactly that of GCN in <xref rid="btab271-T4" ref-type="table">Table 4</xref>. Then, a combination of the KG- and SL-based method, named ‘TransE + GCN’, is further tested. From the first three rows in <xref rid="btab271-T5" ref-type="table">Table 5</xref>, we can observe that additional information from the KG guides the model to achieve better performance than using KG or SL graph alone. TransE, trained on the KG only, reports an AUC score of 0.5870 and an AUPR of 0.6100, which are the lowest values among the three models. GCN, operating on the SL graph directly, leverages Xavier’s uniform distribution (<xref rid="btab271-B11" ref-type="bibr">Glorot and Bengio, 2010</xref>) as the initial node features, obtains AUC score of 0.8329 and AUPR score of 0.8727. The models that inspect the KG and SL graph together outperform either of the above. All the evidence supports that the KG information can help with SL prediction.</p>
      <table-wrap position="float" id="btab271-T5">
        <label>Table 5.</label>
        <caption>
          <p>Impact of KG analysis on AUC and AUPR</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">Method</th>
              <th rowspan="1" colspan="1">AUC</th>
              <th rowspan="1" colspan="1">AUPR</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">KG-based</td>
              <td rowspan="1" colspan="1">TransE</td>
              <td rowspan="1" colspan="1">0.5870 ± 0.0086</td>
              <td rowspan="1" colspan="1">0.6100 ± 0.0109</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SL-based</td>
              <td rowspan="1" colspan="1">GCN</td>
              <td rowspan="1" colspan="1">0.8329 ± 0.0172</td>
              <td rowspan="1" colspan="1">0.8727 ± 0.0110</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">KG + SL-based</td>
              <td rowspan="1" colspan="1">TransE + GCN</td>
              <td rowspan="1" colspan="1">0.9063 ± 0.0071</td>
              <td rowspan="1" colspan="1">0.9138 ± 0.0056</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">RF</td>
              <td rowspan="1" colspan="1">0.8882 ± 0.0130</td>
              <td rowspan="1" colspan="1">0.9218 ± 0.0098</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">KG4SL</td>
              <td rowspan="1" colspan="1"><bold>0.9470 </bold>±<bold> </bold>0.0003</td>
              <td rowspan="1" colspan="1"><bold>0.9564 </bold>±<bold> </bold>0.0005</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p><italic toggle="yes">Note:</italic> The best results for each index are in bold.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>After that, an ensemble learning method named RF (<xref rid="btab271-B4" ref-type="bibr">Breiman, 2001</xref>), which also uses the information extracted from KG and SL, is selected to be compared with ‘TransE + GCN’. The difference between RF and ‘TransE + GCN’ is that whether the features are extracted automatically. The features of RF should be carefully selected manually, whereas the gene embeddings are automatically extracted from TransE and fed into GCN to generate SL prediction results. Here, RF uses six features, namely, minTriangles, maxTriangles, minCoefficient, maxCoeffiecient, sp and sl. For each gene pair, minTriangles and maxTriangles reflect the max and min numbers of triangles that each gene forms. The minCoeffiecient and maxCoeffiecient reflect the min and max likelihood that the neighbors of these two genes are connected. sp is a Boolean value that represents whether the two genes are in the same community detected by the label propagation algorithm. sl means whether two genes are in the same community detected by Louvain algorithm (<xref rid="btab271-B2" ref-type="bibr">Blondel <italic toggle="yes">et al.</italic>, 2008</xref>). The results show that ‘TransE + GCN’ achieves slightly higher AUC and slightly lower AUPR than RF.</p>
      <p>Comparing all these models with KG4SL which is an end-to-end model using the information extracted from KG and SL automatically, KG4SL yields the top AUC of 0.9470 and AUPR of 0.9564. This signifies the benefit of adding a suitable KG in SL prediction.</p>
      <p>Furthermore, to qualitatively interpret the above models’ learning abilities, we draw the link features extracted from these models. First, we fix the dimension of node features to 256. Next, the features for each node of an SL pair in test data are concatenated together, representing the link embedding between them. Then, the high-dimensional feature vectors are mapped into a 2D space by using visualization technique t-SNE (<xref rid="btab271-B37" ref-type="bibr">Van der Maaten and Hinton, 2008</xref>). As <xref rid="btab271-F4" ref-type="fig">Figure 4</xref> shows, orange dots denote there is an SL relation between a pair of test genes and blue dots are the opposite. We are curious whether the models can tell the differences between the two kinds of link types. Clearly, on one hand, TransE has the weakest distinguish capacity, as the SL label information is not taken into account. On the other hand, although both ‘TransE + GCN’ and KG4SL are integrated with the KG, KG4SL makes better use of this information, separating the two types of links more thoroughly.</p>
      <fig position="float" id="btab271-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Visualization of SL interaction network. Link embeddings are generated by different models of gene–gene pairs in the SL matrix. Dot colors indicate whether there is an SL relationship between a pair of genes. TransE or GCN alone cannot distinguish the two types of links well as they only capture information from the KG or SL interaction, whereas KG4SL can distinguish the two link embeddings, demonstrating its ability to learn from both the SL network and the KG</p>
        </caption>
        <graphic xlink:href="btab271f4" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion and discussions</title>
    <p>In this article, we proposed a novel framework named KG4SL for predicting SL, which incorporates a knowledge graph (KG) into the GNN model. Many existing methods view each SL pair as an independent sample from a latent representation, but this assumption is an oversimplification in the biological context of cancer cells. KG can bring additional information such as biological processes which could be crucial for discovering new SL pairs. By injecting the KG, our model was capable of harnessing the aforementioned issue, without manual feature engineering. Extensive experiments have been conducted to examine the impact of KG. The results show that both KG and MP in GNN are essential for boosting the model performance. Therefore, KG4SL represents a breakthrough in applying supervised machine learning to SL prediction.</p>
    <p>Our future work will focus on the following directions. First, we plan to further improve our model, using the strategy of contrastive learning, which is a self-supervised approach to learn graph representation. Secondly, the degrees of some nodes in a KG might be very large, while sampling a fixed-sized neighborhood may not fully capture the neighborhood topological structures of the nodes. To address this issue, it will be a highly desirable future work to contrast multiple receptive fields for a given node, to learn a more robust and enriched embedding. Moreover, inspired by the recently proposed KG attention network (<xref rid="btab271-B42" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2019c</xref>), we are interested in incorporating the attention mechanism into the KG MP. Considering there might be some promiscuous and uninformative neighbors for MP, the attention could play the role of a filter (<xref rid="btab271-B15" ref-type="bibr">Hamilton, 2020</xref>). By inspecting and visualizing the attention weights, interpretability analysis could be done to account for decisions made by GNN models. Thirdly, since our model outperforms most of the state-of-the-art models, it is desirable to utilize our model to discover novel SL pairs and collaborate with biologists to validate candidate SL pairs as drug targets. Last but not least, the Cancer Dependency Map (DepMap) project (<xref rid="btab271-B36" ref-type="bibr">Tsherniak <italic toggle="yes">et al.</italic>, 2017</xref>) aims to examine how perturbing a given target gene in a specific cancer type might affect the tumor growth, including cases when the best targets are SL partners of an altered gene. <xref rid="btab271-B6" ref-type="bibr">Das <italic toggle="yes">et al.</italic> (2019)</xref> predicted the SL pairs in the different cancer types which considered the tissue context. <xref rid="btab271-B39" ref-type="bibr">Wan <italic toggle="yes">et al.</italic> (2020)</xref> introduced the cell-line-specific gene expression information to help predict SL interaction, since most SL pairs remain cell-line specific. It is believed that such context-specific information can provide useful features for the SL prediction problem. Integrating the DepMap data into our KG4SL model, we can develop an AI system to facilitate the discovery of SL-based anticancer therapeutics. As many gene mutations cause cancer cells to inactivate, it is possible to kill the cancer cells by identifying the SL partners of these genes (<xref rid="btab271-B28" ref-type="bibr">O’Neil <italic toggle="yes">et al.</italic>, 2017</xref>). In the area of drug discovery or drug repurposing, using AI methods to narrow candidate drug targets set can speed up the research process.</p>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors would like to thank Xin Liu from ShanghaiTech University for his help with a few case studies of predicted SLs.</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btab271-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ashworth</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) <article-title>Genetic interactions in cancer progression and treatment</article-title>. <source>Cell</source>, <volume>145</volume>, <fpage>30</fpage>–<lpage>38</lpage>.<pub-id pub-id-type="pmid">21458666</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Blondel</surname><given-names>V.D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2008</year>) <article-title>Fast unfolding of communities in large networks</article-title>. <source>J. Stat. Mech. Theory Exp</source>., <volume>2008</volume>, <fpage>P10008</fpage>.</mixed-citation>
    </ref>
    <ref id="btab271-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bordes</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) <article-title>Translating embeddings for modeling multi-relational data</article-title>. In: <source>Advances Neural Information Processing Systems</source>, Vol. <volume>26</volume>, pp. <fpage>2787</fpage>–<lpage>2795</lpage>. Lake Tahoe, Nevada, USA, December 5–12, 2013.</mixed-citation>
    </ref>
    <ref id="btab271-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Breiman</surname><given-names>L.</given-names></string-name></person-group> (<year>2001</year>) <article-title>Random forests</article-title>. <source>Mach. Learn</source>., <volume>45</volume>, <fpage>5</fpage>–<lpage>32</lpage>.</mixed-citation>
    </ref>
    <ref id="btab271-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cai</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Dual-dropout graph convolutional network for predicting synthetic lethality in human cancers</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>4458</fpage>–<lpage>4465</lpage>.<pub-id pub-id-type="pmid">32221609</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Das</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Discoversl: an r package for multi-omic data driven prediction of synthetic lethality in cancers</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>701</fpage>–<lpage>702</lpage>.<pub-id pub-id-type="pmid">30059974</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dhabhar</surname><given-names>F.S.</given-names></string-name></person-group> (<year>2009</year>) <article-title>Enhancing versus suppressive effects of stress on immune function: implications for immunoprotection and immunopathology</article-title>. <source>Neuroimmunomodulation</source>, <volume>16</volume>, <fpage>300</fpage>–<lpage>317</lpage>.<pub-id pub-id-type="pmid">19571591</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dobzhansky</surname><given-names>T.</given-names></string-name></person-group> (<year>1946</year>) <article-title>Genetics of natural populations. xiii. recombination and variability in populations of drosophila pseudoobscura</article-title>. <source>Genetics</source>, <volume>31</volume>, <fpage>269</fpage>–<lpage>290</lpage>.<pub-id pub-id-type="pmid">20985721</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Du</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Genetic interaction mapping in mammalian cells using crispr interference</article-title>. <source>Nat. Methods</source>, <volume>14</volume>, <fpage>577</fpage>.<pub-id pub-id-type="pmid">28481362</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Folger</surname><given-names>O.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) <article-title>Predicting selective drug targets in cancer through metabolic networks</article-title>. <source>Mol. Syst. Biol</source>., <volume>7</volume>, <fpage>501</fpage>.<pub-id pub-id-type="pmid">21694718</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B11">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Glorot</surname><given-names>X.</given-names></string-name>, <string-name><surname>Bengio</surname><given-names>Y.</given-names></string-name></person-group> (<year>2010</year>). <part-title>Understanding the difficulty of training deep feedforward neural networks</part-title>. In: <source>Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</source>, pp. <fpage>249</fpage>–<lpage>256</lpage>. Sardinia, Italy, May 13–15, 2010.</mixed-citation>
    </ref>
    <ref id="btab271-B12">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Grover</surname><given-names>A.</given-names></string-name>, <string-name><surname>Leskovec</surname><given-names>J.</given-names></string-name></person-group> (<year>2016</year>). <part-title>node2vec: scalable feature learning for networks</part-title>. In: <source>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</source>, pp. <fpage>855</fpage>–<lpage>864</lpage>. San Francisco, CA, USA, August 13–17, 2016.</mixed-citation>
    </ref>
    <ref id="btab271-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>SynLethDB: synthetic lethality database toward discovery of selective and sensitive anticancer drug targets</article-title>. <source>Nucleic Acids Res</source>., <volume>44</volume>, <fpage>D1011</fpage>–<lpage>D1017</lpage>.<pub-id pub-id-type="pmid">26516187</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hamilton</surname><given-names>W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Inductive representation learning on large graphs</article-title>. In: <source>Advances in Neural Information Processing Systems</source>, Vol. <volume>30</volume>, pp. <fpage>1024</fpage>–<lpage>1034</lpage>. Long Beach, CA, USA, December 4–9, 2017.</mixed-citation>
    </ref>
    <ref id="btab271-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hamilton</surname><given-names>W.L.</given-names></string-name></person-group> (<year>2020</year>) <article-title>Graph representation learning</article-title>. In: <source>Synthesis Lectures on Artificial Intelligence and Machine Learning</source>, Vol. <volume>14</volume>, pp. <fpage>1</fpage>–<lpage>159</lpage>.</mixed-citation>
    </ref>
    <ref id="btab271-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hartwell</surname><given-names>L.H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1997</year>) <article-title>Integrating genetic approaches into the discovery of anticancer drugs</article-title>. <source>Science</source>, <volume>278</volume>, <fpage>1064</fpage>–<lpage>1068</lpage>.<pub-id pub-id-type="pmid">9353181</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Predicting synthetic lethal interactions in human cancers using graph regularized self-representative matrix factorization</article-title>. <source>BMC Bioinformatics</source>, <volume>20</volume>, <fpage>1</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">30606105</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jacunski</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>Connectivity homology enables inter-species network models of synthetic lethality</article-title>. <source>PLoS Comput. Biol</source>., <volume>11</volume>, <fpage>e1004506</fpage>.<pub-id pub-id-type="pmid">26451775</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jerby-Arnon</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Predicting cancer-specific vulnerability via data-driven detection of synthetic lethality</article-title>. <source>Cell</source>, <volume>158</volume>, <fpage>1199</fpage>–<lpage>1209</lpage>.<pub-id pub-id-type="pmid">25171417</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kipf</surname><given-names>T.N.</given-names></string-name>, <string-name><surname>Welling</surname><given-names>M.</given-names></string-name></person-group> (<year>2016</year>) <article-title>Semi-supervised classification with graph convolutional networks</article-title>. <source>arXiv Preprint arXiv</source>, <volume>1609</volume>, <fpage>02907</fpage>.</mixed-citation>
    </ref>
    <ref id="btab271-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kranthi</surname><given-names>T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) <article-title>Identification of synthetic lethal pairs in biological systems through network information centrality</article-title>. <source>Mol. bioSyst</source>., <volume>9</volume>, <fpage>2163</fpage>–<lpage>2167</lpage>.<pub-id pub-id-type="pmid">23728082</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kwok</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Atr inhibition induces synthetic lethality and overcomes chemoresistance in tp53-or atm-defective chronic lymphocytic leukemia cells</article-title>. <source>Blood</source>, <volume>127</volume>, <fpage>582</fpage>–<lpage>595</lpage>.<pub-id pub-id-type="pmid">26563132</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liany</surname><given-names>H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Predicting synthetic lethal interactions using heterogeneous data sources</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>2209</fpage>–<lpage>2216</lpage>.<pub-id pub-id-type="pmid">31782759</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B24">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>X.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>). <part-title>KGNN: knowledge graph neural network for drug-drug interaction prediction</part-title>. In: <source>Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20</source>, pp. <fpage>2739</fpage>–<lpage>2745</lpage>. Yokohama, Japan.</mixed-citation>
    </ref>
    <ref id="btab271-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>SL<sup>2</sup>MF: predicting Synthetic Lethality in Human Cancers via Logistic Matrix Factorization</article-title>. <source>IEEE/ACM Trans. Comput. Biol. Bioinformatics</source>, <volume>17</volume>, <fpage>748</fpage>–<lpage>757</lpage>.</mixed-citation>
    </ref>
    <ref id="btab271-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lord</surname><given-names>C.J.</given-names></string-name>, <string-name><surname>Ashworth</surname><given-names>A.</given-names></string-name></person-group> (<year>2017</year>) <article-title>Parp inhibitors: synthetic lethality in the clinic</article-title>. <source>Science</source>, <volume>355</volume>, <fpage>1152</fpage>–<lpage>1158</lpage>.<pub-id pub-id-type="pmid">28302823</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luo</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2009</year>) <article-title>A genome-wide rnai screen identifies multiple synthetic lethal interactions with the ras oncogene</article-title>. <source>Cell</source>, <volume>137</volume>, <fpage>835</fpage>–<lpage>848</lpage>.<pub-id pub-id-type="pmid">19490893</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’Neil</surname><given-names>N.J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Synthetic lethality and cancer</article-title>. <source>Nat. Rev. Genet</source>., <volume>18</volume>, <fpage>613</fpage>–<lpage>623</lpage>.<pub-id pub-id-type="pmid">28649135</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B29">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ou</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>). <part-title>Asymmetric transitivity preserving graph embedding</part-title>. In: <source>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</source>, pp. <fpage>1105</fpage>–<lpage>1114</lpage>. San Francisco, CA, USA, August 13–17, 2016.</mixed-citation>
    </ref>
    <ref id="btab271-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Paladugu</surname><given-names>S.R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2008</year>) <article-title>Mining protein networks for synthetic genetic interactions</article-title>. <source>Bmc Bioinformatics</source>, <volume>9</volume>, <fpage>1</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">18173834</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B31">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Perozzi</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>). <part-title>Deepwalk: online learning of social representations</part-title>. In: <source>Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</source>, pp. <fpage>701</fpage>–<lpage>710</lpage>. New York, NY, USA, August 24–27, 2014.</mixed-citation>
    </ref>
    <ref id="btab271-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sanders</surname><given-names>J.T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Radiation-induced DNA damage and repair effects on 3d genome organization</article-title>. <source>Nat. Commun</source>., <volume>11</volume>, <fpage>1</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">31911652</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Simons</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2001</year>) <article-title>Establishment of a chemical synthetic lethality screen in cultured human cells</article-title>. <source>Genome Res</source>., <volume>11</volume>, <fpage>266</fpage>–<lpage>273</lpage>.<pub-id pub-id-type="pmid">11157789</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B34">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Tang</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>). <part-title>Line: large-scale information network embedding</part-title>. In: <source>Proceedings of the 24th International Conference on World Wide Web</source>, pp. <fpage>1067</fpage>–<lpage>1077</lpage>. Florence, Italy, May 18–22, 2015.</mixed-citation>
    </ref>
    <ref id="btab271-B35">
      <mixed-citation publication-type="other">THUDM. (<year>2020</year>). Cogdl project webpage. <ext-link xlink:href="https://github.com/THUDM/cogdl" ext-link-type="uri">https://github.com/THUDM/cogdl</ext-link> (15 January 2021, date last accessed).</mixed-citation>
    </ref>
    <ref id="btab271-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tsherniak</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Defining a cancer dependency map</article-title>. <source>Cell</source>, <volume>170</volume>, <fpage>564</fpage>–<lpage>576</lpage>.<pub-id pub-id-type="pmid">28753430</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Van der Maaten</surname><given-names>L.</given-names></string-name>, <string-name><surname>Hinton</surname><given-names>G.</given-names></string-name></person-group> (<year>2008</year>) <article-title>Visualizing data using t-SNE</article-title>. <source>J. Mach. Learn. Res</source>., <volume>9</volume>(<issue>11</issue>), <fpage>2579</fpage>–<lpage>2605</lpage>.</mixed-citation>
    </ref>
    <ref id="btab271-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Veličković</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Graph attention networks</article-title>. <source>arXiv Preprint arXiv</source>, <volume>1710</volume>, <fpage>10903</fpage>.</mixed-citation>
    </ref>
    <ref id="btab271-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wan</surname><given-names>F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Exp2sl: a machine learning framework for cell-line-specific synthetic lethality prediction</article-title>. <source>Front. Pharmacol</source>., <volume>11</volume>, <fpage>112</fpage>.<pub-id pub-id-type="pmid">32184722</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B40">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019a</year>). <part-title>Knowledge-aware graph neural networks with label smoothness regularization for recommender systems</part-title>. In: <source>Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</source>, pp. <fpage>968</fpage>–<lpage>977</lpage>. Anchorage, AK, USA, August 4–8, 2019.</mixed-citation>
    </ref>
    <ref id="btab271-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019b</year>) <article-title>Deep graph library: a graph-centric, highly-performant package for graph neural networks</article-title>. <source>arXiv Preprint arXiv</source>, <volume>1909</volume>, <fpage>01315</fpage>.</mixed-citation>
    </ref>
    <ref id="btab271-B42">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>X.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019c</year>). <part-title>KGAT: knowledge graph attention network for recommendation</part-title>. In: <source>Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</source>, pp. <fpage>950</fpage>–<lpage>958</lpage>. Anchorage, AK, USA, August 4–8, 2019.</mixed-citation>
    </ref>
    <ref id="btab271-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>In silico prediction of synthetic lethality by meta-analysis of genetic interactions, functions, and pathways in yeast and human cancer</article-title>. <source>Cancer Inform</source>., <volume>13</volume> (<issue>Suppl. 3)</issue>, <fpage>71</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">25452682</pub-id></mixed-citation>
    </ref>
    <ref id="btab271-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>Predicting essential genes and synthetic lethality via influence propagation in signaling pathways of cancer cell fates</article-title>. <source>J. Bioinform. Comput. Biol</source>., <volume>13</volume>, <fpage>1541002</fpage>.<pub-id pub-id-type="pmid">25669329</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
