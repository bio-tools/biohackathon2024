<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9835482</article-id>
    <article-id pub-id-type="pmid">36576008</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac814</article-id>
    <article-id pub-id-type="publisher-id">btac814</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Data and Text Mining</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Sc2Mol: a scaffold-based two-step molecule generator with variational autoencoder and transformer</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Liao</surname>
          <given-names>Zhirui</given-names>
        </name>
        <aff><institution>School of Computer Science, Fudan University</institution>, Shanghai 200433, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xie</surname>
          <given-names>Lei</given-names>
        </name>
        <aff><institution>Department of Computer Science, Hunter College, The City University of New York</institution>, New York, NY 10065, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mamitsuka</surname>
          <given-names>Hiroshi</given-names>
        </name>
        <aff><institution>Bioinformatics Center, Institute for Chemical Research, Kyoto University</institution>, Uji, Kyoto Prefecture 611-0011, <country country="JP">Japan</country></aff>
        <aff><institution>Department of Computer Science, Aalto University</institution>, Espoo 00076, <country country="FI">Finland</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-6067-5312</contrib-id>
        <name>
          <surname>Zhu</surname>
          <given-names>Shanfeng</given-names>
        </name>
        <aff><institution>Institute of Science and Technology for Brain-Inspired Intelligence and MOE Frontiers Center for Brain Science, Fudan University</institution>, Shanghai 200433, <country country="CN">China</country></aff>
        <aff><institution>Shanghai Qi Zhi Institute</institution>, Shanghai 200030, <country country="CN">China</country></aff>
        <aff><institution>Key Laboratory of Computational Neuroscience and Brain-Inspired Intelligence, Fudan University, Ministry of Education</institution>, Shanghai 200433, <country country="CN">China</country></aff>
        <aff><institution>Shanghai Key Lab of Intelligent Information Processing and Shanghai Institute of Artificial Intelligence Algorithm, Fudan University</institution>, Shanghai 200433, <country country="CN">China</country></aff>
        <aff><institution>Zhangjiang Fudan International Innovation Center</institution>, Shanghai 200433, <country country="CN">China</country></aff>
        <aff><institution>Institute of Artificial Intelligence Biomedicine, Nanjing University</institution>, Nanjing, Jiangsu 210031, <country country="CN">China</country></aff>
        <xref rid="btac814-cor1" ref-type="corresp"/>
        <!--zhusf@fudan.edu.cn-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Wren</surname>
          <given-names>Jonathan</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btac814-cor1">To whom correspondence should be addressed. <email>zhusf@fudan.edu.cn</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-12-28">
      <day>28</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>28</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <volume>39</volume>
    <issue>1</issue>
    <elocation-id>btac814</elocation-id>
    <history>
      <date date-type="received">
        <day>31</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>31</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>13</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>12</day>
        <month>1</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac814.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Finding molecules with desired pharmaceutical properties is crucial in drug discovery. Generative models can be an efficient tool to find desired molecules through the distribution learned by the model to approximate given training data. Existing generative models (i) do not consider backbone structures (scaffolds), resulting in inefficiency or (ii) need prior patterns for scaffolds, causing bias. Scaffolds are reasonable to use, and it is imperative to design a generative model without any prior scaffold patterns.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We propose a generative model-based molecule generator, Sc2Mol, without any prior scaffold patterns. Sc2Mol uses SMILES strings for molecules. It consists of two steps: scaffold generation and scaffold decoration, which are carried out by a variational autoencoder and a transformer, respectively. The two steps are powerful for implementing random molecule generation and scaffold optimization. Our empirical evaluation using drug-like molecule datasets confirmed the success of our model in distribution learning and molecule optimization. Also, our model could automatically learn the rules to transform coarse scaffolds into sophisticated drug candidates. These rules were consistent with those for current lead optimization.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The code is available at <ext-link xlink:href="https://github.com/zhiruiliao/Sc2Mol" ext-link-type="uri">https://github.com/zhiruiliao/Sc2Mol</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>62272105</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>In drug discovery, researchers aim to find molecules with desired pharmaceutical properties. However, due to permutations of atoms and bonds, the chemical space is huge: the number of potential drug-like (synthesizable) molecules is estimated to be more than 10<sup>23</sup> (<xref rid="btac814-B24" ref-type="bibr">Polishchuk <italic toggle="yes">et al.</italic>, 2013</xref>), which is an intractable number for exhaustive search by wet-lab experiments. Deep learning-based generative models, which learn the probability distribution of a given massive training dataset and then have succeeded in generating objects, such as images (<xref rid="btac814-B1" ref-type="bibr">Arjovsky <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac814-B16" ref-type="bibr">Karras <italic toggle="yes">et al.</italic>, 2020</xref>), text (<xref rid="btac814-B38" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2017</xref>, <xref rid="btac814-B37" ref-type="bibr">2019</xref>) and music (<xref rid="btac814-B11" ref-type="bibr">Dong <italic toggle="yes">et al.</italic>, 2018</xref>) from the learned distribution, will thus be useful for searching drug candidates in the huge chemical space.</p>
    <p>Molecule generation, which usually represents a molecule by a SMILES string (<xref rid="btac814-B31" ref-type="bibr">Weininger, 1988</xref>) or a molecular graph, has two tasks: distribution learning and molecule optimization (<xref rid="btac814-B19" ref-type="bibr">Langevin <italic toggle="yes">et al.</italic>, 2020</xref>). The first is that a distribution is modeled from a given training dataset, and novel molecules with properties similar to the training dataset are generated from the distribution by random sampling. The second is to modify input molecules and generate molecules with improved scores according to the given evaluation function. Usually, molecules are generated from atoms and bonds in a <italic toggle="yes">de novo</italic> style (e.g. <xref rid="btac814-B6" ref-type="bibr">Blaschke <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac814-B13" ref-type="bibr">Gómez-Bombarelli <italic toggle="yes">et al.</italic>, 2018</xref>). Nonetheless, each molecule has a backbone structure called a <italic toggle="yes">scaffold</italic>. A suitable scaffold is necessary for a molecule to match the binding pocket of a target protein. In addition, synthesizing organic compounds from intermediates with the same scaffolds can reduce medicinal chemistry efforts. Therefore, generating a molecule through a scaffold is a common and efficient practice in drug discovery (<xref rid="btac814-B39" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2007</xref>). However, all recent scaffold-based approaches need expert knowledge, such as pre-defined patterns (<xref rid="btac814-B2" ref-type="bibr">Arús-Pous <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac814-B19" ref-type="bibr">Langevin <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac814-B21" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac814-B22" ref-type="bibr">Lim <italic toggle="yes">et al.</italic>, 2020</xref>). Moreover, in these approaches, a scaffold is defined as a fragment or a substructure (rather than a backbone), being likely to generate molecules with larger shapes than input scaffolds, regardless that a moderate size is important for protein–drug binding. Also, clinical drug candidates should be generated from not only known compounds but also large compound collection through random screening (<xref rid="btac814-B8" ref-type="bibr">Brown and Boström, 2018</xref>). Thus, molecule generation should support both random <italic toggle="yes">de novo</italic> generation and lead molecule optimization.</p>
    <p>We propose an end-to-end deep generative model, Sc2Mol, for generating molecules (represented by SMILE strings) with two steps: scaffold generation and scaffold decoration. We first generate a scaffold that contains only carbon atoms and single bonds by a variational autoencoder (VAE) (<xref rid="btac814-B18" ref-type="bibr">Kingma and Welling, 2014</xref>), which provides a scaffold distribution to find a novel scaffold. We then enrich the generated scaffold by changing atom and bond types by a transformer (<xref rid="btac814-B30" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic>, 2017</xref>), resulting in molecules with desired properties (see <xref rid="btac814-F1" ref-type="fig">Fig. 1</xref>). Our model needs no extra expert knowledge, such as grammar rules and pre-defined substructures, and generates molecules from either random variables or given scaffolds.</p>
    <fig position="float" id="btac814-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>Two-step molecule generation: we first generate a scaffold that only contains carbon atoms and single bonds and then decorate this scaffold with different atoms and bonds</p>
      </caption>
      <graphic xlink:href="btac814f1" position="float"/>
    </fig>
    <p>We used the MOSES dataset (<xref rid="btac814-B25" ref-type="bibr">Polykovskiy <italic toggle="yes">et al.</italic>, 2020</xref>) and a subset of the ZINC database (<xref rid="btac814-B13" ref-type="bibr">Gómez-Bombarelli <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btac814-B29" ref-type="bibr">Sterling and Irwin, 2015</xref>) (both of them are drug-like molecule datasets) to evaluate our model by comparing with well-known baselines: CharVAE (<xref rid="btac814-B13" ref-type="bibr">Gómez-Bombarelli <italic toggle="yes">et al.</italic>, 2018</xref>), JTVAE (<xref rid="btac814-B15" ref-type="bibr">Jin <italic toggle="yes">et al.</italic>, 2018</xref>) and MoFlow (<xref rid="btac814-B36" ref-type="bibr">Zang and Wang, 2020</xref>). Our model achieved comparable performances against the competing methods on randomly generating molecules under several evaluation metrics. The results showed that our model, even though without pre-defined rules, could capture complex SMILES syntax, including matching parentheses for side chains and pairing numbers for ring systems and lower cases for aromatic systems, and chemical rules, such as the similarity between halogens. On the other hand, given scaffolds, Sc2Mol generated molecules by carefully considering the trade-off between the scaffold and molecule similarity. That is, keeping similarity to a reference molecule, our model could reduce the scaffold similarity, even when the scaffolds are not in the training set. Finally, several case studies demonstrated that our model could convert simple carbon scaffolds into potential drug-like compounds.</p>
    <p>Our contribution can be summarized into the following three points:
</p>
    <list list-type="bullet">
      <list-item>
        <p>We present a SMILES-based deep generative model called Sc2Mol for molecule generation, which consists of two steps: scaffold generation and scaffold decoration.</p>
      </list-item>
      <list-item>
        <p>Sc2Mol does not need any expert knowledge, such as pre-defined patterns or syntactic rules. It allows both random <italic toggle="yes">de novo</italic> molecule generation and scaffold transformation (to a molecule with desired properties).</p>
      </list-item>
      <list-item>
        <p>Our experimental results showed that Sc2Mol could learn chemical rules and patterns automatically and could discover potential compounds for mental illness by using the learned rules and patterns.</p>
      </list-item>
    </list>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Problem formulation</title>
      <p>We use a string (SMILES; <xref rid="btac814-B31" ref-type="bibr">Weininger, 1988</xref>) to represent a molecule, meaning that molecule generation can be a text generation problem. Thus, our problem is, given a source string with <italic toggle="yes">l</italic> characters, <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, to generate a target string with <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> characters, <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. We assume that the source and target strings share the same vocabulary with the size of <italic toggle="yes">v</italic>.</p>
      <p>Our method for this problem has two steps (<xref rid="btac814-F1" ref-type="fig">Fig. 1</xref>): (i) scaffold generation: generating a <italic toggle="yes">generic</italic> scaffold and (ii) scaffold decoration: decorating the generic scaffold with atoms and bonds. A generic scaffold can be defined, following (<xref rid="btac814-B6" ref-type="bibr">Blaschke <italic toggle="yes">et al.</italic>, 2020</xref>): a generic (carbon) scaffold is a molecule obtained by replacing all types of non-hydrogen atoms by carbon atoms and all types of bonds by single bonds. Note that a generic scaffold is also a valid molecule. This definition can keep the original molecule shape as possible. We use a VAE for scaffold generation (i.e. a string generation problem) and a transformer for scaffold decoration corresponding to translation from a generic scaffold string to the desired molecule string. <xref rid="btac814-F2" ref-type="fig">Figure 2</xref> shows our entire architecture.</p>
      <fig position="float" id="btac814-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>Our model architecture. For scaffold generation, we use a VAE that receives the source scaffold, keeping the balance between the reconstruction error and the KL-divergence. For scaffold decoration, we use a transformer to transform the generated carbon scaffold into a meaningful molecule string, close to the target molecule string</p>
        </caption>
        <graphic xlink:href="btac814f2" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>2.2 Scaffold generation</title>
      <p>We assume that the latent prior distribution is a standard normal distribution. We represent a character by a one-hot row vector; thus, an input SMILES string with <italic toggle="yes">l</italic> characters can be denoted by a binary matrix <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>×</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. We first apply an embedding layer with a positional encoding to <bold><italic toggle="yes">X</italic></bold>, to learn dense representation from the input. Note that the lookup operation on an embedding matrix can be considered as matrix multiplication, resulting in the following update for the embedding layer:
<disp-formula id="E1"><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">X</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">E</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is the embedding result, <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">E</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is an embedding matrix, and <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is a positional encoding matrix.</p>
      <p>We implement a VAE by stacking <italic toggle="yes">m</italic> gated convolutional neural networks (GatedConv) for strings (<xref rid="btac814-B10" ref-type="bibr">Dauphin <italic toggle="yes">et al.</italic>, 2017</xref>) with residual connection (<xref rid="btac814-B14" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2016</xref>):
<disp-formula id="E2"><mml:math id="M2" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mtext>GatedConv</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo> </mml:mo><mml:mtext>where</mml:mtext><mml:mo> </mml:mo><mml:mtext>GatedConv</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mo>⋆</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">U</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>⊗</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mo>⋆</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">U</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p>⋆ and ⊗ denote the convolution operation and the element-wise product, respectively, <italic toggle="yes">s</italic> is the sigmoid function, <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">U</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">U</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are convolution kernels of size <italic toggle="yes">k</italic>, and <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> are biases. We then use max pooling to reduce the convolution result to vector <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, to obtain mean <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and logarithmic variance <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> of the approximate distribution by two independent fully connected layers:
<disp-formula id="E3"><mml:math id="M3" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mo>=</mml:mo><mml:mtext>MaxPooling</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">h</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">σ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">h</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p>Note that direct sampling from <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is non-differentiable with respect to <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:math></inline-formula> and <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mi mathvariant="bold-italic">σ</mml:mi></mml:math></inline-formula>, and thus we apply the reparameterization trick below:
<disp-formula id="E4"><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mo>⊗</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mtext>where</mml:mtext><mml:mo> </mml:mo><mml:mi>ϵ</mml:mi><mml:mo>∼</mml:mo><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>From the obtained latent variable <bold><italic toggle="yes">z</italic></bold>, we reconstruct the input SMILES string using the following decoder:
<disp-formula id="E5"><mml:math id="M5" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">Z</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mtext>Reshape</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mtext>where</mml:mtext><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msub><mml:mo>.</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">Z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">Z</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mtext>GatedConv</mml:mtext><mml:mn>1</mml:mn><mml:mi mathvariant="normal">D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">Z</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>.</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mtext>Softmax</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">Z</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mn>4</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mn>4</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p>This VAE is designed to model generic carbon scaffolds in a latent space of dimension <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and then sample a random variable from this space to construct a certain scaffold, entirely allowing scaffold hopping.</p>
    </sec>
    <sec>
      <title>2.3 Scaffold decoration</title>
      <p>We decorate each carbon scaffold (output of the VAE) by using a transformer (<xref rid="btac814-B30" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic>, 2017</xref>) to generate the desired compound. Note that the carbon scaffold is a probabilistic matrix rather than a one-hot index matrix, and the argmax operation is non-differentiable. Thus, for training, we use ‘teacher forcing’ (<xref rid="btac814-B33" ref-type="bibr">Williams and Zipser, 1989</xref>), i.e. the ground truth scaffold, to avoid the non-differentiable argmax operation, while for inference, we directly use the scaffold generated by the VAE through the argmax and one-hot operation:
<disp-formula id="E6"><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">E</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mtext>where</mml:mtext><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>for training</mml:mtext><mml:mo>;</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>argmax</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>for inference</mml:mtext><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p><inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is the embedding result of the input scaffold; <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">E</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are the token embedding matrix and positional encoding matrix, respectively, of the transformer. We combine multi-head attention with residual connection (<xref rid="btac814-B14" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2016</xref>), layer normalization (<xref rid="btac814-B20" ref-type="bibr">Lei Ba <italic toggle="yes">et al.</italic>, 2016</xref>) and feed-forward networks to assemble the encoder and decoder layers in the transformer. The decorated SMILES string <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> is given by a fully connected layer with the softmax activation.</p>
    </sec>
    <sec>
      <title>2.4 End-to-end style training of the VAE and transformer</title>
      <p>Assuming that prior distribution <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a standard normal distribution, the VAE loss function can be given as follows:
<disp-formula id="E7"><label>(1)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="script" class="calligraphy">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">vae</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>γ</mml:mo><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script" class="calligraphy">L</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script" class="calligraphy">L</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mtext>where</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="script" class="calligraphy">L</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">D</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">σ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>d</mml:mi></mml:munderover><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mo>μ</mml:mo></mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>and</mml:mtext><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script" class="calligraphy">L</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>CrossEntropy</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>l</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>l</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>v</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p>The VAE loss function (1) balances between the KL-divergence and the reconstruction error by <italic toggle="yes">γ</italic>, the weight over the KL-divergence:
<disp-formula id="E8"><mml:math id="M8" display="block" overflow="scroll"><mml:mrow><mml:mo>γ</mml:mo><mml:mo>=</mml:mo><mml:mtext>min</mml:mtext><mml:mo stretchy="true">(</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>0.001</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>⌊</mml:mo><mml:mrow><mml:mtext>max</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="italic">step</mml:mi><mml:mo>_</mml:mo><mml:mi mathvariant="italic">num</mml:mi><mml:mo>−</mml:mo><mml:mn>40000</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mn>5000</mml:mn></mml:mrow><mml:mo>⌋</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>10000</mml:mn></mml:mrow></mml:mfrac><mml:mo stretchy="true">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>Note that this manner has been adopted to improve training for sentence generation (<xref rid="btac814-B7" ref-type="bibr">Bowman <italic toggle="yes">et al.</italic>, 2016</xref>).</p>
      <p>For training the transformer, we use the cross entropy loss function:
<disp-formula id="E9"><mml:math id="M9" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script" class="calligraphy">L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>CrossEntropy</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>v</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <bold><italic toggle="yes">Y</italic></bold> is the one-hot matrix of the target molecule string and <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> is the output probabilistic matrix.</p>
      <p>Finally, the total loss function is:
<disp-formula id="E10"><mml:math id="M10" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="script" class="calligraphy">L</mml:mi><mml:mo>=</mml:mo><mml:mo>γ</mml:mo><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script" class="calligraphy">L</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script" class="calligraphy">L</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script" class="calligraphy">L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>For optimization, we use the Adam optimizer (<xref rid="btac814-B17" ref-type="bibr">Kingma and Ba, 2015</xref>) with the learning rate of the following warm-up schedule (<xref rid="btac814-B30" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic>, 2017</xref>):
<disp-formula id="E11"><mml:math id="M11" display="block" overflow="scroll"><mml:mrow><mml:mi>l</mml:mi><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>·</mml:mo><mml:mtext>min</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">step</mml:mi><mml:mo>_</mml:mo><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:msup><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="italic">step</mml:mi><mml:mo>_</mml:mo><mml:mi mathvariant="italic">num</mml:mi><mml:mo>·</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>10000</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
    </sec>
    <sec>
      <title>2.5 Two types of molecule generation</title>
      <p>Our model allows two types of molecule generation (i) from a random latent variable and (ii) from a given scaffold, which are <italic toggle="yes">de novo</italic> molecule generation and molecule optimization, respectively. The first type randomly samples a variable from the standard normal distribution and uses the decoder of the VAE and transformer to obtain a molecule without any expert knowledge. The second type starts with an input carbon scaffold and obtains a molecule with proper atoms and bonds based on this scaffold.</p>
      <p>To improve the validity of generated molecules, we added a validity-check component to our model for inference. This component will check the validity of output strings. If the output string is invalid according to the SMILES syntax, the model will discard the string and attempt to make a new generation.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Experiments</title>
    <sec>
      <title>3.1 Dataset</title>
      <p>We used two datasets to evaluate model performance. The first one is the MOSES dataset (<xref rid="btac814-B25" ref-type="bibr">Polykovskiy <italic toggle="yes">et al.</italic>, 2020</xref>), derived by filtering from ZINC (<xref rid="btac814-B29" ref-type="bibr">Sterling and Irwin, 2015</xref>). In MOSES, one molecule has a molecular weight ranging from 250 to 350 Da, no charged atoms, and no rings larger than eight atoms, and atom types are limited to H, C, N, O, F, S, Cl and Br only. Also, all molecules are drug-like, since they pass the medicinal chemistry filters and PAINS filters (<xref rid="btac814-B3" ref-type="bibr">Baell and Holloway, 2010</xref>). MOSES consists of three subsets: training set, test set and novel scaffold set, with around 1.6 million, 176 000 and 176 000 molecules, respectively. All scaffolds in the novel scaffold set differ from those in both the train and test sets.</p>
      <p>The second one is the ZINC-250k dataset (<xref rid="btac814-B13" ref-type="bibr">Gómez-Bombarelli <italic toggle="yes">et al.</italic>, 2018</xref>), which was built by randomly extracting about 250 000 drug-like molecules from ZINC (<xref rid="btac814-B29" ref-type="bibr">Sterling and Irwin, 2015</xref>). A molecule in this dataset is commercially available and has no rings larger than eight atoms, and atom types are limited to H, C, N, O, F, P, S, Cl, Br and I only. We randomly split the ZINC-250k into train (80%) and test (20%) sets.</p>
      <p>We trained our model by the training set, and the trained model was evaluated by the following three tasks: Task (1) random generation from latent variables; Task (2) scaffold decoration for the test set molecules, keeping input as generic scaffold molecules; Task (3) scaffold decoration for the novel scaffold set, keeping the same as the above (2).</p>
    </sec>
    <sec>
      <title>3.2 Experiment setting</title>
      <p>We set model dimension <italic toggle="yes">d</italic> as 256 and latent dimension <italic toggle="yes">d<sub>z</sub></italic> as 64; both the VAE and transformer had a three-layer encoder and a three-layer decoder. All gated convolution layers in the VAE had a kernel size of 3 with a stride length of 1. The transformer used four-head multi-head attention and feed-forward dimension <italic toggle="yes">d<sub>ff</sub></italic> was set at 1024. We set the batch size to 64, and adopted the Adam optimizer (<xref rid="btac814-B17" ref-type="bibr">Kingma and Ba, 2015</xref>) with the learning rate schedule shown in Equation (2). To reduce over-fitting, a drop-out rate (<xref rid="btac814-B28" ref-type="bibr">Srivastava <italic toggle="yes">et al.</italic>, 2014</xref>) of 0.1 was applied. Hyperparameter settings and selection can be found in <xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S1–S3</xref>.</p>
      <p>We used RDKit (<ext-link xlink:href="https://www.rdkit.org/" ext-link-type="uri">https://www.rdkit.org/</ext-link>) for data preprocessing and implemented our model by Tensorflow (<ext-link xlink:href="https://www.tensorflow.org/" ext-link-type="uri">https://www.tensorflow.org/</ext-link>) on a machine with NVIDIA GeForce GTX 1080 Ti GPU.</p>
    </sec>
    <sec>
      <title>3.3 Baselines</title>
      <p><xref rid="btac814-T1" ref-type="table">Table 1</xref> is a comparison of baseline models (and our model) shown below:</p>
      <table-wrap position="float" id="btac814-T1">
        <label>Table 1.</label>
        <caption>
          <p>Comparison of models</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Model</th>
              <th align="center" rowspan="1" colspan="1">Molecular representation</th>
              <th align="center" rowspan="1" colspan="1">Random generation</th>
              <th align="center" rowspan="1" colspan="1">Generation from scaffold</th>
              <th align="center" rowspan="1" colspan="1">Need pre-defined objects</th>
              <th align="center" rowspan="1" colspan="1">Model architecture</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">AddCarbon</td>
              <td rowspan="1" colspan="1">SMILES</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">—</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CharVAE</td>
              <td rowspan="1" colspan="1">SMILES</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">VAE with RNN</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">FragLinker</td>
              <td rowspan="1" colspan="1">SMILES</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">Transformer</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">JTVAE</td>
              <td rowspan="1" colspan="1">Graph</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">VAE with RNN</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">MoFlow</td>
              <td rowspan="1" colspan="1">Graph</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">GCN + CNN</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Sc2Mol(Ours)</td>
              <td rowspan="1" colspan="1">SMILES</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">Yes</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">VAE with CNN + Transformer</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <list list-type="bullet">
        <list-item>
          <p>AddCarbon (<xref rid="btac814-B26" ref-type="bibr">Renz <italic toggle="yes">et al.</italic>, 2019</xref>): a simple model that adds a carbon token ‘C’ to the source SMILES string at a random position.</p>
        </list-item>
        <list-item>
          <p>CharVAE (<xref rid="btac814-B13" ref-type="bibr">Gómez-Bombarelli <italic toggle="yes">et al.</italic>, 2018</xref>): has a VAE for SMILES strings, with convolution layers, followed by a fully connected layer, and a decoder with gated recurrent unit networks (<xref rid="btac814-B9" ref-type="bibr">Chung <italic toggle="yes">et al.</italic>, 2014</xref>).</p>
        </list-item>
        <list-item>
          <p>FragLinker: a SMILES-based model, an extended variant of SyntaLinker (<xref rid="btac814-B34" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2020</xref>). The original SyntaLinker receives only two fragment strings as input and uses a transformer to link the input into a completed molecule. This input is extended into any fragment strings.</p>
        </list-item>
        <list-item>
          <p>JTVAE (<xref rid="btac814-B15" ref-type="bibr">Jin <italic toggle="yes">et al.</italic>, 2018</xref>): first decomposes a molecule into a junction tree, where each node refers to a pre-defined subgraph, and then uses a VAE, to encode both the junction tree and subgraphs into two latent variables, which are decoded to reconstruct the junction tree and assemble subgraphs according to the tree.</p>
        </list-item>
        <list-item>
          <p>MoFlow (<xref rid="btac814-B36" ref-type="bibr">Zang and Wang, 2020</xref>): a graph-based flow model that uses two invertible neural networks to encode atoms and bonds into two Gaussian latent variables and then uses the reverse neural networks to transform Gaussian noise variables into atoms and bonds. This model adopts a validity correction module to ensure chemical validity.</p>
        </list-item>
      </list>
    </sec>
    <sec>
      <title>3.4 Evaluation measures</title>
      <p>All models were trained with the training sets and tested with the test or novel scaffold sets for evaluation. Baseline models were trained in their originally designed ways, in which inputs and expected outputs were molecules.</p>
      <p>For Task 1, we randomly drew 30 000 samples from the standard normal distribution which are the input of the decoder of the variational autoencoder and the rest of the model. For Tasks 2 and 3, we randomly selected 30 000 molecules from the test/novel scaffold set and extracted the carbon scaffolds, which are then the input of the whole model. We first adopted the three common metrics of molecule generation:
</p>
      <list list-type="bullet">
        <list-item>
          <p><bold>Validity</bold>: The ratio of the chemically valid molecules to the totally generated molecules. Higher validity means that the model learns more correctly proper chemical rules, such as valence and aromaticity.</p>
        </list-item>
        <list-item>
          <p><bold>Uniqueness</bold>: The ratio of the uniquely generated valid molecules to the totally generated valid molecules. Higher uniqueness indicates that the model can generate more diverse molecules.</p>
        </list-item>
        <list-item>
          <p><bold>Novelty</bold>: The ratio of the novel valid generated molecules (not in the training set) to the totally valid generated molecules. High novelty means that the model generates molecules not in the training set more.</p>
        </list-item>
      </list>
      <p>Also, we checked the distribution of molecular weights, calculated octanol-water partition coefficients (logP) (<xref rid="btac814-B32" ref-type="bibr">Wildman and Crippen, 1999</xref>) and quantitative estimates of drug-likeness (QED) (<xref rid="btac814-B5" ref-type="bibr">Bickerton <italic toggle="yes">et al.</italic>, 2012</xref>) to illustrate the similarity of the generated molecules to the training set (also the test set for Task 2 and the novel scaffold set for Task 3).</p>
      <p>Additionally, for Tasks 2 and 3, we introduced the following metrics:
</p>
      <list list-type="bullet">
        <list-item>
          <p><bold>Recovery</bold>: The ratio of the desired valid generated molecules (identical to the corresponding reference molecules in the test set) to the totally valid generated molecules. Recovery is proportional to how well the model learned the optimization rules from a scaffold to the desired molecule.</p>
        </list-item>
        <list-item>
          <p><bold>Similarity</bold>: The average Tanimoto similarity between fingerprints [1024-bit extended-connectivity fingerprints with radius 2 (ECFP4) (<xref rid="btac814-B27" ref-type="bibr">Rogers and Hahn, 2010</xref>)] of generated molecules and the corresponding reference molecules in the test set. Similarity is proportional to how well the model captures the optimization rules.</p>
        </list-item>
        <list-item>
          <p><bold>Scaffold similarity (SS)</bold>: The average Tanimoto similarity between fingerprints of the scaffold of generated molecules and the scaffold of the corresponding reference molecules in the test set. Moderate SS is favorable since high SS implies no novel scaffolds, and low SS implies arbitrary generation without considering input scaffolds.</p>
        </list-item>
      </list>
    </sec>
    <sec>
      <title>3.5 Results</title>
      <sec>
        <title>3.5.1 Task 1: Random generation</title>
        <p><xref rid="btac814-T2" ref-type="table">Table 2</xref> shows the performance on the MOSES dataset (three common metrics) of baselines and our model (note that AddCarbon and FragLinker cannot be applied to Task 1), indicating that our model achieved the best in Uniqueness and Novelty. JTVAE achieved the Validity of 100% because of tree decomposition and pre-defined subgraphs, avoiding learning SMILES syntax. MoFlow and our model also achieved the Validity of 100% as well because of benefiting from the validity-check component. <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S4</xref> shows the performance on the ZINC-250k dataset. Similar to the case on the MOSES dataset, our model still achieved the best in three metrics.</p>
        <table-wrap position="float" id="btac814-T2">
          <label>Table 2.</label>
          <caption>
            <p>Performances of models for Task 1 on the MOSES dataset</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Model</th>
                <th rowspan="1" colspan="1">Validity<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Uniqueness<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Novelty<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">AddCarbon</td>
                <td rowspan="1" colspan="1">—</td>
                <td rowspan="1" colspan="1">—</td>
                <td rowspan="1" colspan="1">—</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CharVAE</td>
                <td rowspan="1" colspan="1">3.33</td>
                <td rowspan="1" colspan="1">86.59</td>
                <td rowspan="1" colspan="1">99.50</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">FragLinker</td>
                <td rowspan="1" colspan="1">—</td>
                <td rowspan="1" colspan="1">—</td>
                <td rowspan="1" colspan="1">—</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">JTVAE</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">99.92</td>
                <td rowspan="1" colspan="1">95.98</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">MoFlow</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">99.59</td>
                <td rowspan="1" colspan="1">99.61</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Sc2Mol (Ours)</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>99.99</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>99.72</bold>
                </td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <label>a</label>
              <p>Higher is better.</p>
            </fn>
            <fn id="tblfn2">
              <p><italic toggle="yes">Note</italic>: The best results are highlighted in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p><xref rid="btac814-F3" ref-type="fig">Figure 3a</xref> shows the distributions of molecular weights, logP and QED of the molecules generated in Task 1. Regarding molecular weights and logP, JTVAE and our model showed distributions closer to the training set. Regarding QED (which can be affected by more physical features, such as the molecular polar surface area of molecules), the distribution of JTVAE was the most similar to the training set due to the pre-defined subgraph vocabulary of JTVAE. Without any prior knowledge, our model made the distribution slightly deviate from the training set, and CharVAE made it more away. Most molecules generated by MoFlow had significantly lower QED, whose distribution was far away from the training set.</p>
        <fig position="float" id="btac814-F3">
          <label>Fig. 3.</label>
          <caption>
            <p>Distributions of the properties (molecular weights, logP and QED) of the generated molecules in Tasks (<bold>a</bold>) 1, (<bold>b</bold>) 2 and (<bold>c</bold>) 3</p>
          </caption>
          <graphic xlink:href="btac814f3" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>3.5.2 Task 2: Test scaffold transformation</title>
        <p><xref rid="btac814-T3" ref-type="table">Table 3</xref> shows the performance in six metrics of all models. AddCarbon, FragLinker and MoFlow achieved good scores (&gt;70%) of Validity, Uniqueness and Novelty, but low Recovery (0.00%) and low Similarity (&lt;10%) with high SS (&gt;80%). It means that these models could not modify scaffolds well enough. Particularly, MoFlow showed 100% SS, indicating it was a perfect autoencoder but not a good modifier for scaffold transformation. JTVAE also achieved high scores (&gt;90%) of Validity, Uniqueness and Novelty, while CharVAE performed clearly worse. These two models showed low Recovery (0.00%), Similarity (&lt;10%) and SS (&lt;30%), implying that they could not pay enough attention to the input scaffolds. By contrast, our model achieved the best Validity, Uniqueness and Similarity, and it even recovered some (4.93%) desired reference molecules, although its Novelty decreased. The SS of our model also decreased to a moderate value (72.94%), suggesting that our model performed the best overall.</p>
        <table-wrap position="float" id="btac814-T3">
          <label>Table 3.</label>
          <caption>
            <p>Performance of models on Task 2 (generating molecules from test scaffolds)</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Model</th>
                <th rowspan="1" colspan="1">Validity<xref rid="tblfn3" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Uniqueness<xref rid="tblfn3" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Novelty<xref rid="tblfn3" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Recovery<xref rid="tblfn3" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Similarity<xref rid="tblfn3" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Scaffold similarity (SS)<xref rid="tblfn4" ref-type="table-fn"><sup>b</sup></xref> (%)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">AddCarbon</td>
                <td rowspan="1" colspan="1">99.94</td>
                <td rowspan="1" colspan="1">97.56</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">6.07</td>
                <td rowspan="1" colspan="1">81.04</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CharVAE</td>
                <td rowspan="1" colspan="1">1.88</td>
                <td rowspan="1" colspan="1">78.90</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">11.23</td>
                <td rowspan="1" colspan="1">24.69</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">FragLinker</td>
                <td rowspan="1" colspan="1">95.84</td>
                <td rowspan="1" colspan="1">87.33</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">6.10</td>
                <td rowspan="1" colspan="1">98.79</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">JTVAE</td>
                <td rowspan="1" colspan="1">99.48</td>
                <td rowspan="1" colspan="1">93.77</td>
                <td rowspan="1" colspan="1">99.99</td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">8.69</td>
                <td rowspan="1" colspan="1">24.51</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">MoFlow</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">88.48</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">6.17</td>
                <td rowspan="1" colspan="1">100.00</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Sc2Mol (Ours)</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>97.58</bold>
                </td>
                <td rowspan="1" colspan="1">80.23</td>
                <td rowspan="1" colspan="1">
                  <bold>4.93</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>36.37</bold>
                </td>
                <td rowspan="1" colspan="1">72.94</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn3">
              <label>a</label>
              <p>Higher is better.</p>
            </fn>
            <fn id="tblfn4">
              <label>b</label>
              <p>An appropriate value is good.</p>
            </fn>
            <fn id="tblfn5">
              <p><italic toggle="yes">Note</italic>: The best results are highlighted in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p><xref rid="btac814-F3" ref-type="fig">Figure 3b</xref> shows the distributions of molecular weights, logP and QED of the molecules generated in Task 2. The distributions of molecular weights were all rather similar to each other, except CharVAE. For logP and QED, the distributions of CharVAE and JTVAE had no significant overlaps with other distributions. However, those of AddCarbon, FragLinker and MoFlow were almost identical to that of the scaffolds of the test set. More promisingly, the distributions of our model were extremely similar to those of the training set and the (references of the) test set.</p>
        <p>In summary, (i) CharVAE and JTVAE generated molecules without careful attention to the input scaffolds, resulting in low Similarity, low SS and little overlap with other distributions. (ii) AddCarbon, FragLinker and MoFlow, which modified input scaffolds only slightly, were unable to transform the carbon scaffolds into desired molecules, resulting in only generating molecules very similar to the input scaffolds. (iii) Our model could achieve the highest molecular similarity to the reference molecules and the distribution most highly similar to those molecules. Also, the SS values implied the possibility of generating the most desired scaffolds.</p>
      </sec>
      <sec>
        <title>3.5.3 Task 3: Novel scaffold transformation</title>
        <p><xref rid="btac814-T4" ref-type="table">Table 4</xref> shows the performance of all models under the six metrics, and <xref rid="btac814-F3" ref-type="fig">Figure 3c</xref> shows the distributions of the generated molecules by all models. Entirely the results are consistent with those for Task 2. Note that our model could generate molecules most similar to the reference molecules, regardless that the input scaffolds are not explicitly in the training set. This result confirms that our model can capture, from the given data, rules of transforming scaffolds into desired molecules and apply the rules to even data with unseen scaffolds successfully.</p>
        <table-wrap position="float" id="btac814-T4">
          <label>Table 4.</label>
          <caption>
            <p>Performance of models on Task 3 (generating molecules from novel scaffolds)</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Model</th>
                <th rowspan="1" colspan="1">Validity<xref rid="tblfn6" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Uniqueness<xref rid="tblfn6" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Novelty<xref rid="tblfn6" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Recovery<xref rid="tblfn6" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Similarity<xref rid="tblfn6" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Scaffold similarity (SS) (%)<xref rid="tblfn7" ref-type="table-fn"><sup>b</sup></xref></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">AddCarbon</td>
                <td rowspan="1" colspan="1">
                  <bold>99.96</bold>
                </td>
                <td rowspan="1" colspan="1">94.94</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">5.98</td>
                <td rowspan="1" colspan="1">81.34</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CharVAE</td>
                <td rowspan="1" colspan="1">1.79</td>
                <td rowspan="1" colspan="1">78.21</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">11.05</td>
                <td rowspan="1" colspan="1">24.39</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">FragLinker</td>
                <td rowspan="1" colspan="1">95.74</td>
                <td rowspan="1" colspan="1">74.71</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">6.05</td>
                <td rowspan="1" colspan="1">98.56</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">JTVAE</td>
                <td rowspan="1" colspan="1">99.71</td>
                <td rowspan="1" colspan="1">94.04</td>
                <td rowspan="1" colspan="1">99.99</td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">8.65</td>
                <td rowspan="1" colspan="1">24.59</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">MoFlow</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">76.06</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">6.06</td>
                <td rowspan="1" colspan="1">100.00</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Sc2Mol (Ours)</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>95.19</bold>
                </td>
                <td rowspan="1" colspan="1">81.19</td>
                <td rowspan="1" colspan="1">
                  <bold>4.11</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>34.53</bold>
                </td>
                <td rowspan="1" colspan="1">71.95</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn6">
              <label>a</label>
              <p>Higher is better.</p>
            </fn>
            <fn id="tblfn7">
              <label>b</label>
              <p>An appropriate value is good.</p>
            </fn>
            <fn id="tblfn8">
              <p><italic toggle="yes">Note</italic>: The best results are highlighted in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <title>3.5.4 Ablation study</title>
        <p>We also conducted the ablation study to verify the effectiveness of our model with the following experimental settings: (i) Our proposed model and MoFlow with/without the validity-check component were compared to confirm the effectiveness of this component. (ii) Several baseline models were trained with scaffolds as inputs and molecules as expected outputs, which would be tagged with ‘-s2m’. (iii) Our proposed model was trained with molecules as both source inputs and expected outputs, which would be tagged with ‘-m2m’.Settings 2 and 3 could study how the high-capacity neural networks would affect generation, and whether it would be necessary to decompose the generation process into scaffold and molecule.</p>
        <p><xref rid="btac814-T5" ref-type="table">Table 5</xref> shows the performance of models with/without the validity-check component for Task 1 on MOSES. With validity-check, our model achieved the best Uniqueness and Novelty, and both models reached the Validity of 100%. Without validity-check, the Validity of MoFlow decreased significantly to 33.94%, while our model outperformed MoFlow with a Validity of 63.07%. This result is notable since our model does not have any prior expert knowledge of SMILES syntax. <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S5</xref> shows the experiment results for Task 1 on ZINC, which are consistent with those on MOSES. Without validity-check, the Validity of MoFlow decreased to about 30%, while our model still had a better Validity of more than 50%. Besides, the scores of Uniqueness and Novelty were insensitive to validity-check. Since the cost of SMILES syntax check is low and our model still could achieve an acceptable Validity even without validity-check, introducing validity-check to our model would not increase considerable computation.</p>
        <table-wrap position="float" id="btac814-T5">
          <label>Table 5.</label>
          <caption>
            <p>Ablation study for Task 1 on MOSES</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Model</th>
                <th rowspan="1" colspan="1">Validity<xref rid="tblfn11" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Uniqueness<xref rid="tblfn11" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Novelty<xref rid="tblfn11" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">MoFlow</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">99.59</td>
                <td rowspan="1" colspan="1">99.61</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">MoFlow w.o. VC</td>
                <td rowspan="1" colspan="1">33.94</td>
                <td rowspan="1" colspan="1">99.41</td>
                <td rowspan="1" colspan="1">99.18</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Sc2Mol</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>99.99</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>99.72</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Sc2Mol w.o. VC</td>
                <td rowspan="1" colspan="1">63.07</td>
                <td rowspan="1" colspan="1">99.98</td>
                <td rowspan="1" colspan="1">98.70</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn9">
              <p>w.o. VC, without validity-check component.</p>
            </fn>
            <fn id="tblfn11">
              <label>a</label>
              <p>Higher is better.</p>
            </fn>
            <fn id="tblfn10">
              <p><italic toggle="yes">Note</italic>: The best results are highlighted in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p><xref rid="btac814-T6" ref-type="table">Table 6</xref> shows the performance of models with different input and expected output settings for Task 2 on MOSES. The training data of CharVAE-s2m and FragLinker-s2m were identical to our models, while those of CharVAE, FragLinker and Sc2Mol-m2m were the same. <bold>Validity, Uniqueness</bold>: Our model achieved the best Validity due to the validity-check component, and transformer-based FragLinker also showed good performance on Validity. Transformer-based models reached high scores of Uniqueness (&gt;80%), while CharVAE and CharVAE-s2m failed to generate enough valid and unique molecules (because of low Validity or Uniqueness). These results confirm that high-capacity architectures of neural networks are necessary. <bold>Novelty, Recovery, Similarity and SS:</bold> Transformer-based models trained with ‘s2m’ data showed lower Novelty but higher Recovery and Similarity than their corresponding version of ‘m2m’, respectively. This means that taking scaffolds as input training data could force models to generate expected molecules, although it would decrease some novelty. Note that simply repeating a few unseen molecules would also achieve very high Novelty, but these molecules would not be desired (with low Similarity to the reference). Thus, molecules with acceptable Novelty and enough Similarity would be preferred. In addition, compared with FragLinker-s2m, our model had higher Similarity but lower SS. This result indicates that decomposing generation into two-step and using VAE for scaffold generation could contribute to finding desired molecules with novel scaffolds. <xref rid="btac814-T7" ref-type="table">Table 7</xref> shows the performance of the ablation study for Task 3 on MOSES. These experimental results are similar to those for Task 2, indicating the generalization capabilities of models.</p>
        <table-wrap position="float" id="btac814-T6">
          <label>Table 6.</label>
          <caption>
            <p>Ablation study for Task 2 on MOSES (generating molecules from test scaffolds)</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Model</th>
                <th rowspan="1" colspan="1">Validity<xref rid="tblfn12" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Uniqueness<xref rid="tblfn12" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Novelty<xref rid="tblfn12" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Recovery<xref rid="tblfn12" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Similarity<xref rid="tblfn12" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Scaffold similarity (SS)<xref rid="tblfn13" ref-type="table-fn"><sup>b</sup></xref> (%)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">CharVAE-m2m</td>
                <td rowspan="1" colspan="1">1.88</td>
                <td rowspan="1" colspan="1">78.90</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">11.23</td>
                <td rowspan="1" colspan="1">24.69</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CharVAE-s2m</td>
                <td rowspan="1" colspan="1">12.71</td>
                <td rowspan="1" colspan="1">0.21</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">6.45</td>
                <td rowspan="1" colspan="1">25.87</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">FragLinker-m2m</td>
                <td rowspan="1" colspan="1">95.84</td>
                <td rowspan="1" colspan="1">87.33</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">6.10</td>
                <td rowspan="1" colspan="1">98.79</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">FragLinker-s2m</td>
                <td rowspan="1" colspan="1">95.87</td>
                <td rowspan="1" colspan="1">96.27</td>
                <td rowspan="1" colspan="1">70.30</td>
                <td rowspan="1" colspan="1">1.75</td>
                <td rowspan="1" colspan="1">26.87</td>
                <td rowspan="1" colspan="1">90.81</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Sc2Mol-m2m</td>
                <td rowspan="1" colspan="1">
                  <bold>100</bold>
                </td>
                <td rowspan="1" colspan="1">96.89</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">6.98</td>
                <td rowspan="1" colspan="1">26.53</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Sc2Mol-s2m</td>
                <td rowspan="1" colspan="1">
                  <bold>100</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>97.58</bold>
                </td>
                <td rowspan="1" colspan="1">80.23</td>
                <td rowspan="1" colspan="1">
                  <bold>4.93</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>36.37</bold>
                </td>
                <td rowspan="1" colspan="1">72.94</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn12">
              <label>a</label>
              <p>Higher is better.</p>
            </fn>
            <fn id="tblfn13">
              <label>b</label>
              <p>An appropriate value is good.</p>
            </fn>
            <fn id="tblfn14">
              <p><italic toggle="yes">Note</italic>: The best results are highlighted in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <table-wrap position="float" id="btac814-T7">
          <label>Table 7.</label>
          <caption>
            <p>Ablation study for Task 3 on MOSES (generating molecules from novel scaffolds)</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Model</th>
                <th rowspan="1" colspan="1">Validity<xref rid="tblfn15" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Uniqueness<xref rid="tblfn15" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Novelty<xref rid="tblfn15" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Recovery<xref rid="tblfn15" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Similarity<xref rid="tblfn15" ref-type="table-fn"><sup>a</sup></xref> (%)</th>
                <th rowspan="1" colspan="1">Scaffold similarity (SS)<xref rid="tblfn16" ref-type="table-fn"><sup>b</sup></xref> (%)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">CharVAE-m2m</td>
                <td rowspan="1" colspan="1">1.79</td>
                <td rowspan="1" colspan="1">78.21</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">11.05</td>
                <td rowspan="1" colspan="1">24.39</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CharVAE-s2m</td>
                <td rowspan="1" colspan="1">12.65</td>
                <td rowspan="1" colspan="1">0.20</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">6.52</td>
                <td rowspan="1" colspan="1">26.89</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">FragLinker-m2m</td>
                <td rowspan="1" colspan="1">95.74</td>
                <td rowspan="1" colspan="1">74.71</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">6.05</td>
                <td rowspan="1" colspan="1">98.56</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">FragLinker-s2m</td>
                <td rowspan="1" colspan="1">95.84</td>
                <td rowspan="1" colspan="1">95.93</td>
                <td rowspan="1" colspan="1">68.98</td>
                <td rowspan="1" colspan="1">1.67</td>
                <td rowspan="1" colspan="1">27.43</td>
                <td rowspan="1" colspan="1">90.01</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Sc2Mol-m2m</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">94.78</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">0.00</td>
                <td rowspan="1" colspan="1">7.10</td>
                <td rowspan="1" colspan="1">27.35</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Sc2Mol-s2m</td>
                <td rowspan="1" colspan="1">
                  <bold>100.00</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>95.19</bold>
                </td>
                <td rowspan="1" colspan="1">81.19</td>
                <td rowspan="1" colspan="1">
                  <bold>4.11</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>34.53</bold>
                </td>
                <td rowspan="1" colspan="1">71.95</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn15">
              <label>a</label>
              <p>Higher is better.</p>
            </fn>
            <fn id="tblfn16">
              <label>b</label>
              <p>An appropriate value is good.</p>
            </fn>
            <fn id="tblfn17">
              <p><italic toggle="yes">Note</italic>: The best results are highlighted in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <title>3.5.5 Examples of the generated molecules</title>
        <p><xref rid="btac814-F4" ref-type="fig">Figure 4</xref> shows examples of the generated molecules: <xref rid="btac814-F4" ref-type="fig">Figure 4a</xref> shows three molecules generated from different latent variables from Task 1. In terms of scaffolds, 1 and 2 were similar while 3 was different, since the corresponding latent variables of 1 and 2 were closer to each other, and far away from that of 3; <xref rid="btac814-F4" ref-type="fig">Figure 4b</xref> shows, from Task 2, an input scaffold (4), the reference molecule (5) and the corresponding generated molecule (6) from 4, showing the similarity between 5 and 6, such as the benzene ring and carboxamide. The fluorine at the benzene ring in 5 is replaced by the chlorine in 6. Fluorine and chlorine are in the same group called ‘halogen’, implying that our model was able to discover novel scaffold and learn chemical rules such as halogen similarity and aromatic ring. <xref rid="btac814-F4" ref-type="fig">Figure 4c</xref> shows, from Task 3, an input scaffold (7), the reference molecule (8) and the corresponding generated molecule (9). Two molecules, 8 and 9, share the same scaffolds and moieties. The hydroxy group at the benzene ring in 8 is replaced by the fluorine in 9, where fluorinating is a major strategy of lead compound optimization (<xref rid="btac814-B8" ref-type="bibr">Brown and Boström, 2018</xref>; <xref rid="btac814-B35" ref-type="bibr">Young and Leeson, 2018</xref>). Also, 8 and 9 have aromatic rings, especially not only benzene but also thiazole. The aromatic rings are special in SMILES, such as lowercase letters for aromatic atoms and a pair of numbers for the starting and end of the ring, implying that our transformer architecture is powerful enough to learn the complex SMILES syntax of aromatic systems.</p>
        <fig position="float" id="btac814-F4">
          <label>Fig. 4.</label>
          <caption>
            <p>Examples of the generated molecules: (<bold>a</bold>) Task 1: 1–3 from different latent variables, (<bold>b</bold>) Task 2: input scaffold (4), reference (5) and corresponding generated molecule (6), (<bold>c</bold>) Task 3: input scaffold (7), reference (8) and corresponding generated molecule (9)</p>
          </caption>
          <graphic xlink:href="btac814f4" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>3.5.6 Case study 1: Auglurant</title>
        <p><xref rid="btac814-F5" ref-type="fig">Figure 5</xref> shows an example prediction by our model, starting with a random screened initial compound (10) [which is, in reality, optimized as Auglurant (11), a clinical candidate for mood disorders whose target is mGluR5 (<xref rid="btac814-B4" ref-type="bibr">Bates <italic toggle="yes">et al.</italic>, 2014</xref>; <xref rid="btac814-B12" ref-type="bibr">Felts <italic toggle="yes">et al.</italic>, 2017</xref>)]. The scaffold (12) of 11 was an input of our model, which generated a molecule (13). Note that 11 (ground truth) and 13 (prediction) share the (i) fluorinated benzene, (ii) nitrogen heterocycles and (iii) replacement of the amino group with the methyl group. Importantly, these three points are favorable strategies in lead compound optimization (<xref rid="btac814-B8" ref-type="bibr">Brown and Boström, 2018</xref>; <xref rid="btac814-B23" ref-type="bibr">Pennington and Moustakas, 2017</xref>; <xref rid="btac814-B35" ref-type="bibr">Young and Leeson, 2018</xref>).</p>
        <fig position="float" id="btac814-F5">
          <label>Fig. 5.</label>
          <caption>
            <p>Case study 1, 10: random initial compound for mood disorder target mGluR5, 11: optimized clinical candidate, Auglurant, 12: scaffold from 10 and 13: generated molecule</p>
          </caption>
          <graphic xlink:href="btac814f5" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>3.5.7 Case study 2: Benzodiazepines</title>
        <p>Benzodiazepines (BZD) are a category of psychoactive drugs which has a benzene with a diazepine as the core chemical structure. Many compounds in this category reduce brain activity and thus are used to ease mental problems, such as anxiety, insomnia and seizures. Using a training set and additional 46 commercial BZD drugs (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S6</xref>), we generated scaffolds first and then molecules. <xref rid="btac814-F6" ref-type="fig">Figure 6</xref> shows our process, starting with bromasepam, an anti-anxiety agent and ending with the generated molecules not being in the input set. The bromine in bromazepam was replaced with chlorine in 16. This chlorination appears in other psychoactive drugs, lorazepam (17) and nordazepam (18). Also, the pyridine was replaced with chlorobenzene in 16. Both pyridine and chlorobenzene are aromatic, and chlorobenzene appears in clonazepam, another anti-anxiety drug.</p>
        <fig position="float" id="btac814-F6">
          <label>Fig. 6.</label>
          <caption>
            <p>Case study 2 (benzodiazepine), 14: bromazepam, 15: scaffold from 14, 16: generated molecule, 17: lorazepam, 18: nordazepam and 19: clonazepam</p>
          </caption>
          <graphic xlink:href="btac814f6" position="float"/>
        </fig>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>We presented a molecule generator with two steps, which (i) generates scaffolds with a VAE and (ii) decorates the scaffolds with our transformer. Our extensive empirical results demonstrated the competitive performances of our model against baselines. In particular, our transformer architecture allowed us to learn complex SMILES syntax without any expert knowledge like pre-defined rules (say, substrings and parse trees). Also, our two-step model could capture the chemical rules of transforming an initial carbon scaffold into meaningful molecules. Interesting future work would be to develop a method for a seamless combination of our two steps.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btac814_Supplementary_Data</label>
      <media xlink:href="btac814_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Funding</title>
    <p>This work was supported by National Natural Science Foundation of China [62272105]; Shanghai Municipal Science and Technology Major Project [2018SHZDZX01], ZJ Lab and Shanghai Center for Brain Science and Brain-Inspired Technology to S.Z.; the 111 Project [B18015 to Z.L.]; in part by MEXT KAKENHI [19H04169, 20F20809, 21H05027 and 22H03645] and the AIPSE program of the Academy of Finland to H.M. This work has been partially supported by the National Institute of General Medical Sciences of the National Institute of Health (R01GM122845) to LX and the National Institute on Aging of the National Institute of Health (R01AD057555) to LX.</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The MOSES dataset used in this work is available at <ext-link xlink:href="https://github.com/molecularsets/moses" ext-link-type="uri">https://github.com/molecularsets/moses</ext-link>. The ZINC-250K dataset is available at <ext-link xlink:href="https://github.com/aspuru-guzik-group/chemical_vae" ext-link-type="uri">https://github.com/aspuru-guzik-group/chemical_vae</ext-link>.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac814-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Arjovsky</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) Wasserstein Generative Adversarial Networks. In: <italic toggle="yes">Proceedings of the 34th International Conference on Machine Learning</italic>, <italic toggle="yes">Sydney, Australia</italic>, pp. <fpage>214</fpage>–<lpage>223</lpage>.</mixed-citation>
    </ref>
    <ref id="btac814-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Arús-Pous</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Smiles-based deep generative scaffold decorator for de-novo drug design</article-title>. <source>J. Cheminform</source>., <volume>12</volume>, <fpage>38</fpage>.<pub-id pub-id-type="pmid">33431013</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baell</surname><given-names>J.B.</given-names></string-name>, <string-name><surname>Holloway</surname><given-names>G.A.</given-names></string-name></person-group> (<year>2010</year>) <article-title>New substructure filters for removal of pan assay interference compounds (PAINS) from screening libraries and for their exclusion in bioassays</article-title>. <source>J. Med. Chem</source>., <volume>53</volume>, <fpage>2719</fpage>–<lpage>2740</lpage>.<pub-id pub-id-type="pmid">20131845</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bates</surname><given-names>B.S.</given-names></string-name></person-group><etal>et al</etal> (<year>2014</year>) <article-title>Discovery of vu0431316: a negative allosteric modulator of mglu5 with activity in a mouse model of anxiety</article-title>. <source>Bioorg. Med. Chem. Lett</source>., <volume>24</volume>, <fpage>3307</fpage>–<lpage>3314</lpage>.<pub-id pub-id-type="pmid">24969015</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bickerton</surname><given-names>G.R.</given-names></string-name></person-group><etal>et al</etal> (<year>2012</year>) <article-title>Quantifying the chemical beauty of drugs</article-title>. <source>Nat. Chem</source>., <volume>4</volume>, <fpage>90</fpage>–<lpage>98</lpage>.<pub-id pub-id-type="pmid">22270643</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Blaschke</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Reinvent 2.0: an AI tool for de novo drug design</article-title>. <source>J. Chem. Inf. Model</source>., <volume>60</volume>, <fpage>5918</fpage>–<lpage>5922</lpage>.<pub-id pub-id-type="pmid">33118816</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B7">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Bowman</surname><given-names>S.R.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) Generating sentences from a continuous space. In: <italic toggle="yes">Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning</italic>, pp. <fpage>10</fpage>–<lpage>21</lpage>. Association for Computational Linguistics, Berlin, Germany.</mixed-citation>
    </ref>
    <ref id="btac814-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brown</surname><given-names>D.G.</given-names></string-name>, <string-name><surname>Boström</surname><given-names>J.</given-names></string-name></person-group> (<year>2018</year>) <article-title>Where do recent small molecule clinical development candidates come from?</article-title><source>J. Med. Chem</source>., <volume>61</volume>, <fpage>9442</fpage>–<lpage>9468</lpage>.<pub-id pub-id-type="pmid">29920198</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Chung</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2014</year>) <source>Empirical evaluation of gated recurrent neural networks on sequence modeling</source>. arXiv preprint arXiv:1412.3555.</mixed-citation>
    </ref>
    <ref id="btac814-B10">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Dauphin</surname><given-names>Y.N.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) Language modeling with gated convolutional networks. In: <italic toggle="yes">Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia</italic>, pp. <fpage>933</fpage>–<lpage>941</lpage>.</mixed-citation>
    </ref>
    <ref id="btac814-B11">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Dong</surname><given-names>H.-W.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) MuseGAN: multi-track sequential generative adversarial networks for symbolic music generation and accompaniment. In: <italic toggle="yes">Proceedings of the AAAI Conference on Artificial Intelligence, New Orleans, Louisiana, USA</italic>, Vol. <bold>32</bold>.</mixed-citation>
    </ref>
    <ref id="btac814-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Felts</surname><given-names>A.S.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Discovery of n-(5-fluoropyridin-2-yl)-6-methyl-4-(pyrimidin-5-yloxy)picolinamide (vu0424238): a novel negative allosteric modulator of metabotropic glutamate receptor subtype 5 selected for clinical evaluation</article-title>. <source>J. Med. Chem</source>., <volume>60</volume>, <fpage>5072</fpage>–<lpage>5085</lpage>.<pub-id pub-id-type="pmid">28530802</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gómez-Bombarelli</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>Automatic chemical design using a data-driven continuous representation of molecules</article-title>. <source>ACS Cent. Sci</source>., <volume>4</volume>, <fpage>268</fpage>–<lpage>276</lpage>.<pub-id pub-id-type="pmid">29532027</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) Deep residual learning for image recognition. In: <italic toggle="yes">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</italic>, pp. <fpage>770</fpage>–<lpage>778</lpage>. IEEE Computer Society, Los Alamitos, CA, USA.</mixed-citation>
    </ref>
    <ref id="btac814-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Jin</surname><given-names>W.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) Junction tree variational autoencoder for molecular graph generation. In: <person-group person-group-type="editor"><string-name><surname>Dy</surname><given-names>J.</given-names></string-name> and <string-name><surname>Krause</surname><given-names>A.</given-names></string-name></person-group>, editors, <italic toggle="yes">Proceedings of the 35th International Conference on Machine Learning</italic>, Volume 80 of <italic toggle="yes">Proceedings of Machine Learning Research.</italic> PMLR, pp. <fpage>2323</fpage>–<lpage>2332</lpage>.</mixed-citation>
    </ref>
    <ref id="btac814-B16">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Karras</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) Analyzing and improving the image quality of StyleGAN. In: <italic toggle="yes">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Seattle, WA, USA, pp. 8110-8119.</italic></mixed-citation>
    </ref>
    <ref id="btac814-B17">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>D.P.</given-names></string-name>, <string-name><surname>Ba</surname><given-names>J.</given-names></string-name></person-group> (<year>2015</year>) Adam: a method for stochastic optimization. In:  <italic toggle="yes">Proceedings of</italic><italic toggle="yes">3rd International Conference on Learning Representations, San Diego</italic>, <italic toggle="yes">CA</italic>, <italic toggle="yes">USA.</italic></mixed-citation>
    </ref>
    <ref id="btac814-B18">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>D.P.</given-names></string-name>, <string-name><surname>Welling</surname><given-names>M.</given-names></string-name></person-group> (<year>2014</year>) Auto-encoding variational Bayes. In: <italic toggle="yes">Proceedings of</italic><italic toggle="yes">2nd International Conference on Learning Representations, Banff, AB, Canada</italic>.</mixed-citation>
    </ref>
    <ref id="btac814-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Langevin</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Scaffold-constrained molecular generation</article-title>. <source>J. Chem. Inf. Model</source>., <volume>60</volume>, <fpage>5637</fpage>–<lpage>5646</lpage>.<pub-id pub-id-type="pmid">33301333</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B20">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lei Ba</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <source>Layer normalization</source>. arXiv preprint arXiv:1607.06450.</mixed-citation>
    </ref>
    <ref id="btac814-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Deepscaffold: a comprehensive tool for scaffold-based de novo drug discovery using deep learning</article-title>. <source>J. Chem. Inf. Model</source>., <volume>60</volume>, <fpage>77</fpage>–<lpage>91</lpage>.<pub-id pub-id-type="pmid">31809029</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lim</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Scaffold-based molecular design with a graph generative model</article-title>. <source>Chem. Sci</source>., <volume>11</volume>, <fpage>1153</fpage>–<lpage>1164</lpage>.</mixed-citation>
    </ref>
    <ref id="btac814-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pennington</surname><given-names>L.D.</given-names></string-name>, <string-name><surname>Moustakas</surname><given-names>D.T.</given-names></string-name></person-group> (<year>2017</year>) <article-title>The necessary nitrogen atom: a versatile high-impact design element for multiparameter optimization</article-title>. <source>J. Med. Chem</source>., <volume>60</volume>, <fpage>3552</fpage>–<lpage>3579</lpage>.<pub-id pub-id-type="pmid">28177632</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Polishchuk</surname><given-names>P.G.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <article-title>Estimation of the size of drug-like chemical space based on GDB-17 data</article-title>. <source>J. Comput. Aided Mol. Des</source>., <volume>27</volume>, <fpage>675</fpage>–<lpage>679</lpage>.<pub-id pub-id-type="pmid">23963658</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Polykovskiy</surname><given-names>D.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Molecular sets (MOSES): a benchmarking platform for molecular generation models</article-title>. <source>Front. Pharmacol</source>., <volume>11</volume>, 565644.</mixed-citation>
    </ref>
    <ref id="btac814-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Renz</surname><given-names>P.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>On failure modes in molecule generation and optimization</article-title>. <source>Drug Discov. Today. Technol</source>., <volume>32-33</volume>, <fpage>55</fpage>–<lpage>63</lpage>.<pub-id pub-id-type="pmid">33386095</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rogers</surname><given-names>D.</given-names></string-name>, <string-name><surname>Hahn</surname><given-names>M.</given-names></string-name></person-group> (<year>2010</year>) <article-title>Extended-connectivity fingerprints</article-title>. <source>J. Chem. Inf. Model</source>., <volume>50</volume>, <fpage>742</fpage>–<lpage>754</lpage>.<pub-id pub-id-type="pmid">20426451</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Srivastava</surname><given-names>N.</given-names></string-name></person-group><etal>et al</etal> (<year>2014</year>) <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>. <source>J. Mach. Learn. Res</source>., <volume>15</volume>, <fpage>1929</fpage>–<lpage>1958</lpage>.</mixed-citation>
    </ref>
    <ref id="btac814-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sterling</surname><given-names>T.</given-names></string-name>, <string-name><surname>Irwin</surname><given-names>J.J.</given-names></string-name></person-group> (<year>2015</year>) <article-title>Zinc 15 – ligand discovery for everyone</article-title>. <source>J. Chem. Inf. Model</source>., <volume>55</volume>, <fpage>2324</fpage>–<lpage>2337</lpage>.<pub-id pub-id-type="pmid">26479676</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B30">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Vaswani</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <part-title>Attention is all you need</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Guyon</surname><given-names>I.</given-names></string-name></person-group><etal>et al</etal> (eds) <source>Advances in Neural Information Processing Systems</source>, Vol. <volume>30,</volume> pp. 6000–6010. <publisher-name>Curran Associates, Inc</publisher-name>., Long Beach, CA, USA.</mixed-citation>
    </ref>
    <ref id="btac814-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weininger</surname><given-names>D.</given-names></string-name></person-group> (<year>1988</year>) <article-title>Smiles, a chemical language and information system. 1. Introduction to methodology and encoding rules</article-title>. <source>J. Chem. Inf. Model</source>., <volume>28</volume>, <fpage>31</fpage>–<lpage>36</lpage>.</mixed-citation>
    </ref>
    <ref id="btac814-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wildman</surname><given-names>S.A.</given-names></string-name>, <string-name><surname>Crippen</surname><given-names>G.M.</given-names></string-name></person-group> (<year>1999</year>) <article-title>Prediction of physicochemical parameters by atomic contributions</article-title>. <source>J. Chem. Inf. Comput. Sci</source>., <volume>39</volume>, <fpage>868</fpage>–<lpage>873</lpage>.</mixed-citation>
    </ref>
    <ref id="btac814-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Williams</surname><given-names>R.J.</given-names></string-name>, <string-name><surname>Zipser</surname><given-names>D.</given-names></string-name></person-group> (<year>1989</year>) <article-title>A learning algorithm for continually running fully recurrent neural networks</article-title>. <source>Neural Comput</source>., <volume>1</volume>, <fpage>270</fpage>–<lpage>280</lpage>.</mixed-citation>
    </ref>
    <ref id="btac814-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Syntalinker: automatic fragment linking with deep conditional transformer neural networks</article-title>. <source>Chem. Sci</source>., <volume>11</volume>, <fpage>8312</fpage>–<lpage>8322</lpage>.<pub-id pub-id-type="pmid">34123096</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Young</surname><given-names>R.J.</given-names></string-name>, <string-name><surname>Leeson</surname><given-names>P.D.</given-names></string-name></person-group> (<year>2018</year>) <article-title>Mapping the efficiency and physicochemical trajectories of successful optimizations</article-title>. <source>J. Med. Chem</source>., <volume>61</volume>, <fpage>6421</fpage>–<lpage>6467</lpage>.<pub-id pub-id-type="pmid">29620890</pub-id></mixed-citation>
    </ref>
    <ref id="btac814-B36">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Zang</surname><given-names>C.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>F.</given-names></string-name></person-group> (<year>2020</year>) Moflow: an invertible flow model for generating molecular graphs. In: <italic toggle="yes">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</italic>, New York, NY, USA, pp. <fpage>617</fpage>–<lpage>626</lpage>.</mixed-citation>
    </ref>
    <ref id="btac814-B37">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>H.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) ReCoSa: detecting the relevant contexts with self-attention for multi-turn dialogue generation. In: <italic toggle="yes">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</italic>, pp. <fpage>3721</fpage>–<lpage>3730</lpage>. Association for Computational Linguistics, Florence, Italy</mixed-citation>
    </ref>
    <ref id="btac814-B38">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) Flexible and creative Chinese poetry generation using neural memory. In: <italic toggle="yes">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Volume 1: Long Papers)</italic>, pp. <fpage>1364</fpage>–<lpage>1373</lpage>. Association for Computational Linguistics, Vancouver, Canada.</mixed-citation>
    </ref>
    <ref id="btac814-B39">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>K.Y.J.</given-names></string-name></person-group><etal>et al</etal> (<year>2007</year>) <source>Scaffold-Based Drug Discovery</source>. <publisher-name>Springer Netherlands</publisher-name>, <publisher-loc>Dordrecht</publisher-loc>, pp. <fpage>129</fpage>–<lpage>153</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
