<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-title>BMC Bioinformatics</journal-title>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">1810318</article-id>
    <article-id pub-id-type="publisher-id">1471-2105-7-S1-S7</article-id>
    <article-id pub-id-type="pmid">16723010</article-id>
    <article-id pub-id-type="doi">10.1186/1471-2105-7-S1-S7</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Proceedings</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>ARACNE: An Algorithm for the Reconstruction of Gene Regulatory Networks in a Mammalian Cellular Context</article-title>
    </title-group>
    <contrib-group>
      <contrib id="A1" contrib-type="author">
        <name>
          <surname>Margolin</surname>
          <given-names>Adam A</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>adam@dbmi.columbia.edu</email>
      </contrib>
      <contrib id="A2" contrib-type="author">
        <name>
          <surname>Nemenman</surname>
          <given-names>Ilya</given-names>
        </name>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>ilya.nemenman@columbia.edu</email>
      </contrib>
      <contrib id="A3" contrib-type="author">
        <name>
          <surname>Basso</surname>
          <given-names>Katia</given-names>
        </name>
        <xref ref-type="aff" rid="I3">3</xref>
        <email>kb451@columbia.edu</email>
      </contrib>
      <contrib id="A4" contrib-type="author">
        <name>
          <surname>Wiggins</surname>
          <given-names>Chris</given-names>
        </name>
        <xref ref-type="aff" rid="I2">2</xref>
        <xref ref-type="aff" rid="I4">4</xref>
        <email>chw2@columbia.edu</email>
      </contrib>
      <contrib id="A5" contrib-type="author">
        <name>
          <surname>Stolovitzky</surname>
          <given-names>Gustavo</given-names>
        </name>
        <xref ref-type="aff" rid="I5">5</xref>
        <email>gustavo@us.ibm.com</email>
      </contrib>
      <contrib id="A6" contrib-type="author">
        <name>
          <surname>Favera</surname>
          <given-names>Riccardo Dalla</given-names>
        </name>
        <xref ref-type="aff" rid="I3">3</xref>
        <email>rd10@columbia.edu</email>
      </contrib>
      <contrib id="A7" corresp="yes" contrib-type="author">
        <name>
          <surname>Califano</surname>
          <given-names>Andrea</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>califano@c2b2.columbia.edu</email>
      </contrib>
    </contrib-group>
    <aff id="I1"><label>1</label>Department of Biomedical Informatics, Columbia University, New York, NY 10032</aff>
    <aff id="I2"><label>2</label>Joint Centers for Systems Biology, Columbia University, New York, NY 10032</aff>
    <aff id="I3"><label>3</label>Institute for Cancer Genetics, Columbia University, New York, NY 10032</aff>
    <aff id="I4"><label>4</label>Department of Applied Physics and Applied Mathematics, Columbia University, New York, NY 10032</aff>
    <aff id="I5"><label>5</label>IBM T.J. Watson Research Center, Yorktown Heights, NY 10598</aff>
    <pub-date pub-type="collection">
      <year>2006</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>20</day>
      <month>3</month>
      <year>2006</year>
    </pub-date>
    <volume>7</volume>
    <issue>Suppl 1</issue>
    <supplement>
      <named-content content-type="supplement-title">NIPS workshop on New Problems and Methods in Computational Biology</named-content>
      <named-content content-type="supplement-editor">Gal Chechik, Christina Leslie, Gunnar Rätsch, Koji Tsuda</named-content>
      <ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/content/pdf/1471-2105-7-S1-info.pdf">http://www.biomedcentral.com/content/pdf/1471-2105-7-S1-info.pdf</ext-link>
    </supplement>
    <fpage>S7</fpage>
    <lpage>S7</lpage>
    <abstract>
      <sec>
        <title>Background</title>
        <p>Elucidating gene regulatory networks is crucial for understanding normal cell physiology and complex pathologic phenotypes. Existing computational methods for the genome-wide "reverse engineering" of such networks have been successful only for lower eukaryotes with simple genomes. Here we present <italic>ARACNE</italic>, a novel algorithm, using microarray expression profiles, specifically designed to scale up to the complexity of regulatory networks in mammalian cells, yet general enough to address a wider range of network deconvolution problems. This method uses an information theoretic approach to eliminate the majority of indirect interactions inferred by co-expression methods.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>We prove that ARACNE reconstructs the network exactly (asymptotically) if the effect of loops in the network topology is negligible, and we show that the algorithm works well in practice, even in the presence of numerous loops and complex topologies. We assess ARACNE's ability to reconstruct transcriptional regulatory networks using both a realistic synthetic dataset and a microarray dataset from human B cells. On synthetic datasets ARACNE achieves very low error rates and outperforms established methods, such as Relevance Networks and Bayesian Networks. Application to the deconvolution of genetic networks in human B cells demonstrates ARACNE's ability to infer validated transcriptional targets of the cMYC proto-oncogene. We also study the effects of misestimation of mutual information on network reconstruction, and show that algorithms based on mutual information ranking are more resilient to estimation errors.</p>
      </sec>
      <sec>
        <title>Conclusion</title>
        <p>ARACNE shows promise in identifying direct transcriptional interactions in mammalian cellular networks, a problem that has challenged existing reverse engineering algorithms. This approach should enhance our ability to use microarray data to elucidate functional mechanisms that underlie cellular processes and to identify molecular targets of pharmacological compounds in mammalian cellular networks.</p>
      </sec>
    </abstract>
    <conference>
      <conf-date>
        <day>18</day>
        <month>12</month>
        <year>2004</year>
      </conf-date>
      <conf-name>NIPS workshop on New Problems and Methods in Computational Biology</conf-name>
      <conf-loc>Whistler, Canada</conf-loc>
    </conference>
  </article-meta>
</front>
<body>
  <sec>
    <title>Background</title>
    <p>Cellular phenotypes are determined by the dynamical activity of large networks of co-regulated genes. Thus dissecting the mechanisms of phenotypic selection requires elucidating the functions of the individual genes in the context of the networks in which they operate. Because gene expression is regulated by proteins, which are themselves gene products, statistical associations between gene mRNA abundance levels, while not directly proportional to activated protein concentrations, should provide clues towards uncovering gene regulatory mechanisms. Consequently, the advent of high throughput microarray technologies to simultaneously measure mRNA abundance levels across an entire genome has spawned much research aimed at using these data to construct conceptual "gene network" models to concisely describe the regulatory influences that genes exert on each other.</p>
    <p>Genome-wide clustering of gene expression profiles [<xref ref-type="bibr" rid="B1">1</xref>] provides an important first step towards this goal by grouping together genes that exhibit similar transcriptional responses to various cellular conditions, and are therefore likely to be involved in similar cellular processes. However, the organization of genes into co-regulated clusters provides a very coarse representation of the cellular network. In particular, it cannot separate statistical interactions that are irreducible (i.e., direct) from those arising from cascades of transcriptional interactions that correlate the expression of many noninteracting genes. More generally, as appreciated in statistical physics, long range order (i.e., high correlation among non-directly interacting variables) can easily result from short range interactions [<xref ref-type="bibr" rid="B2">2</xref>]. Thus correlations, or <italic>any other </italic>local dependency measure, cannot be used as the only tool for the reconstruction of interaction networks without additional assumptions.</p>
    <p>Within the last few years a number of sophisticated approaches for the reverse engineering of cellular networks (also called deconvolution) from gene expression data have emerged (reviewed in [<xref ref-type="bibr" rid="B3">3</xref>]). Their goal is to produce a high-fidelity representation of the cellular network topology as a graph, where genes are represented as vertices and are connected by edges representing direct regulatory interactions. The criteria for defining an edge, as well as its biological interpretation, remain imprecise and vary between applications. For example, graphical modeling [<xref ref-type="bibr" rid="B4">4</xref>] defines edges as parent-child relationships between mRNA abundance levels that are most likely to explain the data, integrative methods [<xref ref-type="bibr" rid="B5">5</xref>] use independent experimental clues to define edges as those showing evidence of physical interactions, and other statistical/information theoretical methods [<xref ref-type="bibr" rid="B6">6</xref>] identify edges with the strongest statistical associations between mRNA abundance levels. All available approaches suffer to various degrees from problems such as overfitting, high computational complexity, reliance on non-realistic network models, or a critical dependency on supplementary data that is only available for simple organisms. These limitations have relegated the successful large-scale application of most methods to relatively simple organisms, such as the yeast <italic>Saccharomyces cerevisiae</italic>, and the genome-wide deconvolution of a mammalian network is yet to be reported.</p>
    <p>Here we introduce <italic>ARACNE </italic>(Algorithm for the Reconstruction of Accurate Cellular Networks), a novel information-theoretic algorithm for the reverse engineering of transcriptional networks from microarray data that overcomes some of these limitations. ARACNE defines an edge as an irreducible statistical dependency between gene expression profiles that cannot be explained as an artifact of other statistical dependencies in the network. We suggest that the presence of such irreducible statistical dependencies is likely to identify direct regulatory interactions mediated by a transcription factor binding to a target gene's promoter region, although other types of interactions may also be identified (see Discussion). In this study we focus on the former type of interaction for validation purposes. We demonstrate that ARACNE compares favorably with existing methods and achieves extremely low error rates in identifying transcriptional interactions in a synthetic dataset modeled using realistic Hill kinetics. In a biological context, we show that the algorithm infers bona-fide transcriptional targets in a mammalian gene network. We also study the effects of misestimation of mutual information (MI) on network reconstruction, and show that algorithms based on MI ranking are resilient to estimation errors. The algorithm is general enough to deal with a variety of other network reconstruction problems in biological, social, and engineering fields.</p>
    <sec>
      <title>Theoretical Background</title>
      <p>Several factors have impeded the reliable reconstruction of genome-wide mammalian networks. First, temporal gene expression data is difficult to obtain for higher eukaryotes, and cellular populations harvested from different individuals generally capture random steady states of the underlying biochemical dynamics. This precludes the use of methods that infer temporal associations and thus plausible causal relationships (reviewed in [<xref ref-type="bibr" rid="B7">7</xref>]). Only steady state statistical dependences can be studied, which are not obviously linked to the underlying physical dependency model. Compounding this constraint, there is no universally accepted definition of statistical dependencies in the multivariate setting [<xref ref-type="bibr" rid="B8">8</xref>,<xref ref-type="bibr" rid="B9">9</xref>]. In this work we adopt the definition of [<xref ref-type="bibr" rid="B9">9</xref>], which builds on ideas from the Markov networks literature [<xref ref-type="bibr" rid="B10">10</xref>]. Briefly, we write the joint probability distribution (JPD) of the stationary expressions of all genes, <italic>P</italic>({<italic>g</italic><sub><italic>i</italic></sub>}), <italic>i </italic>= 1,..., <italic>N</italic>, as:</p>
      <p>
        <inline-formula>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M1" name="1471-2105-7-S1-S7-i1" overflow="scroll">
            <mml:semantics definitionURL="" encoding="">
              <mml:mrow>
                <mml:mi>P</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mo>{</mml:mo>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>g</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mo>}</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mn>1</mml:mn>
                  <mml:mi>Z</mml:mi>
                </mml:mfrac>
                <mml:mi>exp</mml:mi>
                <mml:mo>⁡</mml:mo>
                <mml:mrow>
                  <mml:mo>[</mml:mo>
                  <mml:mrow>
                    <mml:mo>−</mml:mo>
                    <mml:mstyle displaystyle="true">
                      <mml:munderover>
                        <mml:mo>∑</mml:mo>
                        <mml:mi>i</mml:mi>
                        <mml:mi>N</mml:mi>
                      </mml:munderover>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>φ</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mi>g</mml:mi>
                              <mml:mi>i</mml:mi>
                            </mml:msub>
                          </mml:mrow>
                          <mml:mo>)</mml:mo>
                        </mml:mrow>
                        <mml:mo>−</mml:mo>
                        <mml:mstyle displaystyle="true">
                          <mml:munderover>
                            <mml:mo>∑</mml:mo>
                            <mml:mrow>
                              <mml:mi>i</mml:mi>
                              <mml:mo>,</mml:mo>
                              <mml:mi>j</mml:mi>
                            </mml:mrow>
                            <mml:mi>N</mml:mi>
                          </mml:munderover>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mi>φ</mml:mi>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mi>j</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mrow>
                              <mml:mo>(</mml:mo>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>i</mml:mi>
                                </mml:msub>
                                <mml:mo>,</mml:mo>
                                <mml:msub>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>j</mml:mi>
                                </mml:msub>
                              </mml:mrow>
                              <mml:mo>)</mml:mo>
                            </mml:mrow>
                            <mml:mo>−</mml:mo>
                            <mml:mstyle displaystyle="true">
                              <mml:munderover>
                                <mml:mo>∑</mml:mo>
                                <mml:mrow>
                                  <mml:mi>i</mml:mi>
                                  <mml:mo>,</mml:mo>
                                  <mml:mi>j</mml:mi>
                                  <mml:mo>,</mml:mo>
                                  <mml:mi>k</mml:mi>
                                </mml:mrow>
                                <mml:mi>N</mml:mi>
                              </mml:munderover>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mi>φ</mml:mi>
                                  <mml:mrow>
                                    <mml:mi>i</mml:mi>
                                    <mml:mi>j</mml:mi>
                                    <mml:mi>k</mml:mi>
                                  </mml:mrow>
                                </mml:msub>
                              </mml:mrow>
                            </mml:mstyle>
                            <mml:mrow>
                              <mml:mo>(</mml:mo>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>i</mml:mi>
                                </mml:msub>
                                <mml:mo>,</mml:mo>
                                <mml:msub>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>j</mml:mi>
                                </mml:msub>
                                <mml:mo>,</mml:mo>
                                <mml:msub>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>k</mml:mi>
                                </mml:msub>
                              </mml:mrow>
                              <mml:mo>)</mml:mo>
                            </mml:mrow>
                            <mml:mo>−</mml:mo>
                            <mml:mn>...</mml:mn>
                          </mml:mrow>
                        </mml:mstyle>
                      </mml:mrow>
                    </mml:mstyle>
                  </mml:mrow>
                  <mml:mo>]</mml:mo>
                </mml:mrow>
                <mml:mo>≡</mml:mo>
                <mml:msup>
                  <mml:mi>e</mml:mi>
                  <mml:mrow>
                    <mml:mo>−</mml:mo>
                    <mml:mi>H</mml:mi>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mrow>
                        <mml:mrow>
                          <mml:mo>{</mml:mo>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mi>g</mml:mi>
                              <mml:mi>i</mml:mi>
                            </mml:msub>
                          </mml:mrow>
                          <mml:mo>}</mml:mo>
                        </mml:mrow>
                      </mml:mrow>
                      <mml:mo>)</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                </mml:msup>
                <mml:mtext>     </mml:mtext>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mn>1</mml:mn>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:mrow>
              <mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaacqWGqbaudaqadaqaamaacmaabaGaem4zaC2aaSbaaSqaaiabdMgaPbqabaaakiaawUhacaGL9baaaiaawIcacaGLPaaacqGH9aqpdaWcaaqaaiabigdaXaqaaiabdQfaAbaacyGGLbqzcqGG4baEcqGGWbaCdaWadaqaaiabgkHiTmaaqahabaacciGae8NXdy2aaSbaaSqaaiabdMgaPbqabaGcdaqadaqaaiabdEgaNnaaBaaaleaacqWGPbqAaeqaaaGccaGLOaGaayzkaaGaeyOeI0YaaabCaeaacqWFgpGzdaWgaaWcbaGaemyAaKMaemOAaOgabeaakmaabmaabaGaem4zaC2aaSbaaSqaaiabdMgaPbqabaGccqGGSaalcqWGNbWzdaWgaaWcbaGaemOAaOgabeaaaOGaayjkaiaawMcaaiabgkHiTmaaqahabaGae8NXdy2aaSbaaSqaaiabdMgaPjabdQgaQjabdUgaRbqabaaabaGaemyAaKMaeiilaWIaemOAaOMaeiilaWIaem4AaSgabaGaemOta4eaniabggHiLdGcdaqadaqaaiabdEgaNnaaBaaaleaacqWGPbqAaeqaaOGaeiilaWIaem4zaC2aaSbaaSqaaiabdQgaQbqabaGccqGGSaalcqWGNbWzdaWgaaWcbaGaem4AaSgabeaaaOGaayjkaiaawMcaaiabgkHiTiabc6caUiabc6caUiabc6caUaWcbaGaemyAaKMaeiilaWIaemOAaOgabaGaemOta4eaniabggHiLdaaleaacqWGPbqAaeaacqWGobGta0GaeyyeIuoaaOGaay5waiaaw2faaiabggMi6Iqadiab+vgaLnaaCaaaleqabaGaeyOeI0ccbiGae0hsaG0aaeWaaeaadaGadaqaaiab9DgaNnaaBaaameaacqqFPbqAaeqaaaWccaGL7bGaayzFaaaacaGLOaGaayzkaaaaaOGaaCzcaiaaxMaadaqadaqaaiabigdaXaGaayjkaiaawMcaaaaa@8F9F@</mml:annotation>
            </mml:semantics>
          </mml:math>
        </inline-formula>
      </p>
      <p>where <italic>N </italic>is the number of genes, <italic>Z </italic>is the normalization factor, also called the <italic>partition function</italic>, <italic>φ</italic>... are <italic>potentials</italic>, and <italic>H</italic>({<italic>g</italic><sub><italic>i</italic></sub>}) is the <italic>Hamiltonian </italic>that defines the system's statistics. Within such a model, we assert that a set of variables interacts if and only if (<italic>iff</italic>) the single potential that depends exclusively on these variables is nonzero. ARACNE aims precisely at identifying which of these potentials are nonzero, and eliminating the others even though their corresponding marginal JPDs may not factorize. While this representation is not directly used by the algorithm, it helps precisely formalize our definition of interaction and the class of irreducible dependencies that it will help elucidate.</p>
      <p>Note that Eq. (1) does not define the potentials uniquely, and additional constraints are needed to avoid the ambiguity (see Appendix B). A reasonable approach is to specify <italic>φ</italic>... using maximum entropy approximations [<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B11">11</xref>] to <italic>P</italic>(<italic>g</italic><sub>1</sub>,..., <italic>g</italic><sub><italic>N</italic></sub>) consistent with known marginals, so that constraining an <italic>n</italic>-way marginal defines its corresponding potential. We refer the reader to [<xref ref-type="bibr" rid="B9">9</xref>] for details.</p>
    </sec>
    <sec>
      <title>Approximations of the interaction structure</title>
      <p>Since typical microarray sample sizes are relatively small, inferring the exponential number of potential <italic>n</italic>-way interactions of Eq. (1) is infeasible and a set of simplifying assumptions must be made about the dependency structure. Eq. (1) provides a principled and controlled way to introduce such approximations. The simplest model is one where genes are assumed independent, i.e., <italic>H</italic>({<italic>g</italic><sub><italic>i</italic></sub>}) = ∑<italic>φ</italic>(<italic>g</italic><sub><italic>i</italic></sub>), such that first-order potentials can be evaluated from the marginal probabilities, <italic>P</italic>(<italic>g</italic><sub><italic>i</italic></sub>), which are estimated from experimental observations. As more data become available we should be able to reliably estimate higher order marginals and incorporate the corresponding potentials progressively, such that for <italic>M </italic>→ ∞ (where <italic>M </italic>is sample set size) the complete form of the JPD is restored. In fact, <italic>M </italic>&gt; 100 is generally sufficient to estimate 2-way marginals in genomics problems, while <italic>P</italic>(<italic>g</italic><sub><italic>i</italic></sub>, <italic>g</italic><sub><italic>j</italic></sub>, <italic>g</italic><sub><italic>k</italic></sub>) requires about an order of magnitude more samples. Thus the current version of ARACNE truncates Eq. (1) at the pairwise interactions level, <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M2" name="1471-2105-7-S1-S7-i2" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaacqWGibasdaqadaqaamaacmaabaGaem4zaC2aaSbaaSqaaiabdMgaPbqabaaakiaawUhacaGL9baaaiaawIcacaGLPaaacqGH9aqpdaaeqbqaaGGaciab=z8aMnaaBaaaleaacqWGPbqAaeqaaaqaaiabdMgaPbqab0GaeyyeIuoakmaabmaabaGaem4zaC2aaSbaaSqaaiabdMgaPbqabaaakiaawIcacaGLPaaacqGHRaWkdaaeqbqaaiab=z8aMnaaBaaaleaacqWGPbqAcqWGQbGAaeqaaOWaaeWaaeaacqWGNbWzdaWgaaWcbaGaemyAaKgabeaakiabcYcaSiabdEgaNnaaBaaaleaacqWGQbGAaeqaaaGccaGLOaGaayzkaaaaleaacqWGPbqAcqGGSaalcqWGQbGAaeqaniabggHiLdaaaa@541C@</mml:annotation></mml:semantics></mml:math></inline-formula>. Within this approximation, all genes for which <italic>φ</italic><sub><italic>ij </italic></sub>= 0 are declared mutually non-interacting. This includes genes that are statistically independent (i.e., <italic>P</italic>(<italic>g</italic><sub><italic>i</italic></sub>, <italic>g</italic><sub><italic>j</italic></sub>) ≈ <italic>P</italic>(<italic>g</italic><sub><italic>i</italic></sub>)<italic>P</italic>(<italic>g</italic><sub><italic>j</italic></sub>)), as well as genes that do not interact directly but are statistically dependent due to their interaction via other genes (i.e. <italic>P</italic>(<italic>g</italic><sub><italic>i</italic></sub>, <italic>g</italic><sub><italic>j</italic></sub>) ≠ <italic>P</italic>(<italic>g</italic><sub><italic>i</italic></sub>)<italic>P</italic>(<italic>g</italic><sub><italic>j</italic></sub>), but <italic>φ</italic><sub><italic>ij </italic></sub>= 0). We note that <italic>P</italic>(<italic>g</italic><sub><italic>i</italic></sub>, <italic>g</italic><sub><italic>j</italic></sub>) = <italic>P</italic>(<italic>g</italic><sub><italic>i</italic></sub>)<italic>P</italic>(<italic>g</italic><sub><italic>j</italic></sub>) is not a sufficient condition for <italic>φ</italic><sub><italic>ij </italic></sub>= 0. We discuss this below.</p>
      <p>Since the number of potential pairwise interactions is quadratic in <italic>N</italic>, identification of indirect statistical interactions is a formidable challenge for all network reconstruction algorithms that rely on statistical associations. However, under certain biologically realistic assumptions about the network topology, the ARACNE algorithm provides a framework to reconstruct two-way interaction networks reliably from a finite number of samples in a computationally feasible time.</p>
    </sec>
  </sec>
  <sec>
    <title>Algorithm</title>
    <p>Within the assumption of a two-way network, all statistical dependencies can be inferred from pairwise marginals, and no higher order analysis is needed. While not implying that this is always the case for biological networks, it is important to understand whether this assumption may allow the inference of a subset of the true interactions with fewer false positives. Thus we identify candidate interactions by estimating pairwise gene expression profile mutual information, <italic>I</italic>(<italic>g</italic><sub><italic>i</italic></sub>, <italic>g</italic><sub><italic>j</italic></sub>) ≡ <italic>I</italic><sub><italic>ij</italic></sub>, an information-theoretic measure of relatedness that is zero <italic>iff </italic><italic>P</italic>(<italic>g</italic><sub><italic>i</italic></sub>, <italic>g</italic><sub><italic>j</italic></sub>) = <italic>P</italic>(<italic>g</italic><sub><italic>i</italic></sub>)<italic>P</italic>(<italic>g</italic><sub><italic>j</italic></sub>). We then filter MIs using an appropriate threshold, <italic>I</italic><sub>0</sub>, computed for a specific p-value, <italic>p</italic><sub>0</sub>, in the null-hypothesis of two independent genes. This step is basically equivalent to the Relevance Networks method [<xref ref-type="bibr" rid="B6">6</xref>] and suffers from the same significant limitations; namely, genes separated by one or more intermediaries (indirect relationships) may be highly co-regulated without implying an irreducible interaction, resulting in numerous false positives.</p>
    <p>Thus in its second step, ARACNE removes the vast majority of indirect candidate interactions (<italic>φ</italic><sub><italic>ij </italic></sub>= 0) using a well-known information theoretic property, the data processing inequality (DPI, discussed in detail later), that has not been previously applied to the reverse engineering of genetic networks.</p>
    <sec>
      <title>Mutual Information</title>
      <p><italic>Mutual information </italic>for a pair of random variables, <italic>x </italic>and <italic>y</italic>, is defined as <italic>I</italic>(<italic>x</italic>, <italic>y</italic>) = <italic>S</italic>(<italic>x</italic>) + <italic>S</italic>(<italic>y</italic>) - <italic>S</italic>(<italic>x</italic>, <italic>y</italic>), where <italic>S</italic>(<italic>t</italic>) is the entropy of an arbitrary variable <italic>t</italic>. For a discrete variable, the <italic>entropy </italic>is <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M3" name="1471-2105-7-S1-S7-i3" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:mi>S</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacqWGtbWudaqadaqaaiabdsha0bGaayjkaiaawMcaaiabg2da9iabgkHiTmaaamaabaGagiiBaWMaei4Ba8Maei4zaCMaemiCaa3aaeWaaeaacqWG0baDdaWgaaWcbaGaemyAaKgabeaaaOGaayjkaiaawMcaaaGaayzkJiaawQYiaiabg2da9iabgkHiTmaaqafabaGaemiCaa3aaeWaaeaacqWG0baDdaWgaaWcbaGaemyAaKgabeaaaOGaayjkaiaawMcaaaWcbaGaemyAaKgabeqdcqGHris5aOGagiiBaWMaei4Ba8Maei4zaCMaemiCaa3aaeWaaeaacqWG0baDdaWgaaWcbaGaemyAaKgabeaaaOGaayjkaiaawMcaaaaa@542D@</mml:annotation></mml:semantics></mml:math></inline-formula> where <italic>p</italic>(<italic>t</italic><sub><italic>i</italic></sub>) = <italic>Prob</italic>(<italic>t </italic>= <italic>t</italic><sub><italic>i</italic></sub>) is the probability of each discrete state (value) of the variable (in this work, logarithms are natural). For continuous variables the entropy is infinite but the MI remains well defined and can be computed by replacing <italic>S</italic>(<italic>x</italic>) with the <italic>differential entropy</italic>, which averages the log-probability density rather than the log-mass. Like the more familiar Pearson correlation, MI measures the degree of statistical dependency between two variables. However, while correlation coefficients are not invariant under reparameterizations and may be zero even for manifestly dependent variables, MI is reparameterization invariant and is nonzero <italic>iff </italic>any kind of statistical dependence exists.</p>
      <sec>
        <title>MI Estimation</title>
        <p>We estimate MI using a computationally efficient Gaussian Kernel estimator [<xref ref-type="bibr" rid="B12">12</xref>]. Given a set of two-dimensional measurements, <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M4" name="1471-2105-7-S1-S7-i4" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacuWG6bGEgaWcamaaBaaaleaacqWGPbqAaeqaaaaa@2FC4@</mml:annotation></mml:semantics></mml:math></inline-formula> ≡ {<italic>x</italic><sub><italic>i</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub>}, <italic>i </italic>= 1 ... <italic>M</italic>, the JPD is approximated as <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M5" name="1471-2105-7-S1-S7-i5" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mstyle displaystyle="true"><mml:msub><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacqWGMbGzdaqadaqaaiqbdQha6zaalaaacaGLOaGaayzkaaGaeyypa0ZaaSGbaeaacqaIXaqmaeaacqWGnbqtaaWaaabeaeaacqWGObaAdaahaaWcbeqaaiabgkHiTiabikdaYaaaaeaacqWGPbqAaeqaniabggHiLdGccqWGhbWrdaqadaqaaiabdIgaOnaaCaaaleqabaGaeyOeI0IaeGymaedaaOWaaqWaaeaacuWG6bGEgaWcaiabgkHiTiqbdQha6zaalaWaaSbaaSqaaiabdMgaPbqabaaakiaawEa7caGLiWoaaiaawIcacaGLPaaaaaa@49B7@</mml:annotation></mml:semantics></mml:math></inline-formula>, where <italic>G</italic>(...) is the bivariate standard normal density. With <italic>f</italic>(<italic>x</italic>) and <italic>f</italic>(<italic>y</italic>) being the marginals of <italic>f </italic>(<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M6" name="1471-2105-7-S1-S7-i6" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacuWG6bGEgaWcaaaa@2E3D@</mml:annotation></mml:semantics></mml:math></inline-formula>), the MI is:</p>
        <p>
          <inline-formula>
            <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M7" name="1471-2105-7-S1-S7-i7" overflow="scroll">
              <mml:semantics definitionURL="" encoding="">
                <mml:mrow>
                  <mml:mi>I</mml:mi>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mrow>
                      <mml:mrow>
                        <mml:mo>{</mml:mo>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>x</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mo>}</mml:mo>
                      </mml:mrow>
                      <mml:mo>,</mml:mo>
                      <mml:mrow>
                        <mml:mo>{</mml:mo>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>y</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mo>}</mml:mo>
                      </mml:mrow>
                    </mml:mrow>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                  <mml:mo>=</mml:mo>
                  <mml:mfrac>
                    <mml:mn>1</mml:mn>
                    <mml:mi>M</mml:mi>
                  </mml:mfrac>
                  <mml:mstyle displaystyle="true">
                    <mml:munder>
                      <mml:mo>∑</mml:mo>
                      <mml:mi>i</mml:mi>
                    </mml:munder>
                    <mml:mrow>
                      <mml:mi>log</mml:mi>
                      <mml:mo>⁡</mml:mo>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mi>f</mml:mi>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mrow>
                              <mml:msub>
                                <mml:mi>x</mml:mi>
                                <mml:mi>i</mml:mi>
                              </mml:msub>
                              <mml:mo>,</mml:mo>
                              <mml:msub>
                                <mml:mi>y</mml:mi>
                                <mml:mi>i</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                            <mml:mo>)</mml:mo>
                          </mml:mrow>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>f</mml:mi>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mrow>
                              <mml:msub>
                                <mml:mi>x</mml:mi>
                                <mml:mi>i</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                            <mml:mo>)</mml:mo>
                          </mml:mrow>
                          <mml:mi>f</mml:mi>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mrow>
                              <mml:msub>
                                <mml:mi>y</mml:mi>
                                <mml:mi>i</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                            <mml:mo>)</mml:mo>
                          </mml:mrow>
                        </mml:mrow>
                      </mml:mfrac>
                    </mml:mrow>
                  </mml:mstyle>
                  <mml:mtext>     </mml:mtext>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mn>2</mml:mn>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                </mml:mrow>
                <mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacqWGjbqsdaqadaqaamaacmaabaGaemiEaG3aaSbaaSqaaiabdMgaPbqabaaakiaawUhacaGL9baacqGGSaaldaGadaqaaiabdMha5naaBaaaleaacqWGPbqAaeqaaaGccaGL7bGaayzFaaaacaGLOaGaayzkaaGaeyypa0ZaaSaaaeaacqaIXaqmaeaacqWGnbqtaaWaaabuaeaacyGGSbaBcqGGVbWBcqGGNbWzdaWcaaqaaiabdAgaMnaabmaabaGaemiEaG3aaSbaaSqaaiabdMgaPbqabaGccqGGSaalcqWG5bqEdaWgaaWcbaGaemyAaKgabeaaaOGaayjkaiaawMcaaaqaaiabdAgaMnaabmaabaGaemiEaG3aaSbaaSqaaiabdMgaPbqabaaakiaawIcacaGLPaaacqWGMbGzdaqadaqaaiabdMha5naaBaaaleaacqWGPbqAaeqaaaGccaGLOaGaayzkaaaaaaWcbaGaemyAaKgabeqdcqGHris5aOGaaCzcaiaaxMaadaqadaqaaiabikdaYaGaayjkaiaawMcaaaaa@5EEE@</mml:annotation>
              </mml:semantics>
            </mml:math>
          </inline-formula>
        </p>
        <p>Since MI is reparameterization invariant, we copula-transform (i.e., rank-order) [<xref ref-type="bibr" rid="B8">8</xref>]<italic> x </italic>and <italic>y </italic>for MI estimation; the range of these transformed variables is thus between 0 and 1, and their marginal probability distributions are manifestly uniform. This decreases the influence of arbitrary transformations involved in microarray data preprocessing and removes the need to consider position-dependent kernel widths, <italic>h</italic>, which might be preferable for non-uniformly distributed data.</p>
        <p>For a spatially uniform <italic>h</italic>, the Gaussian kernel MI estimator is asymptotically unbiased for <italic>M </italic>→ ∞, as long as <italic>h</italic>(<italic>M</italic>) → 0 and [<italic>h</italic>(<italic>M</italic>)]<sup>2</sup><italic>M </italic>→ ∞. However, for finite <italic>M</italic>, the bias strongly depends on <italic>h</italic>(<italic>M</italic>) and the correct choice is not universal. Fortunately, ARACNE's performance does not depend directly on the accuracy of the MI estimate, <italic>I</italic>, but rather on the accuracy of the estimation of MI ranks. For instance, determining if MI is statistically significant requires testing whether <italic>I</italic><sub><italic>ij </italic></sub>≥ <italic>I</italic><sub>0</sub>, where <italic>I</italic><sub>0 </sub>is the statistical significance threshold. Similarly, the DPI (see below) only requires ranking the MIs.</p>
        <p>Producing reliable estimates of the MI ranks is an easier task. From the work on estimation of MI for discrete variables [<xref ref-type="bibr" rid="B13">13</xref>], we expect that, for well-sampled marginals and an undersampled joint, the bias is <italic>b </italic>≈ <italic>b</italic>(<italic>Ī</italic>, <italic>h</italic>) (where the bar denotes the true MI). Such biases almost cancel out for similar MI values; the ordering of MI estimates only weakly depends on the choice of <italic>h </italic>and is stable even when MI itself is uncertain (Figure <xref ref-type="fig" rid="F1">1</xref>). Thus a single "ensemble best" value of <italic>h </italic>can be used rather than optimizing the kernel width for each estimate (a computationally intensive operation). This result is general and should apply to any MI rank-based method. However, we emphasize that, since this result is largely empirical, the dependence of MI rank on the strength of smoothing should be reassessed for data sets with substantially different statistical properties before relying on this conclusion.</p>
      </sec>
    </sec>
    <sec>
      <title>Statistical Threshold for Mutual Information</title>
      <p>Since MI is always non-negative, its evaluation from random samples gives a positive value even for variables that are, in fact, mutually independent. Therefore, we eliminate all edges for which the null hypothesis of mutually independent genes cannot be ruled out. To this extent, we randomly shuffle the expression of genes across the various microarray profiles, similar to [<xref ref-type="bibr" rid="B6">6</xref>], and evaluate the MI for such manifestly independent genes and assign a p-value, <italic>p</italic>, to an MI threshold, <italic>I</italic><sub>0</sub>, by empirically estimating the fraction of the estimates below <italic>I</italic><sub>0</sub>. This is done for different sample sizes <italic>M </italic>and for 10<sup>5 </sup>gene pairs so that reliable estimates of <italic>I</italic><sub>0</sub>(<italic>p</italic>) are produced up to <italic>p </italic>= 10<sup>-4</sup>. Extrapolation to smaller p-values is done using <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M8" name="1471-2105-7-S1-S7-i9" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>≥</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>|</mml:mo><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mi>M</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacqWGWbaCcqGGOaakcqWGjbqscqGHLjYScqWGjbqsdaWgaaWcbaGaeGimaadabeaakiabcYha8jqbdMeajzaaraGaeyypa0JaeGimaaJaeiykaKIaeyyhIuRaemyzau2aaWbaaSqabeaacqGHsislcqaHXoqycqWGnbqtcqWGjbqsdaWgaaadbaGaeGimaadabeaaaaaaaa@4275@</mml:annotation></mml:semantics></mml:math></inline-formula>, where the parameter <italic>α </italic>is fitted from the data. This formula is based on the intuition of the large deviation theory [<xref ref-type="bibr" rid="B14">14</xref>], which for discrete data and unbiased estimators suggests <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M9" name="1471-2105-7-S1-S7-i10" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>≥</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>|</mml:mo><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>M</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacqWGWbaCcqGGOaakcqWGjbqscqGHLjYScqWGjbqsdaWgaaWcbaGaeGimaadabeaakiabcYha8jqbdMeajzaaraGaeyypa0JaeGimaaJaeiykaKIaeyyhIuRaemyzau2aaWbaaSqabeaacqGHsislcqWGnbqtcqWGjbqsdaWgaaadbaGaeGimaadabeaaaaaaaa@40D6@</mml:annotation></mml:semantics></mml:math></inline-formula>. As MI in the continuous case can be estimated by finely discretizing the variables, a similar result should hold, and <italic>α </italic>accounts for possible biases of the estimator at fixed <italic>h</italic>. This produces an excellent agreement with numerical experiments (see <xref ref-type="supplementary-material" rid="S1">additional file 1</xref>: Determination of mutual information statistical significance).</p>
    </sec>
    <sec>
      <title>Data Processing Inequality</title>
      <p>The DPI (Figure <xref ref-type="fig" rid="F2">2</xref>) [<xref ref-type="bibr" rid="B14">14</xref>] states that if genes <italic>g</italic><sub>1 </sub>and <italic>g</italic><sub>3 </sub>interact only through a third gene, <italic>g</italic><sub>2</sub>, (i.e., if the interaction network is <italic>g</italic><sub>1 </sub>↔ ... ↔ <italic>g</italic><sub>2 </sub>↔ ... ↔ <italic>g</italic><sub>3 </sub>and no alternative path exists between <italic>g</italic><sub>1 </sub>and <italic>g</italic><sub>3</sub>), then</p>
      <p><italic>I</italic>(<italic>g</italic><sub>1</sub>, <italic>g</italic><sub>3</sub>) ≤ min [<italic>I</italic>(<italic>g</italic><sub>1</sub>, <italic>g</italic><sub>2</sub>); <italic>I</italic>(<italic>g</italic><sub>2</sub>, <italic>g</italic><sub>3</sub>)].     (3)</p>
      <p>Thus the least of the three MIs can come from indirect interactions only, and checking against the DPI may identify those gene pairs for which <italic>φ</italic><sub><italic>ij </italic></sub>= 0 even though <italic>P</italic>(<italic>g</italic><sub><italic>i</italic></sub>, <italic>g</italic><sub><italic>j</italic></sub>) ≠ <italic>P</italic>(<italic>g</italic><sub><italic>i</italic></sub>)<italic>P</italic>(<italic>g</italic><sub><italic>j</italic></sub>). Correspondingly, ARACNE starts with a network graph where each <italic>I</italic><sub><italic>ij </italic></sub>&gt;<italic>I</italic><sub>0 </sub>is represented by an edge (<italic>ij</italic>). The algorithm then examines each gene triplet for which all three MIs are greater than <italic>I</italic><sub>0 </sub>and removes the edge with the smallest value. Each triplet is analyzed irrespectively of whether its edges have been marked for removal by prior DPI applications to different triplets. Thus the network reconstructed by the algorithm is independent of the order in which the triplets are examined.</p>
      <p>Since this approach focuses only on the reconstruction of pairwise interaction networks, a pair of mutually independent genes, <italic>I</italic><sub><italic>ij </italic></sub>&lt;<italic>I</italic><sub>0</sub>, will never be connected by an edge. Therefore, interactions represented by higher-order potentials for which the corresponding pairwise potentials are zero will not be recovered (see discussion). Additionally, even for a second order interaction network, one may imagine a situation where the effect of a direct interaction is exactly cancelled out by indirect interactions through other node(s), resulting in <italic>φ</italic><sub><italic>ij </italic></sub>≠ 0 and <italic>P</italic>(<italic>g</italic><sub><italic>i</italic></sub>, <italic>g</italic><sub><italic>j</italic></sub>) ≈ <italic>P</italic>(<italic>g</italic><sub><italic>i</italic></sub>)<italic>P</italic>(<italic>g</italic><sub><italic>j</italic></sub>). This situation will not be identified by ARACNE. However, we believe that such precise cancellation is biologically unrealistic and the following theorems specify conditions under which ARACNE will reconstruct the network exactly. Proofs of all theorems can be found in the Appendix A.</p>
      <sec>
        <title>Theorem 1</title>
        <p>If MIs can be estimated with no errors, then ARACNE reconstructs the underlying interaction network exactly, provided this network is a tree and has only pairwise interactions.</p>
        <p>However, unlike standard tree reconstruction methods (e.g. Chow and Liu [<xref ref-type="bibr" rid="B15">15</xref>]), ARACNE is not limited to trees and can produce complicated structures containing many loops. In fact, because of the following two theorems, ARACNE can be viewed as a natural generalization of the Chow-Liu algorithm which overcomes the biologically-unrealistic tree assumption of the latter.</p>
      </sec>
      <sec>
        <title>Theorem 2</title>
        <p>The Chow-Liu (CL) maximum mutual information tree is a subnetwork of the network reconstructed by ARACNE.</p>
      </sec>
      <sec>
        <title>Theorem 3</title>
        <p>Let <italic>π</italic><sub><italic>ik </italic></sub>be the set of nodes forming the shortest path in the network between nodes <italic>i </italic>and <italic>k</italic>. Then, if MIs can be estimated without errors, ARACNE reconstructs an interaction network without false positives edges, provided: (a) the network consists only of pairwise interactions, (b) for each <italic>j </italic>∊ <italic>π</italic><sub><italic>ik</italic></sub>, <italic>I</italic><sub><italic>ij </italic></sub>≥ <italic>I</italic><sub><italic>ik</italic></sub>. Further, ARACNE does not produce any false negatives, and the network reconstruction is exact <italic>iff </italic>(c) for each directly connected pair (<italic>ij</italic>) and for any other node <italic>k</italic>, we have <italic>I</italic><sub><italic>ij </italic></sub>≥ min(<italic>I</italic><sub><italic>jk</italic></sub>, <italic>I</italic><sub><italic>ik</italic></sub>).</p>
        <p>Tree networks satisfy all conditions of Theorem 3, while topologies containing loops may or may not. In particular, networks with three-gene loops definitely violate (c) [but may still satisfy (a) and (b)], and <italic>every </italic>such loop will be opened along the weakest edge. For a tree, there is a unique path that connects two nodes. Similarly, for networks that satisfy (a) and (b), the shortest path dominates inter-node information transfer. We call these networks <italic>locally tree-like</italic>. In other words, an interaction is retained by ARACNE if and only if there exist no alternate paths, via one or more intermediaries or branches on the network graph, which are a better explanation for the information exchange between two genes. Since biochemical dynamics is inherently stochastic, statistical interactions over more than a few separating edges are generically weak. Thus we believe that the local tree assumption is biologically realistic, and we expect ARACNE to produce low false positive rates in practice.</p>
        <p>Finally, to minimize the impact of the variance of the MI estimator, a tolerance, <italic>τ</italic>, may be introduced such that the DPI inequalities become of the form <italic>I</italic><sub><italic>ij </italic></sub>≤ <italic>I</italic><sub><italic>ik</italic></sub>(1 - <italic>τ</italic>), and close values of MI are not pruned. For low values of <italic>τ </italic>(&lt;15%) a reasonable tradeoff between true positives and false positives is achieved (see <xref ref-type="supplementary-material" rid="S2">additional file 2</xref>: Prediction errors as a function of DPI tolerance). This threshold qualitatively matches the variance of the MI estimator and decreases with increasing sample size. Using such non-zero tolerance leads to persistence of some 3-gene loops.</p>
      </sec>
    </sec>
    <sec>
      <title>Algorithmic Complexity</title>
      <p>Because for a network of <italic>N </italic>genes there are at most <italic>N </italic>choose 3 gene triplets, ARACNE's complexity is <italic>O</italic>(<italic>N</italic><sup>3 </sup>+ <italic>N</italic><sup>2</sup><italic>M</italic><sup>2</sup>), where <italic>M </italic>is the number of samples and <italic>N </italic>is the number of genes. The first term relates to the DPI analysis and the second to the mutual information estimation. This compares favorably with optimization methods that must explore an exponential search space (see Comparative Algorithms). In practice, the DPI is applied to a small subset of triplets for which all three edges survive the mutual information thresholding. Therefore, for large <italic>M</italic>, the computationally intensive part is generally associated with the second term (computing mutual information), which scales as <italic>O</italic>(<italic>N</italic><sup>2</sup><italic>M</italic><sup>2</sup>). As a result, ARACNE can efficiently analyze networks with tens of thousands of genes.</p>
    </sec>
  </sec>
  <sec>
    <title>Results</title>
    <p>We study ARACNE's performance in reconstructing a class of synthetic networks proposed by [<xref ref-type="bibr" rid="B16">16</xref>] and a human B lymphocyte genetic network from gene expressions profile data. The latter has been reported in [<xref ref-type="bibr" rid="B17">17</xref>] and will only be recapitulated here. ARACNE's performance is compared against Relevance Networks (RNs) and Bayesian Networks (BNs). RNs are important to characterize the improvement associated with the introduction of the DPI, while BNs have emerged as some of the most widely used reverse engineering methods and provide an ideal comparative benchmark.</p>
    <sec>
      <title>Comparative Algorithms</title>
      <p>A <italic>Bayesian Network </italic>is a representation of a JPD as a directed acyclic graph (DAG) whose vertices correspond to random variables {<italic>X</italic><sub>1</sub>,..., <italic>X</italic><sub><italic>n</italic></sub>}, and whose edges correspond to parent-child dependencies among variables; see [<xref ref-type="bibr" rid="B10">10</xref>] for an introduction and [<xref ref-type="bibr" rid="B18">18</xref>] for a more recent tutorial. We implemented the BN algorithm in this work in accordance with [<xref ref-type="bibr" rid="B19">19</xref>,<xref ref-type="bibr" rid="B20">20</xref>]. In particular, we score graphs using the Bayesian scoring metric [<xref ref-type="bibr" rid="B21">21</xref>], for which we adopt a uniform prior over graphs and employ a Dirichlet prior over parameters to aid in the inference of undersampled conditional distributions of children given their parents. Such an approach inherently penalizes more complex graphs. Learning the most likely network requires exploring the entire graph space for the highest scoring model, which is an NP-complete problem [<xref ref-type="bibr" rid="B22">22</xref>]. Thus heuristic procedures are used to search for locally optimal graph structures. The comparative tests presented here use the greedy hill climbing algorithm with random restarts (simulated annealing and other structure search methods were tested and observed to produce similar results). These results were produced using the LibB software package [<xref ref-type="bibr" rid="B23">23</xref>], which is among the best implementations of the method.</p>
      <p><italic>Relevance Networks </italic>[<xref ref-type="bibr" rid="B6">6</xref>] compute mutual information for all gene pairs in a microarray dataset and infer that two genes are biologically related if their MI is above a certain threshold. This approach is equivalent to the first step in the ARACNE algorithm (i.e., without the DPI); however, we use a more accurate MI estimation procedure than the original implementation and have further developed the method of assigning statistical significance.</p>
    </sec>
    <sec>
      <title>Synthetic Networks</title>
      <sec>
        <title>Networks Specification</title>
        <p>We benchmark the three algorithms using synthetic transcriptional networks proposed by Mendes et al. [<xref ref-type="bibr" rid="B16">16</xref>] as a platform for comparison of reverse engineering algorithms. These networks consist of 100 genes and 200 interactions organized either in an Erdös-Rényi (random network) [<xref ref-type="bibr" rid="B24">24</xref>] or a scale-free [<xref ref-type="bibr" rid="B25">25</xref>] topology (Figure <xref ref-type="fig" rid="F3">3</xref>). In the former, each vertex of a graph is equally likely to be connected to any other vertex; in the latter, the distribution of the number of connections, <italic>k</italic>, associated with each vertex follows a power law, <italic>p</italic>(<italic>k</italic>) ~ <italic>k</italic><sup>-<italic>γ </italic></sup>with <italic>γ </italic>&gt; 0, and large interactions hubs are present. Many real biological networks appear to exhibit such structure [<xref ref-type="bibr" rid="B26">26</xref>].</p>
        <p>The Mendes models use a multiplicative Hill kinetics to approximate transcriptional interactions:</p>
        <p>
          <inline-formula>
            <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M10" name="1471-2105-7-S1-S7-i11" overflow="scroll">
              <mml:semantics definitionURL="" encoding="">
                <mml:mrow>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mi>d</mml:mi>
                      <mml:msub>
                        <mml:mi>x</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>d</mml:mi>
                      <mml:mi>t</mml:mi>
                    </mml:mrow>
                  </mml:mfrac>
                  <mml:mo>=</mml:mo>
                  <mml:msub>
                    <mml:mi>a</mml:mi>
                    <mml:mi>i</mml:mi>
                  </mml:msub>
                  <mml:mstyle displaystyle="true">
                    <mml:munderover>
                      <mml:mo>∏</mml:mo>
                      <mml:mrow>
                        <mml:mi>j</mml:mi>
                        <mml:mo>=</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>N</mml:mi>
                          <mml:mi>I</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                    </mml:munderover>
                    <mml:mrow>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mi>I</mml:mi>
                          <mml:msubsup>
                            <mml:mi>K</mml:mi>
                            <mml:mi>j</mml:mi>
                            <mml:mrow>
                              <mml:msub>
                                <mml:mi>n</mml:mi>
                                <mml:mi>j</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                          </mml:msubsup>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>I</mml:mi>
                          <mml:msubsup>
                            <mml:mi>K</mml:mi>
                            <mml:mi>j</mml:mi>
                            <mml:mrow>
                              <mml:msub>
                                <mml:mi>n</mml:mi>
                                <mml:mi>j</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                          </mml:msubsup>
                          <mml:mo>+</mml:mo>
                          <mml:msubsup>
                            <mml:mi>I</mml:mi>
                            <mml:mi>j</mml:mi>
                            <mml:mrow>
                              <mml:msub>
                                <mml:mi>n</mml:mi>
                                <mml:mi>j</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                          </mml:msubsup>
                        </mml:mrow>
                      </mml:mfrac>
                    </mml:mrow>
                  </mml:mstyle>
                  <mml:mstyle displaystyle="true">
                    <mml:munderover>
                      <mml:mo>∏</mml:mo>
                      <mml:mrow>
                        <mml:mi>l</mml:mi>
                        <mml:mo>=</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>N</mml:mi>
                          <mml:mi>A</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                    </mml:munderover>
                    <mml:mrow>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:mrow>
                          <mml:mn>1</mml:mn>
                          <mml:mo>+</mml:mo>
                          <mml:mfrac>
                            <mml:mrow>
                              <mml:msubsup>
                                <mml:mi>A</mml:mi>
                                <mml:mi>l</mml:mi>
                                <mml:mrow>
                                  <mml:msub>
                                    <mml:mi>m</mml:mi>
                                    <mml:mi>l</mml:mi>
                                  </mml:msub>
                                </mml:mrow>
                              </mml:msubsup>
                            </mml:mrow>
                            <mml:mrow>
                              <mml:mi>A</mml:mi>
                              <mml:msubsup>
                                <mml:mi>K</mml:mi>
                                <mml:mi>l</mml:mi>
                                <mml:mrow>
                                  <mml:msub>
                                    <mml:mi>m</mml:mi>
                                    <mml:mi>l</mml:mi>
                                  </mml:msub>
                                </mml:mrow>
                              </mml:msubsup>
                              <mml:mo>+</mml:mo>
                              <mml:msubsup>
                                <mml:mi>A</mml:mi>
                                <mml:mi>l</mml:mi>
                                <mml:mrow>
                                  <mml:msub>
                                    <mml:mi>m</mml:mi>
                                    <mml:mi>l</mml:mi>
                                  </mml:msub>
                                </mml:mrow>
                              </mml:msubsup>
                            </mml:mrow>
                          </mml:mfrac>
                        </mml:mrow>
                        <mml:mo>)</mml:mo>
                      </mml:mrow>
                      <mml:mo>−</mml:mo>
                      <mml:msub>
                        <mml:mi>b</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>x</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                      <mml:mo>,</mml:mo>
                    </mml:mrow>
                  </mml:mstyle>
                  <mml:mtext>     </mml:mtext>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mn>4</mml:mn>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                </mml:mrow>
                <mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaadaWcaaqaaiabdsgaKjabdIha4naaBaaaleaacqWGPbqAaeqaaaGcbaGaemizaqMaemiDaqhaaiabg2da9iabdggaHnaaBaaaleaacqWGPbqAaeqaaOWaaebCaeaadaWcaaqaaiabdMeajjabdUealnaaDaaaleaacqWGQbGAaeaacqWGUbGBdaWgaaadbaGaemOAaOgabeaaaaaakeaacqWGjbqscqWGlbWsdaqhaaWcbaGaemOAaOgabaGaemOBa42aaSbaaWqaaiabdQgaQbqabaaaaOGaey4kaSIaemysaK0aa0baaSqaaiabdQgaQbqaaiabd6gaUnaaBaaameaacqWGQbGAaeqaaaaaaaaaleaacqWGQbGAcqGH9aqpcqaIXaqmaeaacqWGobGtdaWgaaadbaGaemysaKeabeaaa0Gaey4dIunakmaarahabaWaaeWaaeaacqaIXaqmcqGHRaWkdaWcaaqaaiabdgeabnaaDaaaleaacqWGSbaBaeaacqWGTbqBdaWgaaadbaGaemiBaWgabeaaaaaakeaacqWGbbqqcqWGlbWsdaqhaaWcbaGaemiBaWgabaGaemyBa02aaSbaaWqaaiabdYgaSbqabaaaaOGaey4kaSIaemyqae0aa0baaSqaaiabdYgaSbqaaiabd2gaTnaaBaaameaacqWGSbaBaeqaaaaaaaaakiaawIcacaGLPaaacqGHsislcqWGIbGydaWgaaWcbaGaemyAaKgabeaakiabdIha4naaBaaaleaacqWGPbqAaeqaaOGaeiilaWcaleaacqWGSbaBcqGH9aqpcqaIXaqmaeaacqWGobGtdaWgaaadbaGaemyqaeeabeaaa0Gaey4dIunakiaaxMaacaWLjaWaaeWaaeaacqaI0aanaiaawIcacaGLPaaaaaa@7D47@</mml:annotation>
              </mml:semantics>
            </mml:math>
          </inline-formula>
        </p>
        <p>where <italic>x</italic><sub><italic>i </italic></sub>is the concentration (expression) of the <italic>i</italic>-th gene, <italic>N</italic><sub><italic>I </italic></sub>and <italic>N</italic><sub><italic>A </italic></sub>are the number of upstream inhibitors and activators respectively, and their concentrations are <italic>I</italic><sub><italic>j </italic></sub>and <italic>A</italic><sub><italic>l</italic></sub>. All other parameters are specified in [<xref ref-type="bibr" rid="B16">16</xref>].</p>
        <p>We obtain synthetic expression values of each gene <italic>x</italic><sub><italic>i </italic></sub>in each microarray <italic>M</italic><sub><italic>k </italic></sub>by simulating its dynamics until the system relaxes to a steady state <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M11" name="1471-2105-7-S1-S7-i12" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>≈</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aqatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaajaaOcuWG4baEgaGaaOWaaSbaaSqaaiabdMgaPbqabaGccqGHijYUcqaIWaamaaa@3314@</mml:annotation></mml:semantics></mml:math></inline-formula>. Prior to each simulation, the efficiency of synthesis and degradation reactions are varied by setting <italic>a</italic><sub><italic>i </italic></sub>= <italic>λ</italic><sub><italic>k</italic>,<italic>i </italic></sub><inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M12" name="1471-2105-7-S1-S7-i13" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacuWGHbqygaqeamaaBaaaleaacqWGPbqAaeqaaaaa@2F98@</mml:annotation></mml:semantics></mml:math></inline-formula> and <italic>b</italic><sub><italic>i </italic></sub>= <italic>γ</italic><sub><italic>k</italic>,<italic>i </italic></sub><inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M13" name="1471-2105-7-S1-S7-i14" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>b</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacuWGIbGygaqeamaaBaaaleaacqWGPbqAaeqaaaaa@2F9A@</mml:annotation></mml:semantics></mml:math></inline-formula>, where <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M14" name="1471-2105-7-S1-S7-i13" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacuWGHbqygaqeamaaBaaaleaacqWGPbqAaeqaaaaa@2F98@</mml:annotation></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M15" name="1471-2105-7-S1-S7-i14" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>b</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacuWGIbGygaqeamaaBaaaleaacqWGPbqAaeqaaaaa@2F9A@</mml:annotation></mml:semantics></mml:math></inline-formula> are the original constant values of the parameters, and <italic>λ</italic><sub><italic>k</italic>,<italic>i</italic></sub>, <italic>γ</italic><sub><italic>k</italic>,<italic>i </italic></sub>are random variables uniformly distributed in [0.0, 2.0]. Note that <italic>λ</italic><sub><italic>k</italic>,<italic>i </italic></sub>~ 0.0 corresponds to a gene knock-out, while <italic>λ</italic><sub><italic>k</italic>,<italic>i </italic></sub>~ 2.0 is a 2 fold increase in the synthesis rate. This parameter randomization models the sampling of a population of distinct cellular phenotypes at random time points (at or close to equilibrium), as is the case for the B cell experiments described later, where the efficiency of individual biochemical reactions may be different from assay to assay due to differences in temperature, nutrients, genetic mutations, etc. Although this model is a clear simplification of real biological networks, it forms a reasonably complex interaction network that captures some elements of transcriptional regulation, and an algorithm that does not perform well on this model is unlikely to perform well in a more complex case. Within this model, an interaction is unambiguously defined as a direct regulatory effect of one gene on another. Thus the performance of reverse engineering algorithms can be studied by comparing the inferred statistical interactions to the direct interactions in the model. We specifically note that, to our knowledge, this is the first attempt to benchmark network reverse engineering algorithms based on published objective criteria.</p>
      </sec>
      <sec>
        <title>Performance metrics</title>
        <p>Since genetic networks are sparse, potential false positives (<italic>N</italic><sub><italic>FP</italic></sub>), that is, identification of an irreducible statistical interaction between two genes not connected by a direct regulatory link, far exceed potential true positives (<italic>N</italic><sub><italic>TP</italic></sub>) [<xref ref-type="bibr" rid="B27">27</xref>]. Thus specificity, <italic>N</italic><sub><italic>TN</italic></sub>/(<italic>N</italic><sub><italic>FP </italic></sub>+ <italic>N</italic><sub><italic>TN</italic></sub>), which is typically used in ROC analysis, is inappropriate as even small deviation from a value of 1 will result in large false positive numbers. Therefore, we choose two closely related metrics, precision and recall. Recall, <italic>N</italic><sub><italic>TP</italic></sub>/(<italic>N</italic><sub><italic>TP </italic></sub>+ <italic>N</italic><sub><italic>FN</italic></sub>), indicates the fraction of true interactions correctly inferred by the algorithm, while precision, <italic>N</italic><sub><italic>TP</italic></sub>/(<italic>N</italic><sub><italic>TP </italic></sub>+ <italic>N</italic><sub><italic>FP</italic></sub>), measures the fraction of true interactions among all inferred ones. Note that precision corresponds to the expected success rate in the experimental validation of predicted interactions. Performance will thus be assessed using Precision-Recall Curves (PRCs). PRCs for ARACNE and RNs are generated by adjusting the p-value or, equivalently, the MI threshold. ARACNE's PRC does not extend to 100% recall since the DPI eliminates some interactions even at <italic>p</italic><sub>0 </sub>= 1. To reach the 100% recall, the DPI tolerance, <italic>τ</italic>, can be adjusted until ARACNE's PRC degenerates into that of RNs. For BNs, the adjustable parameter is the Dirichlet pseudocount, and, again, we observe that the maximum recall never reaches 100%.</p>
      </sec>
      <sec>
        <title>Performance Evaluation</title>
        <p>As shown in Figure <xref ref-type="fig" rid="F4">4</xref>, values of precision and recall for ARACNE are consistently better than those for the other tested methods. That is, for any reasonable precision (i.e. &gt;40%), ARACNE has a significantly higher recall than the other methods, and its precision reaches ~100% at significant recall levels. For large p-values, ARACNE begins to rapidly increase the number of false positives without a corresponding increase in true positives (the right tail of ARACNE's PRC). This is likely because as non-statistically significant MI values are accepted, random fluctuations may arbitrarily change the MI rank so that the DPI removes interactions at random. We note that the inflection of the PRC for ARACNE starts at <italic>p</italic><sub>0 </sub>~ 10<sup>-4</sup>, exactly where we would expect the algorithm to begin inferring large numbers of non-statistically significant interactions for a network of this size. This suggests that a sensible value for the MI threshold, producing a near optimal result, can be selected <italic>a priori </italic>using a Bonferroni-corrected p-value based on the number of potential network interactions.</p>
        <p>ARACNE's high performance can be better understood by analyzing the distribution of MIs as a function of the length of the shortest path connecting each gene pair (degree of connectivity). ARACNE depends on MI being enriched for directly interacting genes and decreasing rapidly with this distance. Figure <xref ref-type="fig" rid="F5">5</xref> demonstrates these properties for our simulated datasets. There is no unique choice for the MI threshold that separates directly and indirectly interacting genes, and methods such as RNs that attempt to use a single threshold will either recover many indirect connections or miss a substantial number of direct ones. However, since mutual information decreases rapidly as signals travel over the network, the DPI effectively eliminates indirect interactions whose corresponding JPDs do not factorize. For all tested synthetic microarray sizes and both network topologies, ARACNE recovers far more true connections and far fewer false connections than the other methods (Table <xref ref-type="table" rid="T1">1</xref>). Remarkably, in all cases, application of the DPI eliminates almost all indirect candidate interactions inferred by Relevance Networks at the expense of very few true interactions. We note that since ARACNE's performance degrades as the local topology deviates significantly from a tree, it performs slightly better on Erdös-Rényi than on scale-free topologies, for which small loops are more common. Another challenge in reconstructing the scale-free topology derives from the presence of large hubs with high in-degrees, which have small (and thus difficult to estimate) MI with their individual neighbors. However, ARACNE still performs extremely well even on scale-free topologies because signals in this network decorrelate rather quickly, so the statistical properties of a tree-like structure are locally preserved even in the presence of relatively tight loops (see Theorem 3). We note that ARACNE differs significantly from tree reconstruction methods, as the reconstructed topology for the scale-free network (using 1,000 samples) contains ~30 loops with sizes as small as four (see Appendix C for a description of our loop counting algorithm).</p>
        <p>In summary, ARACNE appears to (a) achieve very high precision and substantial recall, even for few data points (125), (b) allow an optimal choice of the parameters h (Gaussian Kernel width) (Figure <xref ref-type="fig" rid="F6">6</xref>) and <italic>I</italic><sub>0 </sub>(statistical threshold), (c) to be quite stable with respect to the choice of parameters, and (d) to produce robust reconstruction of complex topologies containing many loops.</p>
      </sec>
    </sec>
    <sec>
      <title>Human B Cells</title>
      <p>Although large gene expression datasets such as those derived from systematic perturbations to simple organisms (e.g., [<xref ref-type="bibr" rid="B5">5</xref>]) are not easily obtained for mammalian cells, we suggest that an equivalent dynamic richness can be efficiently achieved by using a significant set of naturally occurring and experimentally generated phenotypic variations of a given cell type. To this end, we have assembled an expression profile dataset consisting of about 340 B lymphocytes derived from normal, tumor-related, and experimentally manipulated populations (for an extensive description see [<xref ref-type="bibr" rid="B28">28</xref>]).</p>
      <p>This dataset was deconvoluted using ARACNE to generate a B cell specific regulatory network consisting of approximately 129,000 interactions. Since the c-MYC proto-oncogene emerges as one of the top 5% largest cellular hubs in the complete network and is extensively characterized in the literature as a transcription factor, we performed a first validation of the overall network quality by comparing its interactions inferred by our method with those previously identified by biochemical methods. The <italic>in silico </italic>generated network is highly enriched in known c-MYC targets; 29 out of 56 (51.8%) genes predicted to be first neighbors were either previously reported in the literature or biochemically validated in our labs, using chromatin immunoprecipitation, as c-MYC targets. This is statistically significant (<italic>P </italic>= 2.9 × 10<sup>-23 </sup>by <italic>χ</italic><sup>2 </sup>test) with respect to the expected 11% of background c-MYC targets among randomly selected genes [<xref ref-type="bibr" rid="B29">29</xref>]. In addition, known c-MYC target genes were significantly more enriched among first neighbors than among second neighbors (51.8% vs. 19.4%), indicating that ARACNE is effective at separating direct regulatory interactions from indirect ones. Biological results related to the complete network structure are described in detail in [<xref ref-type="bibr" rid="B17">17</xref>].</p>
    </sec>
  </sec>
  <sec>
    <title>Discussion</title>
    <p>ARACNE, which is motivated by statistical mechanics and based on an information theoretic approach, provides a provably exact network reconstruction under a controlled set of approximations. While we have shown that these approximations are reasonable even for complex mammalian gene networks, they may cause the algorithm to fail for some control structures. First, ARACNE will open all three-gene loops along the weakest interaction, and therefore introduce false negatives for triplets of interacting genes (although some may be preserved when a nonzero DPI threshold is used). Improvements to the algorithm are being investigated to address this condition. Second, by truncating Eq. (1) at the pairwise interactions, ARACNE will not infer statistical dependencies that are not expressed as pairwise interaction potentials (such as an XOR Boolean table for which MI between any gene pair is zero). By expanding Eq. (1) to include third and higher order potentials our formulation, in principle, can be extended to distinguish higher order interactions as well [<xref ref-type="bibr" rid="B30">30</xref>]. However, we note that in practice (i.e., biochemically) it is difficult to produce <italic>only </italic>higher order interactions without introducing some lower order dependencies [<xref ref-type="bibr" rid="B9">9</xref>], and truncation of the Hamiltonian is not likely to produce serious systematic errors in identifying interactions between gene pairs. In fact, the Mendes networks contain higher order interactions, but corresponding pairwise ones are effectively recovered instead. Another limitation of ARACNE is the inability to infer edge directionality, although we believe this to be a general limitation of all methods that do not use temporal data. We intend to investigate a two-tier approach in which first adirectional gene interactions are inferred, and then edge directionality is assessed via regression algorithms or specific biochemical perturbations.</p>
    <p>Because mRNA abundance measurements only serve as a proxy for the interacting molecular species (i.e., activated protein concentrations), the type of physical interactions corresponding to the irreducible statistical dependencies identified by ARACNE are not always clear. For example, if the activity of a transcription factor is primarily mediated by an activating enzyme, rather than by changes in its mRNA abundance level, we expect ARACNE to identify dependencies between this enzyme and the target genes of the transcription factor. Moreover, a violation of the algorithm's hypotheses may occur for proteins involved in stable complex formation. Since it is energetically efficient for the cell to produce a stochiometrically balanced concentration of proteins involved in stable complexes (e.g., the ribosomal units), evolution has finetuned the transcriptional control of these proteins so that their concentrations are balanced. Thus, regardless of the concentration of the several transcription factors (TF) that may control their expression, the correlation between the final protein concentrations is generally higher than that between each protein and each individual TF. This violates the assumptions of Theorem 3 and produces irreducible statistical interactions between protein pairs involved in stable complex formation. Therefore, we expect some edges to correspond to protein-protein interactions, although we note that this situation would be correctly handled if higher order dependencies were analyzed.</p>
    <p>Finally, we end with the following observation. Since ARACNE may fail for topologies with many tight loops, it is important to understand whether an analyzed topology is, in fact, locally tree like, and, therefore, the reconstruction can be trusted. We suggest two heuristics. First, loopy topologies continue to have more loops after reconstruction (results not shown). Thus an excessive number of loops in a deconvolved network should serve as a warning sign (Appendix C); more analysis is required to determine an acceptable range for this statistic. Second, as in the current analysis, predictions made by ARACNE (or, for that matter, any other computational algorithm) should be directly experimentally verified.</p>
  </sec>
  <sec>
    <title>Conclusion</title>
    <p>The goal of ARACNE is not to recover <italic>all </italic>transcriptional interactions in a genetic network but rather to recover <italic>some </italic>transcriptional interactions with high confidence. Within this scope, ARACNE overcomes several limitations that have impeded the application of previous methods to the genome-wide analysis of mammalian networks. It has a low computational complexity, does not require discretization of the expression levels, and does not rely on unrealistic network models or <italic>a priori </italic>assumptions. The algorithm can be applied to arbitrarily complex networks of transcriptional, or any other, interactions without reliance on heuristic search procedures. Thus we expect ARACNE to be well suited for mammalian gene regulatory networks, which are characterized by a complex topology, do not benefit from well-defined supplemental data (such as comprehensive protein interaction databases available for yeast), and are more difficult to manipulate experimentally, substantially hindering the acquisition of data to which time-series based methods can be applied. There are currently no other examples of a genome-wide mammalian network inferred from microarray expression profiles.</p>
    <p>ARACNE's high precision in reconstructing a synthetic network designed to simulate transcriptional interactions, as well as the inference of bona-fide targets of c-MYC, a known transcription factor, in human B cells, suggest ARACNE's promise in identifying direct transcriptional interactions with low false-positive rates in mammalian networks, an obvious challenge for all reverse engineering algorithms. More research is needed to precisely characterize other types of interactions corresponding to irreducible statistical dependencies identified by ARACNE. We suggest that predictions made by ARACNE can be used in conjunction with other data modalities such as genome-wide location data, DNA sequence information, or targeted biochemical experiments to progress towards this level of detail. We plan to investigate this possibility using a model organism platform as well as extensions to the simulation model. However, studies based on targeted perturbations to model organisms have demonstrated the promise of using conceptual "gene-gene" networks to elucidate functional mechanisms underlying cellular processes [<xref ref-type="bibr" rid="B31">31</xref>] as well as to identify molecular targets of pharmacological compounds [<xref ref-type="bibr" rid="B32">32</xref>]. ARACNE may provide a framework to enable such applications in a mammalian context.</p>
  </sec>
  <sec>
    <title>Appendices</title>
    <sec>
      <title>Appendix A – Proofs of Theorems</title>
      <sec>
        <title>Theorem 1</title>
        <p>If MIs can be estimated with no errors, then ARACNE reconstructs the underlying interaction network exactly, provided this network is a tree and has only pairwise interactions.</p>
        <sec>
          <title>Proof of Theorem 1</title>
          <p>First, notice that for every pair of nodes <italic>i </italic>and <italic>k </italic>not connected by a true direct interaction there is at least one other node <italic>j </italic>that separates them on the network tree. Applying the DPI to the (<italic>ijk</italic>) triplet leads to removal of the (<italic>ik</italic>) edge. Thus only true edges survive. Similarly, every removed edge is not present in the true network. Consider some (<italic>ijk</italic>) triplet. One of these nodes, say <italic>j</italic>, may separate the other two. In this case the removed edge (<italic>ik</italic>) is clearly not in the true tree. Alternatively, there may be no separating node, and one may be able to move between any pair in the triplet without going through the third one. In this case none of the three edges is in the true graph, and any edge the DPI removes is fictitious. Thus all removed edges are indirect, while all remaining edges are factual. The network is reconstructed exactly.</p>
        </sec>
      </sec>
      <sec>
        <title>Theorem 2</title>
        <p>The Chow-Liu (CL) maximum mutual information tree is a subnetwork of the network reconstructed by ARACNE.</p>
        <sec>
          <title>Proof of Theorem 2</title>
          <p>We notice that, without a loss of generality, we can assume that the Chow-Liu tree and the ARACNE construction span all the nodes of the network. If this is not the case, that is, a few connected clusters exist (separated by edges with zero MI), then for the purpose of this theorem we can complete CL and ARACNE structures by the same edges with zero MI without formation of additional loops, till they become spanning. Now suppose that the theorem is false and there exists an edge (<italic>ij</italic>) that belongs to the (completed) CL tree, but does not belong to the ARACNE reconstruction. Since the CL construct is a tree, this edge separates it into two separate trees <italic>T</italic><sub><italic>i </italic></sub>and <italic>T</italic><sub><italic>j </italic></sub>that contain the <italic>i</italic>'th and the <italic>j</italic>'th nodes respectively. Since ARACNE has removed the (<italic>ij</italic>) link, there exists a node <italic>k</italic>, for which min(<italic>I</italic><sub><italic>ik</italic></sub>, <italic>I</italic><sub><italic>jk</italic></sub>) &gt;<italic>I</italic><sub><italic>ij</italic></sub>. Without a loss of generality, let <italic>k </italic>be in <italic>T</italic><sub><italic>i</italic></sub>. Then replacing the (<italic>ij</italic>) edge in the Chow-Liu tree by the (<italic>jk</italic>) edge will form no loops and will preserve the tree structure. This will increase the total MI of the CL reconstruction by <italic>I</italic><sub><italic>jk </italic></sub>- <italic>I</italic><sub><italic>ij </italic></sub>&gt; 0. Thus the original tree is not the maximum MI tree. We arrive at a contradiction, which proves the theorem.</p>
        </sec>
      </sec>
      <sec>
        <title>Theorem 3</title>
        <p>Let <italic>π</italic><sub><italic>ik </italic></sub>be the set of nodes forming the shortest path in the network between nodes <italic>i </italic>and <italic>k</italic>. Then, if MIs can be estimated without errors, ARACNE reconstructs an interaction network without false positives edges, provided: (a) the network consists only of pairwise interactions, (b) for each <italic>j </italic>∊ <italic>π</italic><sub><italic>ik</italic></sub>, <italic>I</italic><sub><italic>ij </italic></sub>≥ <italic>I</italic><sub><italic>ik</italic></sub>. Further, ARACNE does not produce any false negatives, and the network reconstruction is exact <italic>iff </italic>(c) for each directly connected pair (<italic>ij</italic>) and for any other node <italic>k</italic>, we have <italic>I</italic><sub><italic>ij </italic></sub>≥ min(<italic>I</italic><sub><italic>jk</italic></sub>, <italic>I</italic><sub><italic>ik</italic></sub>).</p>
        <sec>
          <title>Proof of Theorem 3</title>
          <p>To prove the absence of false positives, we notice that, for every candidate edge (<italic>ik</italic>) that is not actually in the network, there is at least one node <italic>j</italic>, such that <italic>j </italic>∊ <italic>π</italic><sub><italic>ik</italic></sub>. Applying DPI to the (<italic>ijk</italic>) triplet will remove the (<italic>ik</italic>) edge. Further, we notice that if (c) is satisfied, then any application of DPI will not remove a true edge. However, if (c) does not hold, a true edge will be removed. This completes the proof.</p>
        </sec>
      </sec>
    </sec>
    <sec>
      <title>Appendix B – Relations to Graphical Models and Statistical Physics</title>
      <p>The definition of dependencies employed in the paper, which is based on the presence of a potential that couples interacting genes in the JPD,</p>
      <p>
        <inline-formula>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M16" name="1471-2105-7-S1-S7-i15" overflow="scroll">
            <mml:semantics definitionURL="" encoding="">
              <mml:mrow>
                <mml:mi>P</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mo>{</mml:mo>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>g</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mo>}</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mn>1</mml:mn>
                  <mml:mi>Z</mml:mi>
                </mml:mfrac>
                <mml:mi>exp</mml:mi>
                <mml:mo>⁡</mml:mo>
                <mml:mrow>
                  <mml:mo>[</mml:mo>
                  <mml:mrow>
                    <mml:mo>−</mml:mo>
                    <mml:mstyle displaystyle="true">
                      <mml:munder>
                        <mml:mo>∑</mml:mo>
                        <mml:mi>i</mml:mi>
                      </mml:munder>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>φ</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mi>g</mml:mi>
                              <mml:mi>i</mml:mi>
                            </mml:msub>
                          </mml:mrow>
                          <mml:mo>)</mml:mo>
                        </mml:mrow>
                        <mml:mo>−</mml:mo>
                        <mml:mstyle displaystyle="true">
                          <mml:munder>
                            <mml:mo>∑</mml:mo>
                            <mml:mrow>
                              <mml:mi>i</mml:mi>
                              <mml:mo>,</mml:mo>
                              <mml:mi>j</mml:mi>
                            </mml:mrow>
                          </mml:munder>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mi>φ</mml:mi>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mi>j</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mrow>
                              <mml:mo>(</mml:mo>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>i</mml:mi>
                                </mml:msub>
                                <mml:mo>,</mml:mo>
                                <mml:msub>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>j</mml:mi>
                                </mml:msub>
                              </mml:mrow>
                              <mml:mo>)</mml:mo>
                            </mml:mrow>
                            <mml:mo>−</mml:mo>
                          </mml:mrow>
                        </mml:mstyle>
                        <mml:mstyle displaystyle="true">
                          <mml:munder>
                            <mml:mo>∑</mml:mo>
                            <mml:mrow>
                              <mml:mi>i</mml:mi>
                              <mml:mo>,</mml:mo>
                              <mml:mi>j</mml:mi>
                              <mml:mo>,</mml:mo>
                              <mml:mi>k</mml:mi>
                            </mml:mrow>
                          </mml:munder>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mi>φ</mml:mi>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mi>j</mml:mi>
                                <mml:mi>k</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mrow>
                              <mml:mo>(</mml:mo>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>i</mml:mi>
                                </mml:msub>
                                <mml:mo>,</mml:mo>
                                <mml:msub>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>j</mml:mi>
                                </mml:msub>
                                <mml:mo>,</mml:mo>
                                <mml:msub>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>k</mml:mi>
                                </mml:msub>
                              </mml:mrow>
                              <mml:mo>)</mml:mo>
                            </mml:mrow>
                          </mml:mrow>
                        </mml:mstyle>
                      </mml:mrow>
                    </mml:mstyle>
                    <mml:mo>−</mml:mo>
                    <mml:mo>⋯</mml:mo>
                  </mml:mrow>
                  <mml:mo>]</mml:mo>
                </mml:mrow>
                <mml:mo>≡</mml:mo>
                <mml:msup>
                  <mml:mi>e</mml:mi>
                  <mml:mrow>
                    <mml:mo>−</mml:mo>
                    <mml:mi>H</mml:mi>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mrow>
                        <mml:mrow>
                          <mml:mo>{</mml:mo>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mi>g</mml:mi>
                              <mml:mi>i</mml:mi>
                            </mml:msub>
                          </mml:mrow>
                          <mml:mo>}</mml:mo>
                        </mml:mrow>
                      </mml:mrow>
                      <mml:mo>)</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                </mml:msup>
                <mml:mtext>     </mml:mtext>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mn>5</mml:mn>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:mrow>
              <mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacqWGqbaudaqadaqaamaacmaabaGaem4zaC2aaSbaaSqaaiabdMgaPbqabaaakiaawUhacaGL9baaaiaawIcacaGLPaaacqGH9aqpdaWcaaqaaiabigdaXaqaaiabdQfaAbaacyGGLbqzcqGG4baEcqGGWbaCdaWadaqaaiabgkHiTmaaqafabaacciGae8NXdy2aaSbaaSqaaiabdMgaPbqabaGcdaqadaqaaiabdEgaNnaaBaaaleaacqWGPbqAaeqaaaGccaGLOaGaayzkaaGaeyOeI0YaaabuaeaacqWFgpGzdaWgaaWcbaGaemyAaKMaemOAaOgabeaakmaabmaabaGaem4zaC2aaSbaaSqaaiabdMgaPbqabaGccqGGSaalcqWGNbWzdaWgaaWcbaGaemOAaOgabeaaaOGaayjkaiaawMcaaiabgkHiTaWcbaGaemyAaKMaeiilaWIaemOAaOgabeqdcqGHris5aOWaaabuaeaacqWFgpGzdaWgaaWcbaGaemyAaKMaemOAaOMaem4AaSgabeaakmaabmaabaGaem4zaC2aaSbaaSqaaiabdMgaPbqabaGccqGGSaalcqWGNbWzdaWgaaWcbaGaemOAaOgabeaakiabcYcaSiabdEgaNnaaBaaaleaacqWGRbWAaeqaaaGccaGLOaGaayzkaaaaleaacqWGPbqAcqGGSaalcqWGQbGAcqGGSaalcqWGRbWAaeqaniabggHiLdaaleaacqWGPbqAaeqaniabggHiLdGccqGHsislcqWIVlctaiaawUfacaGLDbaacqGHHjIUcqWGLbqzdaahaaWcbeqaaiabgkHiTiabdIeainaabmaabaWaaiWaaeaacqWGNbWzdaWgaaadbaGaemyAaKgabeaaaSGaay5Eaiaaw2haaaGaayjkaiaawMcaaaaakiabcYcaSiaaxMaacaWLjaWaaeWaaeaacqaI1aqnaiaawIcacaGLPaaaaaa@8C14@</mml:annotation>
            </mml:semantics>
          </mml:math>
        </inline-formula>
      </p>
      <p>is similar to that used in the theory of graphical models, specifically Markov Networks (MNs) [<xref ref-type="bibr" rid="B10">10</xref>]. However, even though there are some dissenting formulations (e.g., [<xref ref-type="bibr" rid="B33">33</xref>]), the usual implementation of MNs [<xref ref-type="bibr" rid="B10">10</xref>] is built using the notion of conditional (in)dependence. In this context it is impossible to distinguish, for example, a clique of three genes that are fully coupled by three pairwise interactions from the same genes coupled by a third order dependence, and also from a combination of both cases. Because of this, many authors use a convention that if a higher order potential <italic>φ</italic>... is present in Equation 1, then all lower order potentials that depend only on a subset of the genes coupled by <italic>φ</italic>... are incorporated into it. In contrast, the definition of [<xref ref-type="bibr" rid="B9">9</xref>], followed in this paper, aims at discriminating interaction orders. Thus, in our case, a three gene pairwise loop is distinct from a three-way interaction. In fact, extensions of ARACNE to deal with the latter have been developed [<xref ref-type="bibr" rid="B30">30</xref>], while the former still requires work.</p>
      <p>As is understood in the graphical models literature, the formulation of Equation 1 resembles some statistical mechanics problems, specifically spin glasses on random networks [<xref ref-type="bibr" rid="B33">33</xref>,<xref ref-type="bibr" rid="B34">34</xref>], particularly if the <italic>g</italic><sub><italic>i </italic></sub>are binary (such discretization of expression levels is a common technique to deal with undersampling). In this case, the genes are the Ising spins, and truncations to the first, second, or the third order potentials are steps towards the mean field, Bethe, and Kikuchi variational approximations [<xref ref-type="bibr" rid="B33">33</xref>,<xref ref-type="bibr" rid="B35">35</xref>-<xref ref-type="bibr" rid="B37">37</xref>]. An important distinction is that in statistical physics one searches for <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M17" name="1471-2105-7-S1-S7-i16" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacuWGqbaugaacaaaa@2DE6@</mml:annotation></mml:semantics></mml:math></inline-formula>({<italic>g</italic><sub><italic>i</italic></sub>}), a variational approximation to the true JPD, <italic>P</italic>({<italic>g</italic><sub><italic>i</italic></sub>}), that minimizes <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M18" name="1471-2105-7-S1-S7-i17" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>‖</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≡</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mo>/</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:msub></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacqWGebardaWgaaWcbaGaem4saSKaemitaWeabeaakmaabmaabaGafmiuaaLbaGaadaqbbaqaaiabdcfaqbGaayzcSdaacaGLOaGaayzkaaGaeyyyIO7aaaWaaeaacyGGSbaBcqGGVbWBcqGGNbWzdaWcgaqaaiqbdcfaqzaaiaaabaGaemiuaafaaaGaayzkJiaawQYiamaaBaaajeaybaGafmiuaaLbaGaaaSqabaaaaa@41B2@</mml:annotation></mml:semantics></mml:math></inline-formula> within a given class of <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M19" name="1471-2105-7-S1-S7-i16" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacuWGqbaugaacaaaa@2DE6@</mml:annotation></mml:semantics></mml:math></inline-formula>, while the definition of [<xref ref-type="bibr" rid="B9">9</xref>] is equivalent to minimizing <italic>D</italic><sub><italic>KL </italic></sub>(<italic>P</italic>||<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M20" name="1471-2105-7-S1-S7-i16" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacuWGqbaugaacaaaa@2DE6@</mml:annotation></mml:semantics></mml:math></inline-formula>). This is because statistical physics solves a direct problem – calculating various spin statistics given an interaction network. In particular, low order marginals <italic>P</italic><sub>L </sub>are unknown and cannot be used in averaging. On the other hand, we are here solving the inverse problem – reconstructing the network given the known true marginal distributions.</p>
      <p>ARACNE, which truncates Equation 1 at the second order potentials, is an analog of the Bethe approximation for the direct problem. Just like this approximation and the associated belief propagation algorithm [<xref ref-type="bibr" rid="B10">10</xref>,<xref ref-type="bibr" rid="B38">38</xref>], ARACNE may fail for loopy topologies. It is, therefore, appealing that, for locally tree-like networks, the algorithm still works well, paralleling the corresponding discussion in statistical physics [<xref ref-type="bibr" rid="B38">38</xref>].</p>
    </sec>
    <sec>
      <title>Appendix C – Counting Loops in an Undirected Adjacency Matrix</title>
      <p>A pairwise interaction network can be represented by an adjacency matrix <italic>A</italic><sub><italic>ij</italic></sub>, where <italic>A</italic><sub><italic>ij </italic></sub>= 1,0 denotes either presence or absence of the corresponding interaction. To test the effect of violation of the "locally tree-like" assumption on the performance of the algorithm, we need to be able to count the number of cycles (loops) in a given network. This is complicated by the fact that the total number of cycles in a graph is not equal to the number of independent cycles; that is the number of edges that need to be removed to transform the graph into a tree. We need to count the number of independent cycles only. Additionally, of all possible complete sets of independent cycles we are interested in identifying the one with the smallest loops (since small loops have the highest potential to violate the locally tree-like assumption). We suggest the following algorithms to solve this task approximately.</p>
      <p>1) We prune the nodes that have 0 or 1 neighbors in the adjacency matrix <italic>A </italic>(since such nodes cannot be part of any loops).</p>
      <p>2) We transform the undirected network <italic>A </italic>into a directed one <italic>B</italic>. For this we identify every <italic>A</italic><sub><italic>ij </italic></sub>≠ 0 in the original network with a node in the new network (edges <italic>ij </italic>and <italic>ji </italic>are represented by separate nodes). If the original network had <italic>A</italic><sub><italic>ij </italic></sub>= <italic>A</italic><sub><italic>jk </italic></sub>= 1, <italic>i </italic>≠ <italic>k</italic>, then <italic>B</italic><sub>(<italic>ij</italic>),(<italic>jk</italic>) </sub>= 1 otherwise <italic>B</italic><sub>(<italic>ij</italic>),(<italic>kl</italic>) </sub>= 0.</p>
      <p>3) We evaluate integer powers of the matrix <italic>B</italic>. If <italic>Tr</italic>(<italic>B</italic><sup><italic>n</italic></sup>) &gt; 0, a loop (or loops) of size <italic>n </italic>are present. For the smallest <italic>n </italic>with loops, we identify one of them (at random), record nodes that form it, and remove one of these nodes in <italic>B </italic>(i.e., edges in <italic>A</italic>).</p>
      <p>4) We repeat 1–3 till no more loops are found.</p>
    </sec>
  </sec>
  <sec>
    <title>Authors' contributions</title>
    <p>AAM: Conducted research, designed study, participated in design of algorithm, wrote manuscript. IN: Designed theoretical framework, participated in design of algorithm, wrote manuscript. KB: Performed biochemical validation. CW: Participated in design of study. GS: Participated in design of algorithm and validation. RDF: Supervised and designed biochemical validation. AC: Designed algorithm, supervised research, wrote manuscript. All authors read and approved the final manuscript.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="S1">
      <caption>
        <title>Additional File 1</title>
        <p>Determination of mutual information statistical significance. P-values are assigned to MI thresholds using a Monte Carlo simulation for different kernel widths, sample sizes (<italic>M</italic>) and for 10<sup>5 </sup>gene pairs so that reliable estimates are produced up to <italic>p </italic>= 10<sup>-4 </sup>(solid lines). Extrapolation to smaller p-values is done using <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M21" name="1471-2105-7-S1-S7-i9" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>≥</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>|</mml:mo><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mi>M</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacqWGWbaCcqGGOaakcqWGjbqscqGHLjYScqWGjbqsdaWgaaWcbaGaeGimaadabeaakiabcYha8jqbdMeajzaaraGaeyypa0JaeGimaaJaeiykaKIaeyyhIuRaemyzau2aaWbaaSqabeaacqGHsislcqaHXoqycqWGnbqtcqWGjbqsdaWgaaadbaGaeGimaadabeaaaaaaaa@4275@</mml:annotation></mml:semantics></mml:math></inline-formula> (dotted lines).</p>
      </caption>
      <media xlink:href="1471-2105-7-S1-S7-S1.eps" mimetype="application" mime-subtype="postscript">
        <caption>
          <p>Click here for file</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="S2">
      <caption>
        <title>Additional File 2</title>
        <p>Prediction errors as a function of DPI tolerance. The number of inferred errors, <italic>N</italic><sub><italic>FP </italic></sub>+ <italic>N</italic><sub><italic>FN</italic></sub>, are plotted as a function of the DPI tolerance, <italic>τ</italic>, for <bold>(a) </bold>the Erdös-Rényi and <bold>(b) </bold>the scale-free topologies. Raising <italic>τ </italic>to a value of 0.2 results in a modest increase in false positives, while larger values of <italic>τ </italic>produce a much sharper increase. Therefore, a moderate choice for the tolerance can help elucidate additional interactions without introducing an excessive number of false positives. Results are calculated for a statistical significance threshold of 10<sup>-4 </sup>and a synthetic microarray size of 1,000.</p>
      </caption>
      <media xlink:href="1471-2105-7-S1-S7-S2.pdf" mimetype="application" mime-subtype="pdf">
        <caption>
          <p>Click here for file</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="S3">
      <caption>
        <title>Additional File 3</title>
        <p>MI distribution for different shortest path lengths for the Erdös-Rényi topology. Red and black arrows are explained in the legend of Figure <xref ref-type="fig" rid="F5">5</xref>. Since there are no large in-degree hubs, decorrelation is slower than for the scale-free network, and MI statistics even for fifth neighbors is still distinguishable from the background.</p>
      </caption>
      <media xlink:href="1471-2105-7-S1-S7-S3.eps" mimetype="application" mime-subtype="postscript">
        <caption>
          <p>Click here for file</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <sec>
      <title>Acknowledgements</title>
      <p>This work was supported by the NCI (1R01CA109755-01A1) and the NIAID (1R01AI066116-01). AAM is supported by the NLM Medical Informatics Research Training Program (5 T15 LM007079-13).</p>
    </sec>
  </ack>
  <ref-list>
    <ref id="B1">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Eisen</surname>
            <given-names>MB</given-names>
          </name>
          <name>
            <surname>Spellman</surname>
            <given-names>PT</given-names>
          </name>
          <name>
            <surname>Brown</surname>
            <given-names>PO</given-names>
          </name>
          <name>
            <surname>Botstein</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Cluster analysis and display of genome-wide expression patterns</article-title>
        <source>Proc Natl Acad Sci U S A</source>
        <year>1998</year>
        <volume>95</volume>
        <fpage>14863</fpage>
        <lpage>14868</lpage>
        <pub-id pub-id-type="pmid">9843981</pub-id>
        <pub-id pub-id-type="doi">10.1073/pnas.95.25.14863</pub-id>
      </citation>
    </ref>
    <ref id="B2">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Ma</surname>
            <given-names>S-K</given-names>
          </name>
        </person-group>
        <source>Statistical mechanics</source>
        <year>1985</year>
        <publisher-name>Singapore: World Scientific</publisher-name>
      </citation>
    </ref>
    <ref id="B3">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>van Someren</surname>
            <given-names>EP</given-names>
          </name>
          <name>
            <surname>Wessels</surname>
            <given-names>LF</given-names>
          </name>
          <name>
            <surname>Backer</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Reinders</surname>
            <given-names>MJ</given-names>
          </name>
        </person-group>
        <article-title>Genetic network modeling</article-title>
        <source>Pharmacogenomics</source>
        <year>2002</year>
        <volume>3</volume>
        <fpage>507</fpage>
        <lpage>525</lpage>
        <pub-id pub-id-type="pmid">12164774</pub-id>
        <pub-id pub-id-type="doi">10.1517/14622416.3.4.507</pub-id>
      </citation>
    </ref>
    <ref id="B4">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Friedman</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Inferring cellular networks using probabilistic graphical models</article-title>
        <source>Science</source>
        <year>2004</year>
        <volume>303</volume>
        <fpage>799</fpage>
        <lpage>805</lpage>
        <pub-id pub-id-type="pmid">14764868</pub-id>
        <pub-id pub-id-type="doi">10.1126/science.1094068</pub-id>
      </citation>
    </ref>
    <ref id="B5">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ideker</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Thorsson</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Ranish</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Christmas</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Buhler</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Eng</surname>
            <given-names>JK</given-names>
          </name>
          <name>
            <surname>Bumgarner</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Goodlett</surname>
            <given-names>DR</given-names>
          </name>
          <name>
            <surname>Aebersold</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Hood</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Integrated genomic and proteomic analyses of a systematically perturbed metabolic network</article-title>
        <source>Science</source>
        <year>2001</year>
        <volume>292</volume>
        <fpage>929</fpage>
        <lpage>934</lpage>
        <pub-id pub-id-type="pmid">11340206</pub-id>
        <pub-id pub-id-type="doi">10.1126/science.292.5518.929</pub-id>
      </citation>
    </ref>
    <ref id="B6">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Butte</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Kohane</surname>
            <given-names>IS</given-names>
          </name>
        </person-group>
        <article-title>Mutual information relevance networks: functional genomic clustering using pairwise entropy measurements</article-title>
        <source>Pac Symp Biocomput</source>
        <year>2000</year>
        <fpage>418</fpage>
        <lpage>429</lpage>
        <pub-id pub-id-type="pmid">10902190</pub-id>
      </citation>
    </ref>
    <ref id="B7">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wiggins</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Nemenman</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Process pathway inference via time series analysis</article-title>
        <source>Experimental Mechanics</source>
        <year>2003</year>
        <volume>43</volume>
        <fpage>361</fpage>
        <lpage>370</lpage>
        <pub-id pub-id-type="doi">10.1177/00144851030433016</pub-id>
      </citation>
    </ref>
    <ref id="B8">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Joe</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <source>Multivariate models and dependence concepts</source>
        <year>1997</year>
        <publisher-name>Boca Raton, FL: Chapman &amp; Hall</publisher-name>
      </citation>
    </ref>
    <ref id="B9">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Nemenman</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Information theory, multivariate dependence, and genetic network inference</article-title>
        <source>Tech Rep NSF-KITP-04-54, KITP, UCSB</source>
        <year>2004</year>
        <comment>arXiv: q-bio/0406015</comment>
      </citation>
    </ref>
    <ref id="B10">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Pearl</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <source>Probabilistic reasoning in intelligent systems: networks of plausible inference</source>
        <year>1988</year>
        <publisher-name>San Francisco, CA: Morgan Kaufmann Publishers, Inc</publisher-name>
      </citation>
    </ref>
    <ref id="B11">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Janes</surname>
            <given-names>ET</given-names>
          </name>
        </person-group>
        <article-title>Information theory and statistical mechanics</article-title>
        <source>Phys Rev</source>
        <year>1957</year>
        <volume>106</volume>
        <fpage>620</fpage>
        <lpage>630</lpage>
        <pub-id pub-id-type="doi">10.1103/PhysRev.106.620</pub-id>
      </citation>
    </ref>
    <ref id="B12">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Beirlant</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Dudewicz</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Gyorfi</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>van der Meulen</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Nonparametric entropy estimation: An overview</article-title>
        <source>Int J Math Stat Sci</source>
        <year>1997</year>
        <volume>6</volume>
        <fpage>17</fpage>
        <lpage>39</lpage>
      </citation>
    </ref>
    <ref id="B13">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Strong</surname>
            <given-names>SP</given-names>
          </name>
          <name>
            <surname>Koberle</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>de Ruyter van Steveninck</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Bialek</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Entropy and information in neural spike trains</article-title>
        <source>Phys Rev Lett</source>
        <year>1998</year>
        <volume>80</volume>
        <fpage>197</fpage>
        <lpage>200</lpage>
        <pub-id pub-id-type="doi">10.1103/PhysRevLett.80.197</pub-id>
      </citation>
    </ref>
    <ref id="B14">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Cover</surname>
            <given-names>TM</given-names>
          </name>
          <name>
            <surname>Thomas</surname>
            <given-names>JA</given-names>
          </name>
        </person-group>
        <source>Elements of Information Theory</source>
        <year>1991</year>
        <publisher-name>New York: John Wiley &amp; Sons</publisher-name>
      </citation>
    </ref>
    <ref id="B15">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chow</surname>
            <given-names>CK</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>CN</given-names>
          </name>
        </person-group>
        <article-title>Approximating discrete probability distributions with dependence trees</article-title>
        <source>IEEE Trans Inf Thy</source>
        <year>1968</year>
        <volume>IT-14</volume>
        <fpage>462</fpage>
        <lpage>467</lpage>
        <pub-id pub-id-type="doi">10.1109/TIT.1968.1054142</pub-id>
      </citation>
    </ref>
    <ref id="B16">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mendes</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Sha</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Artificial gene networks for objective comparison of analysis algorithms</article-title>
        <source>Bioinformatics</source>
        <year>2003</year>
        <volume>19</volume>
        <fpage>II122</fpage>
        <lpage>II129</lpage>
        <pub-id pub-id-type="pmid">14534181</pub-id>
      </citation>
    </ref>
    <ref id="B17">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Basso</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Margolin</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Stolovitzky</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Klein</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Dalla-Favera</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Califano</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Reverse engineering of regulatory networks in human B cells</article-title>
        <source>Nat Genet</source>
        <year>2005</year>
        <volume>37</volume>
        <fpage>382</fpage>
        <lpage>390</lpage>
        <pub-id pub-id-type="pmid">15778709</pub-id>
        <pub-id pub-id-type="doi">10.1038/ng1532</pub-id>
      </citation>
    </ref>
    <ref id="B18">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Heckerman</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>A Tutorial on Learning with Bayesian Networks</article-title>
        <source>Microsoft Research</source>
        <year>1996</year>
      </citation>
    </ref>
    <ref id="B19">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hartemink</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Gifford</surname>
            <given-names>DK</given-names>
          </name>
          <name>
            <surname>Jaakkola</surname>
            <given-names>TS</given-names>
          </name>
          <name>
            <surname>Young</surname>
            <given-names>RA</given-names>
          </name>
        </person-group>
        <article-title>Using graphical models and genomic expression data to statistically validate models of genetic regulatory networks</article-title>
        <source>Pac Symp Biocomput</source>
        <year>2001</year>
        <fpage>422</fpage>
        <lpage>433</lpage>
        <pub-id pub-id-type="pmid">11262961</pub-id>
      </citation>
    </ref>
    <ref id="B20">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>AV</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>PP</given-names>
          </name>
          <name>
            <surname>Hartemink</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Jarvis</surname>
            <given-names>ED</given-names>
          </name>
        </person-group>
        <article-title>Using Bayesian Network Inference Algorithms to Recover Molecular Genetic Regulatory Networks</article-title>
        <source>3rd International Conference on Systems Biology</source>
        <year>2002</year>
      </citation>
    </ref>
    <ref id="B21">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cooper</surname>
            <given-names>GF</given-names>
          </name>
          <name>
            <surname>Herskovits</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>A Bayesian method for the induction of probabilistic networks from data</article-title>
        <source>Machine Learning</source>
        <year>1992</year>
        <volume>9</volume>
        <fpage>309</fpage>
        <lpage>347</lpage>
      </citation>
    </ref>
    <ref id="B22">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Chickering</surname>
            <given-names>DM</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Fisher DaL H</surname>
          </name>
        </person-group>
        <article-title>Learning Bayesian networks is NP-complete</article-title>
        <source>Learning from Data: Artificial Intelligence and Statistics</source>
        <year>1996</year>
        <publisher-name>New York: Springer-Verlag</publisher-name>
        <fpage>121</fpage>
        <lpage>130</lpage>
      </citation>
    </ref>
    <ref id="B23">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Friedman</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Elidan</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>LibB 2.1</article-title>
        <ext-link ext-link-type="uri" xlink:href="http://www.cs.huji.ac.il/labs/compbio/LibB/"/>
      </citation>
    </ref>
    <ref id="B24">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Erdos</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Renyi</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>On Random Graphs</article-title>
        <source>Publ Math Debrecen</source>
        <year>1959</year>
        <volume>6</volume>
        <fpage>290</fpage>
        <lpage>297</lpage>
      </citation>
    </ref>
    <ref id="B25">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Barabasi</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Albert</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Emergence of scaling in random networks</article-title>
        <source>Science</source>
        <year>1999</year>
        <volume>286</volume>
        <fpage>509</fpage>
        <lpage>512</lpage>
        <pub-id pub-id-type="pmid">10521342</pub-id>
        <pub-id pub-id-type="doi">10.1126/science.286.5439.509</pub-id>
      </citation>
    </ref>
    <ref id="B26">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Newman</surname>
            <given-names>MEJ</given-names>
          </name>
        </person-group>
        <article-title>The Structure and Function of Complex Networks</article-title>
        <source>SIAM Review</source>
        <year>2003</year>
        <volume>45</volume>
        <fpage>167</fpage>
        <lpage>256</lpage>
        <pub-id pub-id-type="doi">10.1137/S003614450342480</pub-id>
      </citation>
    </ref>
    <ref id="B27">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yeung</surname>
            <given-names>MK</given-names>
          </name>
          <name>
            <surname>Tegner</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Collins</surname>
            <given-names>JJ</given-names>
          </name>
        </person-group>
        <article-title>Reverse engineering gene networks using singular value decomposition and robust regression</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2002</year>
        <volume>99</volume>
        <fpage>6163</fpage>
        <lpage>6168</lpage>
        <pub-id pub-id-type="pmid">11983907</pub-id>
        <pub-id pub-id-type="doi">10.1073/pnas.092576199</pub-id>
      </citation>
    </ref>
    <ref id="B28">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Klein</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Tu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Stolovitzky</surname>
            <given-names>GA</given-names>
          </name>
          <name>
            <surname>Mattioli</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Cattoretti</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Husson</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Freedman</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Inghirami</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Cro</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Baldini</surname>
            <given-names>L</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Gene expression profiling of B cell chronic lymphocytic leukemia reveals a homogeneous phenotype related to memory B cells</article-title>
        <source>J Exp Med</source>
        <year>2001</year>
        <volume>194</volume>
        <fpage>1625</fpage>
        <lpage>1638</lpage>
        <pub-id pub-id-type="pmid">11733577</pub-id>
        <pub-id pub-id-type="doi">10.1084/jem.194.11.1625</pub-id>
      </citation>
    </ref>
    <ref id="B29">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fernandez</surname>
            <given-names>PC</given-names>
          </name>
          <name>
            <surname>Frank</surname>
            <given-names>SR</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Schroeder</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Greene</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Cocito</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Amati</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Genomic targets of the human c-Myc protein</article-title>
        <source>Genes Dev</source>
        <year>2003</year>
        <volume>17</volume>
        <fpage>1115</fpage>
        <lpage>1129</lpage>
        <pub-id pub-id-type="pmid">12695333</pub-id>
        <pub-id pub-id-type="doi">10.1101/gad.1067003</pub-id>
      </citation>
    </ref>
    <ref id="B30">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Nemenman</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Banerjee</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Margolin</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Califano</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Genome-wide Discovery of Modulators of Transcriptional Interactions in Human B Lymphocytes</article-title>
        <source>Proceedings of the 10th Intl Conf on Res In Comp Mol Biol (RECOMB), Venice Apr 2006</source>
        <comment/>
      </citation>
    </ref>
    <ref id="B31">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tegner</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yeung</surname>
            <given-names>MK</given-names>
          </name>
          <name>
            <surname>Hasty</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Collins</surname>
            <given-names>JJ</given-names>
          </name>
        </person-group>
        <article-title>Reverse engineering gene networks: integrating genetic perturbations with dynamical modeling</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2003</year>
        <volume>100</volume>
        <fpage>5944</fpage>
        <lpage>5949</lpage>
        <pub-id pub-id-type="pmid">12730377</pub-id>
        <pub-id pub-id-type="doi">10.1073/pnas.0933416100</pub-id>
      </citation>
    </ref>
    <ref id="B32">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gardner</surname>
            <given-names>TS</given-names>
          </name>
          <name>
            <surname>di Bernardo</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Lorenz</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Collins</surname>
            <given-names>JJ</given-names>
          </name>
        </person-group>
        <article-title>Inferring genetic networks and identifying compound mode of action via expression profiling</article-title>
        <source>Science</source>
        <year>2003</year>
        <volume>301</volume>
        <fpage>102</fpage>
        <lpage>105</lpage>
        <pub-id pub-id-type="pmid">12843395</pub-id>
        <pub-id pub-id-type="doi">10.1126/science.1081900</pub-id>
      </citation>
    </ref>
    <ref id="B33">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Yedidia</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Opper M, Saad D</surname>
          </name>
        </person-group>
        <article-title>An idiosyncratic journey beyond mean field theory</article-title>
        <source>Advanced Mean Field Methods: Theory and Practice</source>
        <year>2001</year>
        <publisher-name>Cambridge, MA: MIT Press</publisher-name>
      </citation>
    </ref>
    <ref id="B34">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mezard</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Parizi</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>The Bethe lattice spin glass revisited</article-title>
        <source>Eur Phys J B</source>
        <year>2001</year>
        <volume>20</volume>
        <fpage>217</fpage>
      </citation>
    </ref>
    <ref id="B35">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bethe</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Statistical Theory of Superlattices</article-title>
        <source>Proc Roy Soc London A</source>
        <year>1935</year>
        <volume>150</volume>
        <fpage>552</fpage>
      </citation>
    </ref>
    <ref id="B36">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kikuchi</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>A Theory of Cooperative Phenomena</article-title>
        <source>Phys Rev</source>
        <year>1951</year>
        <volume>81</volume>
        <fpage>988</fpage>
        <pub-id pub-id-type="doi">10.1103/PhysRev.81.988</pub-id>
      </citation>
    </ref>
    <ref id="B37">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Opper</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Winther</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Opper M, Saad D</surname>
          </name>
        </person-group>
        <article-title>From naive mean field theory to the TAP equations</article-title>
        <source>Advanced mean field methods: theory and practice</source>
        <year>2001</year>
        <publisher-name>Cambridge, MA: MIT Press</publisher-name>
      </citation>
    </ref>
    <ref id="B38">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yedidia</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>Freeman</surname>
            <given-names>WT</given-names>
          </name>
          <name>
            <surname>Weiss</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Generalized Belief Propagation</article-title>
        <source>Advances in Neural Information Processing Systems (NIPS)</source>
        <year>2001</year>
        <volume>13</volume>
        <fpage>689</fpage>
        <lpage>695</lpage>
      </citation>
    </ref>
  </ref-list>
  <sec sec-type="display-objects">
    <title>Figures and Tables</title>
    <fig position="float" id="F1">
      <label>Figure 1</label>
      <caption>
        <p><bold>MI and MI rank estimation errors for varying Gaussian kernel widths</bold>. The mean absolute percent error in estimating mutual information for bivariate normal densities is compared to the percent of errors in ranking the relative mutual information values for randomly sampled pairs for which the distribution with the lower true MI value is between 70% and 99% of the distribution with the higher value. MI estimation error (dashed blue line) is highly sensitive to the choice of Gaussian kernel width used by the estimator and grows rapidly for non-optimal parameter choices. However, due to similar bias for distributions with close MI values, the error in ranking pairs of MIs (solid red line) is much less sensitive to the choice of this parameter. These averages were produced using samples from 1,000 bivariate normal densities with a random uniformly distributed correlation coefficient <italic>ρ </italic>∊ [0.1, 0.9], such that <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M22" name="1471-2105-7-S1-S7-i8" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciGacaGaaeqabaqabeGadaaakeaacuWGjbqsgaqeaiabg2da9iabgkHiTmaaliaabaGaeGymaedabaGaeGOmaidaaiGbcYgaSjabc+gaVjabcEgaNnaabmaabaGaeGymaeJaeyOeI0IaeqyWdi3aaWbaaSqabeaacqaIYaGmaaaakiaawIcacaGLPaaaaaa@3C35@</mml:annotation></mml:semantics></mml:math></inline-formula>. This results in a distribution of MI values that closely resembles that of the real microarray data.</p>
      </caption>
      <graphic xlink:href="1471-2105-7-S1-S7-1"/>
    </fig>
    <fig position="float" id="F2">
      <label>Figure 2</label>
      <caption>
        <p><bold>Examples of the data processing inequality</bold>. <bold>(a) </bold><italic>g</italic><sub>1</sub>, <italic>g</italic><sub>2</sub>, <italic>g</italic><sub>3</sub>, and <italic>g</italic><sub>4 </sub>are connected in a linear chain relationship. Although all six gene pairs will likely have enriched mutual information, the DPI will infer the most likely path of information flow. For example, <italic>g</italic><sub>1 </sub>↔	<italic>g</italic><sub>3 </sub>will be eliminated because <italic>I</italic>(<italic>g</italic><sub>1</sub>, <italic>g</italic><sub>2</sub>) &gt;<italic>I</italic>(<italic>g</italic><sub>1</sub>, <italic>g</italic><sub>3</sub>) and <italic>I</italic>(<italic>g</italic><sub>2</sub>, <italic>g</italic><sub>3</sub>) &gt;<italic>I</italic>(<italic>g</italic><sub>1</sub>, <italic>g</italic><sub>3</sub>). <italic>g</italic><sub>2 </sub>↔ <italic>g</italic><sub>4 </sub>will be eliminated because <italic>I</italic>(<italic>g</italic><sub>2</sub>, <italic>g</italic><sub>3</sub>) &gt;<italic>I</italic>(<italic>g</italic><sub>2</sub>, <italic>g</italic><sub>4</sub>) and <italic>I</italic>(<italic>g</italic><sub>3</sub>, <italic>g</italic><sub>4</sub>) &gt;<italic>I</italic>(<italic>g</italic><sub>2</sub>, <italic>g</italic><sub>4</sub>). <italic>g</italic><sub>1 </sub>↔ <italic>g</italic><sub>4 </sub>will be eliminated in two ways: first, because <italic>I</italic>(<italic>g</italic><sub>1</sub>, <italic>g</italic><sub>2</sub>) &gt;<italic>I</italic>(<italic>g</italic><sub>1</sub>, <italic>g</italic><sub>4</sub>) and <italic>I</italic>(<italic>g</italic><sub>2</sub>, <italic>g</italic><sub>4</sub>) &gt;<italic>I</italic>(<italic>g</italic><sub>1</sub>, <italic>g</italic><sub>4</sub>), and then because <italic>I</italic>(<italic>g</italic><sub>1</sub>, <italic>g</italic><sub>3</sub>) &gt;<italic>I</italic>(<italic>g</italic><sub>1</sub>, <italic>g</italic><sub>4</sub>) and <italic>I</italic>(<italic>g</italic><sub>3</sub>, <italic>g</italic><sub>4</sub>) &gt;<italic>I</italic>(<italic>g</italic><sub>1</sub>, <italic>g</italic><sub>4</sub>). <bold>(b) </bold>If the underlying interactions form a tree (and MI can be measured without errors), ARACNE will reconstruct the network exactly by removing all false candidate interactions (dashed blue lines) and retaining all true interactions (solid black lines).</p>
      </caption>
      <graphic xlink:href="1471-2105-7-S1-S7-2"/>
    </fig>
    <fig position="float" id="F3">
      <label>Figure 3</label>
      <caption>
        <p><bold>Topology of the 100 gene regulatory networks proposed by Mendes</bold>. Blue/red edges correspond to activation/inhibition. For the Erdös-Rényi topology <bold>(a) </bold>each gene is equally likely to be connected to every other gene, while the scale-free topology <bold>(b) </bold>is characterized by large interaction hubs with many connections.</p>
      </caption>
      <graphic xlink:href="1471-2105-7-S1-S7-3"/>
    </fig>
    <fig position="float" id="F4">
      <label>Figure 4</label>
      <caption>
        <p><bold>Precision vs. Recall for 1,000 samples generated from the Mendes network</bold>. <bold>(a) </bold>Erdös-Rényi network topology. <bold>(b) </bold>Scale-free topology. ARACNE's PRCs are consistently better than those of the other algorithms, and the precision reaches ~100% while maintaining high recall. Points on the PRCs for ARACNE and RNs corresponding to <italic>p</italic><sub>0 </sub>= 10<sup>-4 </sup>(the value yieding &lt;0.5 expected false positives for 4,950 potential interactions) are indicated with arrows.</p>
      </caption>
      <graphic xlink:href="1471-2105-7-S1-S7-4"/>
    </fig>
    <fig position="float" id="F5">
      <label>Figure 5</label>
      <caption>
        <p><bold>Distribution of mutual information for different lengths of the shortest path between genes for the scale-free topology</bold>. Here we plot the log of the empirical probability that MI for a given separation between genes is above some value (in nats) marked on the horizontal axis. High MI values are significantly more probable for closer genes. Statistical significance threshold of 10<sup>-4 </sup>for the background MI distribution, corresponding to <italic>I</italic><sub>0 </sub>= 0.0175 nats, is marked on the graph. As shown, this threshold retains a large number of indirect candidate interactions, and there is no threshold that would be able to separate indirect and direct interactions; a threshold that eliminates most of the former (red arrows) also eliminates the majority of the latter. This severely degrades performance of RNs. (Inset) Expanded log-log view of the MI distribution for 934 gene pairs with 3 or more intermediaries and the background distribution computed by Monte Carlo. The curves are virtually indistinguishable, indicating that the background distribution can be used to obtain reliable estimates of statistical significance thresholds for filtering genes with higher degrees of connectivity. Similar results apply for the Erdös-Rényi topology (see <xref ref-type="supplementary-material" rid="S3">additional file 3</xref>: MI distribution for different shortest path lengths for the Erdös-Rényi topology).</p>
      </caption>
      <graphic xlink:href="1471-2105-7-S1-S7-5"/>
    </fig>
    <fig position="float" id="F6">
      <label>Figure 6</label>
      <caption>
        <p><bold>Synthetic network reconstruction errors for varying Gaussian kernel widths</bold>. The total number of inferred errors (<italic>N</italic><sub><italic>FP </italic></sub>+ <italic>N</italic><sub><italic>FN</italic></sub>) in reconstructing the Mendes networks is stable with respect to choice of estimator kernel width, validating the observation that rankings of MIs are more stable than the MI estimates with respect to changes in this parameter (<bold>Figure 1</bold>). The choice of kernel width for each number of samples that minimizes the mean absolute MI estimation error for bivariate Gaussian densities (indicated with diamonds) yields optimal or near optimal reconstruction of this network for all samples sizes. Results are calculated for a statistical significance threshold of 10<sup>-4 </sup> for the scale-free network topology.</p>
      </caption>
      <graphic xlink:href="1471-2105-7-S1-S7-6"/>
    </fig>
    <table-wrap position="float" id="T1">
      <label>Table 1</label>
      <caption>
        <p>Recovery for varying numbers of samples generated from the Mendes networks, which contain an average of ~194 true interactions after self-loops and bidirectional edges are eliminated.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <td align="left" colspan="9">
              <bold>
                <italic>Erdös-Rényi Topology</italic>
              </bold>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="center" colspan="2">
              <bold>ARACNE</bold>
            </td>
            <td align="center" colspan="2">
              <bold>Relevance Networks</bold>
            </td>
            <td align="center">
              <bold>
                <italic>DPI Sensitivity</italic>
              </bold>
            </td>
            <td align="center">
              <bold>
                <italic>DPI Precision</italic>
              </bold>
            </td>
            <td align="center" colspan="2">
              <bold>Bayesian Networks</bold>
            </td>
          </tr>
          <tr>
            <td align="center">
              <bold>
                <italic>Num samples</italic>
              </bold>
            </td>
            <td align="left">
              <italic>N</italic>
              <sub>
                <italic>TP</italic>
              </sub>
            </td>
            <td align="right">
              <italic>N</italic>
              <sub>
                <italic>FP</italic>
              </sub>
            </td>
            <td align="right">
              <italic>N</italic>
              <sub>
                <italic>TP</italic>
              </sub>
            </td>
            <td align="right">
              <italic>N</italic>
              <sub>
                <italic>FP</italic>
              </sub>
            </td>
            <td/>
            <td/>
            <td align="right">
              <italic>N</italic>
              <sub>
                <italic>TP</italic>
              </sub>
            </td>
            <td align="right">
              <italic>N</italic>
              <sub>
                <italic>FP</italic>
              </sub>
            </td>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="right">
              <italic>1000 </italic>
            </td>
            <td align="left">128.00</td>
            <td align="right">1.33</td>
            <td align="right">143.33</td>
            <td align="right">462.67</td>
            <td align="right">99.71%</td>
            <td align="right">96.78%</td>
            <td align="right">50.00</td>
            <td align="right">32.33</td>
          </tr>
          <tr>
            <td align="right">
              <italic>750 </italic>
            </td>
            <td align="left">124.33</td>
            <td align="right">2.67</td>
            <td align="right">139.33</td>
            <td align="right">411.00</td>
            <td align="right">99.35%</td>
            <td align="right">96.46%</td>
            <td align="right">45.33</td>
            <td align="right">31.00</td>
          </tr>
          <tr>
            <td align="right">
              <italic>500 </italic>
            </td>
            <td align="left">119.00</td>
            <td align="right">1.67</td>
            <td align="right">130.67</td>
            <td align="right">311.33</td>
            <td align="right">99.46%</td>
            <td align="right">96.37%</td>
            <td align="right">41.00</td>
            <td align="right">29.00</td>
          </tr>
          <tr>
            <td align="right">
              <italic>250 </italic>
            </td>
            <td align="left">101.00</td>
            <td align="right">4.67</td>
            <td align="right">110.00</td>
            <td align="right">182.33</td>
            <td align="right">97.44%</td>
            <td align="right">95.18%</td>
            <td align="right">24.67</td>
            <td align="right">25.33</td>
          </tr>
          <tr>
            <td align="right">
              <italic>125 </italic>
            </td>
            <td align="left">81.00</td>
            <td align="right">4.67</td>
            <td align="right">84.67</td>
            <td align="right">95.00</td>
            <td align="right">95.09%</td>
            <td align="right">96.10%</td>
            <td align="right">5.33</td>
            <td align="right">19.00</td>
          </tr>
          <tr>
            <td/>
            <td/>
            <td/>
            <td/>
            <td/>
            <td/>
            <td/>
            <td/>
            <td/>
          </tr>
          <tr>
            <td align="left" colspan="9">
              <bold>
                <italic>Scale-Free Topology</italic>
              </bold>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="center" colspan="2">
              <bold>ARACNE</bold>
            </td>
            <td align="center" colspan="2">
              <bold>Relevance Networks</bold>
            </td>
            <td align="center">
              <bold>
                <italic>DPI Sensitivity</italic>
              </bold>
            </td>
            <td align="center">
              <bold>
                <italic>DPI Precision</italic>
              </bold>
            </td>
            <td align="center" colspan="2">
              <bold>Bayesian Networks</bold>
            </td>
          </tr>
          <tr>
            <td align="center">
              <bold>
                <italic>Num samples</italic>
              </bold>
            </td>
            <td align="left">
              <italic>N</italic>
              <sub>
                <italic>TP</italic>
              </sub>
            </td>
            <td align="right">
              <italic>N</italic>
              <sub>
                <italic>FP</italic>
              </sub>
            </td>
            <td align="right">
              <italic>N</italic>
              <sub>
                <italic>TP</italic>
              </sub>
            </td>
            <td align="right">
              <italic>N</italic>
              <sub>
                <italic>FP</italic>
              </sub>
            </td>
            <td/>
            <td/>
            <td align="right">
              <italic>N</italic>
              <sub>
                <italic>TP</italic>
              </sub>
            </td>
            <td align="right">
              <italic>N</italic>
              <sub>
                <italic>FP</italic>
              </sub>
            </td>
          </tr>
          <tr>
            <td colspan="9">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="right">
              <italic>1000 </italic>
            </td>
            <td align="left">97.67</td>
            <td align="right">2.33</td>
            <td align="right">113.33</td>
            <td align="right">234.00</td>
            <td align="right">99.00%</td>
            <td align="right">93.67%</td>
            <td align="right">38.67</td>
            <td align="right">17.00</td>
          </tr>
          <tr>
            <td align="right">
              <italic>750 </italic>
            </td>
            <td align="left">90.67</td>
            <td align="right">3.33</td>
            <td align="right">103.00</td>
            <td align="right">200.00</td>
            <td align="right">98.33%</td>
            <td align="right">94.10%</td>
            <td align="right">33.33</td>
            <td align="right">15.33</td>
          </tr>
          <tr>
            <td align="right">
              <italic>500 </italic>
            </td>
            <td align="left">80.33</td>
            <td align="right">5.33</td>
            <td align="right">91.67</td>
            <td align="right">154.67</td>
            <td align="right">96.55%</td>
            <td align="right">92.95%</td>
            <td align="right">27.00</td>
            <td align="right">13.33</td>
          </tr>
          <tr>
            <td align="right">
              <italic>250 </italic>
            </td>
            <td align="left">63.33</td>
            <td align="right">7.67</td>
            <td align="right">70.00</td>
            <td align="right">80.00</td>
            <td align="right">90.42%</td>
            <td align="right">91.56%</td>
            <td align="right">9.00</td>
            <td align="right">9.67</td>
          </tr>
          <tr>
            <td align="right">
              <italic>125 </italic>
            </td>
            <td align="left">46.33</td>
            <td align="right">3.67</td>
            <td align="right">48.00</td>
            <td align="right">49.67</td>
            <td align="right">92.62%</td>
            <td align="right">96.50%</td>
            <td align="right">4.00</td>
            <td align="right">6.00</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <p>Recovery for varying numbers of samples generated from the Mendes networks, which contain an average of ~194 true interactions after self-loops and bidirectional edges are eliminated. For all sample sizes ARACNE efficiently eliminates almost all false candidate interactions inferred by RNs, as indicated by the DPI sensitivity (calculated as the percent of false positives eliminated by the DPI), with minimal reduction in true positives, as indicated by the DPI precision (calculated as the percent of false positives removed out of the total number of edges removed by the DPI). Moreover, as the sample size decreases, the number of true connections inferred by ARACNE decays gracefully while the number of false positives remains very low, whereas the performance of Bayesian Networks degrades rapidly for smaller sample sizes as the conditional probability tables become very sparsely populated. Results are calculated using a p-value of 10<sup>-4 </sup>for ARACNE and Relevance Networks, yielding &lt;0.5 expected false positives for 4,950 potential interactions, and using a Dirichlet prior with equivalent sample size of one for Bayesian Networks [19]. Results are averaged over three network configurations for each topology.</p>
      </table-wrap-foot>
    </table-wrap>
  </sec>
</back>
