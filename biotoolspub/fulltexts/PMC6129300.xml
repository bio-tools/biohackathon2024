<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6129300</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/bty210</article-id>
    <article-id pub-id-type="publisher-id">bty210</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Bioimage Informatics</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Comparative analysis of tissue reconstruction algorithms for 3D histology</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-9470-4783</contrib-id>
        <name>
          <surname>Kartasalo</surname>
          <given-names>Kimmo</given-names>
        </name>
        <xref ref-type="aff" rid="bty210-aff1">1</xref>
        <xref ref-type="aff" rid="bty210-aff2">2</xref>
        <xref ref-type="aff" rid="bty210-aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Latonen</surname>
          <given-names>Leena</given-names>
        </name>
        <xref ref-type="aff" rid="bty210-aff1">1</xref>
        <xref ref-type="aff" rid="bty210-aff3">3</xref>
        <xref ref-type="aff" rid="bty210-aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Vihinen</surname>
          <given-names>Jorma</given-names>
        </name>
        <xref ref-type="aff" rid="bty210-aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Visakorpi</surname>
          <given-names>Tapio</given-names>
        </name>
        <xref ref-type="aff" rid="bty210-aff1">1</xref>
        <xref ref-type="aff" rid="bty210-aff3">3</xref>
        <xref ref-type="aff" rid="bty210-aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Nykter</surname>
          <given-names>Matti</given-names>
        </name>
        <xref ref-type="aff" rid="bty210-aff1">1</xref>
        <xref ref-type="aff" rid="bty210-aff2">2</xref>
        <xref ref-type="aff" rid="bty210-aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-9086-9591</contrib-id>
        <name>
          <surname>Ruusuvuori</surname>
          <given-names>Pekka</given-names>
        </name>
        <xref ref-type="aff" rid="bty210-aff1">1</xref>
        <xref ref-type="aff" rid="bty210-aff3">3</xref>
        <xref ref-type="aff" rid="bty210-aff6">6</xref>
        <xref ref-type="corresp" rid="bty210-cor1"/>
        <!--<email>pekka.ruusuvuori@tut.fi</email>-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Murphy</surname>
          <given-names>Robert</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <aff id="bty210-aff1"><label>1</label>Faculty of Medicine and Life Sciences, University of Tampere, Tampere, Finland</aff>
    <aff id="bty210-aff2"><label>2</label>Faculty of Biomedical Sciences and Engineering, Tampere University of Technology, Tampere, Finland</aff>
    <aff id="bty210-aff3"><label>3</label>BioMediTech Institute, Tampere, Finland</aff>
    <aff id="bty210-aff4"><label>4</label>Fimlab Laboratories, Tampere University Hospital, Tampere, Finland</aff>
    <aff id="bty210-aff5"><label>5</label>Faculty of Engineering Sciences, Tampere University of Technology, Tampere, Finland</aff>
    <aff id="bty210-aff6"><label>6</label>Faculty of Computing and Electrical Engineering, Tampere University of Technology, Tampere 33101, Finland</aff>
    <author-notes>
      <corresp id="bty210-cor1">To whom correspondence should be addressed. E-mail: <email>pekka.ruusuvuori@tut.fi</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <day>01</day>
      <month>9</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2018-04-19">
      <day>19</day>
      <month>4</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>19</day>
      <month>4</month>
      <year>2018</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>34</volume>
    <issue>17</issue>
    <fpage>3013</fpage>
    <lpage>3021</lpage>
    <history>
      <date date-type="received">
        <day>29</day>
        <month>11</month>
        <year>2017</year>
      </date>
      <date date-type="rev-recd">
        <day>01</day>
        <month>3</month>
        <year>2018</year>
      </date>
      <date date-type="accepted">
        <day>18</day>
        <month>4</month>
        <year>2018</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2018. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2018</copyright-year>
      <license license-type="cc-by" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="bty210.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Digital pathology enables new approaches that expand beyond storage, visualization or analysis of histological samples in digital format. One novel opportunity is 3D histology, where a three-dimensional reconstruction of the sample is formed computationally based on serial tissue sections. This allows examining tissue architecture in 3D, for example, for diagnostic purposes. Importantly, 3D histology enables joint mapping of cellular morphology with spatially resolved omics data in the true 3D context of the tissue at microscopic resolution. Several algorithms have been proposed for the reconstruction task, but a quantitative comparison of their accuracy is lacking.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We developed a benchmarking framework to evaluate the accuracy of several free and commercial 3D reconstruction methods using two whole slide image datasets. The results provide a solid basis for further development and application of 3D histology algorithms and indicate that methods capable of compensating for local tissue deformation are superior to simpler approaches.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>Code: <ext-link ext-link-type="uri" xlink:href="https://github.com/BioimageInformaticsTampere/RegBenchmark">https://github.com/BioimageInformaticsTampere/RegBenchmark</ext-link>. Whole slide image datasets: <ext-link ext-link-type="uri" xlink:href="http://urn.fi/urn">http://urn.fi/urn</ext-link>: nbn: fi: csc-kata20170705131652639702.</p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Academy of Finland</named-content>
          <named-content content-type="funder-identifier">10.13039/501100002341</named-content>
        </funding-source>
        <award-id>269474</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Tekes</named-content>
          <named-content content-type="funder-identifier">10.13039/501100003406</named-content>
        </funding-source>
        <award-id>269/31/2015</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Cancer Society of Finland</named-content>
          <named-content content-type="funder-identifier">10.13039/501100006383</named-content>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Emil Aaltonen Foundation</named-content>
          <named-content content-type="funder-identifier">10.13039/501100004756</named-content>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Finnish Foundation for Technology Promotion</named-content>
          <named-content content-type="funder-identifier">10.13039/501100005637</named-content>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">KAUTE Foundation</named-content>
          <named-content content-type="funder-identifier">10.13039/100009450</named-content>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Orion Research Foundation</named-content>
          <named-content content-type="funder-identifier">10.13039/501100007083</named-content>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Digitalization of pathology has been accelerated by improvements in technology allowing acquisition of whole slide images (WSI) (<xref rid="bty210-B15" ref-type="bibr">Ghaznavi <italic>et al.</italic>, 2013</xref>; <xref rid="bty210-B17" ref-type="bibr">Griffin and Treanor, 2017</xref>). Besides computer-aided facilitation of pathologists’ tasks, digital pathology can enable new approaches like 3D histology, where three-dimensional reconstructions of samples are formed <italic>in silico</italic> based on serial sections (<xref rid="bty210-B30" ref-type="bibr">Magee <italic>et al.</italic>, 2015</xref>; <xref rid="bty210-B38" ref-type="bibr">Roberts <italic>et al.</italic>, 2012</xref>). While other techniques allow imaging directly in 3D, they are currently incapable of matching the subcellular resolution and throughput of whole slide imaging. Examples of potential applications include construction of data-driven computer models and improved diagnostics of diseases associated with changes in the 3D microarchitecture of tissue. Moreover, 3D histology is compatible with established histopathological interpretation techniques and biochemical assays such as immunohistochemistry or <italic>in situ</italic> hybridization. This raises interesting prospects in view of recent advances in spatially resolved omics (<xref rid="bty210-B33" ref-type="bibr">Mignardi <italic>et al.</italic>, 2017</xref>; <xref rid="bty210-B49" ref-type="bibr">Ståhl <italic>et al.</italic>, 2016</xref>). Pairing imaging with genomic, epigenomic, transcriptomic and proteomic data in the spatial context of tissue holds great promise for pathology and other fields (<xref rid="bty210-B25" ref-type="bibr">Koos <italic>et al.</italic>, 2015</xref>). Taking a step further, this could be performed in 3D to truly probe the relationships between structural and functional features as well as the heterogeneity and interplay between different cell types in tumors, and significant projects are now pursuing these goals (<xref rid="bty210-B26" ref-type="bibr">Ledford, 2017</xref>; <xref rid="bty210-B41" ref-type="bibr">Rusk, 2016</xref>). These kind of approaches have already led to the creation of brain atlases (<xref rid="bty210-B1" ref-type="bibr">Amunts <italic>et al.</italic>, 2013</xref>; <xref rid="bty210-B21" ref-type="bibr">Johnson <italic>et al.</italic>, 2010</xref>; <xref rid="bty210-B27" ref-type="bibr">Lein <italic>et al.</italic>, 2007</xref>). Such high-dimensional data also represent an exciting challenge for new ways of scientific visualization based e.g. on virtual reality techniques (<xref rid="bty210-B7" ref-type="bibr">Calì <italic>et al.</italic>, 2016</xref>; <xref rid="bty210-B26" ref-type="bibr">Ledford, 2017</xref>; <xref rid="bty210-B53" ref-type="bibr">Theart <italic>et al.</italic>, 2017</xref>).</p>
    <p>Despite earlier computational and image acquisition bottlenecks (<xref rid="bty210-B38" ref-type="bibr">Roberts <italic>et al.</italic>, 2012</xref>), several algorithmic 3D histology solutions were already proposed before the recent developments in digital pathology (<xref rid="bty210-B23" ref-type="bibr">Ju <italic>et al.</italic>, 2006</xref>; <xref rid="bty210-B55" ref-type="bibr">Wang <italic>et al.</italic>, 2015</xref>). The key methodological problem is how to accurately register a sequence of 2D images to produce a 3D volume. Simply stacking the images does not result in a coherent volume due to differences between the relative locations and rotation angles of the sections and tissue deformations introduced during embedding and sectioning (<xref rid="bty210-B16" ref-type="bibr">Gibson <italic>et al.</italic>, 2013</xref>). Algorithms for image registration (<xref rid="bty210-B48" ref-type="bibr">Sotiras <italic>et al.</italic>, 2013</xref>) constitute the methodological basis of 3D histology. These algorithms are used to sequentially register each image with its neighbors to bring the entire series into alignment (<xref rid="bty210-B30" ref-type="bibr">Magee <italic>et al.</italic>, 2015</xref>; <xref rid="bty210-B55" ref-type="bibr">Wang <italic>et al.</italic>, 2015</xref>). Registration is accomplished by estimating transformations relating the images. Rigid transformations only allow translation and rotation of the entire image, while affine transformations are additionally able to model anisotropic scaling. Locally varying transformations, also called elastic models, can compensate for deformations on a local scale. Considering several nearby sections together (<xref rid="bty210-B42" ref-type="bibr">Saalfeld <italic>et al.</italic>, 2012</xref>) or applying regularization may be needed to obtain smooth, continuous 3D volumes (<xref rid="bty210-B9" ref-type="bibr">Casero <italic>et al.</italic>, 2017</xref>; <xref rid="bty210-B10" ref-type="bibr">Cifor <italic>et al.</italic>, 2011</xref>; <xref rid="bty210-B14" ref-type="bibr">Gaffling <italic>et al.</italic>, 2015</xref>; <xref rid="bty210-B23" ref-type="bibr">Ju <italic>et al.</italic>, 2006</xref>). After estimating the transformations, they need to be applied to the images via interpolation, which is possibly followed by postprocessing such as 3D visualization. Our focus is on the reconstruction step, which is usually the most difficult and crucial part of the image processing chain. Numerous approaches have been reported, relying on manual alignment (<xref rid="bty210-B35" ref-type="bibr">Onozato <italic>et al.</italic>, 2012</xref>; <xref rid="bty210-B36" ref-type="bibr">Paish <italic>et al.</italic>, 2009</xref>), semi-automatic methods using artificial landmarks (<xref rid="bty210-B20" ref-type="bibr">Hughes <italic>et al.</italic>, 2013</xref>; <xref rid="bty210-B40" ref-type="bibr">Rojas <italic>et al.</italic>, 2015</xref>) and automated algorithms (<xref rid="bty210-B3" ref-type="bibr">Arganda‐Carreras <italic>et al.</italic>, 2010</xref>; <xref rid="bty210-B5" ref-type="bibr">Braumann <italic>et al.</italic>, 2005</xref>; <xref rid="bty210-B9" ref-type="bibr">Casero <italic>et al.</italic>, 2017</xref>; <xref rid="bty210-B10" ref-type="bibr">Cifor <italic>et al.</italic>, 2011</xref>; <xref rid="bty210-B23" ref-type="bibr">Ju <italic>et al.</italic>, 2006</xref>; <xref rid="bty210-B30" ref-type="bibr">Magee <italic>et al.</italic>, 2015</xref>; <xref rid="bty210-B42" ref-type="bibr">Saalfeld <italic>et al.</italic>, 2012</xref>; <xref rid="bty210-B47" ref-type="bibr">Song <italic>et al.</italic>, 2013</xref>; <xref rid="bty210-B50" ref-type="bibr">Stille <italic>et al.</italic>, 2013</xref>; <xref rid="bty210-B56" ref-type="bibr">Xu <italic>et al.</italic>, 2015</xref>).</p>
    <p>Despite the widely acknowledged need for objective assessment of algorithms (<xref rid="bty210-B32" ref-type="bibr">Meijering <italic>et al.</italic>, 2016</xref>), an evaluation of modern computational methodology for 3D histology is lacking. Moreover, the common practice of relying only on visual inspections or a single indirect metric is insufficient (<xref rid="bty210-B39" ref-type="bibr">Rohlfing, 2012</xref>). The previous comparison of algorithms was published a decade ago and only included three basic approaches (<xref rid="bty210-B4" ref-type="bibr">Beare <italic>et al.</italic>, 2008</xref>). We have previously demonstrated a framework (<xref rid="bty210-B24" ref-type="bibr">Kartasalo <italic>et al.</italic>, 2016</xref>) based on a panel of indirect metrics and manually annotated landmarks allowing direct quantification of reconstruction accuracy (<xref rid="bty210-B39" ref-type="bibr">Rohlfing, 2012</xref>). In this study, we applied an extended version of the framework (see <xref ref-type="fig" rid="bty210-F1">Fig. 1</xref>) to address the problem of comparing algorithms for 3D histology. As the basis of our evaluation, we used two WSI datasets representing two different tissue types. One obstacle complicating both the application and fair comparison of most algorithms is sensitivity to various settings or hyperparameters, which typically have to be selected by the user based on rules of thumb and tuned via trial and error. Encouraged by their recent application in the context of digital pathology, we employed automated hyperparameter selection methods to adjust tunable parameters (<xref rid="bty210-B45" ref-type="bibr">Shahriari <italic>et al.</italic>, 2016</xref>; <xref rid="bty210-B52" ref-type="bibr">Teodoro <italic>et al.</italic>, 2017</xref>).
</p>
    <fig id="bty210-F1" orientation="portrait" position="float">
      <label>Fig. 1.</label>
      <caption>
        <p>Evaluation framework. A series of tissue images is input to a reconstruction method for registration. The transformations estimated by the method are re-applied to masks defining the tissue region and images containing landmarks. The registered tissue, mask and landmark images are used to evaluate reconstruction accuracy based on numerical metrics and visual examination. Moreover, tunable settings can be optimized. (Color version of this figure is available at <italic>Bioinformatics</italic> online.)</p>
      </caption>
      <graphic xlink:href="bty210f1"/>
    </fig>
    <p>As a baseline, we evaluated three basic methods: a least-squares fit to landmarks (LS), an optimization-based approach (OPT) and a method based on the Scale Invariant Feature Transform (SIFT) (<xref rid="bty210-B29" ref-type="bibr">Lowe, 2004</xref>). More advanced methods included the Fiji/ImageJ (<xref rid="bty210-B43" ref-type="bibr">Schindelin <italic>et al.</italic>, 2012</xref>; <xref rid="bty210-B44" ref-type="bibr">Schneider <italic>et al.</italic>, 2012</xref>) plugins HyperStackReg (HSR), which is an extension of StackReg (<xref rid="bty210-B54" ref-type="bibr">Thevenaz <italic>et al.</italic>, 1998</xref>), RegisterVirtualStackSlices (RVSS), which is based on bUnwarpJ (<xref rid="bty210-B2" ref-type="bibr">Arganda-Carreras <italic>et al.</italic>, 2006</xref>), and ElasticStackAlignment (ESA) (<xref rid="bty210-B42" ref-type="bibr">Saalfeld <italic>et al.</italic>, 2012</xref>), which is part of the TrakEM2 package (<xref rid="bty210-B8" ref-type="bibr">Cardona <italic>et al.</italic>, 2012</xref>). In addition, we evaluated two commercial tools: Medical Image Manager (MIM) (HeteroGenius Ltd, Leeds, UK) and Voloom (microDimensions GmbH, Munich, Germany). While LS, OPT, SIFT and HSR are based on global transformations, RVSS, ESA, MIM and Voloom use elastic models which make it possible to account for local tissue deformations. For a summary of the evaluated tools, see <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref>.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Data collection and preprocessing</title>
      <p>A murine prostate and a liver were fixed in PAXgene™ (PreAnalytiX GmbH, Hombrechtikon, Switzerland) and formalin, respectively, embedded in paraffin, and cut into serial 5 µm sections. The liver was processed with a laser prior to embedding in order to introduce artificial landmarks into the otherwise homogeneous tissue. Four holes were successfully introduced into the sample. The sections were hematoxylin-eosin (HE) stained and scanned at 20× (pixel size 0.46 µm) to obtain 260 (prostate) and 47 (liver) RGB images. The images were processed in MATLAB R2016b (The MathWorks Inc., Natick, MA, USA) to segment tissue from background and store the results as binary masks.</p>
      <p>A total of 2448 landmarks were manually annotated. In the prostatic tissue, four corresponding points preferably at the centers of bisected nuclei were selected by two observers from each pair of adjacent sections. For the liver, the four holes in each image were marked by the same two observers. Most of the evaluated methods do not allow direct application of transformations to coordinates but support re-applying them to another stack of images. Therefore, we stored the landmarks as images with four disks placed at the landmark locations, each consisting of red, green, blue or yellow pixels. Color is invariant to the applied transformations, allowing post-registration detection of the disks. The tissue, mask and landmark images were downsampled to different resolutions and stored as TIF. See <xref ref-type="supplementary-material" rid="sup1">Supplementary Methods</xref> for details.</p>
    </sec>
    <sec>
      <title>2.2 Evaluation of reconstruction accuracy</title>
      <sec>
        <title>2.2.1 Target registration error</title>
        <p>Pairwise target registration error (TRE) (<xref rid="bty210-B13" ref-type="bibr">Fitzpatrick <italic>et al.</italic>, 1998</xref>), a direct measure of registration accuracy (<xref rid="bty210-B39" ref-type="bibr">Rohlfing, 2012</xref>), was quantified for each pair of adjacent sections. From the landmark images, we detected each landmark based on the colors of the disks and obtained their coordinates as the centroids of the detected pixels. For <italic>N</italic> pairs of sections, TRE was measured for each point (<italic>j</italic> = {1, 2, 3, 4}) and section pair (<italic>i</italic> = {1, 2,…, <italic>N</italic>}) as:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:msub><mml:mrow><mml:mi>T</mml:mi><mml:mi>R</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>‖</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>‖</mml:mo></mml:mrow></mml:math></disp-formula>
that is, the Euclidean distance between the location <bold><italic>X</italic><sub><italic>j,i</italic></sub></bold> of point <italic>j</italic> on the section <italic>i</italic> and the location of the corresponding point on section <italic>i </italic>+<italic> </italic>1.</p>
      </sec>
      <sec>
        <title>2.2.2 Accumulated error</title>
        <p>Accumulated target registration error (ATRE) was calculated to quantify distortion accumulated through the stack, referred to as ‘the banana problem’ (<xref rid="bty210-B31" ref-type="bibr">Malandain <italic>et al.</italic>, 2004</xref>) or ‘the shear effect’ (<xref rid="bty210-B20" ref-type="bibr">Hughes <italic>et al.</italic>, 2013</xref>). Each landmark of the prostate dataset is only present on two consecutive sections and pairwise errors on different sections should thus be independent of each other. However, in the presence of accumulated errors, the error vectors on nearby sections are correlated (<xref rid="bty210-B4" ref-type="bibr">Beare <italic>et al.</italic>, 2008</xref>). We quantified this effect by treating the displacement of each landmark (<italic>j</italic> = {1, 2, 3, 4}) for each pair of sections (<italic>i</italic> = {1, 2,…, <italic>N</italic>}) in vector form as <inline-formula id="IE1"><mml:math id="IM1"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and averaging the four vectors to obtain the mean displacement of each entire section. We then computed the cumulative sum of these mean vectors, proceeding from section 1 to section <italic>N</italic>. For section <italic>k</italic>, ATRE was defined as the Euclidean norm of the cumulative displacement vector:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:msub><mml:mrow><mml:mi>A</mml:mi><mml:mi>T</mml:mi><mml:mi>R</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>‖</mml:mo><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>For the liver, a more direct quantification of ATRE was possible due to the landmarks extending through the sample. Ideally, the landmarks should lie on four parallel lines. In practice, parallelism could be violated due to slight movement of the sample between repeated applications of the laser. In a distorted volume, the landmarks deviate from the linear trajectories when proceeding through the stack. To measure this, we fitted a line in 3D to each of the four series of landmarks, minimizing mean squared error on the image plane. ATRE was then quantified for section <italic>i</italic> and landmark <italic>j</italic> as the Euclidean distance between the location of the landmark <bold><italic>X</italic><sub><italic>j,i</italic></sub></bold> and that of the fitted line <bold><italic>Y</italic><sub><italic>j,i</italic></sub></bold>, on the image plane:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mi>T</mml:mi><mml:mi>R</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>‖</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>‖</mml:mo></mml:mrow></mml:math></disp-formula></p>
      </sec>
      <sec>
        <title>2.2.3 Tissue shrinkage and overlap</title>
        <p>As certain reconstruction methods tend to shrink the tissue, relative change in tissue area (ΔA-%) was computed based on the tissue masks for each section. Overlap was quantified based on the masks for each section pair using the Jaccard index (<xref rid="bty210-B39" ref-type="bibr">Rohlfing, 2012</xref>). The Jaccard index can be considered a quality measure for pixel-wise metrics, as computing them for a pair of sections with little overlap can provide misleading results. Let <italic>A</italic> denote the set of tissue pixels of section <italic>i</italic> and <italic>B</italic> the set of tissue pixels of section <italic>i </italic>+<italic> </italic>1. The Jaccard index is defined as:
<disp-formula id="E4"><label>(4)</label><mml:math id="M4"><mml:msub><mml:mrow><mml:mi>J</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:mi>A</mml:mi><mml:mo>∩</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:mi>A</mml:mi><mml:mo>∪</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math></disp-formula></p>
      </sec>
      <sec>
        <title>2.2.4 Pixel-wise similarity</title>
        <p>For each section pair, we evaluated the similarity of corresponding pixels. After conversion to grayscale we computed the following measures: root mean squared error (RMSE), normalized cross correlation (NCC), mutual information (MI) and normalized mutual information (NMI) (<xref rid="bty210-B51" ref-type="bibr">Studholme <italic>et al.</italic>, 1999</xref>). Only the set of overlapping tissue pixels <italic>A</italic>∩<italic>B</italic> was considered. These indirect metrics provide information from the entire tissue area and complement the TRE evaluation.</p>
      </sec>
      <sec>
        <title>2.2.5 Reconstruction smoothness</title>
        <p>We quantified the smoothness of the reconstruction using contrast <italic>f<sub>2</sub></italic> and correlation <italic>f<sub>3</sub></italic> based on gray-level co-occurrence matrices (GLCMs) (<xref rid="bty210-B10" ref-type="bibr">Cifor <italic>et al.</italic>, 2011</xref>; <xref rid="bty210-B14" ref-type="bibr">Gaffling <italic>et al.</italic>, 2015</xref>; <xref rid="bty210-B18" ref-type="bibr">Haralick and Shanmugam, 1973</xref>). Low contrast and high correlation indicate a smooth reconstruction. We formed the GLCM for each pair of grayscale images based on pixels <italic>A</italic>∩<italic>B</italic> and summed them to obtain a single GLCM for the whole volume.</p>
      </sec>
    </sec>
    <sec>
      <title>2.3 3D reconstruction</title>
      <p><list list-type="bullet"><list-item><p>LS: Least-squares fitting of an affine transformation to the landmarks was implemented in MATLAB R2016b. The result is in principle unaffected by error accumulation (<xref rid="bty210-B56" ref-type="bibr">Xu <italic>et al.</italic>, 2015</xref>).</p></list-item><list-item><p>OPT: Optimization-based reconstruction implemented in MATLAB R2016b was used to estimate pairwise affine transformations by minimizing the value of pixel-wise MSE.</p></list-item><list-item><p>SIFT: Feature-based reconstruction was performed by computing SIFT keypoints (<xref rid="bty210-B29" ref-type="bibr">Lowe, 2004</xref>) for each image pair, establishing putative matches and robustly fitting an affine transformation to the point pairs (<xref rid="bty210-B12" ref-type="bibr">Fischler and Bolles, 1981</xref>). We used the RegisterVirtualStackSlices (<xref rid="bty210-B2" ref-type="bibr">Arganda-Carreras <italic>et al.</italic>, 2006</xref>) implementation in Fiji, also used as an initial step in RVSS and ESA.</p></list-item><list-item><p>HSR: HyperStackReg v. 5 (Ved P. Sharma, Albert Einstein College, <ext-link ext-link-type="uri" xlink:href="https://sites.google.com/site/vedsharma/imagej-plugins-macros/hyperstackreg">https://sites.google.com/site/vedsharma/imagej-plugins-macros/hyperstackreg</ext-link>) was run in Fiji to perform reconstruction using affine transformations.</p></list-item><list-item><p>RVSS: Elastic reconstruction based on the bUnwarpJ algorithm, which is a combination of SIFT and optimization based methods, was applied using the RegisterVirtualStackSlices plugin in Fiji.</p></list-item><list-item><p>ESA: The algorithm implemented in the ElasticStackAlignment plugin (<xref rid="bty210-B42" ref-type="bibr">Saalfeld <italic>et al.</italic>, 2012</xref>) was run via the TrakEM2 package (<xref rid="bty210-B8" ref-type="bibr">Cardona <italic>et al.</italic>, 2012</xref>) in Fiji to perform elastic reconstruction based on a combination of SIFT and optimization methods.</p></list-item><list-item><p>MIM: Medical Image Manager, trial v. 0.94, was applied using images subsampled by a factor of 4 (magnification of 5×) as input. Sections 130 and 24 were used as references for the prostate and liver, respectively. We varied the initial magnification (0.3125×, 0.625×, 1.25× or 2.5×) and the number of non-rigid levels (1, 2, 3 or 4), thus modifying the image resolution used.</p></list-item><list-item><p>Voloom: Trial v. 2.7.1 was used for elastic 3D reconstruction.</p></list-item></list>Fiji (<xref rid="bty210-B43" ref-type="bibr">Schindelin <italic>et al.</italic>, 2012</xref>; <xref rid="bty210-B44" ref-type="bibr">Schneider <italic>et al.</italic>, 2012</xref>) (v. 1.51h) plugins were run via ImageJ-MATLAB interface (v. 0.7.1) (<xref rid="bty210-B19" ref-type="bibr">Hiner <italic>et al.</italic>, 2016</xref>). Transformations were re-applied to the mask and landmark images. Output was saved as TIF. See <xref ref-type="supplementary-material" rid="sup1">Supplementary Methods</xref> for details.</p>
    </sec>
    <sec>
      <title>2.4 Parameter optimization</title>
      <p>In the case of MIM, which had to be operated interactively, we evaluated each combination of tunable values by a parameter sweep. Tunable parameters of the other methods were optimized via Bayesian optimization (<xref rid="bty210-B45" ref-type="bibr">Shahriari <italic>et al.</italic>, 2016</xref>; <xref rid="bty210-B46" ref-type="bibr">Snoek <italic>et al.</italic>, 2012</xref>), which is well-suited for such problems, where the objective function is computationally expensive to evaluate, nonconvex, multimodal, and typically has low to moderate dimensionality. Bayesian optimization has been shown to perform favorably in comparison to other global optimization algorithms on benchmarking functions (<xref rid="bty210-B22" ref-type="bibr">Jones, 2001</xref>) as well as on real WSI data (<xref rid="bty210-B52" ref-type="bibr">Teodoro <italic>et al.</italic>, 2017</xref>). We used MATLAB’s <italic>bayesopt</italic> implementation (<ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com/help/stats/bayesian-optimization-algorithm.html">https://www.mathworks.com/help/stats/bayesian-optimization-algorithm.html</ext-link>) with mean pairwise TRE as the objective function. We utilized a Gaussian process model of the objective function and an automatic relevance determination (ARD) Matérn 5/2 kernel (<xref rid="bty210-B46" ref-type="bibr">Snoek <italic>et al.</italic>, 2012</xref>) with ‘expected-improvement-plus’ as the acquisition function (<xref rid="bty210-B6" ref-type="bibr">Bull, 2011</xref>). Reconstructions with output image dimensions over fivefold compared to the input due to extreme error accumulation were considered failures. The number of variables to optimize was 2 (OPT), 4 (SIFT), 7 (RVSS) or 15 (ESA). We first optimized SIFT alone and used the optimal values for the SIFT step of RVSS and ESA. See <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref> for descriptions of the parameters. The number of seed points was set to twice the number of variables. We ran 30 iterations for OPT due to its simple objective function (<xref rid="bty210-B24" ref-type="bibr">Kartasalo <italic>et al.</italic>, 2016</xref>) and 100 iterations for the other tools. We used the prostate images subsampled by factors of 8 and 16, except for ESA, for which optimization was only feasible using the factor 16. Parameters optimized for ESA using the lower resolution were scaled to be used with the high resolution images. Computations were run on a workstation with Intel Xeon E5-1660 v3 3 GHz and 64 GB of RAM (low resolution) and a cluster node with Intel Xeon E5-2680 v3 2.5 GHz and 128 GB of RAM (high resolution).</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Effect of image resolution on evaluation metrics</title>
      <p>First, we analyzed whether our metrics depend on image resolution (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Results</xref>). TRE, ATRE, Jaccard and ΔA-% are essentially invariant to image resolution. They can be compared across different datasets and resolutions, as long as the accumulation of interpolation errors is avoided. RMSE, NCC, MI, NMI, <italic>f<sub>2</sub></italic> and <italic>f<sub>3</sub></italic> depend both on resolution and image content, and these metrics should thus only be compared within the same dataset and resolution. In all following analyses, we used images subsampled to pixel sizes of 7.36 and 3.68 µm, referred to as low and high resolution, respectively. The pixel sizes are close to the 5 µm section spacing and metrics computed from these images are not distorted by interpolation errors. Furthermore, we will only present RMSE as a measure of pixelwise similarity and <italic>f<sub>2</sub></italic> as a measure of reconstruction smoothness due to their strong correlations with NCC, MI, NMI and <italic>f<sub>3</sub></italic> (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref> for details).</p>
    </sec>
    <sec>
      <title>3.2 Automated parameter tuning</title>
      <p>Of the evaluated methods, LS, HSR and Voloom do not have tunable parameters. For OPT, SIFT, RVSS, ESA and MIM, we tuned the parameters automatically, minimizing the mean TRE computed for the prostate dataset. Parameter optimization took approximately 1500 hours in total to compute, producing 23 terabytes of data.</p>
      <p>The optimization mostly converged close to the final solution in a handful of iterations (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Results</xref>). By inspecting the variation in mean TRE values obtained during the process it is possible to reach a semi-quantitative view of the sensitivity of each method towards parameter adjustments. OPT and SIFT produced similar results for most parameter combinations while ESA, MIM and especially RVSS exhibited more sensitivity to parameter tuning.</p>
      <p>We evaluated possible connections between accuracy and computation time, which might require the user to make a trade-off when selecting parameters (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Results</xref>). The time taken by OPT varied only by a few minutes, except for the single inaccurate solutions where the parameters have not allowed proper convergence of the algorithm. For SIFT, there were no signs of a connection between accuracy and computation time. The differences in computation time between the fastest and slowest iterations of RVSS were roughly twofold and the fastest iterations were generally the ones with the highest error, indicating that minimizing the computation time of RVSS would sacrifice accuracy. In the case of ESA, the effect of parameter tuning was dramatic, leading to variation from approximately 12 min to more than 41 h. However, any clear relationship between computation time and accuracy was not observed.</p>
    </sec>
    <sec>
      <title>3.3 Comparison of algorithms based on the prostate dataset</title>
      <p>Results for the prostate dataset are listed in <xref rid="bty210-T1" ref-type="table">Table 1</xref>. The TRE values of LS based on landmarks by the two observers (LS1 and LS2) establish a baseline of accuracy. The case where the same landmarks were used for reconstruction and for calculating errors (LS1) is an optimistic estimate, representing the best accuracy reachable using an affine model. The errors calculated based on landmarks not used for reconstruction (LS2) represent a more realistic estimate of the accuracy of LS, serving as a cross-validation experiment between the two observers. The discrepancy between the optimistic and cross-validation results indicates that the LS solutions represent overfitting to the landmarks. Therefore, any methods with accuracy approaching LS can be regarded as highly accurate, since the other methods are not provided with any information concerning the landmarks. The systematic difference between TRE and ATRE calculated based on the two sets of landmarks (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref>) is due to the fact that the two observers were free to select different landmarks and the error is generally not constant over the entire tissue section. However, using either set of landmarks leads to the same conclusions regarding the relative accuracy of the methods, confirmed by linear correlation coefficients of approximately 0.999 for mean TRE, 0.995 for maximum TRE, 0.888 for mean ATRE and 0.901 for maximum ATRE between the two sets of landmarks for the low resolution reconstructions. This also holds for the high resolution with corresponding values of 0.999, 0.986, 0.894 and 0.922. This indicates that even though four landmarks per section pair represent a relatively sparse sampling of the entire tissue section area, this number of landmarks is sufficient for reliable error estimation.
<table-wrap id="bty210-T1" orientation="portrait" position="float"><label>Table 1.</label><caption><p>Evaluation results for the prostate data at low (top) and high resolution (bottom)</p></caption><table frame="hsides" rules="groups"><tbody><tr><td rowspan="1" colspan="1"><inline-graphic xlink:href="bty210ilf1.jpg"/></td></tr></tbody></table><table-wrap-foot><fn id="tblfn1"><p><italic>Note</italic>: Results for the unregistered images, LS based on landmarks by observer 1 (LS1) or 2 (LS2) and the automated methods (OPT, SIFT, HSR, RVSS, ESA, MIM, Voloom) using default or optimized parameters. Mean (μ), maximum (max) and standard deviation (σ) over all sections are shown. TRE and ATRE based on landmarks by observer 1 are in μm. In the online version, columns with TRE, ATRE, RMSE, <italic>f2</italic> and ΔA-% are colored from low (blue) to high values (red). Columns with Jaccard are colored from high (blue) to low values (red). (Color version of this table is available at <italic>Bioinformatics</italic> online.)</p></fn></table-wrap-foot></table-wrap></p>
      <p>All methods benefited from parameter tuning on both image resolutions based on most of the metrics, using either set of landmarks for evaluation (see <xref rid="bty210-T1" ref-type="table">Table 1</xref> and <xref ref-type="supplementary-material" rid="sup1">Supplementary Results</xref>). Of the top three methods, MIM and RVSS obtained better accuracy using high resolution images and ESA worked better on the low resolution images. ESA and MIM reached similar mean TRE values, slightly better than RVSS and approaching or exceeding the accuracy of LS. In terms of maximum TRE and ATRE, the three methods were comparable, but RVSS reached slightly lower ATRE than ESA or MIM. Among all tools, ESA and MIM also obtained the highest Jaccard index values. The RMSE and <italic>f<sub>2</sub></italic> metrics do not allow comparison across different image resolutions and one should note that MIM’s output was always stored at the lower resolution for technical reasons. Considering these limitations, we can observe that ESA performed best in terms of these metrics on both image resolutions ahead of RVSS. Changes in tissue area introduced by ESA, MIM and RVSS were moderate. Behind the top three, most other tools reached accuracy comparable to each other. The worst results were obtained using default parameters and for some methods, most notably ESA and RVSS, they were even comparable to the unregistered original images.</p>
      <p>Visual examination in 3D revealed differences in the geometry of the reconstructions formed using each of the methods (<xref ref-type="fig" rid="bty210-F2">Fig. 2</xref>). Compared to the undistorted reference (LS1), the distortions introduced by OPT, SIFT, HSR, ESA and MIM were a manifestation of the typical ‘banana-into-cylinder’ issue. This gradual straightening of curved structures is most clearly seen here in the displacement of the urethra at the top of the stacks. As indicated by the numerical ATRE values, the overall magnitude of this effect was rather similar across the tools. The distortions caused by RVSS and Voloom were more complex, representing clockwise twisting of the sample when seen from the top.
</p>
      <fig id="bty210-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>Reconstructions using (<bold>a</bold>) LS based on landmarks by observer 1, (<bold>b</bold>) OPT, (<bold>c</bold>) SIFT, (<bold>d</bold>) HSR, (<bold>e</bold>) RVSS, (<bold>f</bold>) ESA, (<bold>g</bold>) MIM and (<bold>h</bold>) Voloom. Optimized parameters and the most suitable resolution were used for each method. The dots represent the trajectory of accumulated target registration error from section to section. The horizontal lines indicate the direction and magnitude of the cumulative mean displacement of each section relative to the ideal error-free trajectory (vertical line). Magnified views are shown next to each reconstruction. Viewing the high-resolution color version of the Figure online is recommended. (Color version of this figure is available at <italic>Bioinformatics</italic> online.)</p>
        </caption>
        <graphic xlink:href="bty210f2"/>
      </fig>
    </sec>
    <sec>
      <title>3.4 Comparison of algorithms based on the liver dataset</title>
      <p>Results for the liver dataset are listed in <xref rid="bty210-T2" ref-type="table">Table 2</xref>. The four artificial landmarks were annotated by both observers and the two sets of TRE and ATRE values can be treated as replicates. This is reflected by linear correlation coefficients of approximately one (ranging from 0.99993 to 0.99998) for mean TRE, maximum TRE, mean ATRE and maximum ATRE calculated based on the two sets of landmarks (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref>). In this case, LS thus represents an optimistic estimate of the accuracy reachable with a global affine model. Compared to the prostate sample, this dataset is more challenging to reconstruct due to the more homogeneous appearance of the tissue and the presence of deformations such as folded and torn tissue. This is reflected by the metrics, which generally indicate higher errors, except for RMSE and <italic>f<sub>2</sub></italic> which are lower due to the more homogeneous image content. Ideally, it would be convenient to process different datasets without having to readjust parameters. With this in mind, we reused the parameters optimized for the prostate dataset, treating the evaluation on the liver dataset as an independent validation experiment. Based on most metrics, the optimized parameters generally resulted in an improvement over the default parameters also when applied to the liver dataset (see <xref rid="bty210-T2" ref-type="table">Table 2</xref> and <xref ref-type="supplementary-material" rid="sup1">Supplementary Results</xref>).
<table-wrap id="bty210-T2" orientation="portrait" position="float"><label>Table 2.</label><caption><p>Evaluation results for the liver data at low (top) and high resolution (bottom)</p></caption><table frame="hsides" rules="groups"><tbody><tr><td rowspan="1" colspan="1"><inline-graphic xlink:href="bty210ilf2.jpg"/></td></tr></tbody></table><table-wrap-foot><fn id="tblfn2"><p><italic>Note</italic>: Results for the unregistered images, LS based on landmarks by observer 1 (LS1) or 2 (LS2) and the automated methods (OPT, SIFT, HSR, RVSS, ESA, MIM, Voloom) using default or optimized parameters. Mean (μ), maximum (max) and standard deviation (σ) over all sections are shown. TRE and ATRE based on landmarks by observer 1 are in μm. In the online version, columns with TRE, ATRE, RMSE, <italic>f2</italic> and ΔA-% are colored from low (blue) to high values (red). Columns with Jaccard are colored from high (blue) to low values (red). (Color version of this table is available at <italic>Bioinformatics</italic> online.)</p></fn></table-wrap-foot></table-wrap></p>
      <p>As with the prostate, the lowest TRE values among the automated methods were achieved by ESA on the lower resolution and MIM on the high resolution data with RVSS being the third best method. The other methods reached TRE values comparable to each other. In terms of maximum TRE and ATRE, the conclusion was less clear. Voloom performed better on the lower resolution, reaching a maximum TRE second only to LS, while ESA and OPT also reached comparable values. On this dataset, MIM suffered from larger maximum errors compared to the higher quality prostate sample. The lowest mean ATRE values among all automated methods were obtained by ESA, MIM and Voloom, while in terms of maximum ATRE Voloom was superior to ESA and MIM. ESA was the top method in terms of RMSE and <italic>f<sub>2</sub></italic>, and MIM obtained the highest Jaccard index. Again, the poorest results were obtained when using the default values of tunable parameters.</p>
      <p>Visualization in 3D supported the numerical results (<xref ref-type="fig" rid="bty210-F3">Fig. 3</xref>). ESA, MIM and Voloom formed reconstructions with landmarks concentrated on four roughly parallel lines as expected, but some distortion is visible at the bottom part of the stack reconstructed by MIM. These kind of distortions were more severe in the case of OPT, SIFT, HSR and RVSS.
</p>
      <fig id="bty210-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>Reconstructions using (<bold>a</bold>) LS based on landmarks by observer 1, (<bold>b</bold>) OPT, (<bold>c</bold>) SIFT, (<bold>d</bold>) HSR, (<bold>e</bold>) RVSS, (<bold>f</bold>) ESA, (<bold>g</bold>) MIM and (<bold>h</bold>) Voloom. Optimized parameters and the most suitable resolution were used for each method. The locations of the four landmark points on each section are indicated with dots, shown together with lines of best fit to each of the four series of points. Note that the scale of the vertical axis is different from the horizontal axes in the visualization. Viewing the high-resolution color version of the Figure online is recommended. (Color version of this figure is available at <italic>Bioinformatics</italic> online.)</p>
        </caption>
        <graphic xlink:href="bty210f3"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>Based on this study, methods utilizing locally varying transformations (ESA, MIM, RVSS, Voloom) were superior to those constrained to global affine models (OPT, SIFT, HSR). ESA was the only method to consistently outperform or match the other approaches on two datasets based on the majority of metrics. In the case of the higher quality prostate dataset, differences in accuracy between the tools were rather subtle. All three top-performing methods on this dataset incorporate an elastic transformation model: MIM and RVSS use a B-spline grid and ESA is based on a piecewise linear mesh. While methods relying on a global transformation model also performed reasonably well, the additional accuracy offered by elastic transformations could be crucial when microstructure at the cellular scale is of interest. In the case of the liver sample, more profound differences between the methods were observed, likely due to the more challenging tissue content and the presence of deformations, which cannot be compensated for using a global model. ESA, MIM and Voloom stood out from the other methods. While Voloom appeared to be less accurate on average compared to ESA and MIM based on mean TRE, it demonstrated the lowest maximum and accumulated errors of all automated methods, indicating capability to avoid propagation of errors even in the presence of considerable deformations. The ability of the algorithms to tolerate such deformations is a significant benefit. Due to the mostly manual nature of histological sectioning and brittleness of the thin tissue sections, deformations in the form of folds and tears often occur. This challenge is especially encountered in 3D histology, when uninterrupted sequences of sections are desired.</p>
    <p>Another important property of algorithms to consider is sensitivity to adjustable parameters. Even an algorithm that produces highly accurate results with a carefully selected set of parameter values will be useless if the user has little chance of finding this set of values. Comparing algorithms from this perspective is difficult. Each algorithm has a different set of parameters and the range of values to evaluate has to be selected for each parameter, which can in turn affect the amount of variation observed in the results. Nevertheless, this study still provides a semi-quantitative view of the sensitivity of the studied algorithms against parameter adjustments. Of the evaluated methods, LS, HSR and Voloom are the most convenient due to their lack of tunable parameters. OPT and SIFT also produced similar results with most parameter values. The results produced by ESA varied greatly depending on parameters, but we discovered numerous combinations leading to almost optimal results. In the case of MIM, there are only a handful of tunable parameters and they are relatively easy to tune. Moreover, ESA and MIM appear to be well-behaving in the sense that parameters optimized for the prostate dataset also suited the liver dataset. In contrast, RVSS was found to be difficult to optimize and even though its accuracy using optimized settings was close to ESA and MIM on the prostate dataset, reaching this level of accuracy without automated parameter tuning would be challenging.</p>
    <p>An open question common to all of the methods is how image resolution affects reconstruction accuracy. A pixel size close to the section spacing is often recommended (<xref rid="bty210-B1" ref-type="bibr">Amunts <italic>et al.</italic>, 2013</xref>; <xref rid="bty210-B5" ref-type="bibr">Braumann <italic>et al.</italic>, 2005</xref>; <xref rid="bty210-B11" ref-type="bibr">Dauguet <italic>et al.</italic>, 2007</xref>; <xref rid="bty210-B23" ref-type="bibr">Ju <italic>et al.</italic>, 2006</xref>; <xref rid="bty210-B24" ref-type="bibr">Kartasalo <italic>et al.</italic>, 2016</xref>; <xref rid="bty210-B42" ref-type="bibr">Saalfeld <italic>et al.</italic>, 2012</xref>) based on the assumption that objects smaller than this are only visible on a single section and are thus not useful for registration, and may even introduce errors (<xref rid="bty210-B4" ref-type="bibr">Beare <italic>et al.</italic>, 2008</xref>). However, suitably oriented elongated structures such as blood vessels can be observed on several sections even if their diameter on the image plane is smaller than the section spacing. In principle, some algorithms might thus benefit from a smaller pixel size. We evaluated reconstruction accuracy using pixel sizes of 3.68 and 7.36 µm. Based on the rule of thumb above, it is unclear which one of these should be preferred given a section spacing of 5 µm. Our results indicate that using a pixel size close to the section spacing is a reasonable starting point, but the optimal image resolution depends on the algorithm and also somewhat on the image content. Furthermore, we cannot rule out the possibility that algorithms which performed better on the high resolution images, most notably MIM, might benefit from an even smaller pixel size. In conclusion, the image resolution thus needs to be selected experimentally for each application and algorithm.</p>
    <p>The two samples selected for this study are markedly different in their histological composition. The fact that the top methods performed well on both the prostate and the liver dataset without any retuning of parameters indicates that these methods are not overly sensitive to tissue appearance, and that the results obtained in this study are not specific to a single dataset. However, some variation in the relative performance of the algorithms on the two datasets was still observed. Thus, collecting and annotating additional datasets representing diverse tissue types and other histological stainings, such as immunohistochemistry, remains an important goal for future studies.</p>
    <p>While we evaluated a comprehensive set of methods for 3D histology, it might be worthwhile to adapt general-purpose image registration algorithms to this context. Another opportunity, not supported by any of the methods here, could be the exploitation of additional data obtained e.g. by magnetic resonance imaging or in the form of blockface images (<xref rid="bty210-B1" ref-type="bibr">Amunts <italic>et al.</italic>, 2013</xref>; <xref rid="bty210-B9" ref-type="bibr">Casero <italic>et al.</italic>, 2017</xref>; <xref rid="bty210-B11" ref-type="bibr">Dauguet <italic>et al.</italic>, 2007</xref>; <xref rid="bty210-B16" ref-type="bibr">Gibson <italic>et al.</italic>, 2013</xref>; <xref rid="bty210-B21" ref-type="bibr">Johnson <italic>et al.</italic>, 2010</xref>; <xref rid="bty210-B50" ref-type="bibr">Stille <italic>et al.</italic>, 2013</xref>). Furthermore, although advances in image acquisition and processing have enabled the first steps towards 3D histology, sample preparation still constitutes a significant bottleneck. In the future, emerging technologies for automated sample preparation (<xref rid="bty210-B34" ref-type="bibr">Onozato <italic>et al.</italic>, 2011</xref>) or integrated sectioning and imaging (<xref rid="bty210-B28" ref-type="bibr">Li <italic>et al.</italic>, 2010</xref>; <xref rid="bty210-B37" ref-type="bibr">Ragan <italic>et al.</italic>, 2012</xref>) might potentially transform 3D histology into a high-throughput process.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>Supplementary Data</label>
      <media xlink:href="bty210_supp.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank Ignacio Arganda-Carreras, Martin Groher, Derek Magee, Stephan Saalfeld and Ved Sharma for their helpful advice. Katja Liljeström, Marja Pirinen and Marika Vähä-Jaakkola are acknowledged for skillful technical assistance.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by Academy of Finland [269474]; Tekes [269/31/2015]; Cancer Society of Finland; Emil Aaltonen Foundation; Finnish Foundation for Technology Promotion; KAUTE Foundation; and Orion Research Foundation.</p>
      <p><italic>Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="bty210-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Amunts</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>BigBrain: an ultrahigh-resolution 3D human brain model</article-title>. <source>Science</source>, <volume>340</volume>, <fpage>1472</fpage>–<lpage>1475</lpage>.<pub-id pub-id-type="pmid">23788795</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Arganda-Carreras</surname><given-names>I.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) Consistent and elastic registration of histological sections using vector-spline regularization. In: <italic>International Workshop on Computer Vision Approaches to Medical Image Analysis</italic>, pp. <fpage>85</fpage>–<lpage>95</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Arganda‐Carreras</surname><given-names>I.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>3D reconstruction of histological sections: application to mammary gland tissue</article-title>. <source>Microsci. Res. Technol</source>., <volume>73</volume>, <fpage>1019</fpage>–<lpage>1029</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Beare</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>An assessment of methods for aligning two-dimensional microscope sections to create image volumes</article-title>. <source>J. Neurosci. Methods</source>, <volume>170</volume>, <fpage>332</fpage>–<lpage>344</lpage>.<pub-id pub-id-type="pmid">18321589</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Braumann</surname><given-names>U.</given-names></name></person-group><etal>et al</etal> (<year>2005</year>) 
<article-title>Three-dimensional reconstruction and quantification of cervical carcinoma invasion fronts from histological serial sections</article-title>. <source>IEEE Trans. Med. Imaging</source>, <volume>24</volume>, <fpage>1286</fpage>–<lpage>1307</lpage>.<pub-id pub-id-type="pmid">16229416</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bull</surname><given-names>A.D.</given-names></name></person-group> (<year>2011</year>) 
<article-title>Convergence rates of efficient global optimization algorithms</article-title>. <source>J. Mach. Learn. Res</source>., <volume>12</volume>, <fpage>2879</fpage>–<lpage>2904</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Calì</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Three‐dimensional immersive virtual reality for studying cellular compartments in 3D models from EM preparations of neural tissues</article-title>. <source>J. Comp. Neurol</source>., <volume>524</volume>, <fpage>23</fpage>–<lpage>38</lpage>.<pub-id pub-id-type="pmid">26179415</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cardona</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>TrakEM2 software for neural circuit reconstruction</article-title>. <source>PloS One</source>, <volume>7</volume>, <fpage>e38011.</fpage><pub-id pub-id-type="pmid">22723842</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Casero</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Transformation diffusion reconstruction of three-dimensional histology volumes from two-dimensional image stacks</article-title>. <source>Med. Image Anal</source>., <volume>38</volume>, <fpage>184</fpage>–<lpage>204</lpage>.<pub-id pub-id-type="pmid">28411458</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cifor</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Smoothness-guided 3-D reconstruction of 2-D histological images</article-title>. <source>Neuroimage</source>, <volume>56</volume>, <fpage>197</fpage>–<lpage>211</lpage>.<pub-id pub-id-type="pmid">21277374</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dauguet</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>Three-dimensional reconstruction of stained histological slices and 3D non-linear registration with in-vivo MRI for whole baboon brain</article-title>. <source>J. Neurosci. Methods</source>, <volume>164</volume>, <fpage>191</fpage>–<lpage>204</lpage>.<pub-id pub-id-type="pmid">17560659</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fischler</surname><given-names>M.A.</given-names></name>, <name name-style="western"><surname>Bolles</surname><given-names>R.C.</given-names></name></person-group> (<year>1981</year>) 
<article-title>Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography</article-title>. <source>Commun. ACM</source>, <volume>24</volume>, <fpage>381</fpage>–<lpage>395</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fitzpatrick</surname><given-names>J.M.</given-names></name></person-group><etal>et al</etal> (<year>1998</year>) 
<article-title>Predicting error in rigid-body point-based registration</article-title>. <source>IEEE Trans. Med. Imaging</source>, <volume>17</volume>, <fpage>694</fpage>–<lpage>702</lpage>.<pub-id pub-id-type="pmid">9874293</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gaffling</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>A Gauss-Seidel iteration scheme for reference-free 3-D histological image reconstruction</article-title>. <source>IEEE Trans. Med. Imaging</source>, <volume>34</volume>, <fpage>514</fpage>–<lpage>530</lpage>.<pub-id pub-id-type="pmid">25312918</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ghaznavi</surname><given-names>F.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Digital imaging in pathology: whole-slide imaging and beyond</article-title>. <source>Annu. Rev. Pathol.-Mech</source>., <volume>8</volume>, <fpage>331</fpage>–<lpage>359</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gibson</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>3D prostate histology image reconstruction: quantifying the impact of tissue deformation and histology section location</article-title>. <source>J. Path. Inform</source>., <volume>4</volume>, <fpage>31</fpage>.<pub-id pub-id-type="pmid">24392245</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Griffin</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Treanor</surname><given-names>D.</given-names></name></person-group> (<year>2017</year>) 
<article-title>Digital pathology in clinical use: where are we now and what is holding us back?</article-title><source>Histopathology</source>, <volume>70</volume>, <fpage>134</fpage>–<lpage>145</lpage>.<pub-id pub-id-type="pmid">27960232</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Haralick</surname><given-names>R.M.</given-names></name>, <name name-style="western"><surname>Shanmugam</surname><given-names>K.</given-names></name></person-group> (<year>1973</year>) 
<article-title>Textural features for image classification</article-title>. <source>IEEE Trans. Syst. Man Cybern</source>., <volume>3</volume>, <fpage>610</fpage>–<lpage>621</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hiner</surname><given-names>M.C.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>ImageJ-MATLAB: a bidirectional framework for scientific image analysis interoperability</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>629</fpage>–<lpage>630</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hughes</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Robust alignment of prostate histology slices with quantified accuracy</article-title>. <source>IEEE Trans. Biomed. Eng</source>., <volume>60</volume>, <fpage>281</fpage>–<lpage>291</lpage>.<pub-id pub-id-type="pmid">23144026</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Johnson</surname><given-names>G.A.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Waxholm space: an image-based reference for coordinating mouse brain research</article-title>. <source>Neuroimage</source>, <volume>53</volume>, <fpage>365</fpage>–<lpage>372</lpage>.<pub-id pub-id-type="pmid">20600960</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jones</surname><given-names>D.R.</given-names></name></person-group> (<year>2001</year>) 
<article-title>A taxonomy of global optimization methods based on response surfaces</article-title>. <source>J. Global. Optim</source>., <volume>21</volume>, <fpage>345</fpage>–<lpage>383</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ju</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>3D volume reconstruction of a mouse brain from histological sections using warp filtering</article-title>. <source>J. Neurosci. Methods</source>, <volume>156</volume>, <fpage>84</fpage>–<lpage>100</lpage>.<pub-id pub-id-type="pmid">16580732</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B24">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Kartasalo</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) Benchmarking of algorithms for 3D tissue reconstruction. In: <italic>2016 IEEE International Conference on Image Processing (ICIP)</italic>, pp. <fpage>2360</fpage>–<lpage>2364</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Koos</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Next-generation pathology—surveillance of tumor microecology</article-title>. <source>J. Mol. Biol</source>., <volume>427</volume>, <fpage>2013</fpage>–<lpage>2022</lpage>.<pub-id pub-id-type="pmid">25725260</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ledford</surname><given-names>H.</given-names></name></person-group> (<year>2017</year>) 
<article-title>Cell atlases race to map the body</article-title>. <source>Nature</source>, <volume>542</volume>, <fpage>404</fpage>–<lpage>405</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lein</surname><given-names>E.S.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>Genome-wide atlas of gene expression in the adult mouse brain</article-title>. <source>Nature</source>, <volume>445</volume>, <fpage>168</fpage>–<lpage>176</lpage>.<pub-id pub-id-type="pmid">17151600</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Micro-optical sectioning tomography to obtain a high-resolution atlas of the mouse brain</article-title>. <source>Science</source>, <volume>330</volume>, <fpage>1404</fpage>–<lpage>1408</lpage>.<pub-id pub-id-type="pmid">21051596</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lowe</surname><given-names>D.G.</given-names></name></person-group> (<year>2004</year>) 
<article-title>Distinctive image features from scale-invariant keypoints</article-title>. <source>Int. J. Comput. Vis</source>., <volume>60</volume>, <fpage>91</fpage>–<lpage>110</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Magee</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Histopathology in 3D: from three-dimensional reconstruction to multi-stain and multi-modal analysis</article-title>. <source>J. Path. Inform</source>., <volume>6</volume>, <fpage>6</fpage>.<pub-id pub-id-type="pmid">25774317</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Malandain</surname><given-names>G.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>) 
<article-title>Fusion of autoradiographs with an MR volume using 2-D and 3-D linear transformations</article-title>. <source>Neuroimage</source>, <volume>23</volume>, <fpage>111</fpage>–<lpage>127</lpage>.<pub-id pub-id-type="pmid">15325358</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Meijering</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Imagining the future of bioimage analysis</article-title>. <source>Nat. Biotechnol</source>., <volume>34</volume>, <fpage>1250</fpage>–<lpage>1255</lpage>.<pub-id pub-id-type="pmid">27926723</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mignardi</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Bridging histology and bioinformatics—computational analysis of spatially resolved transcriptomics</article-title>. <source>Proc. IEEE</source>, <volume>105</volume>, <fpage>530</fpage>–<lpage>541</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Onozato</surname><given-names>M.L.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Evaluation of a completely automated tissue-sectioning machine for paraffin blocks</article-title>. <source>J. Clin. Pathol</source>., <fpage>200205</fpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Onozato</surname><given-names>M.L.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>A role of three-dimensional (3D)-reconstruction in the classification of lung adenocarcinoma</article-title>. <source>Anal. Cell. Pathol</source>., <volume>35</volume>, <fpage>79</fpage>–<lpage>84</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Paish</surname><given-names>E.C.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Three-dimensional reconstruction of sentinel lymph nodes with metastatic breast cancer indicates three distinct patterns of tumour growth</article-title>. <source>J. Clin. Pathol</source>., <volume>62</volume>, <fpage>617</fpage>–<lpage>623</lpage>.<pub-id pub-id-type="pmid">19304588</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ragan</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>Serial two-photon tomography for automated ex vivo mouse brain imaging</article-title>. <source>Nat. Methods</source>, <volume>9</volume>, <fpage>255</fpage>–<lpage>258</lpage>.<pub-id pub-id-type="pmid">22245809</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Roberts</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>Toward routine use of 3D histopathology as a research tool</article-title>. <source>Am. J. Pathol</source>., <volume>180</volume>, <fpage>1835</fpage>–<lpage>1842</lpage>.<pub-id pub-id-type="pmid">22490922</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rohlfing</surname><given-names>T.</given-names></name></person-group> (<year>2012</year>) 
<article-title>Image similarity and tissue overlaps as surrogates for image registration accuracy: widely used but unreliable</article-title>. <source>IEEE Trans. Med. Imaging</source>, <volume>31</volume>, <fpage>153</fpage>–<lpage>163</lpage>.<pub-id pub-id-type="pmid">21827972</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rojas</surname><given-names>K.D.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Methodology to study the three-dimensional spatial distribution of prostate cancer and their dependence on clinical parameters</article-title>. <source>J. Med. Imaging</source>, <volume>2</volume>, <fpage>037502</fpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rusk</surname><given-names>N.</given-names></name></person-group> (<year>2016</year>) 
<article-title>Genomics: spatial transcriptomics</article-title>. <source>Nat. Methods</source>, <volume>13</volume>, <fpage>710</fpage>–<lpage>711</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Saalfeld</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>Elastic volume reconstruction from series of ultra-thin microscopy sections</article-title>. <source>Nat. Methods</source>, <volume>9</volume>, <fpage>717</fpage>–<lpage>720</lpage>.<pub-id pub-id-type="pmid">22688414</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schindelin</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>Fiji: an open-source platform for biological-image analysis</article-title>. <source>Nat. Methods</source>, <volume>9</volume>, <fpage>676</fpage>–<lpage>682</lpage>.<pub-id pub-id-type="pmid">22743772</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schneider</surname><given-names>C.A.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>NIH Image to ImageJ: 25 years of image analysis</article-title>. <source>Nat. Methods</source>, <volume>9</volume>, <fpage>671.</fpage><pub-id pub-id-type="pmid">22930834</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shahriari</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Taking the human out of the loop: a review of bayesian optimization</article-title>. <source>Proc. IEEE</source>, <volume>104</volume>, <fpage>148</fpage>–<lpage>175</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Snoek</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>Practical Bayesian optimization of machine learning algorithms</article-title>. <source>Adv. Neurol. Int</source>., <fpage>2951</fpage>–<lpage>2959</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Song</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>3D reconstruction of multiple stained histology images</article-title>. <source>J. Path. Inform</source>., <volume>4</volume>, <fpage>7</fpage>.<pub-id pub-id-type="pmid">23869286</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sotiras</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Deformable medical image registration: a survey</article-title>. <source>IEEE Trans. Med. Imaging</source>, <volume>32</volume>, <fpage>1153</fpage>–<lpage>1190</lpage>.<pub-id pub-id-type="pmid">23739795</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ståhl</surname><given-names>P.L.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Visualization and analysis of gene expression in tissue sections by spatial transcriptomics</article-title>. <source>Science</source>, <volume>353</volume>, <fpage>78</fpage>–<lpage>82</lpage>.<pub-id pub-id-type="pmid">27365449</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B50">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stille</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>3D reconstruction of 2D fluorescence histology images and registration with in vivo MR images: application in a rodent stroke model</article-title>. <source>J. Neurosci. Methods</source>, <volume>219</volume>, <fpage>27</fpage>–<lpage>40</lpage>.<pub-id pub-id-type="pmid">23816399</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B51">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Studholme</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>1999</year>) 
<article-title>An overlap invariant entropy measure of 3D medical image alignment</article-title>. <source>Pattern Recognit</source>., <volume>32</volume>, <fpage>71</fpage>–<lpage>86</lpage>.</mixed-citation>
    </ref>
    <ref id="bty210-B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Teodoro</surname><given-names>G.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Algorithm sensitivity analysis and parameter tuning for tissue image segmentation pipelines</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>1064</fpage>–<lpage>1072</lpage>.<pub-id pub-id-type="pmid">28062445</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B53">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Theart</surname><given-names>R.P.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Virtual reality assisted microscopy data visualization and colocalization analysis</article-title>. <source>BMC Bioinformatics</source>, <volume>18</volume>, <fpage>64.</fpage><pub-id pub-id-type="pmid">28251867</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B54">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Thevenaz</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>1998</year>) 
<article-title>A pyramid approach to subpixel registration based on intensity</article-title>. <source>IEEE Trans. Image Process</source>, <volume>7</volume>, <fpage>27</fpage>–<lpage>41</lpage>.<pub-id pub-id-type="pmid">18267377</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B55">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Three-dimensional reconstruction of light microscopy image sections: present and future</article-title>. <source>Front. Med</source>., <volume>9</volume>, <fpage>30</fpage>–<lpage>45</lpage>.<pub-id pub-id-type="pmid">24952302</pub-id></mixed-citation>
    </ref>
    <ref id="bty210-B56">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Xu</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>A method for 3D histopathology reconstruction supporting mouse microvasculature analysis</article-title>. <source>PloS One</source>, <volume>10</volume>, <fpage>e0126817</fpage>.<pub-id pub-id-type="pmid">26024221</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
