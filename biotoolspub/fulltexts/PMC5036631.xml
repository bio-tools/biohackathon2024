<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Biophysics (Nagoya-shi)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Biophysics (Nagoya-shi)</journal-id>
    <journal-title-group>
      <journal-title>Biophysics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1349-2942</issn>
    <publisher>
      <publisher-name>The Biophysical Society of Japan (BSJ)</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">5036631</article-id>
    <article-id pub-id-type="doi">10.2142/biophysics.1.67</article-id>
    <article-id pub-id-type="publisher-id">1_67</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Articles</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Predicting secondary structures, contact numbers, and residue-wise contact orders of native protein structures from amino acid sequences using critical random networks</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Kinjo</surname>
          <given-names>Akira R.</given-names>
        </name>
        <xref ref-type="aff" rid="af1-1_67">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="af2-1_67">
          <sup>2</sup>
        </xref>
        <xref rid="c1-1_67" ref-type="corresp"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Nishikawa</surname>
          <given-names>Ken</given-names>
        </name>
        <xref ref-type="aff" rid="af1-1_67">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="af2-1_67">
          <sup>2</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="af1-1_67"><label>1</label>Center for Information Biology and DNA Data Bank of Japan, National Institute of Genetics, Mishima 411-8540, Japan</aff>
    <aff id="af2-1_67"><label>2</label>Department of Genetics, The Graduate University for Advanced Studies (SOKENDAI), Mishima 411-8540, Japan</aff>
    <author-notes>
      <corresp id="c1-1_67">Corresponding author: Akira R. Kinjo, Center for Information Biology and DNA Data Bank of Japan, National Institute of Genetics, Mishima, Shizuoka 411-8540, Japan. e-mail: <email>akinjo@genes.nig.ac.jp</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2005</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>22</day>
      <month>11</month>
      <year>2005</year>
    </pub-date>
    <volume>1</volume>
    <fpage>67</fpage>
    <lpage>74</lpage>
    <history>
      <date date-type="received">
        <day>22</day>
        <month>7</month>
        <year>2005</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>10</month>
        <year>2005</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>2005 © The Biophysical Society of Japan</copyright-statement>
      <copyright-year>2005</copyright-year>
    </permissions>
    <abstract>
      <p>Predictions of one-dimensional protein structures such as secondary structures and contact numbers are useful for predicting three-dimensional structure and important for understanding the sequence-structure relationship. Here we present a new machine-learning method, critical random networks (CRNs), for predicting one-dimensional structures, and apply it, with position-specific scoring matrices, to the prediction of secondary structures (SS), contact numbers (CN), and residue-wise contact orders (RWCO). The present method achieves, on average, <italic>Q</italic><sub>3</sub> accuracy of 77.8% for SS, and correlation coefficients of 0.726 and 0.601 for CN and RWCO, respectively. The accuracy of the SS prediction is comparable to that obtained with other state-of-the-art methods, and accuracy of the CN prediction is a significant improvement over that with previous methods. We give a detailed formulation of the critical random networks-based prediction scheme, and examine the context-dependence of prediction accuracies. In order to study the nonlinear and multi-body effects, we compare the CRNs-based method with a purely linear method based on position-specific scoring matrices. Although not superior to the CRNs-based method, the surprisingly good accuracy achieved by the linear method highlights the difficulty in extracting structural features of higher order from an amino acid sequence beyond the information provided by the position-specific scoring matrices.</p>
    </abstract>
    <kwd-group>
      <kwd>protein structure prediction</kwd>
      <kwd>one-dimensional structure</kwd>
      <kwd>position-specific scoring matrix</kwd>
      <kwd>critical random network</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <p>Predicting the three-dimensional structure of a protein from its amino acid sequence is an essential step toward achieving a thorough bottom-up understanding of complex biological phenomena. Recently, much progress has been made in developing so-called <italic>ab initio</italic> or <italic>de novo</italic> structure prediction methods<xref rid="b1-1_67" ref-type="bibr">1</xref>. In the standard approach to <italic>de novo</italic> structure predictions, a protein is represented as a physical object in three-dimensional (3D) space, and the global minimum of free energy surface is sought with a given force-field or a set of scoring functions. In the minimization process, structural features predicted from the amino acid sequence may be used as restraints to limit the conformational space to be sampled. Such structural features include so-called one-dimensional (1D) structures of proteins.</p>
  <p>Protein 1D structures are 3D structural features projected onto strings of residue-wise structural assignments along the amino acid sequence<xref rid="b2-1_67" ref-type="bibr">2</xref>. For example, a string of secondary structures is a 1D structure. Other 1D structures include (solvent) accessibilities<xref rid="b3-1_67" ref-type="bibr">3</xref>, contact numbers<xref rid="b4-1_67" ref-type="bibr">4</xref> and recently introduced residue-wise contact orders<xref rid="b5-1_67" ref-type="bibr">5</xref>. The contact number, also referred to as the coordination number or Ooi number<xref rid="b6-1_67" ref-type="bibr">6</xref>, of a residue is the number of contacts that the residue makes with other residues in the native 3D structure, while the residue-wise contact order of a residue is the sum of sequence separations between that residue and contacting residues. We have recently shown that it is possible to reconstruct the native 3D structure of a protein from a set of three types of native 1D structures, namely secondary structures (SS), contact numbers (CN), and residue-wise contact orders (RWCO)<xref rid="b5-1_67" ref-type="bibr">5</xref>. Therefore, these 1D structures contain rich information regarding the corresponding 3D structure, and their accurate prediction may be very helpful for predicting 3D structure.</p>
  <p>Previously, we have developed a simple linear method of predicting contact numbers from the amino acid sequence<xref rid="b4-1_67" ref-type="bibr">4</xref>. Use of a multiple sequence alignment was shown to improve the accuracy of prediction, achieving an average correlation coefficient of 0.63 between predicted and observed contact numbers per protein. There, we used an amino acid frequency table obtained from the HSSP<xref rid="b7-1_67" ref-type="bibr">7</xref> multiple sequence alignment.</p>
  <p>In this paper, we build on the previous method by introducing a new framework called critical random networks (CRNs), and apply it to the prediction of secondary structures and residue-wise contact orders in addition to contact numbers. In this framework, a state vector of large dimension is associated with each site of a target sequence. The state vectors are connected via random nearest-neighbor interactions. The value of the state vector is determined by solving an equation of state. Then a 1D quantity of each site is predicted as a linear function of the state vector of the site as well as the corresponding local PSSM segment. This approach was inspired by the method of echo state networks (ESNs) which has been recently developed and successfully applied to complex time series analysis<xref rid="b8-1_67" ref-type="bibr">8</xref>,<xref rid="b9-1_67" ref-type="bibr">9</xref>. Unlike ESNs which treat an infinite series of input signals in one direction (from the past to the future), CRNs treat finite systems incorporating both up- and downstream information at the same time. Also, the so-called echo state property is not imposed on a network, but the system is instead set at a critical point of the network. As the input for the CRNs-based prediction, we employ position-specific scoring matrices (PSSMs) generated by PSI-BLAST<xref rid="b10-1_67" ref-type="bibr">10</xref>. With the combination of PSSMs and CRNs, accurate predictions of SS, CN and RWCO have been achieved.</p>
  <p>Currently, almost all the accurate methods for one-dimensional structure predictions combine some kind of sophisticated machine-learning approach such as neural networks and support vector machines with PSSMs. The method presented here is no exception. This trend raises the question as to what extent the machine-learning approaches are effective. In this study, we address this issue by comparing the CRNs-based method with a purely linear method based on PSSMs. Although not as good as the CRNs-based method, the linear predictions are of surprisingly high quality. This result suggests that, although not insignificant, the effect of the machine-learning approaches is relatively of minor importance while the use of PSSMs is the most significant ingredient in one-dimensional structure prediction. The problem of how to effectively extract meaningful information from the amino acid sequence beyond that provided by PSSMs requires yet further study.</p>
  <sec sec-type="methods">
    <title>Materials and methods</title>
    <sec>
      <title>Definition of 1D structures</title>
      <sec>
        <title>Secondary structures (SS).</title>
        <p>Secondary structures were defined by the DSSP program<xref rid="b11-1_67" ref-type="bibr">11</xref>. For three-state SS prediction, the simple encoding scheme was employed. That is, <italic>α</italic> helices (<italic>H</italic>), <italic>β</italic> strands (<italic>E</italic>), and other structures (“coils”) defined by DSSP were encoded as <italic>H</italic>, <italic>E</italic>, and <italic>C</italic>, respectively. For SS prediction, we introduce feature variables (<italic>y<sub>i</sub><sup>H</sup></italic>, <italic>y<sub>i</sub><sup>E</sup></italic>, <italic>y<sub>i</sub><sup>C</sup></italic>) to represent each type of secondary structure at the <italic>i</italic>-th residue position, so that <italic>H</italic> is represented as (1, −1, −1), <italic>E</italic> as (−1, 1, −1), and <italic>C</italic> as (−1, −1, 1).</p>
      </sec>
      <sec>
        <title>Contact numbers (CN).</title>
        <p>Let <italic>C<sub>i</sub></italic><sub>,</sub><italic><sub>j</sub></italic> represent the contact map of a protein. Usually, the contact map is defined so that <italic>C<sub>i</sub></italic><sub>,</sub><italic><sub>j</sub></italic>= 1 if the <italic>i</italic>-th and <italic>j</italic>-th residues are in contact by some definition, or <italic>C<sub>i</sub></italic><sub>,</sub><italic><sub>j</sub></italic>= 0, otherwise. As in our previous study, we slightly modify the definition using a sigmoid function. That is,
<disp-formula id="FD1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> where <italic>r<sub>i,j</sub></italic> is the distance between <italic>C<sub>β</sub></italic> (<italic>C<sub>α</sub></italic> for glycines) atoms of the <italic>i</italic>-th and <italic>j</italic>-th residues, <italic>d</italic>=12 Å is a cutoff distance, and <italic>w</italic> is a sharpness parameter of the sigmoid function which is set to 3<xref rid="b4-1_67" ref-type="bibr">4</xref>,<xref rid="b5-1_67" ref-type="bibr">5</xref>. The rather generous cutoff length of 12 Å was shown to optimize the prediction accuracy<xref rid="b4-1_67" ref-type="bibr">4</xref>. The use of the sigmoid function enables us to use the contact numbers in molecular dynamic simulations<xref rid="b5-1_67" ref-type="bibr">5</xref>. Using the above definition of the contact map, the contact number of the <italic>i</italic>-th residue of a protein is defined as
<disp-formula id="FD2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mover accent="true"><mml:mo>:</mml:mo><mml:mo>˙</mml:mo></mml:mover><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>j</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula> The feature variable <italic>y<sub>i</sub></italic> for CN is defined as <italic>y<sub>i</sub></italic>= <italic>n<sub>i</sub></italic>/log <italic>L</italic> where <italic>L</italic> is the sequence length of a target protein. The normalization factor log <italic>L</italic> is introduced because we have observed that the contact number averaged over a protein chain is roughly proportional to log <italic>L</italic>, and thus division by this value removes the size-dependence of predicted contact numbers.</p>
      </sec>
      <sec>
        <title>Residue-wise contact orders (RWCO).</title>
        <p>RWCOs were first introduced in Kinjo and Nishikawa<xref rid="b5-1_67" ref-type="bibr">5</xref>. Using the same notation as for contact numbers (see above), the RWCO of the <italic>i</italic>-th residue in a protein structure is defined by
<disp-formula id="FD3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mover accent="true"><mml:mo>:</mml:mo><mml:mo>˙</mml:mo></mml:mover><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>j</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> The feature variable <italic>y<sub>i</sub></italic> for RWCO is defined as <italic>y<sub>i</sub></italic>= <italic>o<sub>i</sub></italic>/<italic>L</italic> where <italic>L</italic> is the sequence length. Due to a similar reason as for CN, the normalization factor <italic>L</italic> was introduced to remove the size-dependence of the predicted RWCOs (the RWCO averaged over a protein chain is roughly proportional to the chain length).</p>
      </sec>
    </sec>
    <sec>
      <title>Linear regression scheme</title>
      <p>The input to the prediction scheme we develop in this paper is a position-specific scoring matrix (PSSM) of the amino acid sequence of a target protein. Let us denote the PSSM by <italic>U</italic>=(<bold>u</bold><sub>1</sub>, ..., <bold>u</bold><italic><sub>L</sub></italic>) where <italic>L</italic> is the sequence length of the target protein and <bold>u</bold><italic><sub>i</sub></italic> is a 20-vector containing the scores of 20 types of amino acid residues at the <italic>i</italic>-th position: <bold>u</bold><italic><sub>i</sub></italic>= (<italic>u</italic><sub>1,</sub><italic><sub>i</sub></italic>, ..., <italic>u</italic><sub>20,</sub><italic><sub>i</sub></italic>)<italic><sup>t</sup></italic>.</p>
      <p>When predicting a type of 1D structure, we first predict the feature variable(s) for that type of 1D structure [i.e., <italic>y<sub>i</sub></italic>= <italic>y<sub>i</sub><sup>H</sup></italic>, etc. for SS, <italic>n<sub>i</sub></italic>/log <italic>L</italic> for CN, and <italic>o<sub>i</sub></italic>/<italic>L</italic> for RWCO], and then the feature variable is converted to the target 1D structure. Prediction of the feature variable <italic>y<sub>i</sub></italic> can be considered as a mapping from a given PSSM <italic>U</italic> to <italic>y<sub>i</sub></italic>. More formally, we are going to establish the functional form of the mapping <italic>F</italic> in <italic>ŷ<sub>i</sub></italic> =<italic>F</italic>(<italic>U</italic>, <italic>i</italic>) where <italic>ŷ<sub>i</sub></italic> is the predicted value of the feature variable <italic>y<sub>i</sub></italic>. In our previous paper, we showed that CN can be predicted to a moderate degree of accuracy by a simple linear regression scheme with a local sequence window<xref rid="b4-1_67" ref-type="bibr">4</xref>. Accordingly, we assume that the function <italic>F</italic> can be decomposed into linear (<italic>F<sub>l</sub></italic>) and nonlinear (<italic>F<sub>n</sub></italic>) parts: <italic>F</italic> = <italic>F<sub>l</sub></italic>+ <italic>F<sub>n</sub></italic>.</p>
      <p>The linear part is expressed as
<disp-formula id="FD4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>21</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula> where <italic>M</italic> is the half window size of the local PSSM segment around the <italic>i</italic>-th residue, and {<italic>D<sub>m</sub></italic><sub>,</sub><italic><sub>a</sub></italic>} are the weights to be trained. To treat N- and C-termini separately, we introduced the “terminal residue” as the 21st kind of amino acid residue. The value of <italic>u</italic><sub>21,</sub><italic><sub>i</sub></italic><sub>+</sub><italic><sub>m</sub></italic> is set to unity if <italic>i</italic>+<italic>m</italic>&lt;0 or <italic>i</italic>+<italic>m</italic>&lt;<italic>L</italic>, or to zero otherwise. The “terminal residue” for the central residue (<italic>m</italic>=0) serves as a bias term and is always set to unity.</p>
      <p>To establish the nonlinear part, we first introduce an <italic>N</italic>-dimensional “state vector” <bold>x</bold><italic><sub>i</sub></italic>= (<italic>x</italic><sub>1,</sub><italic><sub>i</sub></italic>, ..., <italic>x<sub>N</sub></italic><sub>,</sub><italic><sub>i</sub></italic>)<italic><sup>t</sup></italic> for the <italic>i</italic>-th sequence position where the dimension <italic>N</italic> is a free parameter. The value of <bold>x</bold><italic><sub>i</sub></italic> is determined by solving the equation of state which is described in the next subsection. For the moment, let us assume that the equation of state has been solved, and denote the solution by 
<inline-formula><mml:math id="m5"><mml:mrow><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>. The state vector can be considered as a function of the whole PSSM <italic>U</italic> (i.e., 
<inline-formula><mml:math id="m6"><mml:mrow><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>U</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>), and implicitly incorporates nonlinear and long-range effects. Now, the nonlinear part <italic>F<sub>n</sub></italic> is expressed as a linear projection of the state vector:
<disp-formula id="FD5"><label>(5)</label><mml:math id="m7"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>U</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> where {<italic>E<sub>k</sub></italic>} are the weights to be trained.</p>
      <p>In summary, the prediction scheme is expressed as
<disp-formula id="FD6"><label>(6)</label><mml:math id="m8"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>21</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>U</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula> Regarding <bold>u</bold><italic><sub>i</sub></italic><sub>–</sub><italic><sub>M</sub></italic>, ..., <bold>u</bold><italic><sub>i</sub></italic><sub>+</sub><italic><sub>M</sub></italic> and 
<inline-formula><mml:math id="m9"><mml:mrow><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> as independent variables, <xref rid="FD6" ref-type="disp-formula">Eq. 6</xref> reduces to a simple linear regression problem for which the optimal weights {<italic>D<sub>m</sub></italic><sub>,</sub><italic><sub>a</sub></italic>} and {<italic>E<sub>k</sub></italic>} are readily determined by using a least squares method. For CN or RWCO predictions, the predicted feature variable can be easily converted to the corresponding 1D quantities by multiplying by log <italic>L</italic> or <italic>L</italic>, respectively. For SS prediction, the secondary structure <italic>ŝ<sub>i</sub></italic> of the <italic>i</italic>-th residue is given by 
<inline-formula><mml:math id="m10"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>arg</mml:mtext><mml:msub><mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>.</p>
    </sec>
    <sec>
      <title>Critical random networks and the equation of state</title>
      <p>We now describe the equation of state for the system of state vectors. We denote <italic>L</italic> state vectors along the amino acid sequence by <bold>X</bold>=(<bold>x</bold><sub>1</sub>, ..., <bold>x</bold><italic><sub>L</sub></italic>) ∈ <bold>R</bold><italic><sup>N</sup></italic><sup>×</sup><italic><sup>L</sup></italic>, and define a nonlinear mapping <italic>g<sub>i</sub></italic>: <bold>R</bold><italic><sup>N</sup></italic><sup>×</sup><italic><sup>L</sup></italic> → <bold>R</bold><italic><sup>N</sup></italic> for <italic>i</italic>=1, ..., <italic>L</italic> by
<disp-formula id="FD7"><label>(7)</label><mml:math id="m11"><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mtext mathvariant="bold">X</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtext>tanh</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mi>W</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mrow><mml:mtext mathvariant="bold">u</mml:mtext></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> where <italic>β</italic> and <italic>α</italic> are positive constants, <italic>W</italic> is an <italic>N</italic>×<italic>N</italic> block-diagonal orthogonal random matrix, and <italic>V</italic> is an <italic>N</italic>×21 random matrix (a unit bias term is assumed in <bold>u</bold><italic><sub>i</sub></italic>). The hyperbolic tangent function (tanh) is applied element-wise. We impose the boundary conditions as <bold>x</bold><sub>0</sub>= <bold>x</bold><italic><sub>L</sub></italic><sub>+1</sub>= 0. In this equation, the term containing <italic>W</italic> represents nearest-neighbor interactions along the sequence. The amino acid sequence information is taken into account as an external field in the form of <italic>α</italic><italic>V</italic><bold>u</bold><italic><sub>i</sub></italic>. Next we define a mapping <italic>G</italic>: <bold>R</bold><italic><sup>N</sup></italic><sup>×</sup><italic><sup>L</sup></italic> → <bold>R</bold><italic><sup>N</sup></italic><sup>×</sup><italic><sup>L</sup></italic> by
<disp-formula id="FD8"><label>(8)</label><mml:math id="m12"><mml:mrow><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext mathvariant="bold">X</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mtext mathvariant="bold">X</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mtext mathvariant="bold">X</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula> Using this mapping <italic>G</italic>, the equation of state is defined as
<disp-formula id="FD9"><label>(9)</label><mml:math id="m13"><mml:mrow><mml:mtext mathvariant="bold">X</mml:mtext><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext mathvariant="bold">X</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula> That is, the state vectors are determined as a fixed point of the mapping <italic>G</italic>. More explicitly, <xref rid="FD9" ref-type="disp-formula">Eq. 9</xref> can be expressed as
<disp-formula id="FD10"><label>(10)</label><mml:math id="m14"><mml:mrow><mml:msub><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>tanh</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mi>W</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mrow><mml:mtext mathvariant="bold">u</mml:mtext></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>for <italic>i</italic>=1, ..., <italic>L</italic>. That is, the state vector <bold>x</bold><italic><sub>i</sub></italic> of the site <italic>i</italic> is determined by the interaction with the state vectors of the neighboring sites <italic>i</italic>-1 and <italic>i</italic>+1 as well as with the ‘external field’ <bold>u</bold><italic><sub>i</sub></italic> of the site. The information on the external field at each site is propagated throughout the entire amino acid sequence via the nearest-neighbor interactions. Therefore, solving <xref rid="FD10" ref-type="disp-formula">Eq. (10)</xref> means finding the state vectors that are consistent with the external field as well as the nearest-neighbor interactions, and each state vector in the obtained solution {<bold>x</bold><italic><sub>i</sub></italic>} self-consistently embodies the information on the entire amino acid sequence in a mean-field sense.</p>
      <p>For <italic>β</italic>&lt;0.5, it can be shown that <italic>G</italic> is a contraction mapping in <bold>R</bold><italic><sup>N</sup></italic><sup>×</sup><italic><sup>L</sup></italic> (with an appropriate norm defined therein). And hence, by the contraction mapping principle<xref rid="b12-1_67" ref-type="bibr">12</xref>, the mapping <italic>G</italic> has a unique fixed point independently of the strength <italic>α</italic> of the external field. When <italic>β</italic> is sufficiently smaller than 0.5, the correlation between two state vectors, say <bold>x</bold><italic><sub>i</sub></italic> and <bold>x</bold><italic><sub>j</sub></italic>, is expected to decay exponentially as a function of the sequential separation |<italic>i</italic>−<italic>j</italic>|. On the other hand, for <italic>β</italic> &gt;0.5, the number of fixed points varies depending on the strength of the external field <italic>α</italic>. In this regime, we cannot reliably solve the equation of state (<xref rid="FD9" ref-type="disp-formula">Eq. 9</xref>). In this sense, <italic>β</italic>=0.5 can be considered as a critical point of the system <bold>X</bold>. From an analogy with critical phenomena of physical systems<xref rid="b13-1_67" ref-type="bibr">13</xref> (note the formal similarity of <xref rid="FD10" ref-type="disp-formula">Eq. 10</xref> with the mean field equation of the Ising model), the correlation length between state vectors is expected to diverge, or become long when the external field is finite but small. We call the system defined by <xref rid="FD10" ref-type="disp-formula">Eq. 10</xref> with <italic>β</italic>=0.5 a critical random network (CRN).</p>
      <p>The equation of state (<xref rid="FD10" ref-type="disp-formula">Eq. 10</xref>) is parameterized by two random matrices <italic>W</italic> and <italic>V</italic>, and consequently, so is the predicted feature variables <italic>ŷ<sub>i</sub></italic>. Following a standard technique of statistical learning such as neural networks<xref rid="b14-1_67" ref-type="bibr">14</xref>, we may improve the prediction accuracy by averaging <italic>ŷ<sub>i</sub></italic> obtained by multiple CRNs with different pairs of <italic>W</italic> and <italic>V</italic>. This averaging operation reduces the prediction errors due to the random fluctuations in the estimated parameters. We employ such an ensemble prediction with 10 sets of random matrices <italic>W</italic> and <italic>V</italic> in the following. The use of a larger number of random matrices for ensemble predictions improved the prediction accuracies slightly, but the difference was insignificant.</p>
    </sec>
    <sec>
      <title>Numerics</title>
      <p>Here we describe the value of the free parameters used, and a numerical procedure to solve the equation of state.</p>
      <p>The half window size <italic>M</italic> in the linear part of <xref rid="FD6" ref-type="disp-formula">Eq. 6</xref> is set to 9 for SS and CN predictions, and to 26 for RWCO predictions. These values were found to be optimal in preliminary studies<sup>4,15.</sup> Regarding the dimension <italic>N</italic> of the state vector, we have found that <italic>N</italic>=2000 gives the best result after some experimentation, and this value is used throughout. Using a state vector with a dimension as large as 2000, it is expected that various properties of amino acid sequences can be extracted and memorized. If the dimension is too large, overfitting may occur, but we did not find such a case up to <italic>N</italic>=2000. Therefore, in principle, the state vector dimension could be even larger (but the computational cost becomes a problem).</p>
      <p>Each element in the <italic>N</italic>×21 random matrix <italic>V</italic> in <xref rid="FD10" ref-type="disp-formula">Eq. 10</xref> is obtained from a uniform distribution in the range [−1, 1] and the strength parameter <italic>α</italic> is set to 0.01. Here and in the following, all random numbers were generated by the Mersenne twister algorithm<xref rid="b16-1_67" ref-type="bibr">16</xref>. The <italic>N</italic>×<italic>N</italic> random matrix <italic>W</italic> is obtained in the following manner. First we generate a random block diagonal matrix <italic>A</italic> whose block sizes are drawn from a uniform distribution of integers 2 to 20 (both inclusive), and the values of the block elements are drawn from the standard Gaussian distribution (zero mean and unit variance). By applying singular value decomposition, we have <italic>A</italic>=<italic>U</italic>Σ<italic>V<sup>t</sup></italic> where <italic>U</italic> and <italic>V</italic> are orthogonal matrices and Σ is a diagonal matrix of singular values. We set <italic>W</italic>=<italic>UV<sup>t</sup></italic> which is orthogonal as well as block diagonal.</p>
      <p>To solve the equation of state (<xref rid="FD10" ref-type="disp-formula">Eq. 10</xref>), we use a simple functional iteration with a Gauss-Seidel-like updating scheme. Let <italic>ν</italic> denote the stage of iteration. We set the initial value of the state vectors (with <italic>ν</italic> =0) as
<disp-formula id="FD11"><label>(11)</label><mml:math id="m15"><mml:mrow><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext>tanh</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mrow><mml:mtext mathvariant="bold">u</mml:mtext></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula> Then, for <italic>i</italic>=1, ..., <italic>L</italic> (in increasing order of <italic>i</italic>), we update the state vectors by
<disp-formula id="FD12"><label>(12)</label><mml:math id="m16"><mml:mrow><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>ν</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>←</mml:mo><mml:mtext>tanh</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>ν</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mrow><mml:mtext mathvariant="bold">u</mml:mtext></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula> Next, we update them in the reverse order. That is, for <italic>i</italic>=<italic>L</italic>, ..., 1 (in decreasing order of <italic>i</italic>),
<disp-formula id="FD13"><label>(13)</label><mml:math id="m17"><mml:mrow><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>ν</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>←</mml:mo><mml:mtext>tanh</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>W</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>ν</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>ν</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mrow><mml:mtext mathvariant="bold">u</mml:mtext></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula> We then set <italic>ν</italic>← +1, and iterate Eqs. <xref ref-type="disp-formula" rid="FD12">(12)</xref> and <xref ref-type="disp-formula" rid="FD13">(13)</xref> until {<bold>x</bold><italic><sub>i</sub></italic>} converges. The convergence criterion is
<disp-formula id="FD14"><label>(14)</label><mml:math id="m18"><mml:mrow><mml:msqrt><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>ν</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>ν</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mtext mathvariant="bold">R</mml:mtext></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:mi>N</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:mrow></mml:msqrt><mml:mo>&lt;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula> where ||·||<sub><bold>R</bold><sup><italic>N</italic></sup></sub> denotes the Euclidean norm. Convergence is typically achieved within 100 to 200 iterations for one protein.</p>
    </sec>
    <sec>
      <title>Preparation of training and test sets</title>
      <p>We use the same set of proteins as used in our preliminary study<xref rid="b15-1_67" ref-type="bibr">15</xref>. In this set, there are 680 protein domains selected from the ASTRAL database<xref rid="b17-1_67" ref-type="bibr">17</xref>, each of which represents a superfamily from one of all-<italic>α</italic>, all-<italic>β</italic>, <italic>α</italic>/<italic>β</italic>, <italic>α</italic>+<italic>β</italic> or “multi-domain” classes of the SCOP database (release 1.65, December 2003)<xref rid="b18-1_67" ref-type="bibr">18</xref>. Conversely, each SCOP superfamily is represented by only one of the protein domains in the data set. Thus, no pair of protein domains in the data set are expected to be homologous to each other. For training the parameters and testing the prediction accuracy, 15-fold cross-validation is employed. The set of 680 proteins is randomly divided into two groups: one consisting of 630 proteins (training set), and the other consisting of 50 proteins (test set). For each training set, the regression parameters {<italic>D<sub>m</sub></italic><sub>,</sub><italic><sub>a</sub></italic>} and {<italic>E<sub>i</sub></italic>} are determined, and using these parameters, the prediction accuracy is evaluated for the corresponding test set. This procedure was repeated 15 times with different random divisions, leading to 15 pairs of training and test sets. In this way, there is some redundancy in the training and test sets although none of the pair of these sets share proteins in common. But this raises no problem since our objective is to estimate the average accuracy of the predictions. A similar validation procedure was also employed by Petersen et al.<xref rid="b19-1_67" ref-type="bibr">19</xref> In total, 750 (=15×50) proteins were tested with which the averages of the measures of accuracy (see below) were calculated.</p>
    </sec>
    <sec>
      <title>Preparation of a position-specific scoring matrix</title>
      <p>To obtain the position-specific scoring matrix (PSSM) of a protein, we conducted ten iterations of a PSI-BLAST<xref rid="b10-1_67" ref-type="bibr">10</xref> search of a customized sequence database with an E-value cutoff of 0.0005<xref rid="b20-1_67" ref-type="bibr">20</xref>. The sequence database was compiled from the DAD database provided by the DNA Data Bank of Japan<xref rid="b21-1_67" ref-type="bibr">21</xref>, from which redundancy was removed by the program CD-HIT<xref rid="b22-1_67" ref-type="bibr">22</xref> with a 95% identity cutoff. This database was subsequently filtered by the program PFILT used in the PSIPRED program<xref rid="b23-1_67" ref-type="bibr">23</xref>. We use the position-specific scoring matrices (PSSM) rather than the frequency tables for the prediction.</p>
    </sec>
    <sec>
      <title>Measures of accuracy</title>
      <p>For assessing the quality of SS predictions, we mainly use <italic>Q</italic><sub>3</sub> and <italic>SOV</italic> (the 1999 revision)<xref rid="b24-1_67" ref-type="bibr">24</xref>. The <italic>Q</italic><sub>3</sub> measure quantifies the percentage of correctly predicted residues, while the <italic>SOV</italic> measure evaluates the segment overlaps of secondary structural elements of predicted and native structures. Optionally, we use <italic>Q<sub>s</sub></italic> and 
<inline-formula><mml:math id="m19"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="italic">pre</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> (with <italic>s</italic> being <italic>H</italic>, <italic>E</italic>, or <italic>C</italic>) and Matthews’ correlation coefficient <italic>MC</italic>. The <italic>Q<sub>s</sub></italic> is defined by the percentage of correctly predicted SS type <italic>s</italic> out of the native SS type <italic>s</italic>, and 
<inline-formula><mml:math id="m20"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="italic">pre</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is defined by the percentage of correctly predicted SS type <italic>s</italic> out of the predicted SS type <italic>s</italic>.</p>
      <p>For CN and RWCO predictions, we use two measures for evaluating the prediction accuracy. The first one is the coefficient of the correlation (<italic>Cor</italic>) between the observed (<italic>n<sub>i</sub></italic>) and predicted (<italic>n̂<sub>i</sub></italic>) CN or RWCO<xref rid="b4-1_67" ref-type="bibr">4</xref>. The second is the RMS error normalized to the standard deviation of the native CN or RWCO (<italic>Dev A</italic>)<xref rid="b4-1_67" ref-type="bibr">4</xref>. While <italic>Cor</italic> measures the quality of relative values, <italic>Dev A</italic> measures that of absolute values of the predicted CN or RWCO.</p>
      <p>Note that the measures <italic>Q</italic><sub>3</sub>, <italic>SOV</italic>, <italic>Cor</italic> and <italic>Dev A</italic> are defined for a single protein chain. In practice, we average these quantities for all the proteins in the test sets to estimate the average accuracy of prediction. On the other hand, per-residue measures, <italic>Q<sub>s</sub></italic>, 
<inline-formula><mml:math id="m21"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="italic">pre</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and <italic>MC</italic>, were calculated using all the residues in the test data sets, rather than on a per-protein basis.</p>
    </sec>
  </sec>
  <sec sec-type="results">
    <title>Results</title>
    <p>We examine the prediction accuracies for SS, CN, and RWCO in turn. The main results are summarized in <xref rid="t1-1_67" ref-type="table">Table 1</xref> and <xref rid="f1-1_67" ref-type="fig">Figure 1</xref>. Finally, in order to examine the effect of nonlinear terms, we verify the results obtained using only linear terms (<xref rid="FD4" ref-type="disp-formula">Eq. 4</xref>).</p>
    <sec>
      <title>Secondary structure prediction</title>
      <p>The average accuracy of predicting secondary structures achieved by the ensemble CRNs-based approach is <italic>Q</italic><sub>3</sub>= 77.8% and <italic>SOV</italic>=77.3 (<xref rid="t1-1_67" ref-type="table">Table 1</xref>). This is comparable to the current state-of-the-art predictors such as PSIPRED<xref rid="b23-1_67" ref-type="bibr">23</xref>. The results in terms of per-residue accuracies (<italic>Q<sub>s</sub></italic> and 
<inline-formula><mml:math id="m22"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="italic">pre</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>) are listed in <xref rid="t2-1_67" ref-type="table">Table 2</xref>. The values of <italic>Q<sub>s</sub></italic> suggest that the present method underestimates <italic>α</italic> helices (<italic>H</italic>) and, especially, <italic>β</italic> strands (<italic>E</italic>) compared to coils <italic>C</italic>. However, when a residue is predicted as being <italic>H</italic> or <italic>E</italic>, the probability of the correct prediction is rather high, especially for <italic>E</italic> (
<inline-formula><mml:math id="m23"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="italic">pre</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>79.9</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math></inline-formula></p>
      <p>). The histogram of <italic>Q</italic><sub>3</sub> (<xref rid="f1-1_67" ref-type="fig">Fig. 1a</xref>) shows that the peak of the histogram resides well beyond <italic>Q</italic><sub>3</sub>= 80%, and that only 20% of the predictions exhibit a <italic>Q</italic><sub>3</sub> of less than 70%. These observations demonstrate the capability of the CRNs-based prediction schemes.</p>
    </sec>
    <sec>
      <title>Contact number prediction</title>
      <p>Using an ensemble of CRNs, a correlation coefficient (<italic>Cor</italic>) of 0.726 and normalized RMS error (<italic>Dev A</italic>) of 0.707 was achieved for CN predictions on average (<xref rid="t1-1_67" ref-type="table">Table 1</xref>). This result is a significant improvement over the previous method<xref rid="b4-1_67" ref-type="bibr">4</xref> which yielded <italic>Cor</italic>=0.627 and <italic>Dev A</italic>=0.941. The median of the distribution of <italic>Cor</italic> (<xref rid="f1-1_67" ref-type="fig">Fig. 1b</xref>) is 0.744, indicating that the majority of the predictions are of very high accuracy.</p>
      <p>We have also examined the dependence of prediction accuracy on the structural class of target proteins (<xref rid="t3-1_67" ref-type="table">Table 3</xref>). Among all the structural classes, <italic>α</italic>/<italic>β</italic> proteins are predicted most accurately with <italic>Cor</italic>=0.757 and <italic>Dev A</italic>=0.668. The accuracy for other classes does not differ qualitatively although all-<italic>β</italic> proteins are predicted slightly less accurately.</p>
    </sec>
    <sec>
      <title>Residue-wise contact order prediction</title>
      <p>For predicting RWCO, the average accuracy was such that <italic>Cor</italic>=0.601 and <italic>Dev A</italic>=0.881. Although these figures appear to be poor compared to those of the CN prediction described above, they are yet statistically significant. The distribution of <italic>Cor</italic> appears to be rather dispersed (<xref rid="f1-1_67" ref-type="fig">Fig. 1c</xref>), indicating that the prediction accuracy strongly depends on the characteristics of each target protein. In a similar manner as for CN, we also examined the dependence of prediction accuracy on the structural class of target proteins (<xref rid="t4-1_67" ref-type="table">Table 4</xref>). In this case, we have found a notable dependence of accuracy on structural class. The best accuracy is obtained for <italic>α</italic>+<italic>β</italic> proteins with <italic>Cor</italic>=0.629 and <italic>Dev A</italic>=0.832. For these proteins, the distribution of <italic>Cor</italic> also shows a good tendency in that the fraction of poor predictions is relatively small (e.g., 14% for <italic>Cor</italic>&lt;0.5). Interestingly, all-<italic>β</italic> proteins also show good accuracies but all-<italic>α</italic> proteins are particularly poorly predicted. These observations suggest that the correlation between the amino acid sequence and RWCO is strongly dependent on the structural class of the target protein. However, the rather dispersed distribution of <italic>Cor</italic> for each class (<xref rid="t4-1_67" ref-type="table">Table 4</xref>) also suggests that there are more detailed effects of the global context on the accuracy of RWCO prediction.</p>
    </sec>
    <sec>
      <title>Purely linear predictions with PSSMs</title>
      <p>Almost all the modern methods for predicting 1D structures make use of PSSMs in combination with some kind of machine-learning technique such as feed-forward or recurrent neural networks or support vector machines. The present study is no exception. Curiously, machine-learning approaches have become so widespread that no attempt appears to have been made to test simplest linear predictors based on PSSMs. In this subsection, we present results of 1D predictions using only the linear terms (<xref rid="FD4" ref-type="disp-formula">Eq. 4</xref>) but without CRNs. In this prediction scheme, the input is a local segment of a PSSM generated by PSI-BLAST, and a feature variable is predicted by a straight forward linear regression.</p>
      <p>As can be clearly seen in <xref rid="t5-1_67" ref-type="table">Table 5</xref>, the results of the linear predictions are surprisingly good although not as good as with CRNs. For example, in SS prediction, the purely linear scheme achieved <italic>Q</italic><sub>3</sub> = 75.2% which is lower than that of the CRNs-based scheme by only 3.6 percentage points. Although this is of course a large difference in a statistical sense, there may not be a discernible difference as far as individual predictions are concerned. (However, the improvement in the <italic>SOV</italic> measure obtained by using CRNs is quite large, indicating that the nonlinear terms in CRNs are indeed able to extract cooperative features.) It is widely accepted that the upper limit of accuracy (<italic>Q</italic><sub>3</sub>) of SS prediction based on a local window of a single sequence is less than 70%<xref rid="b25-1_67" ref-type="bibr">25</xref>. Therefore, more than 5 percentage points of the increase in <italic>Q</italic><sub>3</sub> is brought about simply by the use of PSSMs.</p>
      <p>Similar observations also hold for CN and RWCO predictions (<xref rid="t5-1_67" ref-type="table">Table 5</xref>). In the case of CN prediction, we have previously obtained <italic>Cor</italic>=0.555 by a simple linear method with single sequences<xref rid="b4-1_67" ref-type="bibr">4</xref>. Therefore, the effect of PSSMs is even more dramatic than SS prediction. This may be due to the fact that the most conspicuous feature of amino acid sequences conserved among distant homologs (as detected by PSI-BLAST) is the hydrophobicity of amino acid residues<xref rid="b26-1_67" ref-type="bibr">26</xref>, which is closely related to contact numbers. Of course, the improvement with the use of PSSMs is largely made possible by the recent increase in amino acid sequence databases<xref rid="b27-1_67" ref-type="bibr">27</xref>.</p>
    </sec>
    <sec>
      <title>The significance of criticality</title>
      <p>The condition of criticality (<italic>β</italic>=0.5 in <xref rid="FD10" ref-type="disp-formula">Eq. 10</xref>) is expected to enhance the extraction of the long-range correlations of an amino acid sequence, thus improving the prediction accuracy. To confirm this point, we tested the method by setting <italic>β</italic>=0.1 so that the network of state vectors is not at the critical point any more (otherwise the prediction and validation schemes were the same as above). The prediction accuracies obtained by these non-critical random networks were <italic>Q</italic><sub>3</sub>= 76.7% and <italic>SOV</italic>=76.6 for SS, <italic>Cor</italic>=0.716 and <italic>Dev A</italic>=0.719 for CN, and <italic>Cor</italic>=0.589 and <italic>Dev A</italic>=0.897 for RWCO. These values are inferior to those obtained by the critical random networks (<xref rid="t1-1_67" ref-type="table">Table 1</xref>), although slightly better than the purely linear predictions (<xref rid="t5-1_67" ref-type="table">Table 5</xref>). Therefore, compared to the non-critical random networks, the critical random networks can indeed extract more information from the amino acid sequence and improve the prediction accuracies.</p>
    </sec>
  </sec>
  <sec sec-type="discussion">
    <title>Discussion</title>
    <sec>
      <title>Comparison with other methods</title>
      <p>Regarding the framework of 1D structure prediction, the critical random networks are most closely related to bidirectional recurrent neural networks (BRNNs)<xref rid="b28-1_67" ref-type="bibr">28</xref>, in that both can treat an entire amino acid sequence rather than only a local window segment. The main differences are the following. First, network weights between input and hidden layers as well as those between hidden units are trained in BRNNs, whereas the corresponding weights in CRNs (random matrices <italic>V</italic> and <italic>W</italic>, respectively, in <xref rid="FD10" ref-type="disp-formula">Eq. 10</xref>) are fixed. Second, the output layer is nonlinear in BRNNs but linear in CRNs. Third, the network components that propagate sequence information from the N-terminus to C-terminus are decoupled from those in the opposite direction in BRNNs, but they are coupled in CRNs.</p>
      <p>Regarding the accuracy of SS prediction, BRNNs<xref rid="b29-1_67" ref-type="bibr">29</xref> and CRNs exhibit comparable results of <italic>Q</italic><sub>3</sub>≈ 78%. However, a standard local window-based approach using feed-forward neural networks can also achieve this level of accuracy<xref rid="b23-1_67" ref-type="bibr">23</xref>. Thus, the CRNs-based method is not a single best predictor, but may serve as an addition to consensus predictions.</p>
      <p>Although BRNNs have been also applied to CN prediction<xref rid="b30-1_67" ref-type="bibr">30</xref>, contact numbers are predicted as 2-state categorical data (buried or exposed) so the results cannot be directly compared. Nevertheless, we can convert CRNs-based real-value predictions into 2-state predictions. By using the same thresholds for the 2-state discretization as Pollastri et al.<xref rid="b30-1_67" ref-type="bibr">30</xref> (i.e., the average CN for each residue type), we obtained <italic>Q</italic><sub>2</sub> = 75.6% per chain (75.1% per residue), and Matthews’ correlation coefficient <italic>MC</italic>=0.503 whereas those obtained by BRNNs are <italic>Q</italic><sub>2</sub>= 73.9% (per residue) and <italic>MC</italic>= 0.478. Therefore, for 2-state CN prediction, the present method yields more accurate results.</p>
      <p>Since the present study is the very first attempt to predict RWCOs, there are no alternative methods to compare with. However, the comparison of CRNs-based methods for SS and CN predictions with other methods suggests that the accuracy of the RWCO prediction presented here may be the best possible result using any of the statistical learning methods currently available for predicting 1D structures.</p>
    </sec>
    <sec>
      <title>Possibilities for further improvements</title>
      <p>In the present study, we employed the simplest possible architecture for CRNs in which different sites are connected via nearest-neighbor interactions. A number of possibilities exist for the elaboration of the architecture. For example, we may introduce short-cuts between distant sites to treat non-local interactions more directly. Since the prediction accuracies depend on the structural context of target proteins (<xref rid="t3-1_67" ref-type="table">Tables 3</xref> and <xref rid="t4-1_67" ref-type="table">4</xref>), it may be also useful to include more global features of amino acid sequences such as the bias of amino acid composition or the average of PSSM components. These possibilities are to be pursued in future studies.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions">
    <title>Conclusion</title>
    <p>We have developed a novel method, CRNs-based regression, for predicting 1D protein structures from the amino acid sequence. When combined with position-specific scoring matrices produced by PSI-BLAST, this method yields SS predictions as accurate as the best current predictors, CN predictions far better than previous methods, and RWCO predictions significantly correlated with observed values. We also examined the effect of PSSMs on prediction accuracy, and showed that most improvement is brought by the use of PSSMs although the further improvement due to the CRNs-based method is also significant. In order to achieve qualitatively better predictions, however, it seems necessary to take into account other, more global, information than is provided by PSSMs.</p>
  </sec>
</body>
<back>
  <ack>
    <p>The authors thank Motonori Ota for critical comments on an early version of the manuscript, and Kentaro Tomii for advice on the use of PSI-BLAST. Most of the computations were carried out at the supercomputing facility of the National Institute of Genetics, Japan. This work was supported in part by a grant-in-aid from MEXT, Japan. The source code of the programs for the CRNs-based prediction as well as the lists of protein domains used in this study are available at <ext-link ext-link-type="uri" xlink:href="http://maccl01.genes.nig.ac.jp/~akinjo/crnpred_suppl/">http://maccl01.genes.nig.ac.jp/~akinjo/crnpred_suppl/</ext-link>.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="b1-1_67">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bonneau</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Baker</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Ab initio protein structure prediction: progress and prospects</article-title>
        <source>Annu. Rev. Biophys. Biomol. Struct</source>
        <volume>30</volume>
        <fpage>173</fpage>
        <lpage>189</lpage>
        <year>2001</year>
        <pub-id pub-id-type="pmid">11340057</pub-id>
      </element-citation>
    </ref>
    <ref id="b2-1_67">
      <label>2.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Rost</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Prediction in 1D: secondary structure, membrane helices, and accessibility</article-title>
        <source>Structural Bioinformatics</source>
        <person-group person-group-type="editor">
          <name>
            <surname>Bourne</surname>
            <given-names>PE</given-names>
          </name>
          <name>
            <surname>Weissig</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <comment>chapter 28</comment>
        <fpage>559</fpage>
        <lpage>587</lpage>
        <publisher-name>Wiley-Liss, Inc.</publisher-name>
        <publisher-loc>Hoboken, U.S.A.</publisher-loc>
        <year>2003</year>
      </element-citation>
    </ref>
    <ref id="b3-1_67">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Richards</surname>
            <given-names>FM</given-names>
          </name>
        </person-group>
        <article-title>The interpretation of protein structures: Estimation of static accessibility</article-title>
        <source>J. Mol. Biol</source>
        <volume>55</volume>
        <fpage>379</fpage>
        <lpage>400</lpage>
        <year>1971</year>
        <pub-id pub-id-type="pmid">5551392</pub-id>
      </element-citation>
    </ref>
    <ref id="b4-1_67">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kinjo</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Horimoto</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Nishikawa</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Predicting absolute contact numbers of native protein structure from amino acid sequence</article-title>
        <source>Proteins</source>
        <volume>58</volume>
        <fpage>158</fpage>
        <lpage>165</lpage>
        <year>2005</year>
        <pub-id pub-id-type="pmid">15523668</pub-id>
      </element-citation>
    </ref>
    <ref id="b5-1_67">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kinjo</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Nishikawa</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Recoverable one-dimensional encoding of protein three-dimensional structures</article-title>
        <source>Bioinformatics</source>
        <volume>21</volume>
        <fpage>2167</fpage>
        <lpage>2170</lpage>
        <year>2005</year>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bti330</pub-id>
        <pub-id pub-id-type="pmid">15722374</pub-id>
      </element-citation>
    </ref>
    <ref id="b6-1_67">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nishikawa</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Ooi</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Prediction of the surface-interior diagram of globular proteins by an empirical method</article-title>
        <source>Int. J. Peptide Protein Res</source>
        <volume>16</volume>
        <fpage>19</fpage>
        <lpage>32</lpage>
        <year>1980</year>
        <pub-id pub-id-type="pmid">7440060</pub-id>
      </element-citation>
    </ref>
    <ref id="b7-1_67">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sander</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Schneider</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Database of homology-derived protein structures</article-title>
        <source>Proteins</source>
        <volume>9</volume>
        <fpage>56</fpage>
        <lpage>68</lpage>
        <year>1991</year>
        <pub-id pub-id-type="pmid">2017436</pub-id>
      </element-citation>
    </ref>
    <ref id="b8-1_67">
      <label>8.</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Jaeger</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>The “echo state” approach to analysing and training recurrent neural networks</article-title>
        <comment>Technical Report 148, GMD — German National Research Institute for Computer Science</comment>
        <year>2001</year>
      </element-citation>
    </ref>
    <ref id="b9-1_67">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jaeger</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Haas</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Harnessing nonlinearity: predicting chaotic systems and saving energy in wireless communication</article-title>
        <source>Science</source>
        <volume>304</volume>
        <fpage>78</fpage>
        <lpage>80</lpage>
        <year>2004</year>
        <pub-id pub-id-type="pmid">15064413</pub-id>
      </element-citation>
    </ref>
    <ref id="b10-1_67">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Altschul</surname>
            <given-names>SF</given-names>
          </name>
          <name>
            <surname>Madden</surname>
            <given-names>TL</given-names>
          </name>
          <name>
            <surname>Schaffer</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Lipman</surname>
            <given-names>DL</given-names>
          </name>
        </person-group>
        <article-title>Gapped blast and PSI-blast: A new generation of protein database search programs</article-title>
        <source>Nucleic Acids Res</source>
        <volume>25</volume>
        <fpage>3389</fpage>
        <lpage>3402</lpage>
        <year>1997</year>
        <pub-id pub-id-type="pmid">9254694</pub-id>
      </element-citation>
    </ref>
    <ref id="b11-1_67">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kabsch</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Sander</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Dictionary of protein secondary structure: Pattern recognition of hydrogen bonded and geometrical features</article-title>
        <source>Biopolymers</source>
        <volume>22</volume>
        <fpage>2577</fpage>
        <lpage>2637</lpage>
        <year>1983</year>
        <pub-id pub-id-type="pmid">6667333</pub-id>
      </element-citation>
    </ref>
    <ref id="b12-1_67">
      <label>12.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Takahashi</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <source>Nonlinear Functional Analysis: Fixed Point Theorems and Related Topics</source>
        <publisher-name>Kindai Kagaku Sha</publisher-name>
        <publisher-loc>Tokyo</publisher-loc>
        <year>1988</year>
        <comment>(in Japanese).</comment>
      </element-citation>
    </ref>
    <ref id="b13-1_67">
      <label>13.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Goldenfeld</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <source>Lectures on phase transitions and the renormalization group, volume 85 of <italic>Frontiers in Physics</italic></source>
        <publisher-name>Addison-Wesley, Reading</publisher-name>
        <publisher-loc>Massachusetts</publisher-loc>
        <year>1992</year>
      </element-citation>
    </ref>
    <ref id="b14-1_67">
      <label>14.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Haykin</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <source>Neural Networks: A Comprehensive Foundation</source>
        <edition>2nd ed</edition>
        <publisher-name>Prentice-Hall, Upper Saddle River</publisher-name>
        <publisher-loc>New Jersey</publisher-loc>
        <year>1999</year>
      </element-citation>
    </ref>
    <ref id="b15-1_67">
      <label>15.</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Kinjo</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Nishikawa</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Predicting residue-wise contact orders of native protein structure from amino acid sequence</article-title>
        <comment>arXiv.org:q-bio.BM/0501015</comment>
        <year>2005</year>
      </element-citation>
    </ref>
    <ref id="b16-1_67">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Matsumoto</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Nishimura</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Mersenne twister: a 623-dimensionally equidistributed uniform pseudorandom number generator</article-title>
        <source>ACM Trans. Model. Comput. Simul</source>
        <volume>8</volume>
        <fpage>3</fpage>
        <lpage>30</lpage>
        <year>1998</year>
      </element-citation>
    </ref>
    <ref id="b17-1_67">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chandonia</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Hon</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Walker</surname>
            <given-names>NS</given-names>
          </name>
          <name>
            <surname>Lo Conte</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Koehl</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Levitt</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Brenner</surname>
            <given-names>SE</given-names>
          </name>
        </person-group>
        <article-title>The astral compendium in 2004</article-title>
        <source>Nucleic Acids Res</source>
        <volume>32</volume>
        <fpage>D189</fpage>
        <lpage>D192</lpage>
        <year>2004</year>
        <pub-id pub-id-type="pmid">14681391</pub-id>
      </element-citation>
    </ref>
    <ref id="b18-1_67">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Murzin</surname>
            <given-names>AG</given-names>
          </name>
          <name>
            <surname>Brenner</surname>
            <given-names>SE</given-names>
          </name>
          <name>
            <surname>Hubbard</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Chothia</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>SCOP: A structural classification of proteins database for the investigation of sequences and structures</article-title>
        <source>J. Mol. Biol</source>
        <volume>247</volume>
        <fpage>536</fpage>
        <lpage>540</lpage>
        <year>1995</year>
        <pub-id pub-id-type="pmid">7723011</pub-id>
      </element-citation>
    </ref>
    <ref id="b19-1_67">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Petersen</surname>
            <given-names>TN</given-names>
          </name>
          <name>
            <surname>Lundegaard</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Nielsen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bohr</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Bohr</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Brunak</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Gippert</surname>
            <given-names>GP</given-names>
          </name>
          <name>
            <surname>Lund</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>Prediction of protein secondary structure at 80% accuracy</article-title>
        <source>Proteins</source>
        <volume>41</volume>
        <fpage>17</fpage>
        <lpage>20</lpage>
        <year>2000</year>
        <pub-id pub-id-type="pmid">10944389</pub-id>
      </element-citation>
    </ref>
    <ref id="b20-1_67">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tomii</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Akiyama</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>FORTE: a profile-profile comparison tool for protein fold recognition</article-title>
        <source>Bioinformatics</source>
        <volume>20</volume>
        <fpage>594</fpage>
        <lpage>595</lpage>
        <year>2004</year>
        <pub-id pub-id-type="pmid">14764565</pub-id>
      </element-citation>
    </ref>
    <ref id="b21-1_67">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tateno</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Saitou</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Okubo</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Sugawara</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Gojobori</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>DDBJ in collaboration with mass-sequencing teams on annotation</article-title>
        <source>Nucleic Acids Res</source>
        <volume>33</volume>
        <fpage>D25</fpage>
        <lpage>D28</lpage>
        <year>2005</year>
        <pub-id pub-id-type="pmid">15608189</pub-id>
      </element-citation>
    </ref>
    <ref id="b22-1_67">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Jaroszewski</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Godzik</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Tolerating some redundancy significantly speeds up clustering of large protein databases</article-title>
        <source>Bioinformatics</source>
        <volume>18</volume>
        <fpage>77</fpage>
        <lpage>82</lpage>
        <year>2002</year>
        <pub-id pub-id-type="pmid">11836214</pub-id>
      </element-citation>
    </ref>
    <ref id="b23-1_67">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
        </person-group>
        <article-title>Protein secondary structure prediction based on position-specific scoring matrices</article-title>
        <source>J. Mol. Biol</source>
        <volume>292</volume>
        <fpage>195</fpage>
        <lpage>202</lpage>
        <year>1999</year>
        <pub-id pub-id-type="pmid">10493868</pub-id>
      </element-citation>
    </ref>
    <ref id="b24-1_67">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zemla</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Venclovas</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Fidelis</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Rost</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>A modified definition of sov, a segment-based measure for protein secondary structure prediction assessment</article-title>
        <source>Proteins</source>
        <volume>34</volume>
        <fpage>220</fpage>
        <lpage>223</lpage>
        <year>1999</year>
        <pub-id pub-id-type="pmid">10022357</pub-id>
      </element-citation>
    </ref>
    <ref id="b25-1_67">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Crooks</surname>
            <given-names>GE</given-names>
          </name>
          <name>
            <surname>Brenner</surname>
            <given-names>SE</given-names>
          </name>
        </person-group>
        <article-title>Protein secondary structure: entropy, correlations and prediction</article-title>
        <source>Bioinformatics</source>
        <volume>20</volume>
        <fpage>1603</fpage>
        <lpage>1611</lpage>
        <year>2004</year>
        <pub-id pub-id-type="pmid">14988117</pub-id>
      </element-citation>
    </ref>
    <ref id="b26-1_67">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kinjo</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Nishikawa</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Eigenvalue analysis of amino acid substitution matrices reveals a sharp transition of the mode of sequence conservation in proteins</article-title>
        <source>Bioinformatics</source>
        <volume>20</volume>
        <fpage>2504</fpage>
        <lpage>2508</lpage>
        <year>2004</year>
        <pub-id pub-id-type="pmid">15130930</pub-id>
      </element-citation>
    </ref>
    <ref id="b27-1_67">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Przybylski</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Rost</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Alignments grow, secondary structure prediction improves</article-title>
        <source>Proteins</source>
        <volume>46</volume>
        <fpage>197</fpage>
        <lpage>205</lpage>
        <year>2002</year>
        <pub-id pub-id-type="pmid">11807948</pub-id>
      </element-citation>
    </ref>
    <ref id="b28-1_67">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baldi</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Brunak</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Frasconi</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Soda</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Pollastri</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Exploiting the past and the future in protein secondary structure prediction</article-title>
        <source>Bioinformatics</source>
        <volume>15</volume>
        <fpage>937</fpage>
        <lpage>946</lpage>
        <year>1999</year>
        <pub-id pub-id-type="pmid">10743560</pub-id>
      </element-citation>
    </ref>
    <ref id="b29-1_67">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pollastri</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Przybylski</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Rost</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Baldi</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Improving the prediction of protein secondary structure in three and eight classes using recurrent neural networks and profiles</article-title>
        <source>Proteins</source>
        <volume>47</volume>
        <fpage>228</fpage>
        <lpage>235</lpage>
        <year>2002</year>
        <pub-id pub-id-type="pmid">11933069</pub-id>
      </element-citation>
    </ref>
    <ref id="b30-1_67">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pollastri</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Baldi</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Fariselli</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Casadio</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Prediction of coordination number and relative solvent accessibility in proteins</article-title>
        <source>Proteins</source>
        <volume>47</volume>
        <fpage>142</fpage>
        <lpage>153</lpage>
        <year>2002</year>
        <pub-id pub-id-type="pmid">11933061</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig id="f1-1_67" position="float">
    <label>Figure 1</label>
    <caption>
      <p>Histograms of accuracy measures obtained by ensemble predictions using 10 critical random networks. (a) <italic>Q</italic><sub>3</sub> for secondary structure prediction; (b) <italic>Cor</italic> for contact number prediction; (c) <italic>Cor</italic> for residue-wise contact order prediction.</p>
    </caption>
    <graphic xlink:href="1_67f1"/>
  </fig>
  <table-wrap id="t1-1_67" position="float">
    <label>Table 1</label>
    <caption>
      <p>Summary of average prediction accuracies</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th valign="middle" align="left" rowspan="1" colspan="1">Struct.</th>
          <th valign="middle" align="left" rowspan="1" colspan="1">Accuracy</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td valign="top" align="left" rowspan="1" colspan="1">SS</td>
          <td valign="top" align="left" rowspan="1" colspan="1"><italic>Q</italic><sub>3</sub>= 77.8; <italic>SOV</italic>=77.3</td>
        </tr>
        <tr>
          <td valign="top" align="left" rowspan="1" colspan="1">CN</td>
          <td valign="top" align="left" rowspan="1" colspan="1"><italic>Cor</italic>=0.726; <italic>Dev A</italic>=0.707</td>
        </tr>
        <tr>
          <td valign="top" align="left" rowspan="1" colspan="1">RWCO</td>
          <td valign="top" align="left" rowspan="1" colspan="1"><italic>Cor</italic>=0.601; <italic>Dev A</italic>=0.881</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="t2-1_67" position="float">
    <label>Table 2</label>
    <caption>
      <p>Summary of per-residue accuracies for SS predictions</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th valign="middle" align="center" rowspan="1" colspan="1">measure</th>
          <th valign="middle" align="center" rowspan="1" colspan="1">
            <italic>H</italic>
          </th>
          <th valign="middle" align="center" rowspan="1" colspan="1">
            <italic>E</italic>
          </th>
          <th valign="middle" align="center" rowspan="1" colspan="1">
            <italic>C</italic>
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">
            <italic>Q</italic>
            <sub>s</sub>
          </td>
          <td valign="middle" align="right" rowspan="1" colspan="1">78.4</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">61.9</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">84.6</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">
            <inline-formula>
              <mml:math id="m24">
                <mml:mrow>
                  <mml:msubsup>
                    <mml:mrow>
                      <mml:mi>Q</mml:mi>
                    </mml:mrow>
                    <mml:mtext>s</mml:mtext>
                    <mml:mrow>
                      <mml:mi mathvariant="italic">pre</mml:mi>
                    </mml:mrow>
                  </mml:msubsup>
                </mml:mrow>
              </mml:math>
            </inline-formula>
          </td>
          <td valign="middle" align="right" rowspan="1" colspan="1">81.9</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">79.9</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">74.3</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">
            <italic>MC</italic>
          </td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.704</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.636</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.602</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="t3-1_67" position="float">
    <label>Table 3</label>
    <caption>
      <p>Summary of CN predictions for each SCOP class<xref rid="tfn1-1_67" ref-type="table-fn"><sup>a</sup></xref></p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th valign="middle" rowspan="3" align="left" colspan="1">range<xref rid="tfn2-1_67" ref-type="table-fn"><sup>b</sup></xref> (<italic>Cor</italic>)</th>
          <th colspan="5" valign="middle" align="center" rowspan="1">SCOP class<xref rid="tfn3-1_67" ref-type="table-fn"><sup>c</sup></xref></th>
        </tr>
        <tr>
          <th colspan="5" valign="middle" align="center" rowspan="1">
            <hr/>
          </th>
        </tr>
        <tr>
          <th valign="middle" align="center" rowspan="1" colspan="1">a</th>
          <th valign="middle" align="center" rowspan="1" colspan="1">b</th>
          <th valign="middle" align="center" rowspan="1" colspan="1">c</th>
          <th valign="middle" align="center" rowspan="1" colspan="1">d</th>
          <th valign="middle" align="center" rowspan="1" colspan="1">e</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">(−1, 0.5]</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">8</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">6</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">3</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">14</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">1</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">(0.5, 0.6]</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">19</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">25</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">8</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">19</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">1</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">(0.6, 0.7]</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">29</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">29</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">22</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">54</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">3</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">(0.7, 0.8]</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">62</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">66</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">76</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">85</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">10</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">(0.8, 0.9]</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">43</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">38</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">57</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">67</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">3</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">(0.9, 1.0]</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">1</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">1</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">total</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">162</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">164</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">166</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">240</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">18</td>
        </tr>
        <tr>
          <td colspan="6" valign="middle" align="right" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">average <italic>Cor</italic></td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.721</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.712</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.757</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.728</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.722</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">average <italic>Dev A</italic></td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.715</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.726</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.668</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.717</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.705</td>
        </tr>
      </tbody>
    </table>
    <table-wrap-foot>
      <fn id="tfn1-1_67">
        <label>a</label>
        <p>The number of occurrences of <italic>Cor</italic> for the proteins in the test sets, classified according to the SCOP database; average values of <italic>Cor</italic> and <italic>Dev A</italic> are also listed for each class.</p>
      </fn>
      <fn id="tfn2-1_67">
        <label>b</label>
        <p>The range “(<italic>x</italic>, <italic>y</italic>]” denotes <italic>x</italic>&lt;<italic>Cor</italic>≤<italic>y</italic>.</p>
      </fn>
      <fn id="tfn3-1_67">
        <label>c</label>
        <p>a: all-<italic>α</italic>; b: all-<italic>β</italic>; c: <italic>α</italic>/<italic>β</italic>; d: <italic>α</italic>+<italic>β</italic>; e: multi-domain.</p>
      </fn>
    </table-wrap-foot>
  </table-wrap>
  <table-wrap id="t4-1_67" position="float">
    <label>Table 4</label>
    <caption>
      <p>Summary of RWCO predictions for each SCOP class<xref rid="tfn4-1_67" ref-type="table-fn"><sup>a</sup></xref></p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th valign="middle" rowspan="3" align="left" colspan="1">range (<italic>Cor</italic>)</th>
          <th colspan="5" valign="middle" align="center" rowspan="1">SCOP class</th>
        </tr>
        <tr>
          <th colspan="5" valign="middle" align="center" rowspan="1">
            <hr/>
          </th>
        </tr>
        <tr>
          <th valign="middle" align="center" rowspan="1" colspan="1">a</th>
          <th valign="middle" align="center" rowspan="1" colspan="1">b</th>
          <th valign="middle" align="center" rowspan="1" colspan="1">c</th>
          <th valign="middle" align="center" rowspan="1" colspan="1">d</th>
          <th valign="middle" align="center" rowspan="1" colspan="1">e</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">(−1, 0.5]</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">58</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">31</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">46</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">34</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">6</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">(0.5, 0.6]</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">29</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">37</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">31</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">56</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">4</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">(0.6, 0.7]</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">41</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">27</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">33</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">65</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">5</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">(0.7, 0.8]</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">24</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">47</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">40</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">72</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">3</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">(0.8, 0.9]</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">10</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">22</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">16</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">13</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">total</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">162</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">164</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">166</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">240</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">18</td>
        </tr>
        <tr>
          <td colspan="6" valign="middle" align="right" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">average <italic>Cor</italic></td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.549</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.620</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.595</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.629</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.564</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">average <italic>Dev A</italic></td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.981</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.869</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.857</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.832</td>
          <td valign="middle" align="right" rowspan="1" colspan="1">0.957</td>
        </tr>
      </tbody>
    </table>
    <table-wrap-foot>
      <fn id="tfn4-1_67">
        <label>a</label>
        <p>See <xref rid="t3-1_67" ref-type="table">Table 3</xref> for notations.</p>
      </fn>
    </table-wrap-foot>
  </table-wrap>
  <table-wrap id="t5-1_67" position="float">
    <label>Table 5</label>
    <caption>
      <p>Summary of prediction accuracies using only linear terms</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th valign="middle" align="left" rowspan="1" colspan="1">Struct.</th>
          <th valign="middle" align="left" rowspan="1" colspan="1">Accuracy</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">SS</td>
          <td valign="middle" align="left" rowspan="1" colspan="1"><italic>Q</italic><sub>3</sub>= 75.2; <italic>SOV</italic>=72.7</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">CN</td>
          <td valign="middle" align="left" rowspan="1" colspan="1"><italic>Cor</italic>=0.701; <italic>Dev A</italic>=0.735</td>
        </tr>
        <tr>
          <td valign="middle" align="left" rowspan="1" colspan="1">RWCO</td>
          <td valign="middle" align="left" rowspan="1" colspan="1"><italic>Cor</italic>=0.584; <italic>Dev A</italic>=0.902</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</floats-group>
