<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10126322</article-id>
    <article-id pub-id-type="pmid">37039829</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btad187</article-id>
    <article-id pub-id-type="publisher-id">btad187</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Data and Text Mining</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Identifying B-cell epitopes using AlphaFold2 predicted structures and pretrained language model</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3145-430X</contrib-id>
        <name>
          <surname>Zeng</surname>
          <given-names>Yuansong</given-names>
        </name>
        <aff><institution>School of Computer Science and Engineering, Sun Yat-sen University</institution>, Guangzhou 510000, <country country="CN">China</country></aff>
        <xref rid="btad187-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wei</surname>
          <given-names>Zhuoyi</given-names>
        </name>
        <aff><institution>School of Computer Science and Engineering, Sun Yat-sen University</institution>, Guangzhou 510000, <country country="CN">China</country></aff>
        <xref rid="btad187-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6098-9103</contrib-id>
        <name>
          <surname>Yuan</surname>
          <given-names>Qianmu</given-names>
        </name>
        <aff><institution>School of Computer Science and Engineering, Sun Yat-sen University</institution>, Guangzhou 510000, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-1428-6778</contrib-id>
        <name>
          <surname>Chen</surname>
          <given-names>Sheng</given-names>
        </name>
        <aff><institution>School of Computer Science and Engineering, Sun Yat-sen University</institution>, Guangzhou 510000, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-7449-3093</contrib-id>
        <name>
          <surname>Yu</surname>
          <given-names>Weijiang</given-names>
        </name>
        <aff><institution>School of Computer Science and Engineering, Sun Yat-sen University</institution>, Guangzhou 510000, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lu</surname>
          <given-names>Yutong</given-names>
        </name>
        <aff><institution>School of Computer Science and Engineering, Sun Yat-sen University</institution>, Guangzhou 510000, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-9943-4786</contrib-id>
        <name>
          <surname>Gao</surname>
          <given-names>Jianzhao</given-names>
        </name>
        <aff><institution>School of Mathematical Sciences and LPMC, Nankai University</institution>, Tianjin 300072, <country country="CN">China</country></aff>
        <xref rid="btad187-cor1" ref-type="corresp"/>
        <!--gaojz@nankai.edu.cn-->
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-6782-2813</contrib-id>
        <name>
          <surname>Yang</surname>
          <given-names>Yuedong</given-names>
        </name>
        <aff><institution>School of Computer Science and Engineering, Sun Yat-sen University</institution>, Guangzhou 510000, <country country="CN">China</country></aff>
        <aff><institution>Key Laboratory of Machine Intelligence and Advanced Computing (MOE), Sun Yat-sen University</institution>, Guangzhou 510000, <country country="CN">China</country></aff>
        <xref rid="btad187-cor1" ref-type="corresp"/>
        <!--yangyd25@mail.sysu.edu.cn-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Wren</surname>
          <given-names>Jonathan</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <fn id="btad187-FM1">
        <p>Yuansong Zeng and Zhuoyi Wei contributed equally to this work.</p>
      </fn>
      <corresp id="btad187-cor1">Corresponding author. School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou 510000, China. E-mail: <email>yangyd25@mail.sysu.edu.cn</email> (Y.Y.); School of Mathematical Sciences and LPMC, Nankai University, Tianjin, China. E-mail: <email>gaojz@nankai.edu.cn</email> (J.G.)</corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>4</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-04-11">
      <day>11</day>
      <month>4</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>11</day>
      <month>4</month>
      <year>2023</year>
    </pub-date>
    <volume>39</volume>
    <issue>4</issue>
    <elocation-id>btad187</elocation-id>
    <history>
      <date date-type="received">
        <day>08</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>28</day>
        <month>2</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>3</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>24</day>
        <month>4</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btad187.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Identifying the B-cell epitopes is an essential step for guiding rational vaccine development and immunotherapies. Since experimental approaches are expensive and time-consuming, many computational methods have been designed to assist B-cell epitope prediction. However, existing sequence-based methods have limited performance since they only use contextual features of the sequential neighbors while neglecting structural information.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Based on the recent breakthrough of AlphaFold2 in protein structure prediction, we propose GraphBepi, a novel graph-based model for accurate B-cell epitope prediction. For one protein, the predicted structure from AlphaFold2 is used to construct the protein graph, where the nodes/residues are encoded by ESM-2 learning representations. The graph is input into the edge-enhanced deep graph neural network (EGNN) to capture the spatial information in the predicted 3D structures. In parallel, a bidirectional long short-term memory neural networks (BiLSTM) are employed to capture long-range dependencies in the sequence. The learned low-dimensional representations by EGNN and BiLSTM are then combined into a multilayer perceptron for predicting B-cell epitopes. Through comprehensive tests on the curated epitope dataset, GraphBepi was shown to outperform the state-of-the-art methods by more than 5.5% and 44.0% in terms of AUC and AUPR, respectively. A web server is freely available at <ext-link xlink:href="http://bio-web1.nscc-gz.cn/app/graphbepi" ext-link-type="uri">http://bio-web1.nscc-gz.cn/app/graphbepi</ext-link>.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The datasets, pre-computed features, source codes, and the trained model are available at <ext-link xlink:href="https://github.com/biomed-AI/GraphBepi" ext-link-type="uri">https://github.com/biomed-AI/GraphBepi</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Key R&amp;D Program of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2022YFF1203100</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Guangzhou S&amp; Research Plan</institution>
          </institution-wrap>
        </funding-source>
        <award-id>202007030010</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>B-cells are a crucial element of the immune system to provide immunological protection against harmful molecules or infectious pathogens by producing antibodies that bind with antigens (<xref rid="btad187-B21" ref-type="bibr">Delves et al. 2016</xref>). The specific region of an antigen binding to an antibody is known as antigenic determinant or an epitope (<xref rid="btad187-B24" ref-type="bibr">Paul 2012</xref>). The category of B-cell epitopes (BCEs) is widely classified into two groups: linear and conformational epitopes (<xref rid="btad187-B1" ref-type="bibr">Alghamdi et al. 2022</xref>). Linear epitopes include continuous amino acid residues, whereas conformational epitopes are shaped by a 3D conformation that folds the protein to bind through the interaction of discontinuous amino acid residues. Previous studies show that more than 90% of BCEs are conformational while 10% are linear epitopes (<xref rid="btad187-B3" ref-type="bibr">Barlow et al. 1986</xref>).</p>
    <p>Reliable tools for the identification of BCEs are important in biotechnological and clinical applications (e.g. therapeutic antibody development and vaccine design, as well as in the overall understanding of immune mechanisms) (<xref rid="btad187-B10" ref-type="bibr">Gomara and Haro 2007</xref>). X-ray crystallography and nuclear magnetic resonance techniques are trustable approaches for identifying BCEs (<xref rid="btad187-B22" ref-type="bibr">Mayer and Meyer 2001</xref>). Nevertheless, these traditional experimental approaches are expensive and time-consuming (<xref rid="btad187-B18" ref-type="bibr">Kavitha et al. 2013</xref>). The silico prediction tools can mitigate the identification workload by predicting epitope regions. For example, <xref rid="btad187-B14" ref-type="bibr">Jespersen et al. (2017)</xref> propose the commonly used tool BepiPred-2.0, which employs a random forest model to train annotated epitopes from antibody-antigen protein structures and then uses the trained model to predict newly generated antigen sequences. Afterward, with the increase in biological data, a few deep learning methods are implemented for accurately predicting BCEs. EpiDope (<xref rid="btad187-B5" ref-type="bibr">Collatz et al. 2021</xref>) uses a deep neural network to identify BCEs on individual protein sequences, which extracts context-aware representations for every residue in the sequence via applying the feature vector that has a length of 1000. In this way, EpiDope exceeds baseline methods in identifying BCEs. Although the above methods obtain good performance in identifying linear epitopes, they have difficulty in identifying conformational epitopes consisting of amino acid fragments that are far apart in the protein sequence but are brought together by the conformational folding of the polypeptide chain.</p>
    <p>To solve these problems, several structure-based methods have been designed by considering spatial information. DiscoTope (<xref rid="btad187-B12" ref-type="bibr">Haste Andersen et al. 2006</xref>) is the first approach that focuses on discontinuous epitopes by considering spatial information, amino acid statistics, and surface accessibility. DiscoTope-2.0 (<xref rid="btad187-B19" ref-type="bibr">Kringelum et al. 2012</xref>) is the improved version of DiscoTope by adding half-sphere exposure and propensity scores as a surface measure. Nonetheless, DiscoTope-2.0 does not take into account glycosylation which may significantly affect epitopes. SEPPA 3.0 (<xref rid="btad187-B38" ref-type="bibr">Zhou et al. 2019</xref>) investigates the impact of glycosylation in the antigen surface patches, showing that antibodies may tend to attach in N-glycosylation sites. ElliPro (<xref rid="btad187-B25" ref-type="bibr">Ponomarenko et al. 2008</xref>) characterizes antigenic proteins by approximating them as ellipsoids and then calculates the protrusion index of the residues to cluster them. Epitope3D (<xref rid="btad187-B6" ref-type="bibr">da Silva et al. 2022</xref>) is a new scalable machine learning approach for predicting conformational epitopes by using graph-based structural signatures. So far, structure-based tools have achieved decent performance, most of the time, better than sequence-based tools (<xref rid="btad187-B28" ref-type="bibr">Singh et al. 2013</xref>, <xref rid="btad187-B6" ref-type="bibr">da Silva et al. 2022</xref>). However, since experimentally decided structural information is usually not available, BCEs prediction must in numerous cases be conducted via sequences alone.</p>
    <p>With the great advances in deep learning technologies, protein structure prediction is undergoing a breakthrough. For example, AlphaFold2 (<xref rid="btad187-B16" ref-type="bibr">Jumper et al. 2021</xref>) is a complicated deep-learning model for predicting protein structures, which has integrated a lot of biological and physical knowledge. In the 14th Critical Assessment of Protein Structure Prediction, AlphaFold2 has shown the ability in predicting the structure of the protein with atomic accuracy and demonstrated accuracy competitive with experiments on a large number of cases. On the other hand, unsupervised pre-training using language models has led to breakthrough improvements in natural language processing. Recently, these techniques have been employed in protein sequence representation learning and have shown very promising results in many prediction tasks such as tertiary contacts, mutational effects, and secondary structure (<xref rid="btad187-B9" ref-type="bibr">Elnaggar et al. 2020</xref>, <xref rid="btad187-B35" ref-type="bibr">Yuan et al. 2022</xref>). These breakthroughs inspire us to design an accurate BCE predictor by using the predicted protein structures and the pretrained language model.</p>
    <p>In this study, we propose GraphBepi, a novel graph-based model for accurate epitope prediction. GraphBepi first generates the effective information sequence representations and protein structures from antigen sequences by the pretrained language model and AlphaFold2, respectively. GraphBepi then applies the edge-enhanced deep graph neural network (EGNN) (<xref rid="btad187-B11" ref-type="bibr">Gong and Cheng 2019</xref>) to capture the predicted protein structural information and leverages the bidirectional long short-term memory neural networks (BiLSTM) (<xref rid="btad187-B13" ref-type="bibr">Hochreiter and Schmidhuber 1997</xref>) to capture long-range dependencies from sequences. The low-dimensional representation learned from EGNN and BiLSTM is then combined to predict BCEs. Through comprehensive tests on the curated epitope dataset, GraphBepi was shown to outperform the state-of-the-art methods.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Dataset</title>
      <p>To train and evaluate our model, we took a similar strategy as the study (<xref rid="btad187-B6" ref-type="bibr">da Silva et al. 2022</xref>) to build a large epitope dataset. Specifically, we first fetched all biological assemblies with a value of resolution greater than or equal to 3 Å from the Protein Data Bank deposited before 09 May 2022 (<xref rid="btad187-B4" ref-type="bibr">Berman et al. 2000</xref>). Next, the ANARCI (<xref rid="btad187-B8" ref-type="bibr">Dunbar et al. 2016</xref>) tool was used to identify antibody-antigen complexes and retain antigen chains with lengths of 25–1024. We labeled epitope residues in the antigen molecule depending on a cutoff distance standard. For example, an antigen residue that has at least one heavy atom at a distance of &lt;4 Å to a residue of antibody will be treated as the epitope residue. We removed the antigen chain if it contained epitopes &lt;5. Next, we used MMseqs2 (<xref rid="btad187-B30" ref-type="bibr">Steinegger and Söding 2017</xref>) to cluster antigen sequences, and any antigen sequence belonging to the same cluster was aligned to the cluster representative defined by MMseqs2 through tool blastp (<xref rid="btad187-B15" ref-type="bibr">Johnson et al. 2008</xref>). Each clustering representative sequence was then modified as follows: if an epitope was labeled in the clustering representative, it would be kept. If one epitope was found in any antigen sequence of the aligned sequences, it would be transposed to the clustering representative sequence and marked as an epitope. This process was done at 95% sequence identity, resulting in the size of the dataset with 783 antigen sequences. We further conducted redundancy reduction via MMseqs2 at 70% sequence identity, resulting in generating a nonredundant dataset of 633 antigen sequences. Finally, the antigen sequences deposited after 04 January 2021 were used as the independent test data (56 antigen sequences, consisting of 1393 binding residues, and 14 150 nonbinding residues, with 8.96% of epitope residues), and the rest of the antigen sequences were used as the training data (577 antigen sequences, consisting of 15 981 binding residues, and 119 869 nonbinding residues, with 11.76% of epitope residues).</p>
    </sec>
    <sec>
      <title>2.2 Protein representation</title>
      <sec>
        <title>2.2.1 Language model representation</title>
        <p>The latest language model esm2_t36_3B_UR50D (<xref rid="btad187-B20" ref-type="bibr">Lin et al. 2022</xref>) (denoted as ESM-2) is used for extracting features from each antigen sequence, which is an updated version of esm_msa1b_t12_100M_UR50S (denoted as ESM). The architecture of ESM and ESM-2 is based on the transformer model, and both of them are pretrained on UniRef50 (<xref rid="btad187-B31" ref-type="bibr">Suzek et al. 2007</xref>) through the masked language modeling objective (<xref rid="btad187-B7" ref-type="bibr">Devlin et al. 2018</xref>) in an unsupervised manner. We leverage the ESM-2 to extract sequence representation for each residue, which generates a 2560D feature vector for per-residue. We introduce ESM-2 in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Note S1</xref>. We have also tested another similar protein language model ProtT5-XL-U50 (<xref rid="btad187-B9" ref-type="bibr">Elnaggar et al. 2020</xref>) (denoted as ProtTrans), which is first trained on BFD (<xref rid="btad187-B29" ref-type="bibr">Steinegger et al. 2019</xref>) and then fine-tuned on the UniRef50.</p>
      </sec>
      <sec>
        <title>2.2.2 Evolutionary information</title>
        <p>Evolutionarily conserved residues probably include motifs correlated to crucial properties of the protein. For investigating the importance of evolutionary features, we test the widely used evolutionary features HMM profile and position-specific scoring matrix (PSSM). The HMM profiles are produced by running the tool HHblits (<xref rid="btad187-B27" ref-type="bibr">Remmert et al. 2012</xref>) against UniClust30 (<xref rid="btad187-B23" ref-type="bibr">Mirdita et al. 2017</xref>) using the default setting. The PSSM is produced by conducting the tool PSI-BLAST (<xref rid="btad187-B2" ref-type="bibr">Altschul et al. 1997</xref>) to seek the candidate sequence against UniRef90 (<xref rid="btad187-B31" ref-type="bibr">Suzek et al. 2007</xref>) using an E-value of 0.001 and three iterations. Each residue is embedded into a 20D feature vector through PSSM and HMM, respectively. We detail PSSM and HMM in <xref rid="sup1" ref-type="supplementary-material">Supplementary Note S2</xref>.</p>
      </sec>
      <sec>
        <title>2.2.3 Predicted protein structures</title>
        <p>To take account of spatial information for each residue, we apply the predictive tool AlphaFold2 to predict protein structure. Specifically, we follow the tutorial at <ext-link xlink:href="https://github.com/deepmind/alphafold" ext-link-type="uri">https://github.com/deepmind/alphafold</ext-link> to deploy AlphaFold2 on the Tianhe-2 supercomputer and then predict the protein structures. AlphaFold2 is detailed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Note S3</xref>. We have also investigated another similar protein structural prediction model, esmfold_v1 (<xref rid="btad187-B20" ref-type="bibr">Lin et al. 2022</xref>) (denoted as ESMFold), which is a full end-to-end single sequence structure predictor. We download the pretrained ESMFold and then directly apply it to predict protein structures.</p>
      </sec>
      <sec>
        <title>2.2.4 Structural properties</title>
        <p>We apply the DSSP program (<xref rid="btad187-B17" ref-type="bibr">Kabsch and Sander 1983</xref>) to extract three kinds of structural properties from the AlphaFold2 predicted protein structures: (1) the profile of the 9D one-hot secondary structure, where the main eight dimensions indicate the states of the eight secondary structures and the final dimension indicates the unknown secondary structure. (2) Relative solvent accessibility (RSA) is obtained by normalizing the solvent accessible surface area (ASA) through the maximal possible ASA of the corresponding amino acid type. (3) Peptide backbone torsion angles PSI and PHI are transferred into a 4D feature vector by cosine and sine. In summary, these structural feature vectors with 13 dimensions are called DSSP in this manuscript.</p>
      </sec>
    </sec>
    <sec>
      <title>2.3 The architecture of GraphBepi</title>
      <p>This study proposes a novel method GraphBepi for improving BCEs prediction by considering spatial information. As shown in <xref rid="btad187-F1" ref-type="fig">Fig. 1</xref>, the antigen sequence is fed into the pretrained language model and AlphaFold2 to generate the sequence embedding and protein structures, respectively. The relational graph of residues and DSSP are then extracted from protein structures. The sequence embedding and DSSP are then fed into the BiLSTM module to learn the effective representation by capturing long-range dependencies from sequences. They are also concatenated to form feature vectors of residues in the relational graph and are then fed into the EGNN to learn the structural information. Finally, the output of the EGNN and BiLSTM modules is concatenated to predict BCEs through a multilayer perceptron (MLP).</p>
      <fig position="float" id="btad187-F1">
        <label>Figure 1.</label>
        <caption>
          <p>The framework of the GraphBepi model. The input antigen sequence is respectively fed into the pretrained language model and AlphaFold2 to generate the ESM2-embedding and protein structures. The relational graph of residues and DSSP are extracted from the predicted protein structures. The ESM2-embedding and DSSP are then fed into the BiLSTM module to learn the effective representation by capturing long-range dependencies of the residues. They are also concatenated to form feature vectors of residues in the relational graph, which is then fed into the EGNN to learn the structural information. Finally, the output of the EGNN and BiLSTM modules is concatenated to predict BCEs through an MLP.</p>
        </caption>
        <graphic xlink:href="btad187f1" position="float"/>
      </fig>
      <sec>
        <title>2.3.1 The bidirectional LSTM module</title>
        <p>The long short-term memory (LSTM) is a classic algorithm for capturing long-range dependencies, which is widely used in protein sequence encoding. The BiLSTM model appends one more LSTM layer and reverses the direction of information. Namely, it represents that the input sequence passes backward in the newly added LSTM layer. In this study, we use a bidirectional LSTM to process antigen sequences since they do not have a specific direction. We indicate the output of the BiLSTM using the term <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mi>H</mml:mi></mml:math></inline-formula> for simplicity. The BiLSTM is employed for learning the DSSP structural properties obtained from predicted structures and the sequence embeddings obtained from ESM-2, respectively. We introduce the BiLSTM algorithm carefully in <xref rid="sup1" ref-type="supplementary-material">Supplementary Note S4</xref>.</p>
      </sec>
      <sec>
        <title>2.3.2 Graph construction</title>
        <p>We build the residue-level relational graph <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mo>ε</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>R</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> for the structure of an antigen following <xref rid="btad187-B37" ref-type="bibr">Zhang et al. (2022)</xref>, where <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mi>N</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mi mathvariant="normal">and</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mo>ε</mml:mo><mml:mi mathvariant="normal"> </mml:mi></mml:math></inline-formula> mean the set of residues (nodes) and edges, respectively, and <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mi>R</mml:mi></mml:math></inline-formula> is the set of edge types. The term <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> is used for indicating the edge from node<inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mo> </mml:mo><mml:mi>i</mml:mi></mml:math></inline-formula> to node j with edge type r. We add three types of directed edges into the graph including K-nearest neighbor edges, radius edges, and sequential edges. They are generated as follows: (1) sequential edges: residues <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula> and <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mi>j</mml:mi></mml:math></inline-formula> will be connected by an edge if <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:mi>j</mml:mi><mml:mo>-</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mfenced><mml:mo>&lt;</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">seq</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, where <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mo>|</mml:mo><mml:mi>j</mml:mi><mml:mo>-</mml:mo><mml:mi>i</mml:mi><mml:mo>|</mml:mo></mml:math></inline-formula> represents the sequential distance between residues<inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mo> </mml:mo></mml:math></inline-formula>and <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mi>j</mml:mi></mml:math></inline-formula>, and <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">seq</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a predefined threshold. Then, the <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo>-</mml:mo><mml:mi>i</mml:mi></mml:math></inline-formula> is used as the edge type between residue <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula> and<inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mi mathvariant="normal"> </mml:mi></mml:math></inline-formula><italic toggle="yes">j</italic>. Hence, there are 2<inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">seq</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo></mml:math></inline-formula>1 types of sequential edges. (2) Radius edges: the radius edges between two residues are also added when the spatial distance between them is less than a threshold <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">radius</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. (3) K-nearest neighbor edges: KNN edge types are added by computing the K-nearest neighbors based on the Euclidean distance. In this study, the sequential distance threshold <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">seq</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and the radius are set to 3 and 10, respectively. The number of residue neighbor <italic toggle="yes">k</italic> is set to 10. Finally, the edge types consist of radius edges, KNN edges, and sequential edges, resulting in 2<inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">seq</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>+1 = 7 different types of edges. We further introduce these edge types in <xref rid="sup1" ref-type="supplementary-material">Supplementary Note S5</xref>.</p>
      </sec>
      <sec>
        <title>2.3.3 EGNN module</title>
        <p>We apply the EGNN (<xref rid="btad187-B11" ref-type="bibr">Gong and Cheng 2019</xref>) framework to capture spatial information by adequately integrating node (residue) features and multiple-dimensional edge features. Given a residue graph with <italic toggle="yes">N</italic> residues, we first let <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mi>X</mml:mi></mml:math></inline-formula> be an <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>F</mml:mi></mml:math></inline-formula> matrix representing the residue features of the entire graph, where <italic toggle="yes">F</italic> is the dimension of the residue vector. The edge features are represented by an <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>P</mml:mi></mml:math></inline-formula> tensor, where <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mi>P</mml:mi><mml:mo> </mml:mo></mml:math></inline-formula>is the dimension of the edge feature. Therefore, <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> indicates the <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mi>P</mml:mi></mml:math></inline-formula>-dimensional feature of the edge that connects residue <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula> and residue <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mi>j</mml:mi></mml:math></inline-formula>. The term <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ijp</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo></mml:math></inline-formula>indicates the <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mi>p</mml:mi></mml:math></inline-formula>th channel for the edge feature in <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:mo> </mml:mo></mml:math></inline-formula>Concretely, the feature vector <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup><mml:mo> </mml:mo></mml:math></inline-formula>of residue <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula> at the<inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mo> </mml:mo><mml:mi>l</mml:mi></mml:math></inline-formula> layer will be summed from feature vectors of the neighboring nodes by simultaneously integrating the edge features. The aggregation operation is represented as follows:
where <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mo>σ</mml:mo></mml:math></inline-formula> is the activation function. <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mo>α</mml:mo></mml:math></inline-formula> is the attention operation, which is guided by edge features of the edge connecting two residues; <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mo>α</mml:mo></mml:mrow><mml:mrow><mml:mo>.</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> represents the <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mi>p</mml:mi></mml:math></inline-formula> channel matrix slice of the <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>P</mml:mi></mml:math></inline-formula> tensor. Specifically, we treat multiple-dimensional edge features as multi-channel signals and then perform an individual attention for each channel. These results from each channel are then combined through the concatenation operation <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:math></inline-formula>. For an individual channel of edge features, we conduct the attention function as follows:
where <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is the attention function implemented by a linear function:
where <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mi>L</mml:mi></mml:math></inline-formula> is the LeakyReLU function. The term <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mo>|</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="normal"> </mml:mi></mml:math></inline-formula>is the concatenation operation. In <xref rid="E1" ref-type="disp-formula">Equation (1)</xref>, <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mi>g</mml:mi></mml:math></inline-formula> is the transformation function mapping the residue features from the input to the output space, which can be formulated as follows:
where <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi mathvariant="normal">W</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is a parameter matrix. Finally, the attention coefficients will be treated as the new edge features for the following layer. By this mean, EGNN efficiently integrates the edge and node features.</p>
        <disp-formula id="E1">
          <label>(1)</label>
          <mml:math id="M1" display="block" overflow="scroll">
            <mml:msup>
              <mml:mrow>
                <mml:mi mathvariant="normal">X</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>l</mml:mi>
              </mml:mrow>
            </mml:msup>
            <mml:mo>=</mml:mo>
            <mml:mo>σ</mml:mo>
            <mml:mfenced open="[" close="]" separators="|">
              <mml:mrow>
                <mml:msubsup>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                    <mml:mo>|</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>p</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                </mml:msubsup>
                <mml:mfenced open="(" close=")" separators="|">
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mo>α</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>.</mml:mo>
                        <mml:mi>p</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>l</mml:mi>
                      </mml:mrow>
                    </mml:msubsup>
                    <mml:mfenced open="(" close=")" separators="|">
                      <mml:mrow>
                        <mml:msup>
                          <mml:mrow>
                            <mml:mi>X</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>l</mml:mi>
                            <mml:mo>-</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                        </mml:msup>
                        <mml:mo>,</mml:mo>
                        <mml:msubsup>
                          <mml:mrow>
                            <mml:mi>E</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mo>.</mml:mo>
                            <mml:mi>p</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>l</mml:mi>
                            <mml:mo>-</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                        </mml:msubsup>
                      </mml:mrow>
                    </mml:mfenced>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>g</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>l</mml:mi>
                      </mml:mrow>
                    </mml:msup>
                    <mml:mfenced open="(" close=")" separators="|">
                      <mml:mrow>
                        <mml:msup>
                          <mml:mrow>
                            <mml:mi>X</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>l</mml:mi>
                            <mml:mo>-</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                        </mml:msup>
                      </mml:mrow>
                    </mml:mfenced>
                  </mml:mrow>
                </mml:mfenced>
              </mml:mrow>
            </mml:mfenced>
            <mml:mi mathvariant="normal"> </mml:mi>
          </mml:math>
        </disp-formula>
        <disp-formula id="E2">
          <label>(2)</label>
          <mml:math id="M2" display="block" overflow="scroll">
            <mml:msubsup>
              <mml:mrow>
                <mml:mo>α</mml:mo>
              </mml:mrow>
              <mml:mrow>
                <mml:mi mathvariant="italic">ijp</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>l</mml:mi>
              </mml:mrow>
            </mml:msubsup>
            <mml:mo>=</mml:mo>
            <mml:msup>
              <mml:mrow>
                <mml:mi>f</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>l</mml:mi>
              </mml:mrow>
            </mml:msup>
            <mml:mfenced open="(" close=")" separators="|">
              <mml:mrow>
                <mml:msubsup>
                  <mml:mrow>
                    <mml:mi>X</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>l</mml:mi>
                    <mml:mo>-</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msubsup>
                <mml:mo>,</mml:mo>
                <mml:msubsup>
                  <mml:mrow>
                    <mml:mi>X</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>j</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>l</mml:mi>
                    <mml:mo>-</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msubsup>
              </mml:mrow>
            </mml:mfenced>
            <mml:msubsup>
              <mml:mrow>
                <mml:mi>E</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi mathvariant="italic">ijp</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>l</mml:mi>
                <mml:mo>-</mml:mo>
                <mml:mn>1</mml:mn>
              </mml:mrow>
            </mml:msubsup>
            <mml:mi mathvariant="normal"> </mml:mi>
          </mml:math>
        </disp-formula>
        <disp-formula id="E3">
          <label>(3)</label>
          <mml:math id="M3" display="block" overflow="scroll">
            <mml:msup>
              <mml:mrow>
                <mml:mi>f</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>l</mml:mi>
              </mml:mrow>
            </mml:msup>
            <mml:mfenced open="(" close=")" separators="|">
              <mml:mrow>
                <mml:msubsup>
                  <mml:mrow>
                    <mml:mi>X</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mo>.</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>l</mml:mi>
                    <mml:mo>-</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msubsup>
                <mml:mo>,</mml:mo>
                <mml:msubsup>
                  <mml:mrow>
                    <mml:mi>X</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>j</mml:mi>
                    <mml:mo>.</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>l</mml:mi>
                    <mml:mo>-</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msubsup>
              </mml:mrow>
            </mml:mfenced>
            <mml:mo>=</mml:mo>
            <mml:mi mathvariant="normal">exp</mml:mi>
            <mml:mo>⁡</mml:mo>
            <mml:mo>{</mml:mo>
            <mml:mi>L</mml:mi>
            <mml:mo>(</mml:mo>
            <mml:msup>
              <mml:mrow>
                <mml:mo>α</mml:mo>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>T</mml:mi>
              </mml:mrow>
            </mml:msup>
            <mml:mo>[</mml:mo>
            <mml:mi>W</mml:mi>
            <mml:msubsup>
              <mml:mrow>
                <mml:mi>X</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>i</mml:mi>
                <mml:mo>.</mml:mo>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>l</mml:mi>
                <mml:mo>-</mml:mo>
                <mml:mn>1</mml:mn>
              </mml:mrow>
            </mml:msubsup>
            <mml:mo>|</mml:mo>
            <mml:mo>|</mml:mo>
            <mml:mi>W</mml:mi>
            <mml:msubsup>
              <mml:mrow>
                <mml:mi>X</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>j</mml:mi>
                <mml:mo>.</mml:mo>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>l</mml:mi>
                <mml:mo>-</mml:mo>
                <mml:mn>1</mml:mn>
              </mml:mrow>
            </mml:msubsup>
            <mml:mo>]</mml:mo>
            <mml:mo>)</mml:mo>
            <mml:mo>}</mml:mo>
            <mml:mi mathvariant="normal"> </mml:mi>
          </mml:math>
        </disp-formula>
        <disp-formula id="E4">
          <label>(4)</label>
          <mml:math id="M4" display="block" overflow="scroll">
            <mml:msup>
              <mml:mrow>
                <mml:mi mathvariant="normal">g</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>l</mml:mi>
              </mml:mrow>
            </mml:msup>
            <mml:mo>(</mml:mo>
            <mml:msup>
              <mml:mrow>
                <mml:mi>X</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>l</mml:mi>
                <mml:mo>-</mml:mo>
                <mml:mn>1</mml:mn>
              </mml:mrow>
            </mml:msup>
            <mml:mo>)</mml:mo>
            <mml:mo>=</mml:mo>
            <mml:msup>
              <mml:mrow>
                <mml:mi mathvariant="normal">W</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>l</mml:mi>
              </mml:mrow>
            </mml:msup>
            <mml:msup>
              <mml:mrow>
                <mml:mi>X</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>l</mml:mi>
                <mml:mo>-</mml:mo>
                <mml:mn>1</mml:mn>
              </mml:mrow>
            </mml:msup>
            <mml:mi mathvariant="normal"> </mml:mi>
          </mml:math>
        </disp-formula>
      </sec>
      <sec>
        <title>2.3.4 Multilayer perceptron</title>
        <p>We combine the output of the EGNN module and the BiLSTM module via concatenation operation, and then feed them into the MLP to identify the BCE binding probabilities as follows:
where <inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mn>512</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo> </mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">Dssp</mml:mi><mml:mo> </mml:mo></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mn>256</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="normal">and</mml:mi><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">ESM</mml:mi><mml:mn>2</mml:mn><mml:mo>-</mml:mo><mml:mi mathvariant="normal">seq</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mn>256</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> are the output of the <inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mi mathvariant="normal">l</mml:mi></mml:math></inline-formula>ast layer of EGNN module and the BiLSTM module, respectively. <inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:mi>Y</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> is the predictive result of <inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:mi>N</mml:mi></mml:math></inline-formula> amino acid residues.</p>
        <disp-formula id="E5">
          <label>(5)</label>
          <mml:math id="M5" display="block" overflow="scroll">
            <mml:mi>Y</mml:mi>
            <mml:mo>=</mml:mo>
            <mml:mi mathvariant="normal">Sigmoid</mml:mi>
            <mml:mi mathvariant="normal"> </mml:mi>
            <mml:mfenced open="(" close=")" separators="|">
              <mml:mrow>
                <mml:mfenced open="(" close=")" separators="|">
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>X</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>g</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mfenced open="(" close=")" separators="|">
                          <mml:mrow>
                            <mml:mi>L</mml:mi>
                          </mml:mrow>
                        </mml:mfenced>
                        <mml:mi mathvariant="normal"> </mml:mi>
                      </mml:mrow>
                    </mml:msubsup>
                    <mml:mfenced open="‖" close="‖" separators="|">
                      <mml:mrow>
                        <mml:mi mathvariant="normal"> </mml:mi>
                        <mml:msubsup>
                          <mml:mrow>
                            <mml:mi>H</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi mathvariant="italic">Dssp</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mfenced open="(" close=")" separators="|">
                              <mml:mrow>
                                <mml:mi>L</mml:mi>
                              </mml:mrow>
                            </mml:mfenced>
                          </mml:mrow>
                        </mml:msubsup>
                        <mml:mi mathvariant="normal"> </mml:mi>
                      </mml:mrow>
                    </mml:mfenced>
                    <mml:mi mathvariant="normal"> </mml:mi>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>H</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi mathvariant="italic">ESM</mml:mi>
                        <mml:mn>2</mml:mn>
                        <mml:mo>-</mml:mo>
                        <mml:mi mathvariant="italic">seq</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mfenced open="(" close=")" separators="|">
                          <mml:mrow>
                            <mml:mi>L</mml:mi>
                          </mml:mrow>
                        </mml:mfenced>
                      </mml:mrow>
                    </mml:msubsup>
                  </mml:mrow>
                </mml:mfenced>
                <mml:mi>W</mml:mi>
                <mml:mo>+</mml:mo>
                <mml:mi>b</mml:mi>
              </mml:mrow>
            </mml:mfenced>
          </mml:math>
        </disp-formula>
      </sec>
    </sec>
    <sec>
      <title>2.4 Evaluation metrics and implementation details</title>
      <p>Similar to the previous study (<xref rid="btad187-B34" ref-type="bibr">Yuan et al. 2021</xref>), six commonly used metrics are employed for evaluating prediction performance. They are recall (Rec), precision (Pre), Matthews correlation coefficient (MCC), F1-score (F1), area under the precision-recall curve (AUPR), and area under the receiver operating characteristic curve (AUC):
where TN and TP are true negatives and true positives, meaning the number of nonbinding and binding residues predicted correctly, respectively. FN and FP are false negatives and false positives, representing the number of incorrectly identified nonbinding and binding residues, respectively. AUPR and AUR are computed without thresholds, therefore revealing the overall performance of the method. The rest metrics are computed through a predefined threshold to transfer the predicted scores to binary predictions, where the threshold is decided by maximizing the F1 score.</p>
      <disp-formula id="E6">
        <label>(6)</label>
        <mml:math id="M6" display="block" overflow="scroll">
          <mml:mi mathvariant="normal">Pre</mml:mi>
          <mml:mo>=</mml:mo>
          <mml:mfrac>
            <mml:mrow>
              <mml:mi mathvariant="normal">TP</mml:mi>
            </mml:mrow>
            <mml:mrow>
              <mml:mi mathvariant="normal">TP</mml:mi>
              <mml:mo>+</mml:mo>
              <mml:mi mathvariant="normal">FP</mml:mi>
            </mml:mrow>
          </mml:mfrac>
        </mml:math>
      </disp-formula>
      <disp-formula id="E7">
        <label>(7)</label>
        <mml:math id="M7" display="block" overflow="scroll">
          <mml:mi mathvariant="normal">Rec</mml:mi>
          <mml:mo>=</mml:mo>
          <mml:mfrac>
            <mml:mrow>
              <mml:mi mathvariant="normal">TP</mml:mi>
            </mml:mrow>
            <mml:mrow>
              <mml:mi mathvariant="normal">TP</mml:mi>
              <mml:mo>+</mml:mo>
              <mml:mi mathvariant="normal">FN</mml:mi>
            </mml:mrow>
          </mml:mfrac>
          <mml:mi mathvariant="normal"> </mml:mi>
        </mml:math>
      </disp-formula>
      <disp-formula id="E8">
        <label>(8)</label>
        <mml:math id="M8" display="block" overflow="scroll">
          <mml:mi mathvariant="normal">F</mml:mi>
          <mml:mn>1</mml:mn>
          <mml:mo>=</mml:mo>
          <mml:mn>2</mml:mn>
          <mml:mo>×</mml:mo>
          <mml:mfrac>
            <mml:mrow>
              <mml:mi mathvariant="normal">Precision</mml:mi>
              <mml:mo>×</mml:mo>
              <mml:mi mathvariant="normal">Recall</mml:mi>
            </mml:mrow>
            <mml:mrow>
              <mml:mi mathvariant="normal">Precision</mml:mi>
              <mml:mo>+</mml:mo>
              <mml:mi mathvariant="normal">Recall</mml:mi>
            </mml:mrow>
          </mml:mfrac>
          <mml:mi mathvariant="normal"> </mml:mi>
        </mml:math>
      </disp-formula>
      <disp-formula id="E9">
        <label>(9)</label>
        <mml:math id="M9" display="block" overflow="scroll">
          <mml:mi mathvariant="normal">MCC</mml:mi>
          <mml:mo>=</mml:mo>
          <mml:mfrac>
            <mml:mrow>
              <mml:mi mathvariant="normal">TP</mml:mi>
              <mml:mo>×</mml:mo>
              <mml:mi mathvariant="normal">TN</mml:mi>
              <mml:mo>-</mml:mo>
              <mml:mi mathvariant="normal">FN</mml:mi>
              <mml:mo>×</mml:mo>
              <mml:mi mathvariant="normal">FP</mml:mi>
            </mml:mrow>
            <mml:mrow>
              <mml:msqrt>
                <mml:mfenced open="(" close=")" separators="|">
                  <mml:mrow>
                    <mml:mi mathvariant="normal">TP</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi mathvariant="normal">FP</mml:mi>
                  </mml:mrow>
                </mml:mfenced>
                <mml:mo>×</mml:mo>
                <mml:mfenced open="(" close=")" separators="|">
                  <mml:mrow>
                    <mml:mi mathvariant="normal">TP</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi mathvariant="normal">FN</mml:mi>
                  </mml:mrow>
                </mml:mfenced>
                <mml:mo>×</mml:mo>
                <mml:mfenced open="(" close=")" separators="|">
                  <mml:mrow>
                    <mml:mi mathvariant="normal">TN</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi mathvariant="normal">FP</mml:mi>
                  </mml:mrow>
                </mml:mfenced>
                <mml:mo>×</mml:mo>
                <mml:mfenced open="(" close=")" separators="|">
                  <mml:mrow>
                    <mml:mi mathvariant="normal">TN</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi mathvariant="normal">FN</mml:mi>
                  </mml:mrow>
                </mml:mfenced>
              </mml:msqrt>
            </mml:mrow>
          </mml:mfrac>
          <mml:mi mathvariant="normal"> </mml:mi>
        </mml:math>
      </disp-formula>
      <p>All experimental results were conducted on an Nvidia GeForce RTX 3090 GPU. We introduce the implementation details in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Note S6</xref>.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Performance on the 10-fold CV and independent test</title>
      <p>The GraphBepi method was evaluated according to AUC, AUPR, F1, and MCC using the 10-fold CV on the training set together with the independent test. Concretely, the GraphBepi model achieved AUC values of 0.723 and 0.751, AUPR values of 0.245 and 0.261, F1 values of 0.320 and 0.310, and MCC values of 0.212, and 0.232 on the 10-fold CV and the independent test, respectively (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). The consistent performance on the CV and independent test demonstrated the robustness of our model. For further investigating the advantages of antigen geometric information and the EGNN, we compared GraphBepi with a baseline model transformer consisting of two-layer networks. The transformer was used as a baseline to test the impact of the structural information for epitope prediction, which was fed the same features as GraphBepi. As shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>, GraphBepi consistently outperformed the baseline model transformer with 4.6%, 6.4%, 5.1%, and 5.6% higher values in terms of AUC, AUPR, F1, and MCC, respectively. The improved performance of our method over the transformer may result from its ability in capturing spatial information, because the EGNN helped GraphBepi pay attention to the spatially adjacent residues, which learned the remote residues connected in the whole graph by efficiently integrating different edge features and residue features. As shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>, the removal of edge features caused a decrease of 2.9% in terms of AUPR on the independent test.</p>
      <p>We further evaluated the performance of our method and transformer on amino acids with different numbers of nonlocal contacts. Two residues are considered as nonlocal contacts if they are separated with greater than 20 residues in sequence and their C<inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:mi mathvariant="normal">α</mml:mi></mml:math></inline-formula> distance is &lt;12 Å. <xref rid="btad187-F2" ref-type="fig">Figure 2</xref> shows that our method consistently outperformed the transformer on the independent test data. Concretely, the performance of our method outperformed the transformer by 11% in terms of F1 when the amino acids had 0–9 nonlocal contacts, and the performance gap expanded to 52% when the number of nonlocal contacts were larger than 20. Similar trends could be found when measured by other metrics (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>). The results demonstrated that GraphBepi efficiently captured the spatial information of antigen structures.</p>
      <fig position="float" id="btad187-F2">
        <label>Figure 2.</label>
        <caption>
          <p>The F1 values of GraphBepi and transformer on amino acids with the different numbers of nonlocal contacts.</p>
        </caption>
        <graphic xlink:href="btad187f2" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.2 Representation from pretrained language models is informative for predicting BCEs</title>
      <p>To evaluate the effects of ESM-2 on GraphBepi, we compared ESM-2 with the broadly used evolutionary features, and another two language models (ESM and ProtTrans). As shown in <xref rid="btad187-T1" ref-type="table">Table 1</xref>, on the independent test, the model only using ESM-2 features gained an average AUC and AUPR of 0.736 and 0.240, respectively. By comparison, the uses of only EVO (evolutionary profiles of HMM and PSSM) or DSSP led to 4.9% and 6.9% decreases in terms of AUPR, respectively. The results demonstrated that the embeddings learned from the pretrained language model ESM-2 were better than the evolutionary features.</p>
      <table-wrap position="float" id="btad187-T1">
        <label>Table 1.</label>
        <caption>
          <p>The predictive performance on the independent test using different features.<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref></p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Feature group</th>
              <th rowspan="1" colspan="1">AUC</th>
              <th rowspan="1" colspan="1">AUPR</th>
              <th rowspan="1" colspan="1">F1</th>
              <th rowspan="1" colspan="1">MCC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">EVO</td>
              <td rowspan="1" colspan="1">0.717</td>
              <td rowspan="1" colspan="1">0.191</td>
              <td rowspan="1" colspan="1">0.269</td>
              <td rowspan="1" colspan="1">0.185</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DSSP</td>
              <td rowspan="1" colspan="1">0.680</td>
              <td rowspan="1" colspan="1">0.171</td>
              <td rowspan="1" colspan="1">0.235</td>
              <td rowspan="1" colspan="1">0.142</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ESM-2</td>
              <td rowspan="1" colspan="1">0.736</td>
              <td rowspan="1" colspan="1">0.240</td>
              <td rowspan="1" colspan="1">0.291</td>
              <td rowspan="1" colspan="1">0.212</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">EVO + DSSP</td>
              <td rowspan="1" colspan="1">0.723</td>
              <td rowspan="1" colspan="1">0.200</td>
              <td rowspan="1" colspan="1">0.271</td>
              <td rowspan="1" colspan="1">0.192</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ProtTrans + DSSP</td>
              <td rowspan="1" colspan="1">0.750</td>
              <td rowspan="1" colspan="1">0.260</td>
              <td rowspan="1" colspan="1">0.309</td>
              <td rowspan="1" colspan="1">0.214</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ESM + DSSP</td>
              <td rowspan="1" colspan="1">0.744</td>
              <td rowspan="1" colspan="1">0.216</td>
              <td rowspan="1" colspan="1">0.293</td>
              <td rowspan="1" colspan="1">0.212</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ESM-2 + EVO + DSSP</td>
              <td rowspan="1" colspan="1">
                <bold>0.757</bold>
              </td>
              <td rowspan="1" colspan="1">0.254</td>
              <td rowspan="1" colspan="1">
                <bold>0.317</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.240</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ESM-2 + DSSP(GraphBepi)</td>
              <td rowspan="1" colspan="1">0.751</td>
              <td rowspan="1" colspan="1">
                <bold>0.261</bold>
              </td>
              <td rowspan="1" colspan="1">0.310</td>
              <td rowspan="1" colspan="1">0.232</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <label>a</label>
            <p>EVO means the evolutionary features HMM and PSSM.</p>
          </fn>
          <fn id="tblfn2">
            <p>Bold fonts indicate the best results. </p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>In addition, we investigated the performance of our model when integrating different features. We noted that the performance of EVO could be improved by integrating the structural properties DSSP. Therefore, we also integrated DSSP with ESM-2, which improved by 8.75% in terms of the AUPR metric. These results demonstrated that the structural properties of amino acids such as RSA and secondary structure were sufficient to reserve the complex patterns of epitopes. We then integrated more information including evolutionary features, ESM-2 embeddings, and DSSP.</p>
      <p>The results showed that combing all information brought a minor improvement on the independent test set (&lt;0.01 of AUC). These results demonstrated that the ESM-2 model may potentially reserve the evolutionary information of the protein. We found ESM-2 performed slightly better than ProtTrans, likely because they took different network architectures. ESM-2 and ProtTrans outperformed ESM in all metrics, probably because they used more training parameters and datasets. A similar trend could be found on the CV results. It should be noted that the features were selected according to the CV results (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3 and Note S7</xref>).</p>
    </sec>
    <sec>
      <title>3.3 Comparison with state-of-the-art methods</title>
      <p>In this section, we investigated the relative importance of each module in GraphBepi (<xref rid="btad187-T2" ref-type="table">Table 2</xref>) and compared our model with state-of-the-art methods (<xref rid="btad187-T3" ref-type="table">Table 3</xref>). We first compared GraphBepi with two sequence-based methods (Bepipred 2.0 and EpiDope) and four structure-based approaches (ElliPro, Discotope 2.0, epitope3D, and ScanNet; <xref rid="btad187-B32" ref-type="bibr">Tubiana et al. 2022</xref>) using their default parameters. As ScanNet provided the option to select a transfer learning strategy, we called it ScanNet_T when a transfer learning strategy was used, otherwise ScanNet_WT. As shown in <xref rid="btad187-T3" ref-type="table">Table 3</xref>, our method surpassed the second-ranked method ScanNet_T by 5.5% in terms of AUC, 44.0% in terms of AUPR, 20.4% in terms of F1, and 36.9% in terms of MCC, respectively. We noted that ScanNet_T achieved higher performance than ScanNet_WT, probably because the transfer learning strategy generated profitable parameters for the initial model. The third-ranked method was Discotope-2.0, which achieved comparable performance with method ElliPro in terms of AUC value. The AUPR value of Discotope-2.0 was 3.2% higher than that of ElliPro. However, both of them performed lower than ScanNet_WT, likely because ScanNet_WT applied the deep learning network architecture and transfer learning strategy. Interestingly, although epitope3D was a structure-based method, it performed lower than the sequence-based method EpiDope. It is likely that the experimental structures brought noises due to the flexible characteristic of protein structure. Note that GraphBepi did not have the highest recall since it was an unbalanced measure strongly relying on thresholds. All methods have similar inference time if not considering the time to predict structure through Alphafold2 (<xref rid="sup1" ref-type="supplementary-material">Supplementary Note S8</xref>).</p>
      <table-wrap position="float" id="btad187-T2">
        <label>Table 2.</label>
        <caption>
          <p>The predictive performance of GraphBepi on the independent test when removing each module.<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref></p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Module</th>
              <th rowspan="1" colspan="1">AUC</th>
              <th rowspan="1" colspan="1">AUPR</th>
              <th rowspan="1" colspan="1">F1</th>
              <th rowspan="1" colspan="1">MCC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">GraphBepi w/o EGNN</td>
              <td rowspan="1" colspan="1">0.706</td>
              <td rowspan="1" colspan="1">0.209</td>
              <td rowspan="1" colspan="1">0.275</td>
              <td rowspan="1" colspan="1">0.194</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GraphBepi w/o BiLSTM</td>
              <td rowspan="1" colspan="1">0.742</td>
              <td rowspan="1" colspan="1">0.239</td>
              <td rowspan="1" colspan="1">0.300</td>
              <td rowspan="1" colspan="1">0.226</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GraphBepi</td>
              <td rowspan="1" colspan="1">
                <bold>0.751</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.261</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.310</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.232</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn3">
            <label>a</label>
            <p>w/o represents without the corresponding module.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <table-wrap position="float" id="btad187-T3">
        <label>Table 3.</label>
        <caption>
          <p>Performance comparison of GraphBepi with state-of-the-art methods on the independent test data.<xref rid="tblfn3" ref-type="table-fn"><sup>a</sup></xref></p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Method</th>
              <th rowspan="1" colspan="1">AUC</th>
              <th rowspan="1" colspan="1">AUPR</th>
              <th rowspan="1" colspan="1">F1</th>
              <th rowspan="1" colspan="1">MCC</th>
              <th rowspan="1" colspan="1">Rec</th>
              <th rowspan="1" colspan="1">Pre</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">EpiDope</td>
              <td rowspan="1" colspan="1">0.547</td>
              <td rowspan="1" colspan="1">0.102</td>
              <td rowspan="1" colspan="1">0.173</td>
              <td rowspan="1" colspan="1">0.046</td>
              <td rowspan="1" colspan="1">
                <bold>0.855</bold>
              </td>
              <td rowspan="1" colspan="1">0.096</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Bepipred-2.0</td>
              <td rowspan="1" colspan="1">0.648</td>
              <td rowspan="1" colspan="1">0.132</td>
              <td rowspan="1" colspan="1">0.220</td>
              <td rowspan="1" colspan="1">0.126</td>
              <td rowspan="1" colspan="1">0.562</td>
              <td rowspan="1" colspan="1">0.137</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ElliPro</td>
              <td rowspan="1" colspan="1">0.632</td>
              <td rowspan="1" colspan="1">0.122</td>
              <td rowspan="1" colspan="1">0.217</td>
              <td rowspan="1" colspan="1">0.123</td>
              <td rowspan="1" colspan="1">0.592</td>
              <td rowspan="1" colspan="1">0.133</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Discotope-2.0</td>
              <td rowspan="1" colspan="1">0.655</td>
              <td rowspan="1" colspan="1">0.154</td>
              <td rowspan="1" colspan="1">0.231</td>
              <td rowspan="1" colspan="1">0.136</td>
              <td rowspan="1" colspan="1">0.405</td>
              <td rowspan="1" colspan="1">0.162</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">epitope3D</td>
              <td rowspan="1" colspan="1">0.577</td>
              <td rowspan="1" colspan="1">0.105</td>
              <td rowspan="1" colspan="1">0.135</td>
              <td rowspan="1" colspan="1">0.039</td>
              <td rowspan="1" colspan="1">0.176</td>
              <td rowspan="1" colspan="1">0.109</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ScanNet_WT</td>
              <td rowspan="1" colspan="1">0.648</td>
              <td rowspan="1" colspan="1">0.135</td>
              <td rowspan="1" colspan="1">0.218</td>
              <td rowspan="1" colspan="1">0.121</td>
              <td rowspan="1" colspan="1">0.532</td>
              <td rowspan="1" colspan="1">0.137</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ScanNet_T</td>
              <td rowspan="1" colspan="1">0.712</td>
              <td rowspan="1" colspan="1">0.182</td>
              <td rowspan="1" colspan="1">0.257</td>
              <td rowspan="1" colspan="1">0.170</td>
              <td rowspan="1" colspan="1">0.440</td>
              <td rowspan="1" colspan="1">0.182</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GraphBepi</td>
              <td rowspan="1" colspan="1">
                <bold>0.751</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.261</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.310</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.232</bold>
              </td>
              <td rowspan="1" colspan="1">0.393</td>
              <td rowspan="1" colspan="1">
                <bold>0.255</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn4">
            <label>a</label>
            <p>ScanNet_T means that method ScanNet uses the transfer learning strategy, while ScanNet_WT means that it does not.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>To further investigate the advantages of our method, we analysed the relative importance of each module in GraphBepi by conducting the model ablation study on the test data. As shown in <xref rid="btad187-T2" ref-type="table">Table 2</xref>, the removal of the module BiLSTM caused a decrease of 0.9% and 2.2% in terms of AUC and AUPR. This change indicated that the BiLSTM could capture long-range dependencies of amino acid residues. We also replaced GraphBepi’s BiLSTM with Transformer, resulting in 0.6% and 3% decreases of AUPR for the CV and test results, respectively (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S4</xref>). The removal of the EGNN caused the greatest decrease of 4.5% and 5.2% in terms of AUC and AUPR. The results demonstrated that the spatial information was efficiently captured by the EGNN module. In summary, the cooperation of each module achieved the best performance.</p>
    </sec>
    <sec>
      <title>3.4 Impact of the quality of predicted protein structure</title>
      <p>Since our method used predicted structures, it is interesting to investigate the influence of the quality of predicted protein structure models on the downstream BCEs prediction. Here, we evaluated the performance of our model by using the native protein structures and the predicted protein structures from AlphaFold2 and ESMFold. As shown in <xref rid="btad187-T4" ref-type="table">Table 4</xref>, when using native structures or predicted structures from AlphaFold2, our method obtained comparable results. Concretely, the AUC and AUPR to use native structures were only 0.8% and 0.2% higher than the one to use predicted structures from AlphaFold2. Relatively, the performance using predicted structures from AlphaFold2 was slightly higher than the one using ESM-Fold, likely because of the use of multiple-sequence alignment by Alphafold2. On the other hand, when only using the protein sequence, the performance was significantly lower, demonstrating the importance of structural information for BCEs prediction.</p>
      <table-wrap position="float" id="btad187-T4">
        <label>Table 4.</label>
        <caption>
          <p>The predictive performance of GraphBepi when using only sequence, or different predicted structures.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Structural information</th>
              <th rowspan="1" colspan="1">AUC</th>
              <th rowspan="1" colspan="1">AUPR</th>
              <th rowspan="1" colspan="1">F1</th>
              <th rowspan="1" colspan="1">MCC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Sequence only</td>
              <td rowspan="1" colspan="1">0.698</td>
              <td rowspan="1" colspan="1">0.204</td>
              <td rowspan="1" colspan="1">0.271</td>
              <td rowspan="1" colspan="1">0.187</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ESM-fold predicted structures</td>
              <td rowspan="1" colspan="1">0.746</td>
              <td rowspan="1" colspan="1">0.218</td>
              <td rowspan="1" colspan="1">0.281</td>
              <td rowspan="1" colspan="1">0.208</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AlphaFold2 predicted structures</td>
              <td rowspan="1" colspan="1">0.751</td>
              <td rowspan="1" colspan="1">0.261</td>
              <td rowspan="1" colspan="1">0.310</td>
              <td rowspan="1" colspan="1">0.232</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Native structures</td>
              <td rowspan="1" colspan="1">
                <bold>0.759</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.263</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.320</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.249</bold>
              </td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>To further investigate the advantages of geometric deep learning employed in our method, we computed the average global distance test (<xref rid="btad187-B36" ref-type="bibr">Zemla 2003</xref>) (called GDT-score) between the predicted structures and the native structures through the tool Spalign (<xref rid="btad187-B33" ref-type="bibr">Yang et al. 2012</xref>). <xref rid="btad187-F3" ref-type="fig">Figure 3</xref> shows the quality of the predicted protein structures and the F1 values of each antigen on the independent test data for GraphBepi (black scatters). Specifically, we sorted the antigens based on GDT-score and then split them into nine bins evenly to calculate the mean GDT score and F1 value for every bin (red line). The results showed a positive correlation between the GDT of AlphaFold2 predicting structure and the F1 for its prediction by GraphBepi on the independent test set. The top 20% of antigens with the highest GDT (mean GDT = 0.974) had a mean F1 of 0.406. Whereas, the bottom 20% of antigens with the lowest GDT (mean GDT = 0.563) had a mean average F1 of 0.241. Similar trends could be found in terms of other metrics as shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2</xref>. These results suggested the importance of the quality of antigens structures predicted by AlphaFold2 for BCEs prediction.</p>
      <fig position="float" id="btad187-F3">
        <label>Figure 3.</label>
        <caption>
          <p>Positive correlation between the AlphaFold2 predicted structure quality evaluated by GDT and the GraphBepi performance evaluated by F1 on the independent test set. The black scatter represents the F1 and GDT score for each antigen. The red line represents the average F1 and GDT for each bin after ranking all antigens by GDT and splitting them into nine bins.</p>
        </caption>
        <graphic xlink:href="btad187f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.5 Case study</title>
      <p>To demonstrate the superiority of GraphBepi, we visualized an example (PDB ID: 7S2R, chain A) from the independent test. <xref rid="btad187-F4" ref-type="fig">Figure 4</xref> shows the BCEs predictive results of GraphBepi, GraphBepi without EGNN, the second-ranked method ScanNet_T, and the sequenced-based method Bepipred-2.0. Among the 17 epitopes out of 197 residues, GraphBepi predicted 37 binding residues, of which 13 were TP, resulting in an AUPR of 0.558, F1 of 0.481, and MCC of 0.454. By comparison, the GraphBepi without EGNN predicted 93 binding residues, of which 16 were TP, resulting in a lower AUPR of 0.451, F1 of 0.291, and MCC of 0.289. The results showed that the spatial information captured by the EGNN module could help our method accurately identify the epitopes and reduce the false positive rate. By comparison, the structure-based method ScanNet_T predicted 57 binding residues, of which 11 were TP, resulting in an AUPR of 0.332, F1 of 0.297, and MCC of 0.242. The sequenced-based Bepipred-2.0 predicted 87 binding residues, of which 12 were TP, resulting in a lower AUPR of 0.127, F1 of 0.226, and MCC of 0.157. We also included the predictions for other competing methods in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>.</p>
      <fig position="float" id="btad187-F4">
        <label>Figure 4.</label>
        <caption>
          <p>Visualization of a case of the test data (PDB ID: 7S2R, chain A) predicted by GraphBepi (a), GraphBepi without EGNN (b), ScanNet_T (c), and Bepipred-2.0 (d). True positives, false negatives, and false positives are colored in green, yellow, and red, respectively.</p>
        </caption>
        <graphic xlink:href="btad187f4" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>Identifying BCEs is an essential step for guiding rational vaccine development and immunotherapies. Here, we propose GraphBepi, a novel graph-based model, for accurate epitope prediction by using structural information predicted from AlphaFold2. GraphBepi applies the EGNN to capture the predicted protein structures, and leverages the BiLSTM to capture long-range dependencies from sequences. The low-dimensional representations learned from EGNN and BiLSTM are then combined to predict BCEs. Through comprehensive tests on the curated epitope dataset, GraphBepi was shown to outperform the state-of-the-art methods.</p>
    <p>Although several sequence-based methods have also been designed for identifying the BCEs such as EpiDope and Bepipred 2.0, they obtain limited performance since they only use the contextual features of the sequential neighbors. By comparison, structure-based methods try to solve these problems by considering spatial information, but they are not applicable to most proteins due to a lack of known tertiary structures. At the same time, these methods often use evolutionary information that is time-consuming. Here, we employed AlphaFold2 predicting structures to capture spatial information and ESM-2 to effectively represent protein sequence information. The comprehensive tests indicated that our model obtains superior performance compared to the state-of-the-art tools.</p>
    <p>In spite of the advantages, GraphBepi can be enhanced in several aspects. First, the performance of our model is influenced by the quality of antigen structures predicted from AlphaFold2. This might be relieved by adding other sequence-derived features to increase the robustness of the model. We will explore these challenges in future work. Second, the employed EGNN is a blackbox model. The future combination with explainable models might interpret the prediction or even improve the performance (<xref rid="btad187-B26" ref-type="bibr">Rao et al. 2022</xref>).</p>
    <p>In summary, we have demonstrated that GraphBepi provides a novel graph-based model for accurately predicting BCEs. We also provide the web server of GraphBepi at <ext-link xlink:href="http://bio-web1.nscc-gz.cn/app/graphbepi" ext-link-type="uri">http://bio-web1.nscc-gz.cn/app/graphbepi</ext-link>.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btad187_Supplementary_Data</label>
      <media xlink:href="btad187_supplementary_data.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
    <p>Conflict of interest: None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This study has been supported by the National Key R&amp;D Program of China (2022YFF1203100), National Natural Science Foundation of China (12126610), and Guangzhou S&amp; Research Plan (202007030010).</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btad187-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alghamdi</surname><given-names>W</given-names></string-name>, <string-name><surname>Attique</surname><given-names>M</given-names></string-name>, <string-name><surname>Alzahrani</surname><given-names>E</given-names></string-name></person-group><etal>et al</etal><article-title>LBCEPred: a machine learning model to predict linear B-cell epitopes</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:<fpage>bbac035</fpage>.<pub-id pub-id-type="pmid">35262658</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Altschul</surname><given-names>SF</given-names></string-name>, <string-name><surname>Madden</surname><given-names>TL</given-names></string-name>, <string-name><surname>Schäffer</surname><given-names>AA</given-names></string-name></person-group><etal>et al</etal><article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title>. <source>Nucleic Acids Res</source><year>1997</year>;<volume>25</volume>:<fpage>3389</fpage>–<lpage>402</lpage>.<pub-id pub-id-type="pmid">9254694</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barlow</surname><given-names>D</given-names></string-name>, <string-name><surname>Edwards</surname><given-names>M</given-names></string-name>, <string-name><surname>Thornton</surname><given-names>J.</given-names></string-name></person-group><article-title>Continuous and discontinuous protein antigenic determinants</article-title>. <source>Nature</source><year>1986</year>;<volume>322</volume>:<fpage>747</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">2427953</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berman</surname><given-names>HM</given-names></string-name>, <string-name><surname>Westbrook</surname><given-names>J</given-names></string-name>, <string-name><surname>Feng</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal><article-title>The protein data bank</article-title>. <source>Nucleic Acids Res</source><year>2000</year>;<volume>28</volume>:<fpage>235</fpage>–<lpage>42</lpage>.<pub-id pub-id-type="pmid">10592235</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Collatz</surname><given-names>M</given-names></string-name>, <string-name><surname>Mock</surname><given-names>F</given-names></string-name>, <string-name><surname>Barth</surname><given-names>E</given-names></string-name></person-group><etal>et al</etal><article-title>EpiDope: a deep neural network for linear B-cell epitope prediction</article-title>. <source>Bioinformatics</source><year>2021</year>;<volume>37</volume>:<fpage>448</fpage>–<lpage>55</lpage>.<pub-id pub-id-type="pmid">32915967</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>da Silva</surname><given-names>BM</given-names></string-name>, <string-name><surname>Myung</surname><given-names>Y</given-names></string-name>, <string-name><surname>Ascher</surname><given-names>DB</given-names></string-name></person-group><etal>et al</etal><article-title>epitope3D: a machine learning method for conformational B-cell epitope prediction</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:<fpage>bbab423</fpage>.<pub-id pub-id-type="pmid">34676398</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B7">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Devlin</surname><given-names>J</given-names></string-name>, <string-name><surname>Chang</surname><given-names>M-W</given-names></string-name>, <string-name><surname>Lee</surname><given-names>K</given-names></string-name>, <string-name><surname>Toutanova</surname><given-names>K.</given-names></string-name></person-group> Bert: pre-training of deep bidirectional transformers for language understanding. arXiv, arXiv:1810.04805, <year>2018</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btad187-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dunbar</surname><given-names>J</given-names></string-name>, <string-name><surname>Krawczyk</surname><given-names>K</given-names></string-name>, <string-name><surname>Leem</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>SAbPred: a structure-based antibody prediction server</article-title>. <source>Nucleic Acids Res</source><year>2016</year>;<volume>44</volume>:<fpage>W474</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">27131379</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Elnaggar</surname><given-names>A</given-names></string-name>, <string-name><surname>Heinzinger</surname><given-names>M</given-names></string-name>, <string-name><surname>Dallago</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal> ProtTrans: towards cracking the language of Life's code through self-supervised deep learning and high performance computing. arXiv, arXiv:2007.06225, <year>2020</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btad187-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gomara</surname><given-names>M</given-names></string-name>, <string-name><surname>Haro</surname><given-names>I.</given-names></string-name></person-group><article-title>Synthetic peptides for the immunodiagnosis of human diseases</article-title>. <source>Curr Med Chem</source><year>2007</year>;<volume>14</volume>:<fpage>531</fpage>–<lpage>46</lpage>.<pub-id pub-id-type="pmid">17346145</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B11">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gong</surname><given-names>L</given-names></string-name>, <string-name><surname>Cheng</surname><given-names>Q.</given-names></string-name></person-group> Exploiting edge features for graph neural networks. In: <italic toggle="yes">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 16-20 June 2019, Long Beach, California</italic>, pp. <fpage>9211</fpage>–<lpage>9</lpage>, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="btad187-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Haste Andersen</surname><given-names>P</given-names></string-name>, <string-name><surname>Nielsen</surname><given-names>M</given-names></string-name>, <string-name><surname>Lund</surname><given-names>O.</given-names></string-name></person-group><article-title>Prediction of residues in discontinuous B-cell epitopes using protein 3D structures</article-title>. <source>Protein Sci</source><year>2006</year>;<volume>15</volume>:<fpage>2558</fpage>–<lpage>67</lpage>.<pub-id pub-id-type="pmid">17001032</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hochreiter</surname><given-names>S</given-names></string-name>, <string-name><surname>Schmidhuber</surname><given-names>J.</given-names></string-name></person-group><article-title>Long short-term memory</article-title>. <source>Neural Comput</source><year>1997</year>;<volume>9</volume>:<fpage>1735</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jespersen</surname><given-names>MC</given-names></string-name>, <string-name><surname>Peters</surname><given-names>B</given-names></string-name>, <string-name><surname>Nielsen</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>BepiPred-2.0: improving sequence-based B-cell epitope prediction using conformational epitopes</article-title>. <source>Nucleic Acids Res</source><year>2017</year>;<volume>45</volume>:<fpage>W24</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">28472356</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname><given-names>M</given-names></string-name>, <string-name><surname>Zaretskaya</surname><given-names>I</given-names></string-name>, <string-name><surname>Raytselis</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>NCBI BLAST: a better web interface</article-title>. <source>Nucleic Acids Res</source><year>2008</year>;<volume>36</volume>:<fpage>W5</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">18440982</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jumper</surname><given-names>J</given-names></string-name>, <string-name><surname>Evans</surname><given-names>R</given-names></string-name>, <string-name><surname>Pritzel</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>Highly accurate protein structure prediction with AlphaFold</article-title>. <source>Nature</source><year>2021</year>;<volume>596</volume>:<fpage>583</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kabsch</surname><given-names>W</given-names></string-name>, <string-name><surname>Sander</surname><given-names>C.</given-names></string-name></person-group><article-title>Dictionary of protein secondary structure: pattern recognition of hydrogen-bonded and geometrical features</article-title>. <source>Biopolymers</source><year>1983</year>;<volume>22</volume>:<fpage>2577</fpage>–<lpage>637</lpage>.<pub-id pub-id-type="pmid">6667333</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B18">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kavitha</surname><given-names>K</given-names></string-name>, <string-name><surname>Saritha</surname><given-names>R</given-names></string-name>, <string-name><surname>Chandra</surname><given-names>V.</given-names></string-name></person-group> Computational prediction of continuous B-cell epitopes using random forest classifier. In: <italic toggle="yes">2013 Fourth International Conference on Computing, Communications and Networking Technologies (ICCCNT), 4-6 July 2013, Tiruchengode, India</italic>, pp. <fpage>1</fpage>–<lpage>5</lpage>, IEEE, <year>2013</year>.</mixed-citation>
    </ref>
    <ref id="btad187-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kringelum</surname><given-names>JV</given-names></string-name>, <string-name><surname>Lundegaard</surname><given-names>C</given-names></string-name>, <string-name><surname>Lund</surname><given-names>O</given-names></string-name></person-group><etal>et al</etal><article-title>Reliable B cell epitope predictions: impacts of method development and improved benchmarking</article-title>. <source>PLoS Comput Biol</source><year>2012</year>;<volume>8</volume>:<fpage>e1002829</fpage>.<pub-id pub-id-type="pmid">23300419</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B20">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>Z</given-names></string-name></person-group>, Akin H, Rao R <etal>et al</etal> Evolutionary-scale prediction of atomic level protein structure with a language model. bioRxiv 2022.2007.2020.500902, <year>2022</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btad187-B21">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Delves</surname><given-names>PJ</given-names></string-name>, <string-name><surname>Martin</surname><given-names>SJ</given-names></string-name>, <string-name><surname>Burton</surname><given-names>DR</given-names></string-name>, <string-name><surname>Roitt</surname><given-names>IM.</given-names></string-name></person-group><source>Roitt's Essential Immunology</source>. <publisher-name>John Wiley &amp; Sons</publisher-name>, <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="btad187-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mayer</surname><given-names>M</given-names></string-name>, <string-name><surname>Meyer</surname><given-names>B.</given-names></string-name></person-group><article-title>Group epitope mapping by saturation transfer difference NMR to identify segments of a ligand in direct contact with a protein receptor</article-title>. <source>J Am Chem Soc</source><year>2001</year>;<volume>123</volume>:<fpage>6108</fpage>–<lpage>17</lpage>.<pub-id pub-id-type="pmid">11414845</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mirdita</surname><given-names>M</given-names></string-name>, <string-name><surname>von den Driesch</surname><given-names>L</given-names></string-name>, <string-name><surname>Galiez</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal><article-title>Uniclust databases of clustered and deeply annotated protein sequences and alignments</article-title>. <source>Nucleic Acids Res</source><year>2017</year>;<volume>45</volume>:<fpage>D170</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">27899574</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B24">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Paul</surname><given-names>WE.</given-names></string-name></person-group><source>Fundamental Immunology</source>. <publisher-name>Lippincott Williams &amp; Wilkins</publisher-name>, <year>2012</year>.</mixed-citation>
    </ref>
    <ref id="btad187-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ponomarenko</surname><given-names>J</given-names></string-name>, <string-name><surname>Bui</surname><given-names>H-H</given-names></string-name>, <string-name><surname>Li</surname><given-names>W</given-names></string-name></person-group><etal>et al</etal><article-title>ElliPro: a new structure-based tool for the prediction of antibody epitopes</article-title>. <source>BMC Bioinformatics</source><year>2008</year>;<volume>9</volume>:<fpage>1</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">18173834</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rao</surname><given-names>J</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>S</given-names></string-name>, <string-name><surname>Lu</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>Quantitative evaluation of explainable graph neural networks for molecular property prediction</article-title>. <source>Patterns (N Y)</source><year>2022</year>;<volume>3</volume>:<fpage>100628</fpage>.<pub-id pub-id-type="pmid">36569553</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Remmert</surname><given-names>M</given-names></string-name>, <string-name><surname>Biegert</surname><given-names>A</given-names></string-name>, <string-name><surname>Hauser</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>HHblits: lightning-fast iterative protein sequence searching by HMM-HMM alignment</article-title>. <source>Nat Methods</source><year>2012</year>;<volume>9</volume>:<fpage>173</fpage>–<lpage>5</lpage>.</mixed-citation>
    </ref>
    <ref id="btad187-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singh</surname><given-names>H</given-names></string-name>, <string-name><surname>Ansari</surname><given-names>HR</given-names></string-name>, <string-name><surname>Raghava</surname><given-names>GP.</given-names></string-name></person-group><article-title>Improved method for linear B-cell epitope prediction using antigen’s primary sequence</article-title>. <source>PLoS One</source><year>2013</year>;<volume>8</volume>:<fpage>e62216</fpage>.<pub-id pub-id-type="pmid">23667458</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Steinegger</surname><given-names>M</given-names></string-name>, <string-name><surname>Mirdita</surname><given-names>M</given-names></string-name>, <string-name><surname>Söding</surname><given-names>J.</given-names></string-name></person-group><article-title>Protein-level assembly increases protein sequence recovery from metagenomic samples manyfold</article-title>. <source>Nat Methods</source><year>2019</year>;<volume>16</volume>:<fpage>603</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">31235882</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Steinegger</surname><given-names>M</given-names></string-name>, <string-name><surname>Söding</surname><given-names>J.</given-names></string-name></person-group><article-title>MMseqs2 enables sensitive protein sequence searching for the analysis of massive data sets</article-title>. <source>Nat Biotechnol</source><year>2017</year>;<volume>35</volume>:<fpage>1026</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">29035372</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Suzek</surname><given-names>BE</given-names></string-name>, <string-name><surname>Huang</surname><given-names>H</given-names></string-name>, <string-name><surname>McGarvey</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal><article-title>UniRef: comprehensive and non-redundant UniProt reference clusters</article-title>. <source>Bioinformatics</source><year>2007</year>;<volume>23</volume>:<fpage>1282</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">17379688</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tubiana</surname><given-names>J</given-names></string-name>, <string-name><surname>Schneidman-Duhovny</surname><given-names>D</given-names></string-name>, <string-name><surname>Wolfson</surname><given-names>HJ.</given-names></string-name></person-group><article-title>ScanNet: an interpretable geometric deep learning model for structure-based protein binding site prediction</article-title>. <source>Nat Methods</source><year>2022</year>;<volume>19</volume>:<fpage>1</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">35017739</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Zhan</surname><given-names>J</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>H</given-names></string-name></person-group><etal>et al</etal><article-title>A new size-independent score for pairwise protein structure alignment and its application to structure classification and nucleic-acid binding prediction</article-title>. <source>Proteins</source><year>2012</year>;<volume>80</volume>:<fpage>2080</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">22522696</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yuan</surname><given-names>Q</given-names></string-name>, <string-name><surname>Chen</surname><given-names>J</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>H</given-names></string-name></person-group><etal>et al</etal><article-title>Structure-aware protein–protein interaction site prediction using deep graph convolutional network</article-title>. <source>Bioinformatics</source><year>2021</year>;<volume>38</volume>:<fpage>125</fpage>–<lpage>32</lpage>.<pub-id pub-id-type="pmid">34498061</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yuan</surname><given-names>Q</given-names></string-name>, <string-name><surname>Chen</surname><given-names>S</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>Alignment-free metal ion-binding site prediction from protein sequence through pretrained language model and multi-task learning</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>(<issue>6</issue>):<fpage>bbac444</fpage>.<pub-id pub-id-type="pmid">36274238</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zemla</surname><given-names>A.</given-names></string-name></person-group><article-title>LGA: a method for finding 3D similarities in protein structures</article-title>. <source>Nucleic Acids Res</source><year>2003</year>;<volume>31</volume>:<fpage>3370</fpage>–<lpage>4</lpage>.<pub-id pub-id-type="pmid">12824330</pub-id></mixed-citation>
    </ref>
    <ref id="btad187-B37">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Z, Xu M, Jamasb AR</given-names></string-name></person-group><etal>et al</etal> Protein representation learning by geometric structure pretraining. arXiv, arXiv:2203.06125, <year>2022</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btad187-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>C</given-names></string-name>, <string-name><surname>Chen</surname><given-names>Z</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>L</given-names></string-name></person-group><etal>et al</etal><article-title>SEPPA 3.0—enhanced spatial epitope prediction enabling glycoprotein antigens</article-title>. <source>Nucleic Acids Res</source><year>2019</year>;<volume>47</volume>:<fpage>W388</fpage>–<lpage>94</lpage>.<pub-id pub-id-type="pmid">31114919</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
