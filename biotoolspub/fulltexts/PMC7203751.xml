<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7203751</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa029</article-id>
    <article-id pub-id-type="publisher-id">btaa029</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Applications Notes</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Bioimage Informatics</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>3D-Cell-Annotator: an open-source active surface tool for single-cell segmentation in 3D microscopy images</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Tasnadi</surname>
          <given-names>Ervin A</given-names>
        </name>
        <xref ref-type="aff" rid="btaa029-aff1">b1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Toth</surname>
          <given-names>Timea</given-names>
        </name>
        <xref ref-type="aff" rid="btaa029-aff1">b1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kovacs</surname>
          <given-names>Maria</given-names>
        </name>
        <xref ref-type="aff" rid="btaa029-aff1">b1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Diosdi</surname>
          <given-names>Akos</given-names>
        </name>
        <xref ref-type="aff" rid="btaa029-aff1">b1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pampaloni</surname>
          <given-names>Francesco</given-names>
        </name>
        <xref ref-type="aff" rid="btaa029-aff2">b2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Molnar</surname>
          <given-names>Jozsef</given-names>
        </name>
        <xref ref-type="aff" rid="btaa029-aff1">b1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-0371-7782</contrib-id>
        <name>
          <surname>Piccinini</surname>
          <given-names>Filippo</given-names>
        </name>
        <xref ref-type="corresp" rid="btaa029-cor1"/>
        <xref ref-type="aff" rid="btaa029-aff3">b3</xref>
        <!--<email>filippo.piccinini@irst.emr.it</email>-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Horvath</surname>
          <given-names>Peter</given-names>
        </name>
        <xref ref-type="corresp" rid="btaa029-cor1"/>
        <xref ref-type="aff" rid="btaa029-aff1">b1</xref>
        <xref ref-type="aff" rid="btaa029-aff4">b4</xref>
        <xref ref-type="aff" rid="btaa029-aff5">b5</xref>
        <!--<email>horvath.peter@brc.hu</email>-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Valencia</surname>
          <given-names>Alfonso</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <aff id="btaa029-aff1"><label>b1</label><institution>Synthetic and System Biology Unit</institution>, Biological Research Centre (BRC), Szeged H-6726, <country country="HU">Hungary</country></aff>
    <aff id="btaa029-aff2"><label>b2</label><institution>Buchmann Institute for Molecular Life Sciences (BMLS)</institution>, Goethe University of Frankfurt, DE-60438 Frankfurt, <country country="DE">Germany</country></aff>
    <aff id="btaa029-aff3"><label>b3</label><institution>Istituto Scientifico Romagnolo per lo Studio e la Cura dei Tumori (IRST) IRCCS</institution>, I-47014 Meldola (FC), <country country="IT">Italy</country></aff>
    <aff id="btaa029-aff4"><label>b4</label><institution>Institute for Molecular Medicine Finland University of Helsinki</institution>, FI-00014 Helsinki, <country country="FI">Finland</country></aff>
    <aff id="btaa029-aff5"><label>b5</label><institution>Single-Cell Technologies Ltd</institution>, H-6726 Szeged, <country country="HU">Hungary</country></aff>
    <author-notes>
      <corresp id="btaa029-cor1">To whom correspondence should be addressed. <email>filippo.piccinini@irst.emr.it</email> or <email>horvath.peter@brc.hu</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <day>01</day>
      <month>5</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-01-17">
      <day>17</day>
      <month>1</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>17</day>
      <month>1</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>9</issue>
    <fpage>2948</fpage>
    <lpage>2949</lpage>
    <history>
      <date date-type="received">
        <day>23</day>
        <month>6</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>30</day>
        <month>12</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>15</day>
        <month>1</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa029.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Summary</title>
        <p>Segmentation of single cells in microscopy images is one of the major challenges in computational biology. It is the first step of most bioimage analysis tasks, and essential to create training sets for more advanced deep learning approaches. Here, we propose 3D-Cell-Annotator to solve this task using 3D active surfaces together with shape descriptors as prior information in a semi-automated fashion. The software uses the convenient 3D interface of the widely used Medical Imaging Interaction Toolkit (MITK). Results on 3D biological structures (e.g. spheroids, organoids and embryos) show that the precision of the segmentation reaches the level of a human expert.</p>
      </sec>
      <sec id="s2">
        <title>Availability and implementation</title>
        <p>3D-Cell-Annotator is implemented in CUDA/C++ as a patch for the segmentation module of MITK. The 3D-Cell-Annotator enabled MITK distribution can be downloaded at: <ext-link ext-link-type="uri" xlink:href="http://www.3D-cell-annotator.org">www.3D-cell-annotator.org</ext-link>. It works under Windows 64-bit systems and recent Linux distributions even on a consumer level laptop with a CUDA-enabled video card using recent NVIDIA drivers.</p>
      </sec>
      <sec id="s3">
        <title>Supplementary information</title>
        <p><ext-link ext-link-type="uri" xlink:href="https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btaa029#supplementary-data">Supplementary data</ext-link> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>LENDULET-BIOMAG</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2018-342</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>European Regional Development Funds</institution>
          </institution-wrap>
        </funding-source>
        <award-id>GINOP-2.3.2-15-2016-00026</award-id>
        <award-id>GINOP-2.3.2-15-2016-00037</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Union for International Cancer Control</institution>
            <institution-id institution-id-type="DOI">10.13039/100010260</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>UICC</institution>
            <institution-id institution-id-type="DOI">10.13039/100004432</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>UICC Technical Fellowship</institution>
          </institution-wrap>
        </funding-source>
        <award-id>UICC-TF/19/640197</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="2"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Multicellular 3D biological models, the so-called ‘-oids’ (e.g. spheroids and organoids) are increasingly used as cellular models for anti-cancer drug screening and toxicology studies, since they represent physiological proxies of human tissues and can replace animal models (<xref rid="btaa029-B8" ref-type="bibr">Zanoni <italic>et al</italic>., 2016</xref>). Light-Sheet Fluorescence Microscopy (LSFM), confocal and multiphoton systems allow an in-depth observation of tissues in the size range of a few hundred microns. Despite the exponentially growing popularity of 3D models, few tools are available to analyse large aggregates at a single-cell level (<xref rid="btaa029-B1" ref-type="bibr">Carragher <italic>et al.</italic>, 2018</xref>). In this work, we are focussing on the 3D nuclei segmentation problem as one of the most fundamental tasks of bioimage analysis, and the starting point of further phenotype-based statistics. Recently, it has been shown that deep learning-based systems highly outperform classical image processing methods in 2D nuclei segmentation (<xref rid="btaa029-B3" ref-type="bibr">Hollandi <italic>et al.</italic>, 2019</xref>). However, these methods need accurate and large training sets, e.g. 3D-annotated spheroids. Creating such ground truth datasets in 2D is mostly straightforward by drawing the contours of each cell on a 2D canvas. Similarly, the obvious extension to 3D would involve the annotation of each slice of the volume data. However, it is quite evident that this oversimplified method is not only time-consuming, but also leads to discontinuous object surfaces, while the quality of segmentation strongly depends on the chosen plane. To overcome these problems, we designed 3D-Cell-Annotator (<xref ref-type="fig" rid="btaa029-F1">Fig. 1a</xref>). It provides an alternative for precise outlining of 3D shapes using a special type of active surface model (<xref rid="btaa029-B4" ref-type="bibr">Molnar <italic>et al.</italic>, 2017</xref>).</p>
    <fig id="btaa029-F1" orientation="portrait" position="float">
      <label>Fig. 1.</label>
      <caption>
        <p>(<bold>a</bold>) 3D-Cell-Annotator graphical user interface. (<bold>b</bold>) Confocal single-cell dataset annotated by three experts. Despite the fact that the annotators are all experts in the field, the obtained segmentations slightly differ (green contours). However, those obtained by the proposed software does not vary significantly (red contour). (<bold>c</bold>) Segmentations of a cancer-derived multicellular spheroid, imaged with an LSFM at a single-cell level. (<bold>d</bold>) 3D-Cell-Annotator can be used to extract cells with a special phenotype as shown in the magnified cell (red). (Color version of this figure is available at <italic>Bioinformatics</italic> online.) </p>
      </caption>
      <graphic xlink:href="btaa029f1"/>
    </fig>
  </sec>
  <sec>
    <title>2 The proposed software</title>
    <p>Instead of the classical slice-by-slice manual annotation approach, to obtain accurate single-cell annotation we propose a 3D active surface-based solution with shape priors called <italic>3</italic><italic>D selective segmentation</italic> (<xref rid="btaa029-B4" ref-type="bibr">Molnar <italic>et al.</italic>, 2017</xref>). Because of the pure 3D nature of our method, the spatial dependencies across all dimensions are considered by the algorithm, thus most of the time-consuming hand-drawing work may be eliminated. A 3D-Cell-Annotator is distributed as a module of the widely used Medical Imaging Interaction Toolkit (MITK, <xref rid="btaa029-B5" ref-type="bibr">Nolden <italic>et al.</italic>, 2013</xref>). Active surface models are computationally complex and expensive; therefore, our model was targeted to Graphic Processing Unit, implemented in the NVidia CUDA framework to provide a speed increase of several orders of magnitude compared with classical CPU implementations. Annotation can be provided cell-by-cell by placing initial seedpoints. A fully automated batch segmentation mode is also available. Although the general active surface algorithm may output clusters of objects when multiple cells share boundaries, the proposed selective active surface applies forces to fulfil shape descriptor values provided by the user. Mathematical foundations are explained in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material S1</xref>. Flow-chart of the segmentation approach is reported in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material S2</xref>.</p>
  </sec>
  <sec>
    <title>3 Results</title>
    <p>To evaluate 3D-Cell-Annotator we used (i) a confocal dataset of 77 <italic>z</italic>-stacks, each containing one single cell (<xref rid="btaa029-B6" ref-type="bibr">Poulet <italic>et al.</italic>, 2015</xref>; <xref ref-type="fig" rid="btaa029-F1">Fig. 1b</xref>); (ii) an LSFM dataset used in <xref rid="btaa029-B2" ref-type="bibr">Gole <italic>et al.</italic> 2016</xref>, representing a low intensity contrast cancer multicellular spheroid composed of 52 cells (<xref ref-type="fig" rid="btaa029-F1">Fig. 1c</xref>); and (iii) a mouse embryo dataset containing 56 cells acquired by a confocal microscope (<xref rid="btaa029-B7" ref-type="bibr">Saiz <italic>et al.</italic>, 2016</xref>; <xref ref-type="fig" rid="btaa029-F1">Fig. 1d</xref>). All the used datasets are publicly available (<xref ref-type="supplementary-material" rid="sup1">Supplementary Material S3</xref>). We computed the Jaccard Index (<xref ref-type="supplementary-material" rid="sup1">Supplementary Material S4</xref>) for the segmentations obtained by 3D-Cell-Annotator compared with other tools (<xref ref-type="supplementary-material" rid="sup1">Supplementary Material S5</xref>), as well as to manual segmentations executed by expert annotators familiar with 3D microscopy images and 3D-Cell-Annotator. All the details of the performed experiments are reported in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material S6</xref>. The obtained results (<xref ref-type="supplementary-material" rid="sup1">Supplementary Materials S7–S9</xref>) prove that 3D-Cell-Annotator offers an accuracy level reaching that of a human expert. In addition, besides outperforming state-of-the-art freely available tools, it decreases the time of annotation by 3-fold.</p>
  </sec>
  <sec>
    <title>4 Conclusions</title>
    <p>3D-Cell-Annotator provides a user friendly and precise solution for segmenting single cells in 3D cell cultures imaged with confocal, multiphoton or LSFM, even for large datasets with touching cells and suboptimal imaging conditions, like in the case of spheroids, organoids and embryos. Reaching the accuracy of an expert human annotator, 3D-Cell-Annotator is an optimal solution for generating training tests for more advanced machine learning approaches. Further improvements will include the implementation of different approaches for cell splitting. Source code, user manual, video tutorials and all the masks discussed in this work are available at: <ext-link ext-link-type="uri" xlink:href="http://www.3D-cell-annotator.org">www.3D-cell-annotator.org</ext-link>.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btaa029_Supplementary_Data</label>
      <media xlink:href="btaa029_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We thank Laurent Gole (Institute of Molecular and Cell Biology, A*STAR, Singapore), Anna-Katerina Hadjantonakis and Nestor Saiz (Sloan Kettering Institute, New York, USA) for material and information shared about 3D-cell-segmentation tools; Máté Görbe and Gabriella Tick (BRC, Hungary) for creating the website and videos; Dora Bokor, PharmD and Réka Kresák (BRC, Hungary) for proofreading the article and the <xref ref-type="supplementary-material" rid="sup1">Supplementary Materials</xref>. </p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by the LENDULET-BIOMAG Grant [2018-342] and from the European Regional Development Funds [GINOP-2.3.2-15-2016-00026 and GINOP-2.3.2-15-2016-00037] to E.T., T.T., M.K., A.D., J.M., F.P. and H.P.; the Union for International Cancer Control (UICC) for a granted UICC Technical Fellowship [ref: UICC-TF/19/640197] to F.P. </p>
      <p><italic>Conflict of Interest</italic>: none declared. </p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa029-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Carragher</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Concerns, challenges and promises of high-content analysis of 3D cellular models</article-title>. <source>Nat. Rev. Drug Discov</source>., <volume>17</volume>, <fpage>606</fpage>.<pub-id pub-id-type="pmid">29977053</pub-id></mixed-citation>
    </ref>
    <ref id="btaa029-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gole</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>OpenSegSPIM: a user-friendly segmentation tool for SPIM data</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>2075</fpage>–<lpage>2077</lpage>.<pub-id pub-id-type="pmid">27153681</pub-id></mixed-citation>
    </ref>
    <ref id="btaa029-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Hollandi</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>A deep learning framework for nucleus segmentation using image style transfer</article-title>. <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/580605v1">https://www.biorxiv.org/content/10.1101/580605v1 (25 January 2020, date last accessed).</ext-link></mixed-citation>
    </ref>
    <ref id="btaa029-B4">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Molnar</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>). Active surfaces for selective object segmentation in 3D. In: <italic>IEEE International Conference on Digital Image Computing: Techniques and Applications</italic> (DICTA), <italic>29 November - 1 December 2017</italic>, pp. 1–7. IEEE, Sydney, NSW, Australia.</mixed-citation>
    </ref>
    <ref id="btaa029-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nolden</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>The Medical Imaging Interaction Toolkit: challenges and advances</article-title>. <source>Int. J. Comput. Assist. Radiol. Surg</source>., <volume>8</volume>, <fpage>607</fpage>–<lpage>620</lpage>.<pub-id pub-id-type="pmid">23588509</pub-id></mixed-citation>
    </ref>
    <ref id="btaa029-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Poulet</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>NucleusJ: an ImageJ plugin for quantifying 3D images of interphase nuclei</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>1144</fpage>–<lpage>1146</lpage>.<pub-id pub-id-type="pmid">25416749</pub-id></mixed-citation>
    </ref>
    <ref id="btaa029-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Saiz</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Quantitative analysis of protein expression to study lineage specification in mouse preimplantation embryos</article-title>. <source>J. Vis. Exp</source>., <volume>108</volume>, <fpage>e53654</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa029-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zanoni</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>3D tumor spheroid models for in vitro therapeutic screening: a systematic approach to enhance the biological relevance of data obtained</article-title>. <source>Sci. Rep</source>., <volume>6</volume>, <fpage>19103</fpage>.<pub-id pub-id-type="pmid">26752500</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
