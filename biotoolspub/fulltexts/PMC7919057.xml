<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Cells</journal-id>
    <journal-id journal-id-type="iso-abbrev">Cells</journal-id>
    <journal-id journal-id-type="publisher-id">cells</journal-id>
    <journal-title-group>
      <journal-title>Cells</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2073-4409</issn>
    <publisher>
      <publisher-name>MDPI</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7919057</article-id>
    <article-id pub-id-type="pmid">33671933</article-id>
    <article-id pub-id-type="doi">10.3390/cells10020397</article-id>
    <article-id pub-id-type="publisher-id">cells-10-00397</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DVDeconv: An Open-Source MATLAB Toolbox for Depth-Variant Asymmetric Deconvolution of Fluorescence Micrographs</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Kim</surname>
          <given-names>Boyoung</given-names>
        </name>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Brooks</surname>
          <given-names>Doug</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
      <contrib contrib-type="editor">
        <name>
          <surname>Sorvina</surname>
          <given-names>Alexandra</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
      <contrib contrib-type="editor">
        <name>
          <surname>Hickey</surname>
          <given-names>Shane</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <aff id="af1-cells-10-00397">Robot R&amp;D Group, Factory Automation Technology Team, Global Technology Center, Samsung Electronics, 129, Samsung-ro, Yeongtong, Suwon 443-742, Gyeonggi, Korea; <email>by1110.kim@samsung.com</email></aff>
    <pub-date pub-type="epub">
      <day>15</day>
      <month>2</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>2</month>
      <year>2021</year>
    </pub-date>
    <volume>10</volume>
    <issue>2</issue>
    <elocation-id>397</elocation-id>
    <history>
      <date date-type="received">
        <day>03</day>
        <month>1</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>11</day>
        <month>2</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2021 by the author.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license license-type="open-access">
        <license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p>
      </license>
    </permissions>
    <abstract>
      <p>To investigate the cellular structure, biomedical researchers often obtain three-dimensional images by combining two-dimensional images taken along the z axis. However, these images are blurry in all directions due to diffraction limitations. This blur becomes more severe when focusing further inside the specimen as photons in deeper focus must traverse a longer distance within the specimen. This type of blur is called depth-variance. Moreover, due to lens imperfection, the blur has asymmetric shape. Most deconvolution solutions for removing blur assume depth-invariant or x-y symmetric blur, and presently, there is no open-source for depth-variant asymmetric deconvolution. In addition, existing datasets for deconvolution microscopy also assume invariant or x-y symmetric blur, which are insufficient to reflect actual imaging conditions. DVDeconv, that is a set of MATLAB functions with a user-friendly graphical interface, has been developed to address depth-variant asymmetric blur. DVDeconv includes dataset, depth-variant asymmetric point spread function generator, and deconvolution algorithms. Experimental results using DVDeconv reveal that depth-variant asymmetric deconvolution using DVDeconv removes blurs accurately. Furthermore, the dataset in DVDeconv constructed can be used to evaluate the performance of microscopy deconvolution to be developed in the future.</p>
    </abstract>
    <kwd-group>
      <kwd>3D microscopy</kwd>
      <kwd>fluorescence microscopy</kwd>
      <kwd>deconvolution</kwd>
      <kwd>blind deconvolution</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="sec1-cells-10-00397">
    <title>1. Introduction</title>
    <p>One of the most basic imaging techniques in biomedical research is wide-field fluorescence microscopy. In wide-field fluorescence microscopy, a dye-labeled specimen is illuminated with light that matches the excitation spectrum of the dye, and emitted light is captured by a camera [<xref rid="B1-cells-10-00397" ref-type="bibr">1</xref>]. Because fluorescent molecules act like light sources located at specific regions within the specimen, the target of interest within the specimen can be observed with high contrast. Additionally, researchers can obtain a three-dimensional (3D) specimen image by taking two-dimensional (2D) fluorescence microscopy images along the z axis [<xref rid="B2-cells-10-00397" ref-type="bibr">2</xref>].</p>
    <p>A disadvantage of obtaining 3D specimen images using this technique is that the image captured is blurry because of diffraction and lens aberrations. The blurry image can be modeled by the summation of the product of a clear image and the point spread function (PSF) of the imaging system. The PSF describes the response of the imaging system to a point object. The PSF has a spread shape along the x-y plane and the z axis because out-of-focus intensities enter the in-focus plane. Therefore, the PSF for wide-field microscopy has a unique shape. The PSF in the lateral (x-y) plane contains the Airy disk, while the PSF in the z (x-z or y-z) plane has an hourglass shape. Additionally, some refractive index changes or lens aberration are also present, and the PSF shape is distorted as an asymmetric Airy disk and hourglass shape.</p>
    <p>There are two approaches to remove blur in an image. The first approach is to change the hardware to modify the PSF such that it has a more point-like shape. Confocal microscopy and super-resolution microscopy, such as structured illumination microscopy (SIM), photo-activated localization microscopy (PALM), stochastic optical reconstruction microscopy (STORM), and stimulated emission depletion (STED), are included in this approach. Without any post-processing, these microscopy techniques allow researchers to obtain high-quality images. Especially, SIM is suitable for live cell imaging because it is based on conventional microscopy imaging and does not require mechanical movement in the z plane or special fluorescent dyes [<xref rid="B3-cells-10-00397" ref-type="bibr">3</xref>]. However, the first approach has several disadvantages, such as the need for an additional optical setup and a high cost [<xref rid="B4-cells-10-00397" ref-type="bibr">4</xref>]. The second approach for blur removal is the use of a deconvolution algorithm that removes blurs using PSF information. While the second approach requires post-processing, it enables resolution enhancement, contrast enhancement, and denoising without hardware or additional cost [<xref rid="B5-cells-10-00397" ref-type="bibr">5</xref>]. This paper focuses on this second approach. Both approaches for 3D microscopy take time to capture z planes with mechanical movement along z axis. If the user considers live cell imaging, SIM and wide-field microscopy with deconvolution will be suitable because of their fast image acquisition speed.</p>
    <p>A high-performance deconvolution algorithm should accurately reflect the imaging environment. Various deconvolution software packages that remove blur in fluorescence micrographs have been released: Huygens, AutoQuant, COSMOS, and DeconvolutionLab [<xref rid="B6-cells-10-00397" ref-type="bibr">6</xref>,<xref rid="B7-cells-10-00397" ref-type="bibr">7</xref>,<xref rid="B8-cells-10-00397" ref-type="bibr">8</xref>,<xref rid="B9-cells-10-00397" ref-type="bibr">9</xref>]. Huygens provides depth-invariant deconvolution processing of large data in parallel. Blind deconvolution and high-speed depth-invariant deconvolution are available in AutoQuant and Deconvolution Lab provides an open-source depth-invariant deconvolution algorithm based on ImageJ. However, it has been reported that the PSF is variant along the z axis [<xref rid="B7-cells-10-00397" ref-type="bibr">7</xref>,<xref rid="B10-cells-10-00397" ref-type="bibr">10</xref>,<xref rid="B11-cells-10-00397" ref-type="bibr">11</xref>,<xref rid="B12-cells-10-00397" ref-type="bibr">12</xref>,<xref rid="B13-cells-10-00397" ref-type="bibr">13</xref>,<xref rid="B14-cells-10-00397" ref-type="bibr">14</xref>,<xref rid="B15-cells-10-00397" ref-type="bibr">15</xref>,<xref rid="B16-cells-10-00397" ref-type="bibr">16</xref>,<xref rid="B17-cells-10-00397" ref-type="bibr">17</xref>] and deconvolution results that do not reflect depth-variance in the PSF have elongated results [<xref rid="B18-cells-10-00397" ref-type="bibr">18</xref>]. COSMOS software provides both depth-invariant and depth-variant deconvolution algorithms using x-y symmetric PSFs [<xref rid="B7-cells-10-00397" ref-type="bibr">7</xref>]. However, even if a deconvolution reflects depth-variance of PSF, if the asymmetry of PSF is not reflected, it causes incorrect results [<xref rid="B19-cells-10-00397" ref-type="bibr">19</xref>]. Based on a review of publications to date, there is no deconvolution algorithm software or toolbox that reflects both the depth-variance and asymmetry of the PSF. In addition, existing synthetic datasets for evaluation assume depth-invariance or x-y symmetry. However, actual images have depth-variant asymmetric blurs. </p>
    <p>This study provides the specifics of depth-invariant and variant deconvolution algorithms using asymmetric PSFs, as well as parameter settings for both PSF generation and deconvolution. An open-source toolbox DVDeconv has been developed to allow users to easily utilize the deconvolution algorithm. To reflect the actual imaging conditions and accurate evaluation, a new dataset is also released and shared in DVDeconv. DVDeconv can be downloaded from github (<uri xlink:href="https://github.com/bykimpage/DVDeconv">https://github.com/bykimpage/DVDeconv</uri>). Comparisons of deconvolution results of depth-invariant and depth-variant one-step late (OSL) and generalized expectation-maximization (GEM) algorithms used in DVDeconv are also discussed in this paper.</p>
  </sec>
  <sec id="sec2-cells-10-00397">
    <title>2. Materials and Methods</title>
    <sec id="sec2dot1-cells-10-00397">
      <title>2.1. Image Model</title>
      <p>An observed 3D image, <inline-formula><mml:math id="mm1"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:math></inline-formula>, can be modeled by the following summation of the product of the PSF, <inline-formula><mml:math id="mm2"><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:math></inline-formula>, and an object that we want to retrieve, <inline-formula><mml:math id="mm3"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:math></inline-formula>, under Poisson noise model [<xref rid="B13-cells-10-00397" ref-type="bibr">13</xref>]:<disp-formula id="FD1-cells-10-00397"><label>(1)</label><mml:math id="mm4"><mml:mrow><mml:mrow><mml:mtext> </mml:mtext><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>Poisson</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>∑</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>Poisson</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>⊗</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm5"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm6"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> indicate 3D locations in image space and object space, respectively. In this paper, the sum of products is defined as <inline-formula><mml:math id="mm7"><mml:mrow><mml:mo>⊗</mml:mo></mml:mrow></mml:math></inline-formula>. Photons in fluorescence microscopy are under a Poisson distribution because they are collected in a dark room [<xref rid="B20-cells-10-00397" ref-type="bibr">20</xref>]. To easily differentiate them, the negative log-likelihood function of Equation (1) is evaluated as follows:<disp-formula id="FD2-cells-10-00397"><label>(2)</label><mml:math id="mm8"><mml:mrow><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mstyle mathsize="100%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>⊗</mml:mo><mml:mi>h</mml:mi><mml:mo>−</mml:mo><mml:mi>g</mml:mi><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>⊗</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>!</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p>The Poisson image model is weak at noise [<xref rid="B16-cells-10-00397" ref-type="bibr">16</xref>], thus a penalty term is added to the negative log-likelihood function as follows:<disp-formula id="FD3-cells-10-00397"><label>(3)</label><mml:math id="mm9"><mml:mrow><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mi>w</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mtext> </mml:mtext><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mo>∇</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p><inline-formula><mml:math id="mm10"><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm11"><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula> denote the regularization parameter, which varies between 0 to 1, and the penalty term, respectively. Ordinarily, the total variation (TV) term is used as the penalty term, which imposes an L2 penalty on differences between adjacent pixels. Image deconvolution with TV restricts noise amplification at simultaneously preserved edges [<xref rid="B21-cells-10-00397" ref-type="bibr">21</xref>]. However, it couples each pixel with its neighbors in such a way that a direct derivative for maximizing the penalized likelihood function is not possible. The most utilized method for maximizing the likelihood function with TV is the OSL. If the image deconvolution method is described as a Richardson–Lucy algorithm with total variation regularization, it typically indicates an OSL algorithm [<xref rid="B22-cells-10-00397" ref-type="bibr">22</xref>]. As the means of maximizing the likelihood function, this method approximates the difference between neighbor pixels of the current image as the difference of the image at the previous iteration. The final form of the OSL algorithm is as follows:<disp-formula id="FD4-cells-10-00397"><label>(4)</label><mml:math id="mm12"><mml:mrow><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>⊗</mml:mo><mml:mfrac><mml:mi>g</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>⊗</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>div</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm13"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula> indicates the iteration number and <inline-formula><mml:math id="mm14"><mml:mrow><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> represents the mirrored PSF. As shown in Equation (4), the estimated image at the previous iteration is used for calculating the differentiation of the TV. In other words, OSL approximates the purple surrogate function in <xref ref-type="fig" rid="cells-10-00397-f001">Figure 1</xref> and finds the minimum value of the red graph iteratively. Therefore, the OSL can easily obtain the maximum solution of the likelihood function. Unfortunately, the approximated likelihood function does not guarantee a convergence. To overcome this problem, the GEM algorithm is adopted, as suggested in previous work [<xref rid="B13-cells-10-00397" ref-type="bibr">13</xref>,<xref rid="B16-cells-10-00397" ref-type="bibr">16</xref>]. </p>
      <p>The GEM algorithm indirectly evaluates the maximum likelihood using separable quadratic surrogates of the penalty term [<xref rid="B23-cells-10-00397" ref-type="bibr">23</xref>], as described in <xref ref-type="fig" rid="cells-10-00397-f001">Figure 1</xref>. The final form of the GEM algorithm is as follows [<xref rid="B13-cells-10-00397" ref-type="bibr">13</xref>]:<disp-formula id="FD5-cells-10-00397"><label>(5)</label><mml:math id="mm15"><mml:mrow><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mover><mml:mi>c</mml:mi><mml:mo>ˇ</mml:mo></mml:mover><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo>ˇ</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mrow><mml:mtext> </mml:mtext><mml:mi>when</mml:mi><mml:mtext> </mml:mtext></mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mover><mml:mi>c</mml:mi><mml:mo>ˇ</mml:mo></mml:mover><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mrow><mml:mtext> </mml:mtext><mml:mi>when</mml:mi><mml:mtext> </mml:mtext></mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm16"><mml:mrow><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo>ˇ</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm17"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula> represent curvature and sub-iteration, respectively. <inline-formula><mml:math id="mm18"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm19"><mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> are defined as
<disp-formula id="FD6-cells-10-00397"><label>(6)</label><mml:math id="mm20"><mml:mrow><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>⊗</mml:mo><mml:mfrac><mml:mi>g</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>⊗</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mover><mml:mi>c</mml:mi><mml:mo>ˇ</mml:mo></mml:mover><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p>The iteration of the GEM algorithm is the process of finding the lowest point of the orange graph, and the sub-iteration is the process of finding the lowest point of the blue graph. Therefore, GEM can find the maximum solution of the likelihood function without approximation of objective function. This iterative technique is slow to converge toward the final result but guarantees the convergence of the cost function. It was previously proven to be effective in biomedical image reconstruction problems [<xref rid="B13-cells-10-00397" ref-type="bibr">13</xref>].</p>
    </sec>
    <sec id="sec2dot2-cells-10-00397">
      <title>2.2. Space-Invariant Deconvolution (Depth-Invariant Deconvolution)</title>
      <p>The equations presented thus far can be adapted to a space-variant to invariant image model. Most existing image deconvolution methods in fluorescence microscopy assume space-invariance [<xref rid="B24-cells-10-00397" ref-type="bibr">24</xref>,<xref rid="B25-cells-10-00397" ref-type="bibr">25</xref>,<xref rid="B26-cells-10-00397" ref-type="bibr">26</xref>,<xref rid="B27-cells-10-00397" ref-type="bibr">27</xref>]. If the PSF is invariant, all pixels in the obtained image space have the same blur. The assumption makes <inline-formula><mml:math id="mm21"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>⊗</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> transform as the convolution <inline-formula><mml:math id="mm22"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>∗</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, which is depicted in <xref ref-type="fig" rid="cells-10-00397-f002">Figure 2</xref>.</p>
      <p>Under the space-invariant image model assumption, the final form of the OSL equation can be described as
<disp-formula id="FD7-cells-10-00397"><label>(7)</label><mml:math id="mm23"><mml:mrow><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mfrac><mml:mi>g</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>∗</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>div</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p><inline-formula><mml:math id="mm24"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> of the GEM algorithm can also be converted as follows:<disp-formula id="FD8-cells-10-00397"><label>(8)</label><mml:math id="mm25"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mfrac><mml:mi>g</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>∗</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p>As shown in Equations (7) and (8), only one PSF model is needed and the sum of the products of <inline-formula><mml:math id="mm26"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm27"><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:math></inline-formula> simplifies to one convolution. However, fluorescent micrographs suffer from more severe blur when the microscope focuses deeper within the specimen [<xref rid="B10-cells-10-00397" ref-type="bibr">10</xref>,<xref rid="B14-cells-10-00397" ref-type="bibr">14</xref>]. Therefore, the space-invariant assumption is only effective in a 2D image or for a very shallow specimen.</p>
    </sec>
    <sec id="sec2dot3-cells-10-00397">
      <title>2.3. Depth-Variant Deconvolution</title>
      <p>The depth-variant deconvolution implies that blur changes with depth and that the blur is invariant along the same depth. In the depth-variant image model, <inline-formula><mml:math id="mm28"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>⊗</mml:mo><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mo>∑</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> can be expressed as <inline-formula><mml:math id="mm29"><mml:mrow><mml:mrow><mml:mo>∑</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. This equation shows a sum of convolutions between the specimen plane at a specific depth and the PSF with respect to the depth, as depicted in <xref ref-type="fig" rid="cells-10-00397-f003">Figure 3</xref>.</p>
      <p>As shown in <xref ref-type="fig" rid="cells-10-00397-f002">Figure 2</xref> and <xref ref-type="fig" rid="cells-10-00397-f003">Figure 3</xref>, the observed image depends on the depth-invariance of the PSF. The space-invariant image model can be applicable in the case of a thin specimen, but in most cases, the deconvolution algorithm should reflect the depth-variant image model. The final form of the OSL algorithm reflecting the depth-variant image model is
<disp-formula id="FD9-cells-10-00397"><label>(9)</label><mml:math id="mm30"><mml:mrow><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>∑</mml:mo><mml:mfrac><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mstyle mathsize="100%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>div</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p>Additionally, <inline-formula><mml:math id="mm31"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> of the GEM algorithm under the depth-invariant image model can be converted as
<disp-formula id="FD10-cells-10-00397"><label>(10)</label><mml:math id="mm32"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>∑</mml:mo><mml:mfrac><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mstyle mathsize="100%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msup><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p>Depth-variant image deconvolution algorithms need as many PSF models as the number of <inline-formula><mml:math id="mm33"><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:math></inline-formula> stacks and restore the specimen image using PSFs corresponding to the depth, as shown in <xref ref-type="fig" rid="cells-10-00397-f003">Figure 3</xref>. The resolution of wide-field fluorescence microscopy is limited by diffraction to about 500 <inline-formula><mml:math id="mm34"><mml:mrow><mml:mrow><mml:mi>nm</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> along the <italic>z</italic>-axis. Therefore, it is recommended to shoot to cover 500 nm above and below the desired area. In the case of taking a micrograph moving in the <italic>z</italic>-axis every 160<inline-formula><mml:math id="mm35"><mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mi>nm</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, it is recommended to take four more micrographs above and below the region of interest. The required PSFs can be easily generated with the PSF Generator of DVDeconv toolbox, which is handled in detail in the Experimental Setting of Results Section. </p>
    </sec>
    <sec id="sec2dot4-cells-10-00397">
      <title>2.4. PSF Model</title>
      <p>To estimate an accurate specimen image, an accurate PSF acquisition is necessary. For depth-variant deconvolution, PSFs for each depth are required. DVDeconv provides a PSF generator for this purpose. This section describes the PSF model and the method for setting its parameters.</p>
      <p>The PSF model in DVDeconv is based on the simplified Zernike polynomial PSF model [<xref rid="B19-cells-10-00397" ref-type="bibr">19</xref>,<xref rid="B28-cells-10-00397" ref-type="bibr">28</xref>]. The Zernike polynomial PSF model is a parametric PSF that includes all aberrations and is expressed as a squared magnitude of the complex-valued amplitude PSF at the emission wavelength:<disp-formula id="FD11-cells-10-00397"><label>(11)</label><mml:math id="mm36"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm37"><mml:mrow><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the complex-valued amplitude PSF at emission wavelength <inline-formula><mml:math id="mm38"><mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. A complex-valued amplitude PSF is defined by
<disp-formula id="FD12-cells-10-00397"><label>(12)</label><mml:math id="mm39"><mml:mrow><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>∬</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">M</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm40"><mml:mrow><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm41"><mml:mrow><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> show the defocus term and spherical aberration. Each term can be written as [<xref rid="B19-cells-10-00397" ref-type="bibr">19</xref>,<xref rid="B29-cells-10-00397" ref-type="bibr">29</xref>]
<disp-formula id="FD13-cells-10-00397"><label>(13)</label><mml:math id="mm42"><mml:mrow><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>cos</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>cos</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mi>where</mml:mi><mml:mo> </mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>sin</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>k</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>sin</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>k</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm43"><mml:mrow><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm44"><mml:mrow><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> are angles in the immersion medium plane and the object plane, respectively. <inline-formula><mml:math id="mm45"><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm46"><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> are the refractive index of the immersion and specimen, respectively. <inline-formula><mml:math id="mm47"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">M</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> in Equation (12) is the product of an apodization function and the Zernike polynomials [<xref rid="B29-cells-10-00397" ref-type="bibr">29</xref>,<xref rid="B30-cells-10-00397" ref-type="bibr">30</xref>,<xref rid="B31-cells-10-00397" ref-type="bibr">31</xref>] that can be written as
<disp-formula id="FD14-cells-10-00397"><label>(14)</label><mml:math id="mm48"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">M</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>cos</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mi>ω</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">M</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mo> </mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>k</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt><mml:mo>&lt;</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>NA</mml:mi></mml:mrow><mml:mi>λ</mml:mi></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mi>otherwise</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow><mml:mo> </mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>w</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo> </mml:mo><mml:mi>ω</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">M</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mstyle mathsize="100%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mn>12</mml:mn></mml:mrow></mml:munder><mml:msub><mml:mi>M</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm49"><mml:mrow><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the modulus at each Zernike polynomial <inline-formula><mml:math id="mm50"><mml:mrow><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. <inline-formula><mml:math id="mm51"><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi></mml:mrow></mml:math></inline-formula> represents a collection of moduli. Because Equation (12) already includes the influence of the defocus and the spherical aberration, only <inline-formula><mml:math id="mm52"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula>-coma <inline-formula><mml:math id="mm53"><mml:mrow><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mn>8</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm54"><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:math></inline-formula>-coma <inline-formula><mml:math id="mm55"><mml:mrow><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> aberrations, which strongly influence the PSF, are added to the Zernike polynomials [<xref rid="B19-cells-10-00397" ref-type="bibr">19</xref>]. If a PSF model that reflects other aberration terms is needed, it is easily achieved by substituting the amount of aberration for <inline-formula><mml:math id="mm56"><mml:mrow><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> corresponding to each aberration <inline-formula><mml:math id="mm57"><mml:mrow><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="sec3-cells-10-00397">
    <title>3. Results</title>
    <sec id="sec3dot1-cells-10-00397">
      <title>3.1. Experimental Setting</title>
      <sec id="sec3dot1dot1-cells-10-00397">
        <title>3.1.1. PSF Generator</title>
        <p>The PSF generator in DVDeconv can generate depth-variant PSFs by simply inputting microscope information. When the PSF generator is launched, initial parameter values are already filled, as shown in <xref ref-type="fig" rid="cells-10-00397-f004">Figure 4</xref>. The unit of wavelength in the PSF generator is nanometers (nm). The unit of x-y and z resolution is microns (μm). Depth-variant PSFs are generated by the number of values inserted in the # of PSFs prompt. The number of PSFs should be the same as the number of z pixels in the image to be restored. Generated PSFs have voxel sizes based on the user inputted x-y-z pixel values. </p>
        <p>Values input in the <inline-formula><mml:math id="mm60"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula>-coma and <inline-formula><mml:math id="mm61"><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:math></inline-formula>-coma aberration prompt cause asymmetry of the PSF. The aberration values are obtained by unconstrained nonlinear optimization. The optimization function finds the best aberration values that maximize the probability of being observed as the captured image from the generated PSF with the aberration values. The value for aberrations can be found from maximizing the following equation [<xref rid="B13-cells-10-00397" ref-type="bibr">13</xref>,<xref rid="B19-cells-10-00397" ref-type="bibr">19</xref>]:<disp-formula id="FD15-cells-10-00397"><label>(15)</label><mml:math id="mm62"><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>φ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>d</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>φ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>s</mml:mi><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>8</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:munder><mml:mstyle mathsize="100%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>⊗</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>g</mml:mi><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>⊗</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>!</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p>
        <p>DVDeconv also provides the code and README file for estimating aberration values.</p>
      </sec>
      <sec id="sec3dot1dot2-cells-10-00397">
        <title>3.1.2. Deconvolution</title>
        <p>DVDeconv provides both depth-invariant and depth-variant OSL and GEM algorithms with deconvolution results dependent on parameter settings. This section discusses the meaning and impact of each parameter value.</p>
        <p>The regularization parameter <inline-formula><mml:math id="mm63"><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:math></inline-formula> has a value between 0 and 1. When <inline-formula><mml:math id="mm64"><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:math></inline-formula> is close to 1, noise is removed, but image details are destroyed. When <inline-formula><mml:math id="mm65"><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:math></inline-formula> is 0, the deconvolution algorithm becomes the Richardson–Lucy algorithm. A higher value of <inline-formula><mml:math id="mm66"><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:math></inline-formula> is preferred when noise is severe.</p>
        <p>Because all algorithms in DVDeconv are iterative methods, the number of iterations must be included. Too small a number of iterations will not show enough of a reconstructed deconvolution result, and too large a number of iterations will cause noise amplification. DVDeconv provides a save function for every iterative result. If the user runs the deconvolution algorithms after selecting the every iteration save button, deconvolution results are saved as a tif. or mat. format. The user can choose the result with the approximate number of iterations.</p>
        <p>Only the GEM algorithms include the curvature, <inline-formula><mml:math id="mm67"><mml:mrow><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo>ˇ</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>, parameter due to the presence of the surrogate function. If the value of curvature is small, the iteration speed is fast, and the probability of algorithm convergence is low. On the other hand, if the value of curvature is large, the iteration speed is slow, and the convergence probability is high.</p>
      </sec>
    </sec>
    <sec id="sec3dot2-cells-10-00397">
      <title>3.2. Dataset</title>
      <p>All of the algorithms in DVDeconv were evaluated on synthetic data. The results applied to the actual data are revealed in the previous paper, and the results of applying the asymmetric depth-variant function showed superior performance [<xref rid="B13-cells-10-00397" ref-type="bibr">13</xref>,<xref rid="B19-cells-10-00397" ref-type="bibr">19</xref>]. At present, there are few open datasets for deconvolution algorithms of micrographs, and those that are available are generated under the assumption of a symmetric PSF [<xref rid="B5-cells-10-00397" ref-type="bibr">5</xref>,<xref rid="B7-cells-10-00397" ref-type="bibr">7</xref>,<xref rid="B8-cells-10-00397" ref-type="bibr">8</xref>], which reflects the actual microscope environment inaccurately. Therefore, a synthetic dataset was generated using a depth-variant asymmetric PSF, the generation source of this dataset is also included in DVDeconv. A blurred object was generated by the summation of the product of an object and 3D depth-variant PSFs at each depth. Then, Gaussian noise was added and the final synthetic image was generated under a Poisson distribution. DVDeconv provides two noise conditions, 10 dB and 15 dB Gaussian noise cases, which are shown in <xref ref-type="fig" rid="cells-10-00397-f005">Figure 5</xref>.</p>
      <p>The generated image has 256 × 256 × 128 voxels of size 64.5 × 64.5 × 160 nm. Dataset images have a dynamic range of 0 to 65535 (uint16). The hollow bars in the synthesized data have a length of 85 pixels. The square of the inner radius of the bars is 15, and that of the outer radius is 43. As shown in <xref ref-type="fig" rid="cells-10-00397-f005">Figure 5</xref>b, bars that should look the same look differently spread out because different depths have different PSFs. As can be seen from <xref ref-type="fig" rid="cells-10-00397-f005">Figure 5</xref>c,d, 10 dB image has more noise than the 15dB image. </p>
    </sec>
    <sec id="sec3dot3-cells-10-00397">
      <title>3.3. Deconvolution Results</title>
      <p>Peak signal-to-noise ratio (PSNR), signal-to-noise ratio (SNR), standard deviation of peaks, relative contrast, memory, and processing time were used to measure the performance of the DVDeconv algorithms on synthetic data.</p>
      <p><xref ref-type="fig" rid="cells-10-00397-f006">Figure 6</xref> shows deconvolution results from the image in <xref ref-type="fig" rid="cells-10-00397-f005">Figure 5</xref>c. Images in <xref ref-type="fig" rid="cells-10-00397-f006">Figure 6</xref> show the cross-sections cut off the middle of each axis. The value of the regularization parameter <inline-formula><mml:math id="mm68"><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:math></inline-formula> was set to 0.00001 in the 15dB dataset. As shown in <xref ref-type="fig" rid="cells-10-00397-f006">Figure 6</xref>a–d, there are still blurs around the bars in x-y section because the depth-invariant deconvolutions only reflect the blur information at a certain depth. In this experiment, depth-invariant algorithms utilized the PSF at the central depth (the 64th pixel). On the other hand, the depth-variant algorithms remove blurs well, as shown in <xref ref-type="fig" rid="cells-10-00397-f006">Figure 6</xref>e–h. There is almost no difference between the OSL and GEM algorithms in <xref ref-type="fig" rid="cells-10-00397-f006">Figure 6</xref>.</p>
      <p><xref ref-type="fig" rid="cells-10-00397-f007">Figure 7</xref> shows deconvolution results from the image in <xref ref-type="fig" rid="cells-10-00397-f005">Figure 5</xref>d. The same as <xref ref-type="fig" rid="cells-10-00397-f006">Figure 6</xref>, images in <xref ref-type="fig" rid="cells-10-00397-f007">Figure 7</xref> show the cross sections cut off the middle of each axis. The γ value was set to 0.0006 for the depth-variant GEM algorithm in 10dB dataset. In the rest algorithm, the γ value was set to 0.0001 for the 10dB dataset. <xref ref-type="fig" rid="cells-10-00397-f007">Figure 7</xref>a–d show more severe blurs around the bars than those in <xref ref-type="fig" rid="cells-10-00397-f006">Figure 6</xref>a–d because the observed image has more noise. However, despite severe noise, the depth-variant deconvolution algorithms restore bar shapes, as shown in <xref ref-type="fig" rid="cells-10-00397-f007">Figure 7</xref>e–h. </p>
      <p>There is almost no difference between the OSL and GEM algorithms in <xref ref-type="fig" rid="cells-10-00397-f006">Figure 6</xref> and <xref ref-type="fig" rid="cells-10-00397-f007">Figure 7</xref>. Moreover, there is almost no difference between reconstructed images with the asymmetry applied and those without asymmetry to the naked eye. </p>
      <p>The quantified performance of the deconvolution algorithms was evaluated with PSNR and SNR. PSNR and SNR have been utilized to calculate similarities between the original image and the reconstructed image. A higher value indicates higher image quality. The PSNR and SNR evaluation results are represented in <xref rid="cells-10-00397-t001" ref-type="table">Table 1</xref>. Depth-variant algorithms have higher PSNR and SNR values than those of depth-invariant algorithms for both 10 dB and 15 dB images, which is consistent with the qualitative results. The best PSNR and SNR value is shown in bold.</p>
      <p>From the results, depth-variant asymmetric algorithms show the best performance. The depth-variant OSL and GEM algorithms have the same PSNR and SNR value for the 15 dB image. For the 10 dB image, the depth-variant asymmetric OSL algorithm shows the best performance. From the results, it can be seen that the performance improves as the characteristics of depth-variance and asymmetry of PSF are applied. PSNR and SNR values of the depth-variant OSL algorithm can have those values of about 0.0258 over depth-variant GEM algorithm. </p>
      <p>Deconvolution algorithms with standard deviation and relative contrasts were also evaluated. <xref ref-type="fig" rid="cells-10-00397-f008">Figure 8</xref> and <xref ref-type="fig" rid="cells-10-00397-f009">Figure 9</xref> show the intensity profiles of the deconvolution results at different noise levels (15 dB and 10 dB, respectively). The intensity profiles at the center of each bar were normalized by the maximum intensity and plotted as different colors in <xref ref-type="fig" rid="cells-10-00397-f008">Figure 8</xref> and <xref ref-type="fig" rid="cells-10-00397-f009">Figure 9</xref>. The horizontal axes in <xref ref-type="fig" rid="cells-10-00397-f008">Figure 8</xref> and <xref ref-type="fig" rid="cells-10-00397-f009">Figure 9</xref> designate pixel locations along the <italic>x</italic>-axis. Intensity profiles were normalized by the maximum value of the x-z plane image. Because depth-invariant algorithms restore images using only the PSF at the center of depth, intensity peaks in <xref ref-type="fig" rid="cells-10-00397-f008">Figure 8</xref> and <xref ref-type="fig" rid="cells-10-00397-f009">Figure 9</xref>a–d are uneven compared to those in <xref ref-type="fig" rid="cells-10-00397-f008">Figure 8</xref> and <xref ref-type="fig" rid="cells-10-00397-f009">Figure 9</xref>e–h. This indicates that depth-variant deconvolution is effective regardless of the amount of noise.</p>
      <p>To quantify the unevenness of intensity peaks, the standard deviation of peaks (std) and the ratio between the minimum peak and maximum peak of the bars were computed. The closer std value to zero shows the smaller difference between peaks. The closer the relative contrast value to one, the higher the evenness between bars and thus high restoration performance. The std and relative contrasts are shown in <xref rid="cells-10-00397-t002" ref-type="table">Table 2</xref>. The best std and relative ratio are shown in bold.</p>
      <p>The values of std and relative contrast from depth-variant algorithms show higher intensity evenness in depth than those from depth-invariant algorithms. Different from SNR and PSNR results, the depth-variant asymmetric GEM algorithm performed the best performance. On the other hand, in common with PSNR and SNR results, the deconvolution algorithm improves performance as more PSF characteristics were added. </p>
      <p>We implemented DVDeconv in MATLAB 2016a on Intel CORE i5-6500 processor with Windows 10. <xref rid="cells-10-00397-t003" ref-type="table">Table 3</xref> shows memory requirements and processing time (of one iteration) for each deconvolution algorithm. </p>
      <p>Depth-variant algorithms take more memory and processing time because they estimate the original image using PSFs at every <inline-formula><mml:math id="mm69"><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:math></inline-formula> pixel. With the same depth assumptions, the GEM algorithm spends more processing time than the OSL algorithm because the GEM algorithm also executes sub-iterations for the surrogate function. From the quantified deconvolution results in <xref rid="cells-10-00397-t001" ref-type="table">Table 1</xref> and <xref rid="cells-10-00397-t002" ref-type="table">Table 2</xref>, the user would choose depth-variant algorithms for thick specimen images. However, this choice costs approximately thirty-seven times more memory and four to thirty-nine times more processing time. <xref rid="cells-10-00397-t003" ref-type="table">Table 3</xref> and reference [<xref rid="B19-cells-10-00397" ref-type="bibr">19</xref>] provide users with memory requirement and processing time expectations and help users choose an appropriate algorithm.</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="sec4-cells-10-00397">
    <title>4. Discussion</title>
    <p>In this study, a new open-source MATLAB toolbox for deconvolution of fluorescence micrographs, DVDeconv, is investigated. The software provides not only depth-invariant but also depth-variant asymmetric algorithms. Performance of the algorithms was evaluated using SNR, PSNR, std of peaks, relative contrast, memory, and computational time. From experimental results, it is shown that deconvolution algorithms using depth-variant asymmetric PSF remove blurs effectively but require more memory and computational time than depth-invariant algorithms. Moreover, DVDeconv provides a PSF generator and datasets under a realistic assumption of depth-variant asymmetric blur. This work, in conjunction with the DVDeconv toolbox, is expected to assist in research where depth-variant and asymmetric characteristics of blur are applicable, especially in the field of biomedical imaging.</p>
    <p>ImageJ has completely outperformed the commercially available microscopy packages in every aspect of image analysis, the deconvolution algorithms remain an unconquered stronghold. If DVDeconv is ported and included in ImageJ, utilizing various deconvolution algorithms will be easier for biologists.</p>
    <p>The proposed DVDeconv provides nonlinear deconvolution algorithms. While linear deconvolution does not create higher frequency components above that spatial threshold, nonlinear deconvolution estimates the true image by reviewing the result over multiple iterations. For this reason, it is more effective to enhance an image resolution with nonlinear deconvolution than with linear deconvolution. The nonlinear deconvolution can create the components above the cut-off frequency. As more iterations are executed, nonlinear deconvolution gradually makes the object size small using the observed image and the estimated PSF. However, too many iterations can cause noise amplification and shrinking of objects.</p>
    <p>The number of iterations for deconvolution should be set high enough so that convergence is observed. In order to observe the convergence, DVDeconv provides a function to save the deconvolution image after every iteration. Users can find out that is almost no change in the deconvolution images after a certain iteration by checking the saved images. When there is almost no change in the images, it is considered that the algorithm reaches convergence. Users can also observe noise amplification in the images after excessive iteration. All experiments in this paper showed the convergence within 30 iterations. Details on how to reproduce the experimental results are described in README file of DVDeconv.</p>
    <p>The regularization parameter of deconvolution closer to 1 reduces noise but destroys image details. The experiments in this paper used the regularization parameter as 0.00001 for 15 dB image. The maximum regularization parameter for 10 dB image was 0.0006. Based on these values, users could adjust the regularization parameter for their image.</p>
    <p>For future work, there are <inline-formula><mml:math id="mm70"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> variant deconvolution and machine learning approaches that can be applied as blur, there is also a variant along the <inline-formula><mml:math id="mm71"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>-axis. <inline-formula><mml:math id="mm72"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula>-<inline-formula><mml:math id="mm73"><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:math></inline-formula>-<inline-formula><mml:math id="mm74"><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:math></inline-formula> variant deconvolution could help obtain more accurate specimen images, but this algorithm would need more PSFs and more computational resources. In addition, as machine learning algorithms have evolved, machine learning deconvolution for micrographs has been introduced [<xref rid="B32-cells-10-00397" ref-type="bibr">32</xref>,<xref rid="B33-cells-10-00397" ref-type="bibr">33</xref>,<xref rid="B34-cells-10-00397" ref-type="bibr">34</xref>]. Machine learning-based open-source for deconvolution microscopy is expected to be released in the foreseeable future.</p>
  </sec>
  <sec sec-type="conclusions" id="sec5-cells-10-00397">
    <title>5. Conclusions</title>
    <p>This study established a new open-source MATLAB toolbox called DVDeconv, which provides dataset, PSF generator, and deconvolution algorithms for removing blurs of fluorescence micrographs. DVDeconv reflects actual imaging conditions that blurs are depth-variant and asymmetric. Qualified and quantified deconvolution results verified that the proposed depth-variant asymmetric deconvolution outperforms deconvolutions that do not reflect depth-variance or asymmetry.</p>
    <p>DVDeconv takes about 30 min for deconvolution of 256 × 256 × 128 voxels 3D data. The current machine learning algorithm takes 0.4 s for deconvolution of 1024 × 1024 pixels 2D data [<xref rid="B33-cells-10-00397" ref-type="bibr">33</xref>]. It is expected that the machine learning algorithm for 256 × 256 × 128 voxels 3D data would take at least eight times more in terms of the number of voxels. In other words, 3D deconvolution cannot be conducted in real time with both image processing algorithms and machine learning algorithms. However, as GPU performance is advanced, 3D convolution operations in image processing and inferences in machine learning will be accelerated. This will gradually enable 3D image deconvolution in real time.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Publisher’s Note:</bold> MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <notes>
    <title>Author Contributions</title>
    <p>The author B.K. confirms sole responsibility for the following: study conception and design, data collection, analysis and interpretation of results, and manuscript preparation. The author has read and agreed to the published version of the manuscript.</p>
  </notes>
  <notes>
    <title>Funding</title>
    <p>This research received no external funding.</p>
  </notes>
  <notes>
    <title>Institutional Review Board Statement</title>
    <p>Not applicable.</p>
  </notes>
  <notes>
    <title>Informed Consent Statement</title>
    <p>Not applicable.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data Availability Statement</title>
    <p>The source code and dataset can be downloaded from github (<uri xlink:href="https://github.com/bykimpage/DVDeconv">https://github.com/bykimpage/DVDeconv</uri>). </p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Conflicts of Interest</title>
    <p>The author declares no conflict of interest.</p>
  </notes>
  <ref-list>
    <title>References</title>
    <ref id="B1-cells-10-00397">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sarder</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Nehorai</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Deconvolution methods for 3-D fluorescence microscopy images</article-title>
        <source>IEEE Signal. Process. Mag.</source>
        <year>2006</year>
        <volume>23</volume>
        <fpage>32</fpage>
        <lpage>45</lpage>
        <pub-id pub-id-type="doi">10.1109/MSP.2006.1628876</pub-id>
      </element-citation>
    </ref>
    <ref id="B2-cells-10-00397">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sibarita</surname>
            <given-names>J.B.</given-names>
          </name>
        </person-group>
        <article-title>Deconvolution microscopy</article-title>
        <source>Adv. Biochem. Eng. Biotechnol</source>
        <year>2005</year>
        <volume>95</volume>
        <fpage>201</fpage>
        <lpage>243</lpage>
        <pub-id pub-id-type="doi">10.1007/b102215</pub-id>
        <?supplied-pmid 16080270?>
        <pub-id pub-id-type="pmid">16080270</pub-id>
      </element-citation>
    </ref>
    <ref id="B3-cells-10-00397">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gustafsson</surname>
            <given-names>M.G.</given-names>
          </name>
        </person-group>
        <article-title>Surpassing the lateral resolution limit by a factor of two using structured illumination microscopy</article-title>
        <source>J. Microsc.</source>
        <year>2000</year>
        <volume>198</volume>
        <fpage>82</fpage>
        <lpage>87</lpage>
        <pub-id pub-id-type="doi">10.1046/j.1365-2818.2000.00710.x</pub-id>
        <?supplied-pmid 10810003?>
        <pub-id pub-id-type="pmid">10810003</pub-id>
      </element-citation>
    </ref>
    <ref id="B4-cells-10-00397">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>McNally</surname>
            <given-names>J.G.</given-names>
          </name>
          <name>
            <surname>Karpova</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Cooper</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Conchello</surname>
            <given-names>J.A.</given-names>
          </name>
        </person-group>
        <article-title>Three-dimensional imaging by deconvolution microscopy</article-title>
        <source>Methods</source>
        <year>1999</year>
        <volume>19</volume>
        <fpage>373</fpage>
        <lpage>385</lpage>
        <pub-id pub-id-type="doi">10.1006/meth.1999.0873</pub-id>
        <pub-id pub-id-type="pmid">10579932</pub-id>
      </element-citation>
    </ref>
    <ref id="B5-cells-10-00397">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sage</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Donati</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Soulez</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Fortun</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Schmit</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Seitz</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Guiet</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Vonesch</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Unser</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>DeconvolutionLab2: An open-source software for deconvolution microscopy</article-title>
        <source>Methods</source>
        <year>2017</year>
        <volume>115</volume>
        <fpage>28</fpage>
        <lpage>41</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ymeth.2016.12.015</pub-id>
        <?supplied-pmid 28057586?>
        <pub-id pub-id-type="pmid">28057586</pub-id>
      </element-citation>
    </ref>
    <ref id="B6-cells-10-00397">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ponti</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Schwarb</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Gulati</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Baker</surname>
            <given-names>V.</given-names>
          </name>
        </person-group>
        <article-title>Huygens remote manager: A web interface for high-volume batch deconvolution</article-title>
        <source>Imaging Microsc.</source>
        <year>2007</year>
        <volume>9</volume>
        <fpage>57</fpage>
        <lpage>58</lpage>
        <pub-id pub-id-type="doi">10.1002/imic.200790154</pub-id>
      </element-citation>
    </ref>
    <ref id="B7-cells-10-00397">
      <label>7.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Ghosh</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <source>COSMOS User Manual</source>
        <publisher-name>Computational Imaging Research Laboratory, The University of Memphis</publisher-name>
        <publisher-loc>Memphis, TN, USA</publisher-loc>
        <year>2010</year>
      </element-citation>
    </ref>
    <ref id="B8-cells-10-00397">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Griffa</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Garin</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Sage</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Comparison of deconvolution software in 3D microscopy: A user point of view—Part 1</article-title>
        <source>GIT Imaging Microsc.</source>
        <year>2010</year>
        <volume>12</volume>
        <fpage>43</fpage>
        <lpage>45</lpage>
      </element-citation>
    </ref>
    <ref id="B9-cells-10-00397">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Griffa</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Garin</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Sage</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Comparison of deconvolution software in 3D microscopy: A user point of view—Part 2</article-title>
        <source>GIT Imaging Microsc.</source>
        <year>2010</year>
        <volume>12</volume>
        <fpage>41</fpage>
        <lpage>43</lpage>
      </element-citation>
    </ref>
    <ref id="B10-cells-10-00397">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gibson</surname>
            <given-names>S.F.</given-names>
          </name>
          <name>
            <surname>Lanni</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>Experimental test of an analytical model of aberration in an oil-immersion objective lens used in three-dimensional light microscopy</article-title>
        <source>Josa A</source>
        <year>1992</year>
        <volume>9</volume>
        <fpage>154</fpage>
        <lpage>166</lpage>
        <pub-id pub-id-type="doi">10.1364/JOSAA.9.000154</pub-id>
      </element-citation>
    </ref>
    <ref id="B11-cells-10-00397">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wallace</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Schaefer</surname>
            <given-names>L.H.</given-names>
          </name>
          <name>
            <surname>Swedlow</surname>
            <given-names>J.R.</given-names>
          </name>
        </person-group>
        <article-title>A working person’s guide to deconvolution in light microscopy</article-title>
        <source>Biotechniques</source>
        <year>2001</year>
        <volume>31</volume>
        <fpage>1076</fpage>
        <lpage>1097</lpage>
        <pub-id pub-id-type="doi">10.2144/01315bi01</pub-id>
        <pub-id pub-id-type="pmid">11730015</pub-id>
      </element-citation>
    </ref>
    <ref id="B12-cells-10-00397">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Preza</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Conchello</surname>
            <given-names>J.A.</given-names>
          </name>
        </person-group>
        <article-title>Depth-variant maximum-likelihood restoration for three-dimensional fluorescence microscopy</article-title>
        <source>Josa A</source>
        <year>2004</year>
        <volume>21</volume>
        <fpage>1593</fpage>
        <lpage>1601</lpage>
        <pub-id pub-id-type="doi">10.1364/JOSAA.21.001593</pub-id>
        <?supplied-pmid 15384425?>
        <pub-id pub-id-type="pmid">15384425</pub-id>
      </element-citation>
    </ref>
    <ref id="B13-cells-10-00397">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Naemura</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>Blind Depth-variant Deconvolution of 3D Data in Wide-field Fluorescence Microscopy</article-title>
        <source>Sci. Rep.</source>
        <year>2015</year>
        <volume>5</volume>
        <fpage>9894</fpage>
        <pub-id pub-id-type="doi">10.1038/srep09894</pub-id>
        <?supplied-pmid 25950821?>
        <pub-id pub-id-type="pmid">25950821</pub-id>
      </element-citation>
    </ref>
    <ref id="B14-cells-10-00397">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shaevitz</surname>
            <given-names>J.W.</given-names>
          </name>
          <name>
            <surname>Fletcher</surname>
            <given-names>D.A.</given-names>
          </name>
        </person-group>
        <article-title>Enhanced three-dimensional deconvolution microscopy using a measured depth-varying point-spread function</article-title>
        <source>Josa A</source>
        <year>2007</year>
        <volume>24</volume>
        <fpage>2622</fpage>
        <lpage>2627</lpage>
        <pub-id pub-id-type="doi">10.1364/JOSAA.24.002622</pub-id>
        <?supplied-pmid 17767232?>
        <pub-id pub-id-type="pmid">17767232</pub-id>
      </element-citation>
    </ref>
    <ref id="B15-cells-10-00397">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Maalouf</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Colicchio</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Dieterlen</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Fluorescence microscopy three-dimensional depth variant point spread function interpolation using Zernike moments</article-title>
        <source>Josa A</source>
        <year>2011</year>
        <volume>28</volume>
        <fpage>1864</fpage>
        <lpage>1870</lpage>
        <pub-id pub-id-type="doi">10.1364/JOSAA.28.001864</pub-id>
      </element-citation>
    </ref>
    <ref id="B16-cells-10-00397">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>An</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Ahn</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>Depth-variant deconvolution of 3D widefield fluorescence microscopy using the penalized maximum likelihood estimation method</article-title>
        <source>Opt. Express</source>
        <year>2013</year>
        <volume>21</volume>
        <fpage>27668</fpage>
        <lpage>27681</lpage>
        <pub-id pub-id-type="doi">10.1364/OE.21.027668</pub-id>
        <pub-id pub-id-type="pmid">24514285</pub-id>
      </element-citation>
    </ref>
    <ref id="B17-cells-10-00397">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>J.Y.</given-names>
          </name>
          <name>
            <surname>Du</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Measure and model a 3-D space-variant PSF for fluorescence microscopy image deblurring</article-title>
        <source>Opt. Express</source>
        <year>2018</year>
        <volume>26</volume>
        <fpage>14375</fpage>
        <lpage>14391</lpage>
        <pub-id pub-id-type="doi">10.1364/OE.26.014375</pub-id>
        <pub-id pub-id-type="pmid">29877477</pub-id>
      </element-citation>
    </ref>
    <ref id="B18-cells-10-00397">
      <label>18.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Preza</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Conchello</surname>
            <given-names>J.A.</given-names>
          </name>
        </person-group>
        <article-title>Image estimation accounting for point-spread function depth variation in three-dimensional fluorescence microscopy</article-title>
        <source>Proceedings of the Three-Dimensional and Multidimensional Microscopy: Image Acquisition and Processing X</source>
        <conf-loc>San Jose, CA, USA</conf-loc>
        <conf-date>9 July 2003</conf-date>
        <comment>International Society for Optics and Photonics</comment>
        <volume>Volume 4964</volume>
        <fpage>135</fpage>
        <lpage>142</lpage>
      </element-citation>
    </ref>
    <ref id="B19-cells-10-00397">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Naemura</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>Blind deconvolution of 3D fluorescence microscopy using depth-variant asymmetric PSF</article-title>
        <source>Microsc. Res. Tech.</source>
        <year>2016</year>
        <volume>79</volume>
        <fpage>480</fpage>
        <lpage>494</lpage>
        <pub-id pub-id-type="doi">10.1002/jemt.22650</pub-id>
        <pub-id pub-id-type="pmid">27062314</pub-id>
      </element-citation>
    </ref>
    <ref id="B20-cells-10-00397">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mukamel</surname>
            <given-names>E.A.</given-names>
          </name>
          <name>
            <surname>Babcock</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Zhuang</surname>
            <given-names>X.</given-names>
          </name>
        </person-group>
        <article-title>Statistical deconvolution for superresolution fluorescence microscopy</article-title>
        <source>Biophys. J.</source>
        <year>2012</year>
        <volume>102</volume>
        <fpage>2391</fpage>
        <lpage>2400</lpage>
        <pub-id pub-id-type="doi">10.1016/j.bpj.2012.03.070</pub-id>
        <pub-id pub-id-type="pmid">22677393</pub-id>
      </element-citation>
    </ref>
    <ref id="B21-cells-10-00397">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dey</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Blanc-Feraud</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Zimmer</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Roux</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Kam</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Olivo-Marin</surname>
            <given-names>J.C.</given-names>
          </name>
          <name>
            <surname>Zerubia</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Richardson–Lucy algorithm with total variation regularization for 3D confocal microscope deconvolution</article-title>
        <source>Microsc. Res. Tech.</source>
        <year>2006</year>
        <volume>69</volume>
        <fpage>260</fpage>
        <lpage>266</lpage>
        <pub-id pub-id-type="doi">10.1002/jemt.20294</pub-id>
        <pub-id pub-id-type="pmid">16586486</pub-id>
      </element-citation>
    </ref>
    <ref id="B22-cells-10-00397">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fessler</surname>
            <given-names>J.A.</given-names>
          </name>
          <name>
            <surname>Hero</surname>
            <given-names>A.O.</given-names>
          </name>
        </person-group>
        <article-title>Penalized maximum-likelihood image reconstruction using space-alternating generalized EM algorithms</article-title>
        <source>IEEE Trans. Image Process.</source>
        <year>1995</year>
        <volume>4</volume>
        <fpage>1417</fpage>
        <lpage>1429</lpage>
        <pub-id pub-id-type="doi">10.1109/83.465106</pub-id>
        <pub-id pub-id-type="pmid">18291973</pub-id>
      </element-citation>
    </ref>
    <ref id="B23-cells-10-00397">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Long</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Fessler</surname>
            <given-names>J.A.</given-names>
          </name>
        </person-group>
        <article-title>Multi-material decomposition using statistical image reconstruction for spectral CT</article-title>
        <source>IEEE Trans. Med Imaging</source>
        <year>2014</year>
        <volume>33</volume>
        <fpage>1614</fpage>
        <lpage>1626</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2014.2320284</pub-id>
        <?supplied-pmid 24801550?>
        <pub-id pub-id-type="pmid">24801550</pub-id>
      </element-citation>
    </ref>
    <ref id="B24-cells-10-00397">
      <label>24.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Markham</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Conchello</surname>
            <given-names>J.A.</given-names>
          </name>
        </person-group>
        <article-title>Parametric blind deconvolution of microscopic images: Further results</article-title>
        <source>Proceedings of the Three-Dimensional and Multidimensional Microscopy: Image Acquisition and Processing V</source>
        <conf-loc>San Jose, CA, USA</conf-loc>
        <conf-date>9 June 1998</conf-date>
        <comment>International Society for Optics and Photonics</comment>
        <volume>Volume 3261</volume>
        <fpage>38</fpage>
        <lpage>49</lpage>
      </element-citation>
    </ref>
    <ref id="B25-cells-10-00397">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Joshi</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>M.I.</given-names>
          </name>
        </person-group>
        <article-title>Maximum a posteriori estimation with Good’s roughness for three-dimensional optical-sectioning microscopy</article-title>
        <source>Josa A</source>
        <year>1993</year>
        <volume>10</volume>
        <fpage>1078</fpage>
        <lpage>1085</lpage>
        <pub-id pub-id-type="doi">10.1364/JOSAA.10.001078</pub-id>
        <?supplied-pmid 8496727?>
        <pub-id pub-id-type="pmid">8496727</pub-id>
      </element-citation>
    </ref>
    <ref id="B26-cells-10-00397">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Markham</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Conchello</surname>
            <given-names>J.A.</given-names>
          </name>
        </person-group>
        <article-title>Fast maximum-likelihood image-restoration algorithms for three-dimensional fluorescence microscopy</article-title>
        <source>Josa A</source>
        <year>2001</year>
        <volume>18</volume>
        <fpage>1062</fpage>
        <lpage>1071</lpage>
        <pub-id pub-id-type="doi">10.1364/JOSAA.18.001062</pub-id>
        <pub-id pub-id-type="pmid">11336209</pub-id>
      </element-citation>
    </ref>
    <ref id="B27-cells-10-00397">
      <label>27.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Soulez</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Denis</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Tourneur</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Thiébaut</surname>
            <given-names>E.</given-names>
          </name>
        </person-group>
        <article-title>Blind deconvolution of 3D data in wide field fluorescence microscopy</article-title>
        <source>Proceedings of the 2012 9th IEEE International Symposium on Biomedical Imaging (ISBI)</source>
        <conf-loc>Barcelona, Spain</conf-loc>
        <conf-date>2–5 May 2012</conf-date>
        <fpage>1735</fpage>
        <lpage>1738</lpage>
      </element-citation>
    </ref>
    <ref id="B28-cells-10-00397">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hanser</surname>
            <given-names>B.M.</given-names>
          </name>
          <name>
            <surname>Gustafsson</surname>
            <given-names>M.G.L.</given-names>
          </name>
          <name>
            <surname>Agard</surname>
            <given-names>D.A.</given-names>
          </name>
          <name>
            <surname>Sedat</surname>
            <given-names>J.W.</given-names>
          </name>
        </person-group>
        <article-title>Phase-retrieved pupil functions in wide-field fluorescence microscopy</article-title>
        <source>J. Microsc.</source>
        <year>2004</year>
        <volume>216</volume>
        <fpage>32</fpage>
        <lpage>48</lpage>
        <pub-id pub-id-type="doi">10.1111/j.0022-2720.2004.01393.x</pub-id>
        <pub-id pub-id-type="pmid">15369481</pub-id>
      </element-citation>
    </ref>
    <ref id="B29-cells-10-00397">
      <label>29.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Pankajakshan</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Blanc-Féraud</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Kam</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Zerubia</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Point-spread function retrieval for fluorescence microscopy</article-title>
        <source>Proceedings of the 2009 IEEE International Symposium on Biomedical Imaging: From Nano to Macro</source>
        <conf-loc>Boston, MA, USA</conf-loc>
        <conf-date>28 June–1 July 2009</conf-date>
        <fpage>1095</fpage>
        <lpage>1098</lpage>
      </element-citation>
    </ref>
    <ref id="B30-cells-10-00397">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Maeda</surname>
            <given-names>P.Y.</given-names>
          </name>
        </person-group>
        <article-title>Zernike polynomials and their use in describing the wavefront aberrations of the human eye</article-title>
        <source>Course Proj. Appl. Vis. Imaging Syst. Psych.</source>
        <year>2003</year>
        <volume>221</volume>
        <fpage>362</fpage>
      </element-citation>
    </ref>
    <ref id="B31-cells-10-00397">
      <label>31.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Pankajakshan</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Kam</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Dieterlen</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Engler</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Blanc-Féraud</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Zerubia</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Olivo-Marin</surname>
            <given-names>J.C.</given-names>
          </name>
        </person-group>
        <article-title>Point-spread function model for fluorescence macroscopy imaging</article-title>
        <source>Proceedings of the 2010 Conference Record of the Forty Fourth Asilomar Conference on Signals, Systems and Computers</source>
        <conf-loc>Pacific Grove, CA, USA</conf-loc>
        <conf-date>7–10 November 2010</conf-date>
        <fpage>1364</fpage>
        <lpage>1368</lpage>
      </element-citation>
    </ref>
    <ref id="B32-cells-10-00397">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Weigert</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Schmidt</surname>
            <given-names>U.</given-names>
          </name>
          <name>
            <surname>Boothe</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Müller</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Dibrov</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Jain</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Wilhelm</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Schmidt</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Broaddus</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Rocha-Martins</surname>
            <given-names>M.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Content-aware image restoration: Pushing the limits of fluorescence microscopy</article-title>
        <source>Nat. Methods</source>
        <year>2018</year>
        <volume>15</volume>
        <fpage>1090</fpage>
        <lpage>1097</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-018-0216-7</pub-id>
        <pub-id pub-id-type="pmid">30478326</pub-id>
      </element-citation>
    </ref>
    <ref id="B33-cells-10-00397">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Rivenson</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Jin</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Günaydın</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Bentolila</surname>
            <given-names>L.A.</given-names>
          </name>
          <name>
            <surname>Kural</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Ozcan</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Deep learning enables cross-modality super-resolution in fluorescence microscopy</article-title>
        <source>Nat. Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <fpage>103</fpage>
        <lpage>110</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-018-0239-0</pub-id>
        <pub-id pub-id-type="pmid">30559434</pub-id>
      </element-citation>
    </ref>
    <ref id="B34-cells-10-00397">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lim</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>S.E.</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Sim</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>J.C.</given-names>
          </name>
        </person-group>
        <article-title>Cyclegan with a blur kernel for deconvolution microscopy: Optimal transport geometry</article-title>
        <source>IEEE Trans. Comput. Imaging</source>
        <year>2020</year>
        <volume>6</volume>
        <fpage>1127</fpage>
        <lpage>1138</lpage>
        <pub-id pub-id-type="doi">10.1109/TCI.2020.3006735</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig id="cells-10-00397-f001" orientation="portrait" position="float">
    <label>Figure 1</label>
    <caption>
      <p>Illustration of the GEM algorithm concept.</p>
    </caption>
    <graphic xlink:href="cells-10-00397-g001"/>
  </fig>
  <fig id="cells-10-00397-f002" orientation="portrait" position="float">
    <label>Figure 2</label>
    <caption>
      <p>Calculation of the depth-invariant image model.</p>
    </caption>
    <graphic xlink:href="cells-10-00397-g002"/>
  </fig>
  <fig id="cells-10-00397-f003" orientation="portrait" position="float">
    <label>Figure 3</label>
    <caption>
      <p>Calculation of the depth-variant image model.</p>
    </caption>
    <graphic xlink:href="cells-10-00397-g003"/>
  </fig>
  <fig id="cells-10-00397-f004" orientation="portrait" position="float">
    <label>Figure 4</label>
    <caption>
      <p>DVDeconv PSF Generator GUI.</p>
    </caption>
    <graphic xlink:href="cells-10-00397-g004"/>
  </fig>
  <fig id="cells-10-00397-f005" orientation="portrait" position="float">
    <label>Figure 5</label>
    <caption>
      <p>Dataset for DVDeconv evaluation: (<bold>a</bold>) Original image, (<bold>b</bold>) blurred image, and blurred image with (<bold>c</bold>) 15 dB and (<bold>d</bold>) 10 dB Gaussian noise under a Poisson distribution.</p>
    </caption>
    <graphic xlink:href="cells-10-00397-g005"/>
  </fig>
  <fig id="cells-10-00397-f006" orientation="portrait" position="float">
    <label>Figure 6</label>
    <caption>
      <p>Deconvolution results using the (<bold>a</bold>) depth-invariant symmetric OSL algorithm, (<bold>b</bold>) depth-invariant symmetric GEM algorithm, (<bold>c</bold>) depth-variant symmetric OSL algorithm, (<bold>d</bold>) depth-variant symmetric GEM algorithm (<bold>e</bold>) depth-variant symmetric OSL algorithm, (<bold>f</bold>) depth-variant asymmetric GEM algorithm, (<bold>g</bold>) depth-variant asymmetric OSL algorithm, and (<bold>h</bold>) depth-variant asymmetric GEM algorithm on the 15 dB Gaussian noise image.</p>
    </caption>
    <graphic xlink:href="cells-10-00397-g006"/>
  </fig>
  <fig id="cells-10-00397-f007" orientation="portrait" position="float">
    <label>Figure 7</label>
    <caption>
      <p>Deconvolution results using the (<bold>a</bold>) depth-invariant symmetric OSL algorithm, (<bold>b</bold>) depth-invariant symmetric GEM algorithm, (<bold>c</bold>) depth-variant symmetric OSL algorithm, (<bold>d</bold>) depth-variant symmetric GEM algorithm, (<bold>e</bold>) depth-variant symmetric OSL algorithm, (<bold>f</bold>) depth-variant asymmetric GEM algorithm, (<bold>g</bold>) depth-variant asymmetric OSL algorithm, and (<bold>h</bold>) depth-variant asymmetric GEM algorithm on the 10 dB Gaussian noise image.</p>
    </caption>
    <graphic xlink:href="cells-10-00397-g007"/>
  </fig>
  <fig id="cells-10-00397-f008" orientation="portrait" position="float">
    <label>Figure 8</label>
    <caption>
      <p>Intensity profiles of deconvolution results for 15 dB images: (<bold>a</bold>) Depth-invariant symmetric OSL algorithm, (<bold>b</bold>) depth-invariant symmetric GEM algorithm, (<bold>c</bold>) depth-variant symmetric OSL algorithm, (<bold>d</bold>) depth-variant symmetric GEM algorithm, (<bold>e</bold>) depth-variant symmetric OSL algorithm, (<bold>f</bold>) depth-variant asymmetric GEM algorithm, (<bold>g</bold>) depth-variant asymmetric OSL algorithm, and (<bold>h</bold>) depth-variant asymmetric GEM algorithm.</p>
    </caption>
    <graphic xlink:href="cells-10-00397-g008"/>
  </fig>
  <fig id="cells-10-00397-f009" orientation="portrait" position="float">
    <label>Figure 9</label>
    <caption>
      <p>Intensity profiles of deconvolution results for 10 dB images: (<bold>a</bold>) Depth-invariant symmetric OSL algorithm, (<bold>b</bold>) depth-invariant symmetric GEM algorithm, (<bold>c</bold>) depth-variant symmetric OSL algorithm, (<bold>d</bold>) depth-variant symmetric GEM algorithm, (<bold>e</bold>) depth-variant symmetric OSL algorithm, (<bold>f</bold>) depth-variant asymmetric GEM algorithm, (<bold>g</bold>) depth-variant asymmetric OSL algorithm, and (<bold>h</bold>) depth-variant asymmetric GEM algorithm.</p>
    </caption>
    <graphic xlink:href="cells-10-00397-g009"/>
  </fig>
  <table-wrap id="cells-10-00397-t001" orientation="portrait" position="float">
    <object-id pub-id-type="pii">cells-10-00397-t001_Table 1</object-id>
    <label>Table 1</label>
    <caption>
      <p>Peak signal-to-noise ratio (PSNR) and signal-to-noise ratio (SNR) results.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Depth-Variance</th>
          <th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Asymmetry</th>
          <th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Surrogate Func (GEM)</th>
          <th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">PSNR</th>
          <th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">SNR</th>
        </tr>
        <tr>
          <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15 dB</th>
          <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10 dB</th>
          <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15 dB</th>
          <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10 dB</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">28.8546</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">28.6793</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5.5394</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5.3641</td>
        </tr>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">28.8549</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">28.6839</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5.5398</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5.3688</td>
        </tr>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">28.8598</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">28.6895</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5.5447</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5.3743</td>
        </tr>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">28.8603</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">28.6946</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5.5452</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5.3795</td>
        </tr>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">29.1655</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">28.8552</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5.8504</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5.5400</td>
        </tr>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">29.1655</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">28.8247</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5.8504</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5.5096</td>
        </tr>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
            <bold>29.1933</bold>
          </td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
            <bold>28.8762</bold>
          </td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
            <bold>5.8782</bold>
          </td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
            <bold>5.5611</bold>
          </td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
            <bold>29.1933</bold>
          </td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">28.8504</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
            <bold>5.8782</bold>
          </td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5.5353</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="cells-10-00397-t002" orientation="portrait" position="float">
    <object-id pub-id-type="pii">cells-10-00397-t002_Table 2</object-id>
    <label>Table 2</label>
    <caption>
      <p>Standard deviation of peaks and relative contrast.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Depth-Variance</th>
          <th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Asymmetry</th>
          <th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Surrogate Func (GEM)</th>
          <th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Std</th>
          <th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Relative Contrast</th>
        </tr>
        <tr>
          <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15 dB</th>
          <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10 dB</th>
          <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15 dB</th>
          <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10 dB</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0373</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0400</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.8780</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.8975</td>
        </tr>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0373</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0400</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.8780</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.8970</td>
        </tr>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0369</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0398</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.8788</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.8988</td>
        </tr>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0369</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0398</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.8788</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.8984</td>
        </tr>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0339</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0203</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.8767</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.9403</td>
        </tr>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0339</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0203</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.8767</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.9359</td>
        </tr>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
            <bold>0.0332</bold>
          </td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0201</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
            <bold>0.8812</bold>
          </td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.9404</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">✓</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
            <bold>0.0332</bold>
          </td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
            <bold>0.0200</bold>
          </td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
            <bold>0.8812</bold>
          </td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
            <bold>0.9414</bold>
          </td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="cells-10-00397-t003" orientation="portrait" position="float">
    <object-id pub-id-type="pii">cells-10-00397-t003_Table 3</object-id>
    <label>Table 3</label>
    <caption>
      <p>Memory requirements and processing time.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
</th>
          <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Memory [GB]</th>
          <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Time [s]</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">Depth-invariant OSL</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.668</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1.4</td>
        </tr>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">Depth-invariant GEM</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.668</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">15</td>
        </tr>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">Depth-variant OSL</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">24.5</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">54.64</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Depth-variant GEM</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">24.5</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">66.33</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</floats-group>
