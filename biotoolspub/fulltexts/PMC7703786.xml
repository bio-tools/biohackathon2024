<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7703786</article-id>
    <article-id pub-id-type="pmid">31501885</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btz682</article-id>
    <article-id pub-id-type="publisher-id">btz682</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Data and Text Mining</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-4972-239X</contrib-id>
        <name>
          <surname>Lee</surname>
          <given-names>Jinhyuk</given-names>
        </name>
        <xref ref-type="aff" rid="btz682-aff1">1</xref>
        <xref ref-type="author-notes" rid="btz682-FM1"/>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-6435-548X</contrib-id>
        <name>
          <surname>Yoon</surname>
          <given-names>Wonjin</given-names>
        </name>
        <xref ref-type="aff" rid="btz682-aff1">1</xref>
        <xref ref-type="author-notes" rid="btz682-FM1"/>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-0240-6210</contrib-id>
        <name>
          <surname>Kim</surname>
          <given-names>Sungdong</given-names>
        </name>
        <xref ref-type="aff" rid="btz682-aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-8224-8354</contrib-id>
        <name>
          <surname>Kim</surname>
          <given-names>Donghyeon</given-names>
        </name>
        <xref ref-type="aff" rid="btz682-aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-0240-6210</contrib-id>
        <name>
          <surname>Kim</surname>
          <given-names>Sunkyu</given-names>
        </name>
        <xref ref-type="aff" rid="btz682-aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-7633-1074</contrib-id>
        <name>
          <surname>So</surname>
          <given-names>Chan Ho</given-names>
        </name>
        <xref ref-type="aff" rid="btz682-aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-6798-9106</contrib-id>
        <name>
          <surname>Kang</surname>
          <given-names>Jaewoo</given-names>
        </name>
        <xref ref-type="aff" rid="btz682-aff1">1</xref>
        <xref ref-type="aff" rid="btz682-aff3">3</xref>
        <xref ref-type="corresp" rid="btz682-cor1"/>
        <!--<email>kangj@korea.ac.kr</email>-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Wren</surname>
          <given-names>Jonathan</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <aff id="btz682-aff1"><label>1</label><institution>Department of Computer Science and Engineering, Korea University</institution>, Seoul 02841, <country country="KR">Korea</country></aff>
    <aff id="btz682-aff2"><label>2</label><institution>Clova AI Research, Naver Corp</institution>, Seong-Nam 13561, <country country="KR">Korea</country></aff>
    <aff id="btz682-aff3"><label>3</label><institution>Interdisciplinary Graduate Program in Bioinformatics, Korea University</institution>, Seoul 02841, <country country="KR">Korea</country></aff>
    <author-notes>
      <corresp id="btz682-cor1">To whom correspondence should be addressed. <email>kangj@korea.ac.kr</email></corresp>
      <fn id="btz682-FM1">
        <p>Jinhyuk Lee and Wonjin Yoon wish it to be known that the first two authors contributed equally.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="ppub">
      <day>15</day>
      <month>2</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-09-10">
      <day>10</day>
      <month>9</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>10</day>
      <month>9</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>4</issue>
    <fpage>1234</fpage>
    <lpage>1240</lpage>
    <history>
      <date date-type="received">
        <day>16</day>
        <month>5</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>29</day>
        <month>7</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>5</day>
        <month>9</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="cc-by" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btz682.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora. With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the following three representative biomedical text mining tasks: biomedical named entity recognition (0.62% F1 score improvement), biomedical relation extraction (2.80% F1 score improvement) and biomedical question answering (12.24% MRR improvement). Our analysis results show that pre-training BERT on biomedical corpora helps it to understand complex biomedical texts.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>We make the pre-trained weights of BioBERT freely available at <ext-link ext-link-type="uri" xlink:href="https://github.com/naver/biobert-pretrained">https://github.com/naver/biobert-pretrained</ext-link>, and the source code for fine-tuning BioBERT available at <ext-link ext-link-type="uri" xlink:href="https://github.com/dmis-lab/biobert">https://github.com/dmis-lab/biobert</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">National Research Foundation of Korea(NRF) funded by the Korea government</named-content>
        </funding-source>
        <award-id>NRF-2017R1A2A1A17069645</award-id>
        <award-id>NRF-2017M3C4A7065887</award-id>
        <award-id>NRF-2014M3C9A3063541</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>The volume of biomedical literature continues to rapidly increase. On average, more than 3000 new articles are published every day in peer-reviewed journals, excluding pre-prints and technical reports such as clinical trial reports in various archives. PubMed alone has a total of 29M articles as of January 2019. Reports containing valuable information about new discoveries and new insights are continuously added to the already overwhelming amount of literature. Consequently, there is increasingly more demand for accurate biomedical text mining tools for extracting information from the literature.</p>
    <p>Recent progress of biomedical text mining models was made possible by the advancements of deep learning techniques used in natural language processing (NLP). For instance, Long Short-Term Memory (LSTM) and Conditional Random Field (CRF) have greatly improved performance in biomedical named entity recognition (NER) over the last few years (<xref rid="btz682-B7" ref-type="bibr">Giorgi and Bader, 2018</xref>; <xref rid="btz682-B8" ref-type="bibr">Habibi <italic>et al.</italic>, 2017</xref>; <xref rid="btz682-B33" ref-type="bibr">Wang <italic>et al.</italic>, 2018</xref>; <xref rid="btz682-B37" ref-type="bibr">Yoon <italic>et al.</italic>, 2019</xref>). Other deep learning based models have made improvements in biomedical text mining tasks such as relation extraction (RE) (<xref rid="btz682-B2" ref-type="bibr">Bhasuran and Natarajan, 2018</xref>; <xref rid="btz682-B13" ref-type="bibr">Lim and Kang, 2018</xref>) and question answering (QA) (<xref rid="btz682-B34" ref-type="bibr">Wiese <italic>et al.</italic>, 2017</xref>).</p>
    <p>However, directly applying state-of-the-art NLP methodologies to biomedical text mining has limitations. First, as recent word representation models such as Word2Vec (<xref rid="btz682-B18" ref-type="bibr">Mikolov <italic>et al.</italic>, 2013</xref>), ELMo (<xref rid="btz682-B22" ref-type="bibr">Peters <italic>et al.</italic>, 2018</xref>) and BERT (<xref rid="btz682-B4" ref-type="bibr">Devlin <italic>et al.</italic>, 2019</xref>) are trained and tested mainly on datasets containing general domain texts (e.g. Wikipedia), it is difficult to estimate their performance on datasets containing biomedical texts. Also, the word distributions of general and biomedical corpora are quite different, which can often be a problem for biomedical text mining models. As a result, recent models in biomedical text mining rely largely on adapted versions of word representations (<xref rid="btz682-B8" ref-type="bibr">Habibi <italic>et al.</italic>, 2017</xref>; <xref rid="btz682-B23" ref-type="bibr">Pyysalo <italic>et al.</italic>, 2013</xref>).</p>
    <p>In this study, we hypothesize that current state-of-the-art word representation models such as BERT need to be trained on biomedical corpora to be effective in biomedical text mining tasks. Previously, Word2Vec, which is one of the most widely known context independent word representation models, was trained on biomedical corpora which contain terms and expressions that are usually not included in a general domain corpus (<xref rid="btz682-B23" ref-type="bibr">Pyysalo <italic>et al.</italic>, 2013</xref>). While ELMo and BERT have proven the effectiveness of contextualized word representations, they cannot obtain high performance on biomedical corpora because they are pre-trained on only general domain corpora. As BERT achieves very strong results on various NLP tasks while using almost the same structure across the tasks, adapting BERT for the biomedical domain could potentially benefit numerous biomedical NLP researches.</p>
  </sec>
  <sec>
    <title>2 Approach</title>
    <p>In this article, we introduce BioBERT, which is a pre-trained language representation model for the biomedical domain. The overall process of pre-training and fine-tuning BioBERT is illustrated in <xref ref-type="fig" rid="btz682-F1">Figure 1</xref>. First, we initialize BioBERT with weights from BERT, which was pre-trained on general domain corpora (English Wikipedia and BooksCorpus). Then, BioBERT is pre-trained on biomedical domain corpora (PubMed abstracts and PMC full-text articles). To show the effectiveness of our approach in biomedical text mining, BioBERT is fine-tuned and evaluated on three popular biomedical text mining tasks (NER, RE and QA). We test various pre-training strategies with different combinations and sizes of general domain corpora and biomedical corpora, and analyze the effect of each corpus on pre-training. We also provide in-depth analyses of BERT and BioBERT to show the necessity of our pre-training strategies.
</p>
    <fig id="btz682-F1" orientation="portrait" position="float">
      <label>Fig. 1.</label>
      <caption>
        <p>Overview of the pre-training and fine-tuning of BioBERT</p>
      </caption>
      <graphic xlink:href="btz682f1"/>
    </fig>
    <p>The contributions of our paper are as follows:
<list list-type="bullet"><list-item><p>BioBERT is the first domain-specific BERT based model pre-trained on biomedical corpora for 23 days on eight NVIDIA V100 GPUs.</p></list-item><list-item><p>We show that pre-training BERT on biomedical corpora largely improves its performance. BioBERT obtains higher F1 scores in biomedical NER (<bold>0.62</bold>) and biomedical RE (<bold>2.80</bold>), and a higher MRR score (<bold>12.24</bold>) in biomedical QA than the current state-of-the-art models.</p></list-item><list-item><p>Compared with most previous biomedical text mining models that are mainly focused on a single task such as NER or QA, our model BioBERT achieves state-of-the-art performance on various biomedical text mining tasks, while requiring only minimal architectural modifications.</p></list-item><list-item><p>We make our pre-processed datasets, the pre-trained weights of BioBERT and the source code for fine-tuning BioBERT publicly available.</p></list-item></list></p>
  </sec>
  <sec>
    <title>3 Materials and methods</title>
    <p>BioBERT basically has the same structure as BERT. We briefly discuss the recently proposed BERT, and then we describe in detail the pre-training and fine-tuning process of BioBERT.</p>
    <sec>
      <title>3.1 BERT: bidirectional encoder representations from transformers</title>
      <p>Learning word representations from a large amount of unannotated text is a long-established method. While previous models (e.g. Word2Vec (<xref rid="btz682-B18" ref-type="bibr">Mikolov <italic>et al.</italic>, 2013</xref>), GloVe (<xref rid="btz682-B21" ref-type="bibr">Pennington <italic>et al.</italic>, 2014</xref>)) focused on learning context independent word representations, recent works have focused on learning context dependent word representations. For instance, ELMo (<xref rid="btz682-B22" ref-type="bibr">Peters <italic>et al.</italic>, 2018</xref>) uses a bidirectional language model, while CoVe (<xref rid="btz682-B17" ref-type="bibr">McCann <italic>et al.</italic>, 2017</xref>) uses machine translation to embed context information into word representations.</p>
      <p>BERT (<xref rid="btz682-B4" ref-type="bibr">Devlin <italic>et al.</italic>, 2019</xref>) is a contextualized word representation model that is based on a masked language model and pre-trained using bidirectional transformers (<xref rid="btz682-B32" ref-type="bibr">Vaswani <italic>et al.</italic>, 2017</xref>). Due to the nature of language modeling where future words cannot be seen, previous language models were limited to a combination of two unidirectional language models (i.e. left-to-right and right-to-left). BERT uses a masked language model that predicts randomly masked words in a sequence, and hence can be used for learning bidirectional representations. Also, it obtains state-of-the-art performance on most NLP tasks, while requiring minimal task-specific architectural modification. According to the authors of BERT, incorporating information from bidirectional representations, rather than unidirectional representations, is crucial for representing words in natural language. We hypothesize that such bidirectional representations are also critical in biomedical text mining as complex relationships between biomedical terms often exist in a biomedical corpus (<xref rid="btz682-B11" ref-type="bibr">Krallinger <italic>et al.</italic>, 2017</xref>). Due to the space limitations, we refer readers to <xref rid="btz682-B4" ref-type="bibr">Devlin <italic>et al.</italic> (2019)</xref> for a more detailed description of BERT.</p>
    </sec>
    <sec>
      <title>3.2 Pre-training BioBERT</title>
      <p>As a general purpose language representation model, BERT was pre-trained on English Wikipedia and BooksCorpus. However, biomedical domain texts contain a considerable number of domain-specific proper nouns (e.g. BRCA1, c.248T&gt;C) and terms (e.g. transcriptional, antimicrobial), which are understood mostly by biomedical researchers. As a result, NLP models designed for general purpose language understanding often obtains poor performance in biomedical text mining tasks. In this work, we pre-train BioBERT on PubMed abstracts (PubMed) and PubMed Central full-text articles (PMC). The text corpora used for pre-training of BioBERT are listed in <xref rid="btz682-T1" ref-type="table">Table 1</xref>, and the tested combinations of text corpora are listed in <xref rid="btz682-T2" ref-type="table">Table 2</xref>. For computational efficiency, whenever the Wiki + Books corpora were used for pre-training, we initialized BioBERT with the pre-trained BERT model provided by <xref rid="btz682-B4" ref-type="bibr">Devlin <italic>et al.</italic> (2019)</xref>. We define BioBERT as a language representation model whose pre-training corpora includes biomedical corpora (e.g. BioBERT (+ PubMed)).
</p>
      <table-wrap id="btz682-T1" orientation="portrait" position="float">
        <label>Table 1.</label>
        <caption>
          <p>List of text corpora used for BioBERT</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Corpus</th>
              <th align="left" rowspan="1" colspan="1">Number of words</th>
              <th align="left" rowspan="1" colspan="1">Domain</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">English Wikipedia</td>
              <td rowspan="1" colspan="1">2.5B</td>
              <td rowspan="1" colspan="1">General</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BooksCorpus</td>
              <td rowspan="1" colspan="1">0.8B</td>
              <td rowspan="1" colspan="1">General</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PubMed Abstracts</td>
              <td rowspan="1" colspan="1">4.5B</td>
              <td rowspan="1" colspan="1">Biomedical</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PMC Full-text articles</td>
              <td rowspan="1" colspan="1">13.5B</td>
              <td rowspan="1" colspan="1">Biomedical</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap id="btz682-T2" orientation="portrait" position="float">
        <label>Table 2.</label>
        <caption>
          <p>Pre-training BioBERT on different combinations of the following text corpora: English Wikipedia (Wiki), BooksCorpus (Books), PubMed abstracts (PubMed) and PMC full-text articles (PMC)</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Model</th>
              <th align="left" rowspan="1" colspan="1">Corpus combination</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">BERT (<xref rid="btz682-B4" ref-type="bibr">Devlin <italic>et al.</italic>, 2019</xref>)</td>
              <td rowspan="1" colspan="1">Wiki + Books</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioBERT (+PubMed)</td>
              <td rowspan="1" colspan="1">Wiki + Books + PubMed</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioBERT (+PMC)</td>
              <td rowspan="1" colspan="1">Wiki + Books + PMC</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioBERT (+PubMed + PMC)</td>
              <td rowspan="1" colspan="1">Wiki + Books + PubMed + PMC</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>For tokenization, BioBERT uses WordPiece tokenization (<xref rid="btz682-B35" ref-type="bibr">Wu <italic>et al.</italic>, 2016</xref>), which mitigates the out-of-vocabulary issue. With WordPiece tokenization, any new words can be represented by frequent subwords (e.g. <italic>Immunoglobulin</italic> =&gt; <italic>I ##mm ##uno ##g ##lo ##bul ##in</italic>). We found that using cased vocabulary (not lower-casing) results in slightly better performances in downstream tasks. Although we could have constructed new WordPiece vocabulary based on biomedical corpora, we used the original vocabulary of BERT<sub><monospace>BASE</monospace></sub> for the following reasons: (i) compatibility of BioBERT with BERT, which allows BERT pre-trained on general domain corpora to be re-used, and makes it easier to interchangeably use existing models based on BERT and BioBERT and (ii) any new words may still be represented and fine-tuned for the biomedical domain using the original WordPiece vocabulary of BERT.</p>
    </sec>
    <sec>
      <title>3.3 Fine-tuning BioBERT</title>
      <p>With minimal architectural modification, BioBERT can be applied to various downstream text mining tasks. We fine-tune BioBERT on the following three representative biomedical text mining tasks: NER, RE and QA.</p>
      <p><italic>Named</italic> <italic>e</italic><italic>ntity</italic> <italic>r</italic><italic>ecognition</italic> is one of the most fundamental biomedical text mining tasks, which involves recognizing numerous domain-specific proper nouns in a biomedical corpus. While most previous works were built upon different combinations of LSTMs and CRFs (<xref rid="btz682-B7" ref-type="bibr">Giorgi and Bader, 2018</xref>; <xref rid="btz682-B8" ref-type="bibr">Habibi <italic>et al.</italic>, 2017</xref>; <xref rid="btz682-B33" ref-type="bibr">Wang <italic>et al.</italic>, 2018</xref>), BERT has a simple architecture based on bidirectional transformers. BERT uses a single output layer based on the representations from its last layer to compute only token level BIO2 probabilities. Note that while previous works in biomedical NER often used word embeddings trained on PubMed or PMC corpora (<xref rid="btz682-B8" ref-type="bibr">Habibi <italic>et al.</italic>, 2017</xref>; <xref rid="btz682-B37" ref-type="bibr">Yoon <italic>et al.</italic>, 2019</xref>), BioBERT directly learns WordPiece embeddings during pre-training and fine-tuning. For the evaluation metrics of NER, we used entity level precision, recall and F1 score.</p>
      <p><italic>Relation</italic> <italic>e</italic><italic>xtraction</italic> is a task of classifying relations of named entities in a biomedical corpus. We utilized the sentence classifier of the original version of BERT, which uses a [CLS] token for the classification of relations. Sentence classification is performed using a single output layer based on a [CLS] token representation from BERT. We anonymized target named entities in a sentence using pre-defined tags such as @GENE$ or @DISEASE$. For instance, a sentence with two target entities (gene and disease in this case) is represented as “<italic>Serine at position 986 of @GENE$ may be an independent genetic predictor of angiographic @DISEASE$</italic>.” The precision, recall and F1 scores on the RE task are reported.</p>
      <p><italic>Question</italic> <italic>a</italic><italic>nswering</italic> is a task of answering questions posed in natural language given related passages. To fine-tune BioBERT for QA, we used the same BERT architecture used for SQuAD (<xref rid="btz682-B24" ref-type="bibr">Rajpurkar <italic>et al.</italic>, 2016</xref>). We used the BioASQ factoid datasets because their format is similar to that of SQuAD. Token level probabilities for the start/end location of answer phrases are computed using a single output layer. However, we observed that about 30% of the BioASQ factoid questions were unanswerable in an extractive QA setting as the exact answers did not appear in the given passages. Like <xref rid="btz682-B34" ref-type="bibr">Wiese <italic>et al.</italic> (2017)</xref>, we excluded the samples with unanswerable questions from the training sets. Also, we used the same pre-training process of <xref rid="btz682-B34" ref-type="bibr">Wiese <italic>et al.</italic> (2017)</xref>, which uses SQuAD, and it largely improved the performance of both BERT and BioBERT. We used the following evaluation metrics from BioASQ: strict accuracy, lenient accuracy and mean reciprocal rank.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Results</title>
    <sec>
      <title>4.1 Datasets</title>
      <p>The statistics of biomedical NER datasets are listed in <xref rid="btz682-T3" ref-type="table">Table 3</xref>. We used the pre-processed versions of all the NER datasets provided by <xref rid="btz682-B33" ref-type="bibr">Wang <italic>et al.</italic> (2018)</xref> except the 2010 i2b2/VA, JNLPBA and Species-800 datasets. The pre-processed NCBI Disease dataset has fewer annotations than the original dataset due to the removal of duplicate articles from its training set. We used the CoNLL format (<ext-link ext-link-type="uri" xlink:href="https://github.com/spyysalo/standoff2conll">https://github.com/spyysalo/standoff2conll</ext-link>) for pre-processing the 2010 i2b2/VA and JNLPBA datasets. The Species-800 dataset was pre-processed and split based on the dataset of Pyysalo (<ext-link ext-link-type="uri" xlink:href="https://github.com/spyysalo/s800">https://github.com/spyysalo/s800</ext-link>). We did not use alternate annotations for the BC2GM dataset, and all NER evaluations are based on entity-level exact matches. Note that although there are several other recently introduced high quality biomedical NER datasets (<xref rid="btz682-B19" ref-type="bibr">Mohan and Li, 2019</xref>), we use datasets that are frequently used by many biomedical NLP researchers, which makes it much easier to compare our work with theirs. The RE datasets contain gene–disease relations and protein–chemical relations (<xref rid="btz682-T4" ref-type="table">Table 4</xref>). Pre-processed GAD and EU-ADR datasets are available with our provided codes. For the CHEMPROT dataset, we used the same pre-processing procedure described in <xref rid="btz682-B13" ref-type="bibr">Lim and Kang (2018)</xref>. We used the BioASQ factoid datasets, which can be converted into the same format as the SQuAD dataset (<xref rid="btz682-T5" ref-type="table">Table 5</xref>). We used full abstracts (PMIDs) and related questions and answers provided by the BioASQ organizers. We have made the pre-processed BioASQ datasets publicly available. For all the datasets, we used the same dataset splits used in previous works (<xref rid="btz682-B13" ref-type="bibr">Lim and Kang, 2018</xref>; <xref rid="btz682-B29" ref-type="bibr">Tsatsaronis <italic>et al.</italic>, 2015</xref>; <xref rid="btz682-B33" ref-type="bibr">Wang <italic>et al.</italic>, 2018</xref>) for a fair evaluation; however, the splits of LINAAEUS and Species-800 could not be found from <xref rid="btz682-B7" ref-type="bibr">Giorgi and Bader (2018)</xref> and may be different. Like previous work (<xref rid="btz682-B2" ref-type="bibr">Bhasuran and Natarajan, 2018</xref>), we reported the performance of 10-fold cross-validation on datasets that do not have separate test sets (e.g. GAD, EU-ADR).
</p>
      <table-wrap id="btz682-T3" orientation="portrait" position="float">
        <label>Table 3.</label>
        <caption>
          <p>Statistics of the biomedical named entity recognition datasets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Dataset</th>
              <th align="left" rowspan="1" colspan="1">Entity type</th>
              <th align="left" rowspan="1" colspan="1">Number of annotations</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">NCBI Disease (<xref rid="btz682-B5" ref-type="bibr">Doğan <italic>et al.</italic>, 2014</xref>)</td>
              <td rowspan="1" colspan="1">Disease</td>
              <td rowspan="1" colspan="1">6881</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">2010 i2b2/VA (<xref rid="btz682-B30" ref-type="bibr">Uzuner et al., 2011</xref>)</td>
              <td rowspan="1" colspan="1">Disease</td>
              <td rowspan="1" colspan="1">19 665</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BC5CDR (<xref rid="btz682-B12" ref-type="bibr">Li <italic>et al.</italic>, 2016</xref>)</td>
              <td rowspan="1" colspan="1">Disease</td>
              <td rowspan="1" colspan="1">12 694</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BC5CDR (<xref rid="btz682-B12" ref-type="bibr">Li <italic>et al.</italic>, 2016</xref>)</td>
              <td rowspan="1" colspan="1">Drug/Chem.</td>
              <td rowspan="1" colspan="1">15 411</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BC4CHEMD (<xref rid="btz682-B10" ref-type="bibr">Krallinger <italic>et al.</italic>, 2015</xref>)</td>
              <td rowspan="1" colspan="1">Drug/Chem.</td>
              <td rowspan="1" colspan="1">79 842</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BC2GM (<xref rid="btz682-B26" ref-type="bibr">Smith <italic>et al.</italic>, 2008</xref>)</td>
              <td rowspan="1" colspan="1">Gene/Protein</td>
              <td rowspan="1" colspan="1">20 703</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">JNLPBA (<xref rid="btz682-B9" ref-type="bibr">Kim <italic>et al.</italic>, 2004</xref>)</td>
              <td rowspan="1" colspan="1">Gene/Protein</td>
              <td rowspan="1" colspan="1">35 460</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">LINNAEUS (<xref rid="btz682-B6" ref-type="bibr">Gerner <italic>et al.</italic>, 2010</xref>)</td>
              <td rowspan="1" colspan="1">Species</td>
              <td rowspan="1" colspan="1">4077</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Species-800 (<xref rid="btz682-B20" ref-type="bibr">Pafilis <italic>et al.</italic>, 2013</xref>)</td>
              <td rowspan="1" colspan="1">Species</td>
              <td rowspan="1" colspan="1">3708</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic>Note:</italic> The number of annotations from <xref rid="btz682-B8" ref-type="bibr">Habibi <italic>et al.</italic> (2017)</xref> and <xref rid="btz682-B38" ref-type="bibr">Zhu <italic>et al.</italic> (2018)</xref> is provided.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <table-wrap id="btz682-T4" orientation="portrait" position="float">
        <label>Table 4.</label>
        <caption>
          <p>Statistics of the biomedical relation extraction datasets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Dataset</th>
              <th align="left" rowspan="1" colspan="1">Entity type</th>
              <th align="left" rowspan="1" colspan="1">Number of relations</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">GAD (<xref rid="btz682-B3" ref-type="bibr">Bravo et al., 2015</xref>)</td>
              <td rowspan="1" colspan="1">Gene–disease</td>
              <td rowspan="1" colspan="1">5330</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">EU-ADR (<xref rid="btz682-B31" ref-type="bibr">Van Mulligen <italic>et al.</italic>, 2012</xref>)</td>
              <td rowspan="1" colspan="1">Gene–disease</td>
              <td rowspan="1" colspan="1">355</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CHEMPROT (<xref rid="btz682-B11" ref-type="bibr">Krallinger <italic>et al.</italic>, 2017</xref>)</td>
              <td rowspan="1" colspan="1">Protein–chemical</td>
              <td rowspan="1" colspan="1">10 031</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p><italic>Note:</italic> For the CHEMPROT dataset, the number of relations in the training, validation and test sets was summed.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <table-wrap id="btz682-T5" orientation="portrait" position="float">
        <label>Table 5.</label>
        <caption>
          <p>Statistics of biomedical question answering datasets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Dataset</th>
              <th align="left" rowspan="1" colspan="1">Number of train</th>
              <th align="left" rowspan="1" colspan="1">Number of test</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">BioASQ 4b-factoid (<xref rid="btz682-B29" ref-type="bibr">Tsatsaronis <italic>et al.</italic>, 2015</xref>)</td>
              <td rowspan="1" colspan="1">327</td>
              <td rowspan="1" colspan="1">161</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioASQ 5b-factoid (<xref rid="btz682-B29" ref-type="bibr">Tsatsaronis <italic>et al.</italic>, 2015</xref>)</td>
              <td rowspan="1" colspan="1">486</td>
              <td rowspan="1" colspan="1">150</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioASQ 6b-factoid (<xref rid="btz682-B29" ref-type="bibr">Tsatsaronis <italic>et al.</italic>, 2015</xref>)</td>
              <td rowspan="1" colspan="1">618</td>
              <td rowspan="1" colspan="1">161</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>We compare BERT and BioBERT with the current state-of-the-art models and report their scores. Note that the state-of-the-art models each have a different architecture and training procedure. For instance, the state-of-the-art model by <xref rid="btz682-B37" ref-type="bibr">Yoon <italic>et al.</italic> (2019)</xref> trained on the JNLPBA dataset is based on multiple Bi-LSTM CRF models with character level CNNs, while the state-of-the-art model by <xref rid="btz682-B7" ref-type="bibr">Giorgi and Bader (2018)</xref> trained on the LINNAEUS dataset uses a Bi-LSTM CRF model with character level LSTMs and is additionally trained on silver-standard datasets. On the other hand, BERT and BioBERT have exactly the same structure, and use only the gold standard datasets and not any additional datasets.</p>
    </sec>
    <sec>
      <title>4.2 Experimental setups</title>
      <p>We used the BERT<sub><monospace>BASE</monospace></sub> model pre-trained on English Wikipedia and BooksCorpus for 1M steps. BioBERT v1.0 (+ PubMed + PMC) is the version of BioBERT (+ PubMed + PMC) trained for 470 K steps. When using both the PubMed and PMC corpora, we found that 200K and 270K pre-training steps were optimal for PubMed and PMC, respectively. We also used the ablated versions of BioBERT v1.0, which were pre-trained on only PubMed for 200K steps (BioBERT v1.0 (+ PubMed)) and PMC for 270K steps (BioBERT v1.0 (+ PMC)). After our initial release of BioBERT v1.0, we pre-trained BioBERT on PubMed for 1M steps, and we refer to this version as BioBERT v1.1 (+ PubMed). Other hyper-parameters such as batch size and learning rate scheduling for pre-training BioBERT are the same as those for pre-training BERT unless stated otherwise.</p>
      <p>We pre-trained BioBERT using Naver Smart Machine Learning (NSML) (<xref rid="btz682-B28" ref-type="bibr">Sung <italic>et al.</italic>, 2017</xref>), which is utilized for large-scale experiments that need to be run on several GPUs. We used eight NVIDIA V100 (32GB) GPUs for the pre-training. The maximum sequence length was fixed to 512 and the mini-batch size was set to 192, resulting in 98 304 words per iteration. It takes more than 10 days to pre-train BioBERT v1.0 (+ PubMed + PMC) nearly 23 days for BioBERT v1.1 (+ PubMed) in this setting. Despite our best efforts to use BERT<sub><monospace>LARGE</monospace></sub>, we used only BERT<sub><monospace>BASE</monospace></sub> due to the computational complexity of BERT<sub><monospace>LARGE</monospace></sub>.</p>
      <p>We used a single NVIDIA Titan Xp (12GB) GPU to fine-tune BioBERT on each task. Note that the fine-tuning process is more computationally efficient than pre-training BioBERT. For fine-tuning, a batch size of 10, 16, 32 or 64 was selected, and a learning rate of 5e−5, 3e−5 or 1e−5 was selected. Fine-tuning BioBERT on QA and RE tasks took less than an hour as the size of the training data is much smaller than that of the training data used by <xref rid="btz682-B4" ref-type="bibr">Devlin <italic>et al.</italic> (2019)</xref>. On the other hand, it takes more than 20 epochs for BioBERT to reach its highest performance on the NER datasets.</p>
    </sec>
    <sec>
      <title>4.3 Experimental results</title>
      <p>The results of NER are shown in <xref rid="btz682-T6" ref-type="table">Table 6</xref>. First, we observe that BERT, which was pre-trained on only the general domain corpus is quite effective, but the micro averaged F1 score of BERT was lower (2.01 lower) than that of the state-of-the-art models. On the other hand, BioBERT achieves higher scores than BERT on all the datasets. BioBERT outperformed the state-of-the-art models on six out of nine datasets, and BioBERT v1.1 (+ PubMed) outperformed the state-of-the-art models by 0.62 in terms of micro averaged F1 score. The relatively low scores on the LINNAEUS dataset can be attributed to the following: (i) the lack of a silver-standard dataset for training previous state-of-the-art models and (ii) different training/test set splits used in previous work (<xref rid="btz682-B7" ref-type="bibr">Giorgi and Bader, 2018</xref>), which were unavailable.
</p>
      <table-wrap id="btz682-T6" orientation="portrait" position="float">
        <label>Table 6.</label>
        <caption>
          <p>Test results in biomedical named entity recognition</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">BERT</th>
              <th align="left" colspan="3" rowspan="1">BioBERT v1.0<hr/></th>
              <th rowspan="1" colspan="1">BioBERT v1.1</th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">Type</th>
              <th rowspan="1" colspan="1">Datasets</th>
              <th rowspan="1" colspan="1">Metrics</th>
              <th rowspan="1" colspan="1">SOTA</th>
              <th rowspan="1" colspan="1">(Wiki + Books)</th>
              <th rowspan="1" colspan="1">(+ PubMed)</th>
              <th rowspan="1" colspan="1">(+ PMC)</th>
              <th rowspan="1" colspan="1">(+ PubMed + PMC)</th>
              <th rowspan="1" colspan="1">(+ PubMed)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Disease</td>
              <td rowspan="1" colspan="1">NCBI disease</td>
              <td rowspan="1" colspan="1">P</td>
              <td rowspan="1" colspan="1">
                <underline>88.30</underline>
              </td>
              <td rowspan="1" colspan="1">84.12</td>
              <td rowspan="1" colspan="1">86.76</td>
              <td rowspan="1" colspan="1">86.16</td>
              <td rowspan="1" colspan="1">
                <bold>89.04</bold>
              </td>
              <td rowspan="1" colspan="1">88.22</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">R</td>
              <td rowspan="1" colspan="1">89.00</td>
              <td rowspan="1" colspan="1">87.19</td>
              <td rowspan="1" colspan="1">88.02</td>
              <td rowspan="1" colspan="1">89.48</td>
              <td rowspan="1" colspan="1">
                <underline>89.69</underline>
              </td>
              <td rowspan="1" colspan="1">
                <bold>91.25</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">F</td>
              <td rowspan="1" colspan="1">88.60</td>
              <td rowspan="1" colspan="1">85.63</td>
              <td rowspan="1" colspan="1">87.38</td>
              <td rowspan="1" colspan="1">87.79</td>
              <td rowspan="1" colspan="1">
                <underline>89.36</underline>
              </td>
              <td rowspan="1" colspan="1">
                <bold>89.71</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">2010 i2b2/VA</td>
              <td rowspan="1" colspan="1">P</td>
              <td rowspan="1" colspan="1">
                <underline>87.44</underline>
              </td>
              <td rowspan="1" colspan="1">84.04</td>
              <td rowspan="1" colspan="1">85.37</td>
              <td rowspan="1" colspan="1">85.55</td>
              <td rowspan="1" colspan="1">
                <bold>87.50</bold>
              </td>
              <td rowspan="1" colspan="1">86.93</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">R</td>
              <td rowspan="1" colspan="1">
                <underline>86.25</underline>
              </td>
              <td rowspan="1" colspan="1">84.08</td>
              <td rowspan="1" colspan="1">85.64</td>
              <td rowspan="1" colspan="1">85.72</td>
              <td rowspan="1" colspan="1">85.44</td>
              <td rowspan="1" colspan="1">
                <bold>86.53</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">F</td>
              <td rowspan="1" colspan="1">
                <bold>86.84</bold>
              </td>
              <td rowspan="1" colspan="1">84.06</td>
              <td rowspan="1" colspan="1">85.51</td>
              <td rowspan="1" colspan="1">85.64</td>
              <td rowspan="1" colspan="1">86.46</td>
              <td rowspan="1" colspan="1">
                <underline>86.73</underline>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BC5CDR</td>
              <td rowspan="1" colspan="1">P</td>
              <td rowspan="1" colspan="1">
                <bold>89.61</bold>
              </td>
              <td rowspan="1" colspan="1">81.97</td>
              <td rowspan="1" colspan="1">85.80</td>
              <td rowspan="1" colspan="1">84.67</td>
              <td rowspan="1" colspan="1">85.86</td>
              <td rowspan="1" colspan="1">
                <underline>86.47</underline>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">R</td>
              <td rowspan="1" colspan="1">83.09</td>
              <td rowspan="1" colspan="1">82.48</td>
              <td rowspan="1" colspan="1">86.60</td>
              <td rowspan="1" colspan="1">85.87</td>
              <td rowspan="1" colspan="1">
                <underline>87.27</underline>
              </td>
              <td rowspan="1" colspan="1">
                <bold>87.84</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">F</td>
              <td rowspan="1" colspan="1">
                <underline>86.23</underline>
              </td>
              <td rowspan="1" colspan="1">82.41</td>
              <td rowspan="1" colspan="1">86.20</td>
              <td rowspan="1" colspan="1">85.27</td>
              <td rowspan="1" colspan="1">86.56</td>
              <td rowspan="1" colspan="1">
                <bold>87.15</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Drug/chem.</td>
              <td rowspan="1" colspan="1">BC5CDR</td>
              <td rowspan="1" colspan="1">P</td>
              <td rowspan="1" colspan="1">
                <bold>94.26</bold>
              </td>
              <td rowspan="1" colspan="1">90.94</td>
              <td rowspan="1" colspan="1">92.52</td>
              <td rowspan="1" colspan="1">92.46</td>
              <td rowspan="1" colspan="1">93.27</td>
              <td rowspan="1" colspan="1">
                <underline>93.68</underline>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">R</td>
              <td rowspan="1" colspan="1">92.38</td>
              <td rowspan="1" colspan="1">91.38</td>
              <td rowspan="1" colspan="1">92.76</td>
              <td rowspan="1" colspan="1">92.63</td>
              <td rowspan="1" colspan="1">
                <bold>93.61</bold>
              </td>
              <td rowspan="1" colspan="1">
                <underline>93.26</underline>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">F</td>
              <td rowspan="1" colspan="1">93.31</td>
              <td rowspan="1" colspan="1">91.16</td>
              <td rowspan="1" colspan="1">92.64</td>
              <td rowspan="1" colspan="1">92.54</td>
              <td rowspan="1" colspan="1">
                <underline>93.44</underline>
              </td>
              <td rowspan="1" colspan="1">
                <bold>93.47</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BC4CHEMD</td>
              <td rowspan="1" colspan="1">P</td>
              <td rowspan="1" colspan="1">
                <underline>92.29</underline>
              </td>
              <td rowspan="1" colspan="1">91.19</td>
              <td rowspan="1" colspan="1">91.77</td>
              <td rowspan="1" colspan="1">91.65</td>
              <td rowspan="1" colspan="1">92.23</td>
              <td rowspan="1" colspan="1">
                <bold>92.80</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">R</td>
              <td rowspan="1" colspan="1">90.01</td>
              <td rowspan="1" colspan="1">88.92</td>
              <td rowspan="1" colspan="1">
                <underline>90.77</underline>
              </td>
              <td rowspan="1" colspan="1">90.30</td>
              <td rowspan="1" colspan="1">90.61</td>
              <td rowspan="1" colspan="1">
                <bold>91.92</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">F</td>
              <td rowspan="1" colspan="1">91.14</td>
              <td rowspan="1" colspan="1">90.04</td>
              <td rowspan="1" colspan="1">91.26</td>
              <td rowspan="1" colspan="1">90.97</td>
              <td rowspan="1" colspan="1">
                <underline>91.41</underline>
              </td>
              <td rowspan="1" colspan="1">
                <bold>92.36</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Gene/protein</td>
              <td rowspan="1" colspan="1">BC2GM</td>
              <td rowspan="1" colspan="1">P</td>
              <td rowspan="1" colspan="1">81.81</td>
              <td rowspan="1" colspan="1">81.17</td>
              <td rowspan="1" colspan="1">81.72</td>
              <td rowspan="1" colspan="1">82.86</td>
              <td rowspan="1" colspan="1">
                <bold>85.16</bold>
              </td>
              <td rowspan="1" colspan="1">
                <underline>84.32</underline>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">R</td>
              <td rowspan="1" colspan="1">81.57</td>
              <td rowspan="1" colspan="1">82.42</td>
              <td rowspan="1" colspan="1">83.38</td>
              <td rowspan="1" colspan="1">
                <underline>84.21</underline>
              </td>
              <td rowspan="1" colspan="1">83.65</td>
              <td rowspan="1" colspan="1">
                <bold>85.12</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">F</td>
              <td rowspan="1" colspan="1">81.69</td>
              <td rowspan="1" colspan="1">81.79</td>
              <td rowspan="1" colspan="1">82.54</td>
              <td rowspan="1" colspan="1">83.53</td>
              <td rowspan="1" colspan="1">
                <underline>84.40</underline>
              </td>
              <td rowspan="1" colspan="1">
                <bold>84.72</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">JNLPBA</td>
              <td rowspan="1" colspan="1">P</td>
              <td rowspan="1" colspan="1">
                <bold>74.43</bold>
              </td>
              <td rowspan="1" colspan="1">69.57</td>
              <td rowspan="1" colspan="1">71.11</td>
              <td rowspan="1" colspan="1">71.17</td>
              <td rowspan="1" colspan="1">
                <underline>72.68</underline>
              </td>
              <td rowspan="1" colspan="1">72.24</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">R</td>
              <td rowspan="1" colspan="1">
                <underline>83.22</underline>
              </td>
              <td rowspan="1" colspan="1">81.20</td>
              <td rowspan="1" colspan="1">83.11</td>
              <td rowspan="1" colspan="1">82.76</td>
              <td rowspan="1" colspan="1">83.21</td>
              <td rowspan="1" colspan="1">
                <bold>83.56</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">F</td>
              <td rowspan="1" colspan="1">
                <bold>78.58</bold>
              </td>
              <td rowspan="1" colspan="1">74.94</td>
              <td rowspan="1" colspan="1">76.65</td>
              <td rowspan="1" colspan="1">76.53</td>
              <td rowspan="1" colspan="1">
                <underline>77.59</underline>
              </td>
              <td rowspan="1" colspan="1">77.49</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Species</td>
              <td rowspan="1" colspan="1">LINNAEUS</td>
              <td rowspan="1" colspan="1">P</td>
              <td rowspan="1" colspan="1">
                <underline>92.80</underline>
              </td>
              <td rowspan="1" colspan="1">91.17</td>
              <td rowspan="1" colspan="1">91.83</td>
              <td rowspan="1" colspan="1">91.62</td>
              <td rowspan="1" colspan="1">
                <bold>93.84</bold>
              </td>
              <td rowspan="1" colspan="1">90.77</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">R</td>
              <td rowspan="1" colspan="1">
                <bold>94.29</bold>
              </td>
              <td rowspan="1" colspan="1">84.30</td>
              <td rowspan="1" colspan="1">84.72</td>
              <td rowspan="1" colspan="1">85.48</td>
              <td rowspan="1" colspan="1">
                <underline>86.11</underline>
              </td>
              <td rowspan="1" colspan="1">85.83</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">F</td>
              <td rowspan="1" colspan="1">
                <bold>93.54</bold>
              </td>
              <td rowspan="1" colspan="1">87.60</td>
              <td rowspan="1" colspan="1">88.13</td>
              <td rowspan="1" colspan="1">88.45</td>
              <td rowspan="1" colspan="1">
                <underline>89.81</underline>
              </td>
              <td rowspan="1" colspan="1">88.24</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Species-800</td>
              <td rowspan="1" colspan="1">P</td>
              <td rowspan="1" colspan="1">
                <bold>74.34</bold>
              </td>
              <td rowspan="1" colspan="1">69.35</td>
              <td rowspan="1" colspan="1">70.60</td>
              <td rowspan="1" colspan="1">71.54</td>
              <td rowspan="1" colspan="1">
                <underline>72.84</underline>
              </td>
              <td rowspan="1" colspan="1">72.80</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">R</td>
              <td rowspan="1" colspan="1">
                <underline>75.96</underline>
              </td>
              <td rowspan="1" colspan="1">74.05</td>
              <td rowspan="1" colspan="1">75.75</td>
              <td rowspan="1" colspan="1">74.71</td>
              <td rowspan="1" colspan="1">
                <bold>77.97</bold>
              </td>
              <td rowspan="1" colspan="1">75.36</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">F</td>
              <td rowspan="1" colspan="1">
                <underline>74.98</underline>
              </td>
              <td rowspan="1" colspan="1">71.63</td>
              <td rowspan="1" colspan="1">73.08</td>
              <td rowspan="1" colspan="1">73.09</td>
              <td rowspan="1" colspan="1">
                <bold>75.31</bold>
              </td>
              <td rowspan="1" colspan="1">74.06</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn3">
            <p><italic>Notes:</italic> Precision (P), Recall (R) and F1 (F) scores on each dataset are reported. The best scores are in bold, and the second best scores are underlined. We list the scores of the state-of-the-art (SOTA) models on different datasets as follows: scores of <xref rid="btz682-B36" ref-type="bibr">Xu <italic>et al.</italic> (2019)</xref> on NCBI Disease, scores of <xref rid="btz682-B25" ref-type="bibr">Sachan <italic>et al.</italic> (2018)</xref> on BC2GM, scores of <xref rid="btz682-B38" ref-type="bibr">Zhu <italic>et al.</italic> (2018)</xref> (single model) on 2010 i2b2/VA, scores of <xref rid="btz682-B15" ref-type="bibr">Lou <italic>et al.</italic> (2017)</xref> on BC5CDR-disease, scores of <xref rid="btz682-B16" ref-type="bibr">Luo <italic>et al.</italic> (2018)</xref> on BC4CHEMD, scores of <xref rid="btz682-B37" ref-type="bibr">Yoon <italic>et al.</italic> (2019)</xref> on BC5CDR-chemical and JNLPBA and scores of <xref rid="btz682-B7" ref-type="bibr">Giorgi and Bader (2018)</xref> on LINNAEUS and Species-800.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>The RE results of each model are shown in <xref rid="btz682-T7" ref-type="table">Table 7</xref>. BERT achieved better performance than the state-of-the-art model on the CHEMPROT dataset, which demonstrates its effectiveness in RE. On average (micro), BioBERT v1.0 (+ PubMed) obtained a higher F1 score (2.80 higher) than the state-of-the-art models. Also, BioBERT achieved the highest F1 scores on 2 out of 3 biomedical datasets.
</p>
      <table-wrap id="btz682-T7" orientation="portrait" position="float">
        <label>Table 7.</label>
        <caption>
          <p>Biomedical relation extraction test results</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">BERT</th>
              <th align="left" colspan="3" rowspan="1">BioBERT v1.0<hr/></th>
              <th rowspan="1" colspan="1">BioBERT v1.1</th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">Relation</th>
              <th rowspan="1" colspan="1">Datasets</th>
              <th rowspan="1" colspan="1">Metrics</th>
              <th rowspan="1" colspan="1">SOTA</th>
              <th rowspan="1" colspan="1">(Wiki + Books)</th>
              <th rowspan="1" colspan="1">(+ PubMed)</th>
              <th rowspan="1" colspan="1">(+ PMC)</th>
              <th rowspan="1" colspan="1">(+ PubMed + PMC)</th>
              <th rowspan="1" colspan="1">(+ PubMed)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Gene–disease</td>
              <td rowspan="1" colspan="1">GAD</td>
              <td rowspan="1" colspan="1">P</td>
              <td rowspan="1" colspan="1">
                <bold>79.21</bold>
              </td>
              <td rowspan="1" colspan="1">74.28</td>
              <td rowspan="1" colspan="1">76.43</td>
              <td rowspan="1" colspan="1">75.20</td>
              <td rowspan="1" colspan="1">75.95</td>
              <td rowspan="1" colspan="1">
                <underline>77.32</underline>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">R</td>
              <td rowspan="1" colspan="1">
                <bold>89.25</bold>
              </td>
              <td rowspan="1" colspan="1">85.11</td>
              <td rowspan="1" colspan="1">87.65</td>
              <td rowspan="1" colspan="1">86.15</td>
              <td rowspan="1" colspan="1">
                <underline>88.08</underline>
              </td>
              <td rowspan="1" colspan="1">82.68</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">F</td>
              <td rowspan="1" colspan="1">
                <bold>83.93</bold>
              </td>
              <td rowspan="1" colspan="1">79.29</td>
              <td rowspan="1" colspan="1">
                <underline>81.61</underline>
              </td>
              <td rowspan="1" colspan="1">80.24</td>
              <td rowspan="1" colspan="1">81.52</td>
              <td rowspan="1" colspan="1">79.83</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">EU-ADR</td>
              <td rowspan="1" colspan="1">P</td>
              <td rowspan="1" colspan="1">76.43</td>
              <td rowspan="1" colspan="1">75.45</td>
              <td rowspan="1" colspan="1">78.04</td>
              <td rowspan="1" colspan="1">
                <bold>81.05</bold>
              </td>
              <td rowspan="1" colspan="1">
                <underline>80.92</underline>
              </td>
              <td rowspan="1" colspan="1">77.86</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">R</td>
              <td rowspan="1" colspan="1">
                <bold>98.01</bold>
              </td>
              <td rowspan="1" colspan="1">
                <underline>96.55</underline>
              </td>
              <td rowspan="1" colspan="1">93.86</td>
              <td rowspan="1" colspan="1">93.90</td>
              <td rowspan="1" colspan="1">90.81</td>
              <td rowspan="1" colspan="1">83.55</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">F</td>
              <td rowspan="1" colspan="1">
                <underline>85.34</underline>
              </td>
              <td rowspan="1" colspan="1">84.62</td>
              <td rowspan="1" colspan="1">84.44</td>
              <td rowspan="1" colspan="1">
                <bold>86.51</bold>
              </td>
              <td rowspan="1" colspan="1">84.83</td>
              <td rowspan="1" colspan="1">79.74</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Protein–chemical</td>
              <td rowspan="1" colspan="1">CHEMPROT</td>
              <td rowspan="1" colspan="1">P</td>
              <td rowspan="1" colspan="1">74.80</td>
              <td rowspan="1" colspan="1">76.02</td>
              <td rowspan="1" colspan="1">76.05</td>
              <td rowspan="1" colspan="1">
                <bold>77.46</bold>
              </td>
              <td rowspan="1" colspan="1">75.20</td>
              <td rowspan="1" colspan="1">
                <underline>77.02</underline>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">R</td>
              <td rowspan="1" colspan="1">56.00</td>
              <td rowspan="1" colspan="1">71.60</td>
              <td rowspan="1" colspan="1">74.33</td>
              <td rowspan="1" colspan="1">72.94</td>
              <td rowspan="1" colspan="1">
                <underline>75.09</underline>
              </td>
              <td rowspan="1" colspan="1">
                <bold>75.90</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">F</td>
              <td rowspan="1" colspan="1">64.10</td>
              <td rowspan="1" colspan="1">73.74</td>
              <td rowspan="1" colspan="1">
                <underline>75.18</underline>
              </td>
              <td rowspan="1" colspan="1">75.13</td>
              <td rowspan="1" colspan="1">75.14</td>
              <td rowspan="1" colspan="1">
                <bold>76.46</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn4">
            <p><italic>Notes:</italic> Precision (P), Recall (R) and F1 (F) scores on each dataset are reported. The best scores are in bold, and the second best scores are underlined. The scores on GAD and EU-ADR were obtained from <xref rid="btz682-B2" ref-type="bibr">Bhasuran and Natarajan (2018)</xref>, and the scores on CHEMPROT were obtained from <xref rid="btz682-B13" ref-type="bibr">Lim and Kang (2018)</xref>.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>The QA results are shown in <xref rid="btz682-T8" ref-type="table">Table 8</xref>. We micro averaged the best scores of the state-of-the-art models from each batch. BERT obtained a higher micro averaged MRR score (7.0 higher) than the state-of-the-art models. All versions of BioBERT significantly outperformed BERT and the state-of-the-art models, and in particular, BioBERT v1.1 (+ PubMed) obtained a strict accuracy of 38.77, a lenient accuracy of 53.81 and a mean reciprocal rank score of 44.77, all of which were micro averaged. On all the biomedical QA datasets, BioBERT achieved new state-of-the-art performance in terms of MRR.
</p>
      <table-wrap id="btz682-T8" orientation="portrait" position="float">
        <label>Table 8.</label>
        <caption>
          <p>Biomedical question answering test results</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">BERT</th>
              <th align="left" colspan="3" rowspan="1">BioBERT v1.0<hr/></th>
              <th rowspan="1" colspan="1">BioBERT v1.1</th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">Datasets</th>
              <th rowspan="1" colspan="1">Metrics</th>
              <th rowspan="1" colspan="1">SOTA</th>
              <th rowspan="1" colspan="1">(Wiki + Books)</th>
              <th rowspan="1" colspan="1">(+ PubMed)</th>
              <th rowspan="1" colspan="1">(+ PMC)</th>
              <th rowspan="1" colspan="1">(+ PubMed + PMC)</th>
              <th rowspan="1" colspan="1">(+ PubMed)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">BioASQ 4b</td>
              <td rowspan="1" colspan="1">S</td>
              <td rowspan="1" colspan="1">20.01</td>
              <td rowspan="1" colspan="1">27.33</td>
              <td rowspan="1" colspan="1">25.47</td>
              <td rowspan="1" colspan="1">26.09</td>
              <td rowspan="1" colspan="1">
                <bold>28.57</bold>
              </td>
              <td rowspan="1" colspan="1">
                <underline>27.95</underline>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">L</td>
              <td rowspan="1" colspan="1">28.81</td>
              <td rowspan="1" colspan="1">
                <underline>44.72</underline>
              </td>
              <td rowspan="1" colspan="1">
                <underline>44.72</underline>
              </td>
              <td rowspan="1" colspan="1">42.24</td>
              <td rowspan="1" colspan="1">
                <bold>47.82</bold>
              </td>
              <td rowspan="1" colspan="1">44.10</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">M</td>
              <td rowspan="1" colspan="1">23.52</td>
              <td rowspan="1" colspan="1">33.77</td>
              <td rowspan="1" colspan="1">33.28</td>
              <td rowspan="1" colspan="1">32.42</td>
              <td rowspan="1" colspan="1">
                <bold>35.17</bold>
              </td>
              <td rowspan="1" colspan="1">
                <underline>34.72</underline>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioASQ 5b</td>
              <td rowspan="1" colspan="1">S</td>
              <td rowspan="1" colspan="1">41.33</td>
              <td rowspan="1" colspan="1">39.33</td>
              <td rowspan="1" colspan="1">41.33</td>
              <td rowspan="1" colspan="1">42.00</td>
              <td rowspan="1" colspan="1">
                <underline>44.00</underline>
              </td>
              <td rowspan="1" colspan="1">
                <bold>46.00</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">L</td>
              <td rowspan="1" colspan="1">
                <underline>56.67</underline>
              </td>
              <td rowspan="1" colspan="1">52.67</td>
              <td rowspan="1" colspan="1">55.33</td>
              <td rowspan="1" colspan="1">54.67</td>
              <td rowspan="1" colspan="1">
                <underline>56.67</underline>
              </td>
              <td rowspan="1" colspan="1">
                <bold>60.00</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">M</td>
              <td rowspan="1" colspan="1">47.24</td>
              <td rowspan="1" colspan="1">44.27</td>
              <td rowspan="1" colspan="1">46.73</td>
              <td rowspan="1" colspan="1">46.93</td>
              <td rowspan="1" colspan="1">
                <underline>49.38</underline>
              </td>
              <td rowspan="1" colspan="1">
                <bold>51.64</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioASQ 6b</td>
              <td rowspan="1" colspan="1">S</td>
              <td rowspan="1" colspan="1">24.22</td>
              <td rowspan="1" colspan="1">33.54</td>
              <td rowspan="1" colspan="1">
                <bold>43.48</bold>
              </td>
              <td rowspan="1" colspan="1">41.61</td>
              <td rowspan="1" colspan="1">40.37</td>
              <td rowspan="1" colspan="1">
                <underline>42.86</underline>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">L</td>
              <td rowspan="1" colspan="1">37.89</td>
              <td rowspan="1" colspan="1">51.55</td>
              <td rowspan="1" colspan="1">55.90</td>
              <td rowspan="1" colspan="1">55.28</td>
              <td rowspan="1" colspan="1">
                <bold>57.77</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>57.77</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">M</td>
              <td rowspan="1" colspan="1">27.84</td>
              <td rowspan="1" colspan="1">40.88</td>
              <td rowspan="1" colspan="1">
                <underline>48.11</underline>
              </td>
              <td rowspan="1" colspan="1">47.02</td>
              <td rowspan="1" colspan="1">47.48</td>
              <td rowspan="1" colspan="1">
                <bold>48.43</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn5">
            <p><italic>Notes:</italic> Strict Accuracy (S), Lenient Accuracy (L) and Mean Reciprocal Rank (M) scores on each dataset are reported. The best scores are in bold, and the second best scores are underlined. The best BioASQ 4b/5b/6b scores were obtained from the BioASQ leaderboard (<ext-link ext-link-type="uri" xlink:href="http://participants-area.bioasq.org">http://participants-area.bioasq.org</ext-link>).</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
  </sec>
  <sec>
    <title>5 Discussion</title>
    <p>We used additional corpora of different sizes for pre-training and investigated their effect on performance. For BioBERT v1.0 (+ PubMed), we set the number of pre-training steps to 200K and varied the size of the PubMed corpus. <xref ref-type="fig" rid="btz682-F2">Figure 2(a)</xref> shows that the performance of BioBERT v1.0 (+ PubMed) on three NER datasets (NCBI Disease, BC2GM, BC4CHEMD) changes in relation to the size of the PubMed corpus. Pre-training on 1 billion words is quite effective, and the performance on each dataset mostly improves until 4.5 billion words. We also saved the pre-trained weights from BioBERT v1.0 (+ PubMed) at different pre-training steps to measure how the number of pre-training steps affects its performance on fine-tuning tasks. <xref ref-type="fig" rid="btz682-F2">Figure 2(b)</xref> shows the performance changes of BioBERT v1.0 (+ PubMed) on the same three NER datasets in relation to the number of pre-training steps. The results clearly show that the performance on each dataset improves as the number of pre-training steps increases. Finally, <xref ref-type="fig" rid="btz682-F2">Figure 2(c)</xref> shows the absolute performance improvements of BioBERT v1.0 (+ PubMed + PMC) over BERT on all 15 datasets. F1 scores were used for NER/RE, and MRR scores were used for QA. BioBERT significantly improves performance on most of the datasets.
</p>
    <fig id="btz682-F2" orientation="portrait" position="float">
      <label>Fig. 2.</label>
      <caption>
        <p>(<bold>a</bold>) Effects of varying the size of the PubMed corpus for pre-training. (<bold>b</bold>) NER performance of BioBERT at different checkpoints. (<bold>c</bold>) Performance improvement of BioBERT v1.0 (+ PubMed + PMC) over BERT</p>
      </caption>
      <graphic xlink:href="btz682f2"/>
    </fig>
    <p>As shown in <xref rid="btz682-T9" ref-type="table">Table 9</xref>, we sampled predictions from BERT and BioBERT v1.1 (+PubMed) to see the effect of pre-training on downstream tasks. BioBERT can recognize biomedical named entities that BERT cannot and can find the exact boundaries of named entities. While BERT often gives incorrect answers to simple biomedical questions, BioBERT provides correct answers to such questions. Also, BioBERT can provide longer named entities as answers.
</p>
    <table-wrap id="btz682-T9" orientation="portrait" position="float">
      <label>Table 9.</label>
      <caption>
        <p>Prediction samples from BERT and BioBERT on NER and QA datasets</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="left" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th rowspan="1" colspan="1">Task</th>
            <th align="left" rowspan="1" colspan="1">Dataset</th>
            <th align="left" rowspan="1" colspan="1">Model</th>
            <th align="left" rowspan="1" colspan="1">Sample</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">NER</td>
            <td rowspan="1" colspan="1">NCBI disease</td>
            <td rowspan="1" colspan="1">BERT</td>
            <td rowspan="1" colspan="1">WT1 missense mutations, associated with male pseudohermaphroditism in <bold>Denys–Drash syndrome</bold>, fail to …</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">BioBERT</td>
            <td rowspan="1" colspan="1">WT1 missense mutations, associated with <bold>male pseudohermaphroditism</bold> in <bold>Denys–Drash syndrome</bold>, fail to …</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">BC5CDR (Drug/Chem.)</td>
            <td rowspan="1" colspan="1">BERT</td>
            <td rowspan="1" colspan="1">… a case of oral <bold>penicillin anaphylaxis</bold> is described, and the terminology …</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">BioBERT</td>
            <td rowspan="1" colspan="1">… a case of oral <bold>penicillin</bold> anaphylaxis is described, and the terminology …</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">BC2GM</td>
            <td rowspan="1" colspan="1">BERT</td>
            <td rowspan="1" colspan="1">Like the DMA, but unlike all other mammalian class II A genes, the zebrafish gene codes for two cysteine residues …</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">BioBERT</td>
            <td rowspan="1" colspan="1">Like the <bold>DMA</bold>, but unlike all other mammalian class II A genes, the zebrafish gene codes for two cysteine residues …</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">QA</td>
            <td rowspan="1" colspan="1">BioASQ 6b-factoid</td>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">Q: Which type of urinary incontinence is diagnosed with the Q tip test?</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">BERT</td>
            <td rowspan="1" colspan="1">A total of 25 women affected by clinical <bold>stress</bold> urinary incontinence (SUI) were enrolled. After undergoing (…) Q-tip test, …</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">BioBERT</td>
            <td rowspan="1" colspan="1">A total of 25 women affected by clinical <bold>stress urinary incontinence</bold> (SUI) were enrolled. After undergoing (…) Q-tip test, …</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">Q: Which bacteria causes erythrasma?</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">BERT</td>
            <td rowspan="1" colspan="1"><bold>Corynebacterium</bold> minutissimum is the bacteria that leads to cutaneous eruptions of erythrasma …</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">BioBERT</td>
            <td rowspan="1" colspan="1"><bold>Corynebacterium minutissimum</bold> is the bacteria that leads to cutaneous eruptions of erythrasma …</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn id="tblfn6">
          <p><italic>Note:</italic> Predicted named entities for NER and predicted answers for QA are in bold.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
  </sec>
  <sec>
    <title>6 Conclusion</title>
    <p>In this article, we introduced BioBERT, which is a pre-trained language representation model for biomedical text mining. We showed that pre-training BERT on biomedical corpora is crucial in applying it to the biomedical domain. Requiring minimal task-specific architectural modification, BioBERT outperforms previous models on biomedical text mining tasks such as NER, RE and QA.</p>
    <p>The pre-released version of BioBERT (January 2019) has already been shown to be very effective in many biomedical text mining tasks such as NER for clinical notes (<xref rid="btz682-B1" ref-type="bibr">Alsentzer <italic>et al.</italic>, 2019</xref>), human phenotype-gene RE (<xref rid="btz682-B27" ref-type="bibr">Sousa <italic>et al.</italic>, 2019</xref>) and clinical temporal RE (<xref rid="btz682-B14" ref-type="bibr">Lin <italic>et al.</italic>, 2019</xref>). The following updated versions of BioBERT will be available to the bioNLP community: (i) BioBERT<sub><monospace>BASE</monospace></sub> and BioBERT<sub><monospace>LARGE</monospace></sub> trained on only PubMed abstracts without initialization from the existing BERT model and (ii) BioBERT<sub><monospace>BASE</monospace></sub> and BioBERT<sub><monospace>LARGE</monospace></sub> trained on domain-specific vocabulary based on WordPiece.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This research was supported by the National Research Foundation of Korea(NRF) funded by the Korea government (NRF-2017R1A2A1A17069645, NRF-2017M3C4A7065887, NRF-2014M3C9A3063541).</p>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btz682-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Alsentzer</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Publicly available clinical bert embeddings</article-title>. In: <source>Proceedings of the 2nd Clinical Natural Language Processing Workshop, Minneapolis, MN, USA</source>. pp. <fpage>72</fpage>–<lpage>78</lpage>. Association for Computational Linguistics. <ext-link ext-link-type="uri" xlink:href="https://www.aclweb.org/anthology/W19-1909">https://www.aclweb.org/anthology/W19-1909</ext-link>.</mixed-citation>
    </ref>
    <ref id="btz682-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bhasuran</surname><given-names>B.</given-names></name>, <name name-style="western"><surname>Natarajan</surname><given-names>J.</given-names></name></person-group> (<year>2018</year>) 
<article-title>Automatic extraction of gene-disease associations from literature using joint ensemble learning</article-title>. <source>PLoS One</source>, <volume>13</volume>, <fpage>e0200699</fpage>.<pub-id pub-id-type="pmid">30048465</pub-id></mixed-citation>
    </ref>
    <ref id="btz682-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bravo</surname><given-names>À.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Extraction of relations between genes and diseases from text and large-scale data analysis: implications for translational research</article-title>. <source>BMC Bioinformatics</source>, <volume>16</volume>, <fpage>55</fpage>.<pub-id pub-id-type="pmid">25886734</pub-id></mixed-citation>
    </ref>
    <ref id="btz682-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Devlin</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Bert: pre-training of deep bidirectional transformers for language understanding</article-title>. In: <source>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), Minneapolis, MN, USA</source>. pp. <fpage>4171</fpage>–<lpage>4186</lpage>. Association for Computational Linguistics. <ext-link ext-link-type="uri" xlink:href="https://www.aclweb.org/anthology/N19-1423">https://www.aclweb.org/anthology/N19-1423</ext-link>.</mixed-citation>
    </ref>
    <ref id="btz682-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Doğan</surname><given-names>R.I.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>NCBI disease corpus: a resource for disease name recognition and concept normalization</article-title>. <source>J. Biomed. Inform</source>., <volume>47</volume>, <fpage>1</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">24393765</pub-id></mixed-citation>
    </ref>
    <ref id="btz682-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gerner</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Linnaeus: a species name identification system for biomedical literature</article-title>. <source>BMC Bioinformatics</source>, <volume>11</volume>, <fpage>85</fpage>.<pub-id pub-id-type="pmid">20149233</pub-id></mixed-citation>
    </ref>
    <ref id="btz682-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Giorgi</surname><given-names>J.M.</given-names></name>, <name name-style="western"><surname>Bader</surname><given-names>G.D.</given-names></name></person-group> (<year>2018</year>) 
<article-title>Transfer learning for biomedical named entity recognition with neural networks</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>4087</fpage>.<pub-id pub-id-type="pmid">29868832</pub-id></mixed-citation>
    </ref>
    <ref id="btz682-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Habibi</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Deep learning with word embeddings improves biomedical named entity recognition</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>i37</fpage>–<lpage>i48</lpage>.<pub-id pub-id-type="pmid">28881963</pub-id></mixed-citation>
    </ref>
    <ref id="btz682-B9">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Kim</surname><given-names>J.-D.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>) <chapter-title>Introduction to the bio-entity recognition task at JNLPBA</chapter-title> In: <italic>Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications (NLPBA/BioNLP), Geneva, Switzerland</italic> pp. 73–78. COLING. <ext-link ext-link-type="uri" xlink:href="https://www.aclweb.org/anthology/W04-1213">https://www.aclweb.org/anthology/W04-1213</ext-link>.</mixed-citation>
    </ref>
    <ref id="btz682-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Krallinger</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>The chemdner corpus of chemicals and drugs and its annotation principles</article-title>. <source>J. Cheminform</source>., <volume>7</volume>. </mixed-citation>
    </ref>
    <ref id="btz682-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Krallinger</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Overview of the BioCreative VI chemical-protein interaction track</article-title>. In: <source>Proceedings of the BioCreative VI Workshop, Bethesda, MD, USA</source>, pp. <fpage>141</fpage>–<lpage>146</lpage>. <ext-link ext-link-type="uri" xlink:href="https://academic.oup.com/database/article/doi/10.1093/database/bay073/5055578">https://academic.oup.com/database/article/doi/10.1093/database/bay073/5055578</ext-link>.</mixed-citation>
    </ref>
    <ref id="btz682-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Biocreative V CDR task corpus: a resource for chemical disease relation extraction</article-title>. <source>Database</source>, <volume>2016</volume>.</mixed-citation>
    </ref>
    <ref id="btz682-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lim</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Kang</surname><given-names>J.</given-names></name></person-group> (<year>2018</year>) 
<article-title>Chemical–gene relation extraction using recursive neural network</article-title>. <source>Database</source>, <volume>2018</volume>.</mixed-citation>
    </ref>
    <ref id="btz682-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lin</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>A bert-based universal model for both within-and cross-sentence clinical temporal relation extraction</article-title>. In: <source>Proceedings of the 2nd Clinical Natural Language Processing Workshop, Minneapolis, MN, USA.</source> pp. <fpage>65</fpage>–<lpage>71</lpage>. Association for Computational Linguistics. <ext-link ext-link-type="uri" xlink:href="https://www.aclweb.org/anthology/W19-1908">https://www.aclweb.org/anthology/W19-1908</ext-link>.</mixed-citation>
    </ref>
    <ref id="btz682-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lou</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>A transition-based joint model for disease named entity recognition and normalization</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>2363</fpage>–<lpage>2371</lpage>.<pub-id pub-id-type="pmid">28369171</pub-id></mixed-citation>
    </ref>
    <ref id="btz682-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Luo</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>1381</fpage>–<lpage>1388</lpage>.<pub-id pub-id-type="pmid">29186323</pub-id></mixed-citation>
    </ref>
    <ref id="btz682-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>McCann</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Learned in translation: contextualized word vectors</article-title>. In: Guyon,I. <italic>et al.</italic> (eds.), <source>Advances in Neural Information Processing Systems 30</source>, Curran Associates, Inc., pp. <fpage>6294</fpage>–<lpage>6305</lpage>. <ext-link ext-link-type="uri" xlink:href="http://papers.nips.cc/paper/7209-learned-in-translation-contextualized-word-vectors.pdf">http://papers.nips.cc/paper/7209-learned-in-translation-contextualized-word-vectors.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="btz682-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mikolov</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Distributed representations of words and phrases and their compositionality</article-title>. In: Burges,C.J.C. (eds.), <source>Advances in Neural Information Processing Systems 26</source>, Curran Associates, Inc., pp. <fpage>3111</fpage>–<lpage>3119</lpage>. <ext-link ext-link-type="uri" xlink:href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="btz682-B19">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Mohan</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>D.</given-names></name></person-group> (<year>2019</year>) Medmentions: a large biomedical corpus annotated with UMLS concepts. <italic>arXiv preprint arXiv: 1902.09476</italic>.</mixed-citation>
    </ref>
    <ref id="btz682-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pafilis</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>The species and organisms resources for fast and accurate identification of taxonomic names in text</article-title>. <source>PLoS One</source>, <volume>8</volume>, <fpage>e65390</fpage>.<pub-id pub-id-type="pmid">23823062</pub-id></mixed-citation>
    </ref>
    <ref id="btz682-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pennington</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Glove: Global vectors for word representation</article-title>. In: <source>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Doha, Qatar</source>. pp. <fpage>1532</fpage>–<lpage>1543</lpage>. Association for Computational Linguistics. <ext-link ext-link-type="uri" xlink:href="https://www.aclweb.org/anthology/D14-1162">https://www.aclweb.org/anthology/D14-1162</ext-link>.</mixed-citation>
    </ref>
    <ref id="btz682-B22">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Peters</surname><given-names>M.E.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) Deep contextualized word representations. In: <italic>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), New Orleans, LA</italic> pp. 2227–2237. Association for Computational Linguistics. <ext-link ext-link-type="uri" xlink:href="https://www.aclweb.org/anthology/N18-1202">https://www.aclweb.org/anthology/N18-1202</ext-link>.</mixed-citation>
    </ref>
    <ref id="btz682-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pyysalo</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Distributional semantics resources for biomedical text processing</article-title>. In: <source>Proceedings of the 5th International Symposium on Languages in Biology and Medicine, Tokyo, Japan</source>, pp. <fpage>39</fpage>–<lpage>43</lpage>. <ext-link ext-link-type="uri" xlink:href="https://academic.oup.com/bioinformatics/article/33/14/i37/3953940">https://academic.oup.com/bioinformatics/article/33/14/i37/3953940</ext-link>.</mixed-citation>
    </ref>
    <ref id="btz682-B24">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Rajpurkar</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) Squad: 100,000+ questions for machine comprehension of text. In: <italic>Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Austin, TX</italic> pp. 2383–2392. Association for Computational Linguistics. <ext-link ext-link-type="uri" xlink:href="https://www.aclweb.org/anthology/D16-1264">https://www.aclweb.org/anthology/D16-1264</ext-link>.</mixed-citation>
    </ref>
    <ref id="btz682-B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Sachan</surname><given-names>D.S.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) Effective use of bidirectional language modeling for transfer learning in biomedical named entity recognition. In: Finale,D.-V. <italic>et al.</italic> (eds.), <italic>Proceedings of Machine Learning Research, Palo Alto, CA</italic>, Vol. 85, pp. 383–402. PMLR. <ext-link ext-link-type="uri" xlink:href="http://proceedings.mlr.press/v85/sachan18a.html">http://proceedings.mlr.press/v85/sachan18a.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="btz682-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Smith</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>Overview of biocreative ii gene mention recognition</article-title>. <source>Genome Biol</source>., <volume>9</volume>, <fpage>S2</fpage>.</mixed-citation>
    </ref>
    <ref id="btz682-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sousa</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>A silver standard corpus of human phenotype-gene relations</article-title>. In: <source>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), Minneapolis, MN</source>. pp. <fpage>1487</fpage>–<lpage>1492</lpage>. Association for Computational Linguistics. <ext-link ext-link-type="uri" xlink:href="https://www.aclweb.org/anthology/N19-1152">https://www.aclweb.org/anthology/N19-1152</ext-link>.</mixed-citation>
    </ref>
    <ref id="btz682-B28">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Sung</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) NSML: A machine learning platform that enables you to focus on your models. <italic>arXiv preprint arXiv: 1712.05902</italic>.</mixed-citation>
    </ref>
    <ref id="btz682-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tsatsaronis</surname><given-names>G.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition</article-title>. <source>BMC Bioinformatics</source>, <volume>16</volume>, <fpage>138</fpage>.<pub-id pub-id-type="pmid">25925131</pub-id></mixed-citation>
    </ref>
    <ref id="btz682-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Uzuner</surname><given-names>Ö.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text</article-title>. <source>J. Am. Med. Inform. Assoc</source>., <volume>18</volume>, <fpage>552</fpage>–<lpage>556</lpage>.<pub-id pub-id-type="pmid">21685143</pub-id></mixed-citation>
    </ref>
    <ref id="btz682-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Van Mulligen</surname><given-names>E.M.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>The EU-ADR corpus: annotated drugs, diseases, targets, and their relationships</article-title>. <source>J. Biomed. Inform</source>., <volume>45</volume>, <fpage>879</fpage>–<lpage>884</lpage>.<pub-id pub-id-type="pmid">22554700</pub-id></mixed-citation>
    </ref>
    <ref id="btz682-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vaswani</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Attention is all you need</article-title>. In: Guyon,I. <italic>et al.</italic> (eds.), <source>Advances in Neural Information Processing Systems</source>, pp. <fpage>5998</fpage>–<lpage>6008</lpage>. Curran Associates, Inc. <ext-link ext-link-type="uri" xlink:href="http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf">http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="btz682-B33">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>X.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) Cross-type biomedical named entity recognition with deep multi-task learning. <italic>Bioinformatics</italic>, <bold>35</bold>, 1745–1752.</mixed-citation>
    </ref>
    <ref id="btz682-B34">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Wiese</surname><given-names>G.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) Neural domain adaptation for biomedical question answering. In: <italic>Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017), Vancouver, Canada</italic> pp. 281–289. Association for Computational Linguistics. <ext-link ext-link-type="uri" xlink:href="https://www.aclweb.org/anthology/K17-1029">https://www.aclweb.org/anthology/K17-1029</ext-link>.</mixed-citation>
    </ref>
    <ref id="btz682-B35">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Wu</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) Google’s neural machine translation system: Bridging the gap between human and machine translation. <italic>arXiv preprint arXiv: 1609.08144</italic>.</mixed-citation>
    </ref>
    <ref id="btz682-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Xu</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Document-level attention-based BiLSTM-CRF incorporating disease dictionary for disease named entity recognition</article-title>. <source>Comput. Biol. Med</source>., <volume>108</volume>, <fpage>122</fpage>–<lpage>132</lpage>.<pub-id pub-id-type="pmid">31003175</pub-id></mixed-citation>
    </ref>
    <ref id="btz682-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yoon</surname><given-names>W.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Collabonet: collaboration of deep neural networks for biomedical named entity recognition</article-title>. <source>BMC Bioinformatics</source>, <volume>20</volume>, <fpage>249</fpage>.<pub-id pub-id-type="pmid">31138109</pub-id></mixed-citation>
    </ref>
    <ref id="btz682-B38">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Zhu</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) Clinical concept extraction with contextual word embedding. <italic>NIPS Machine Learning for Health Workshop</italic>
<ext-link ext-link-type="uri" xlink:href="http://par.nsf.gov/biblio/10098080">http://par.nsf.gov/biblio/10098080</ext-link>.</mixed-citation>
    </ref>
  </ref-list>
</back>
