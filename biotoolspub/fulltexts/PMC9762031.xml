<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9762031</article-id>
    <article-id pub-id-type="publisher-id">5102</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-022-05102-1</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MR-KPA: medication recommendation by combining knowledge-enhanced pre-training with a deep adversarial network</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Lin</surname>
          <given-names>Shaofu</given-names>
        </name>
        <address>
          <email>linshaofu@bjut.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Mengzhen</given-names>
        </name>
        <address>
          <email>wangmengzhen@emails.bjut.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shi</surname>
          <given-names>Chengyu</given-names>
        </name>
        <address>
          <email>scy88@emails.bjut.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xu</surname>
          <given-names>Zhe</given-names>
        </name>
        <address>
          <email>xuzhe0539@163.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Lihong</given-names>
        </name>
        <address>
          <email>chenlihong@emails.bjut.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gao</surname>
          <given-names>Qingcai</given-names>
        </name>
        <address>
          <email>gaoqingcai@emails.bjut.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Chen</surname>
          <given-names>Jianhui</given-names>
        </name>
        <address>
          <email>chenjianhui@bjut.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.28703.3e</institution-id><institution-id institution-id-type="ISNI">0000 0000 9040 3743</institution-id><institution>Faculty of Information Technology, </institution><institution>Beijing University of Technology, </institution></institution-wrap>Beijing, China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.28703.3e</institution-id><institution-id institution-id-type="ISNI">0000 0000 9040 3743</institution-id><institution>Beijing International Collaboration Base on Brain Informatics and Wisdom Services, </institution><institution>Beijing University of Technology, </institution></institution-wrap>Beijing, China </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.28703.3e</institution-id><institution-id institution-id-type="ISNI">0000 0000 9040 3743</institution-id><institution>Beijing Key Laboratory of MRI and Brain Informatics, </institution><institution>Beijing University of Technology, </institution></institution-wrap>Beijing, China </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.419897.a</institution-id><institution-id institution-id-type="ISNI">0000 0004 0369 313X</institution-id><institution>Engineering Research Center of Intelligent Perception and Autonomous Control, </institution><institution>Ministry of Education, </institution></institution-wrap>Beijing, China </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="GRID">grid.419897.a</institution-id><institution-id institution-id-type="ISNI">0000 0004 0369 313X</institution-id><institution>Engineering Research Center of Digital Community, </institution><institution>Ministry of Education, </institution></institution-wrap>Beijing, China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>19</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>19</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <elocation-id>552</elocation-id>
    <history>
      <date date-type="received">
        <day>10</day>
        <month>6</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>6</day>
        <month>12</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Medication recommendation based on electronic medical record (EMR) is a research hot spot in smart healthcare. For developing computational medication recommendation methods based on EMR, an important challenge is the lack of a large number of longitudinal EMR data with time correlation. Faced with this challenge, this paper proposes a new EMR-based medication recommendation model called MR-KPA, which combines knowledge-enhanced pre-training with the deep adversarial network to improve medication recommendation from both feature representation and the fine-tuning process. Firstly, a knowledge-enhanced pre-training visit model is proposed to realize domain knowledge-based external feature fusion and pre-training-based internal feature mining for improving the feature representation. Secondly, a medication recommendation model based on the deep adversarial network is developed to optimize the fine-tuning process of pre-training visit model and alleviate over-fitting of model caused by the task gap between pre-training and recommendation.</p>
      </sec>
      <sec>
        <title>Result</title>
        <p id="Par2">The experimental results on EMRs from medical and health institutions in Hainan Province, China show that the proposed MR-KPA model can effectively improve the accuracy of medication recommendation on small-scale longitudinal EMR data compared with existing representative methods.</p>
      </sec>
      <sec>
        <title>Conclusion</title>
        <p id="Par3">The advantages of the proposed MR-KPA are mainly attributed to knowledge enhancement based on ontology embedding, the pre-training visit model and adversarial training. Each of these three optimizations is very effective for improving the capability of medication recommendation on small-scale longitudinal EMR data, and the pre-training visit model has the most significant improvement effect. These three optimizations are also complementary, and their integration makes the proposed MR-KPA model achieve the best recommendation effect.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Medication recommendation</kwd>
      <kwd>Electronic medical record</kwd>
      <kwd>Graph attention network</kwd>
      <kwd>Pre-training model</kwd>
      <kwd>Adversarial training</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>National Key Research and Development Program of China</institution>
        </funding-source>
        <award-id>2020YFB2104402</award-id>
        <award-id>2020YFB2104402</award-id>
        <award-id>2020YFB2104402</award-id>
        <award-id>2020YFB2104402</award-id>
        <award-id>2020YFB2104402</award-id>
        <principal-award-recipient>
          <name>
            <surname>Lin</surname>
            <given-names>Shaofu</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Mengzhen</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>Chengyu</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Zhe</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Jianhui</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Beijing Natural Science Foundation</institution>
        </funding-source>
        <award-id>4222022</award-id>
        <award-id>4222022</award-id>
        <award-id>4222022</award-id>
        <award-id>4222022</award-id>
        <award-id>4222022</award-id>
        <award-id>4222022</award-id>
        <principal-award-recipient>
          <name>
            <surname>Wang</surname>
            <given-names>Mengzhen</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>Chengyu</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Zhe</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Lihong</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>Qingcai</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Jianhui</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par4">Electronic medical records (EMRs) represent a patient’s historical visit sequence, where each sequence contains a series of clinical events (diagnosis, procedure, medication, etc.) for a single admission. More and more attention has been paid to EMR-based auxiliary diagnosis and treatment, such as clinical knowledge question answering [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>], health risk warning [<xref ref-type="bibr" rid="CR3">3</xref>–<xref ref-type="bibr" rid="CR6">6</xref>], auxiliary diagnostic [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>] and electronic prescription recommendation [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR10">10</xref>]. Medication recommendation is an important research direction in EMR-based applications. Given a patient’s current clinical events and history of visits, the goal of the medication recommendation task is to provide a personalized combination of medications appropriate to his or her health status. It is a crucial data mining task for an intelligent healthcare system [<xref ref-type="bibr" rid="CR11">11</xref>] and many important recommendation models have been developed [<xref ref-type="bibr" rid="CR12">12</xref>–<xref ref-type="bibr" rid="CR16">16</xref>].</p>
    <p id="Par5">Existing EMR-based medication recommendation methods are mainly data-driven and adopt machine learning methods, especially deep networks, to model on various clinical event sequences. In order to improve the accuracy of recommendation, related studies mainly adopted longitudinal sequential recommendation methods which integrated patient’s current health conditions and historical visit information to effectively leverage the temporal dependencies among clinical events for medication recommendation [<xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR17">17</xref>]. Recent studies focused on developing novel and complex neural networks to capture deep-level data features, including complete structure information [<xref ref-type="bibr" rid="CR11">11</xref>], drug-drug interactions [<xref ref-type="bibr" rid="CR12">12</xref>], multiple-level importance [<xref ref-type="bibr" rid="CR18">18</xref>], relationships between historical and current diagnoses [<xref ref-type="bibr" rid="CR19">19</xref>], irregular time-series dependencies [<xref ref-type="bibr" rid="CR20">20</xref>], for improving recommendation capabilities.</p>
    <p id="Par6">However, some diseases may require multiple follow-up visits while others do not. Patients may also visit different hospitals each time resulting in incomplete multiple-visit records. So patients’ longitudinal EMR data with multiple visits are relatively few. For example, in the experiment we collected a total data of 151,908 EMRs but only 10,448 EMRs were involved with multiple visits. The longitudinal data only account for 6.9 <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\%$$\end{document}</tex-math><mml:math id="M2"><mml:mo>%</mml:mo></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq1.gif"/></alternatives></inline-formula> of the total data. They are often discontinuous and can lead to information bias in research [<xref ref-type="bibr" rid="CR21">21</xref>]. The lack of longitudinal data has become an important challenge for EMR-based medication recommendation.</p>
    <p id="Par7">Few-shot learning, which use small sample data for effective model training, is a current research hot spot. Related methods are divided into three categories usually, including fine-tuning, data enhancement and migration [<xref ref-type="bibr" rid="CR22">22</xref>]. Data enhancement methods [<xref ref-type="bibr" rid="CR23">23</xref>] usually need high-quality domain knowledge bases and are easy to introduce noise. Migration methods [<xref ref-type="bibr" rid="CR24">24</xref>] need a group of labeled data in the similar fields for transfer learning. Hence, fine-tuning methods [<xref ref-type="bibr" rid="CR25">25</xref>], especially pre-training [<xref ref-type="bibr" rid="CR26">26</xref>], have become the main means for few-shot learning of EMR-based models. At present, EMRs or EHRs pre-training is attracting attentions [<xref ref-type="bibr" rid="CR27">27</xref>–<xref ref-type="bibr" rid="CR29">29</xref>]. However, existing EMRs pre-training methods need a large number of unlabeled data, which have the same source as labeled data, and neglect the optimization of the fine-tuning process. They also only focus disease prediction tasks whose number of classifications is far lower than medication recommendation tasks. Therefore, these existing EMRs pre-training methods cannot be used directly to solve the problem of lacking longitudinal data in EMR-based medication recommendation.</p>
    <p id="Par8">Based on the above observations and our previous study [<xref ref-type="bibr" rid="CR30">30</xref>], this paper proposes a MR-KPA model which combines knowledge-enhanced pre-training with a deep adversarial network to realize medication recommendation based on small-scale longitudinal EMR data. The main contributions can be summarized as follows:<list list-type="bullet"><list-item><p id="Par9">Firstly, a knowledge-enhanced pre-training visit model is proposed to realize domain knowledge-based external feature fusion and pre-training-based internal feature mining for improving medication recommendation on small-scale longitudinal EMR data. Different from existing EMRs pre-training methods, this visit model uses a large number of single-visit EMR data for pre-training, in order to avoid splitting longitudinal EMR data that is already insufficient.</p></list-item><list-item><p id="Par10">Secondly, a medication recommendation model based on the deep adversarial network is developed to apply EMRs pre-training to medication recommendation for the first time. By introducing adversarial training, the fine-tuning process of pre-training visit model can be optimized to alleviate over-fitting of model caused by the task gap between pre-training and recommendation.</p></list-item><list-item><p id="Par11">Finally, a group of experiments have been performed based on real EMR data from medical and health institutions in Hainan Province, China. Experimental results show that the proposed method can effectively improve the accuracy of medication recommendation based on small-scale longitudinal EMR data.</p></list-item></list>The rest of this paper is organized as follows. “Related work” section introduces related work. “<xref rid="Sec3" ref-type="sec">Medical codes and data sets</xref>” section describes medical codes and data sets. “<xref rid="Sec6" ref-type="sec">Method</xref>” section introduces the proposed MR-KPA model. In “<xref rid="Sec11" ref-type="sec">Experiment</xref>” and “<xref rid="Sec16" ref-type="sec">Discussion</xref>” sections, the predictive performance of this model is compared and analyzed with baselines and variants. Finally, “<xref rid="Sec20" ref-type="sec">Conclusion</xref>” section gives the conclusions and future work.</p>
  </sec>
  <sec id="Sec2">
    <title>Related work</title>
    <p id="Par12">Leveraging recommendation algorithms [<xref ref-type="bibr" rid="CR31">31</xref>, <xref ref-type="bibr" rid="CR32">32</xref>]to recommend rational and effective medications in time for patients, as a paramount recommendation task in the health domain, has been widely researched [<xref ref-type="bibr" rid="CR11">11</xref>]. Existing methods are mainly data-driven and depended on large amounts of EMR data.</p>
    <p id="Par13">Early approaches often adopted instance-based methods, which only focused on current health conditions and failed to make full use of historical information. Syed-Abdul et al. [<xref ref-type="bibr" rid="CR33">33</xref>] proposed a smart medication recommendation model for the electronic prescription. In order to reduce the probability of illegal prescription, this smart model adopted the association rule mining technology to find the relationship between two labels for reducing the probability of illegal prescription. Zhang et al. [<xref ref-type="bibr" rid="CR34">34</xref>] proposed the LEAP model to predict combination of medicines by giving patient’s diagnoses. This LEAP model is a variant of sequence-to-sequence model based on content-attention mechanism and, focuses on modeling mappings between instances and tag dependencies.</p>
    <p id="Par14">Obviously, patients’ historical EMR data can help to do medication recommendation. At present, studies on EMR-based medication recommendations mainly adopt longitudinal sequential recommendation methods which recommend medications based on both current health conditions and historical information [<xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR17">17</xref>]. Choi et al. used a two-level neural attention model to detect influential past visits and significant clinical variables within those visits for improved medication recommendation [<xref ref-type="bibr" rid="CR17">17</xref>]. An et al. proposed a relational perception LSTM (R-LSTM) to deal with the relationship between diseases and medications in longitudinal medical records, which can better integrated historical information into medication level patient representation [<xref ref-type="bibr" rid="CR13">13</xref>]. Wang et al. proposed the adversarially regularized model for medication recommendation (ARMR), which built a key-value memory network based on information from historical admissions and carried out multi-hop reading on the memory network to recommend medications [<xref ref-type="bibr" rid="CR12">12</xref>]. An et al. proposed a multilevel selective and interactive network (MeSIN) which fully leveraged the inherent multilevel structure of EHR data to learn a comprehensive patient representation for reasonable medication recommendation [<xref ref-type="bibr" rid="CR11">11</xref>].</p>
    <p id="Par15">Table <xref rid="Tab1" ref-type="table">1</xref> gives a comparison of the above EMRs-based medication recommendation methods. As shown in this table, existing studies on longitudinal sequential medication recommendation mainly focused on developing different deep neural networks to capture deep-level features in EMR data. Such approaches depended on massive longitudinal EMR data. Therefore, the lack of longitudinal EMR data has become an important challenge of EMR-based medication recommendation. At present, medication recommendation based on relatively small-scale longitudinal EMR data is not given enough attention. The studies on few-shot learning of EMRs-based models mainly focused on pre-training of EMRs or EHRs data in disease prediction tasks. Various EMRs or EHRs pre-training tasks are designed to learn feature expression from large-scale unlabeled data through a self-supervised learning method [<xref ref-type="bibr" rid="CR26">26</xref>]. For examples, Rasmy et al. [<xref ref-type="bibr" rid="CR27">27</xref>] proposed Med-BERT, which adapted the BERT framework originally developed for the text domain to the structured EHR domain. Fine-tuning experiments on two clinical databases showed that Med-BERT can benefit disease prediction studies with small local training datasets, reduce data collection expenses, and accelerate the pace of artificial intelligence aided healthcare. Ren et al. proposed [<xref ref-type="bibr" rid="CR28">28</xref>] a novel model RAPT, which stands for representation by Pre-training time-aware Transformer, and devise three pre-training tasks to handle data insufficiency, data incompleteness and short sequence problems. Extensive experimental results for four downstream tasks have shown the effectiveness of the proposed approach. Meng et al. [<xref ref-type="bibr" rid="CR29">29</xref>] presented a temporal deep learning model to perform bidirectional representation learning on EHR sequences with a transformer architecture and the pre-training task of masked language modeling to predict future diagnosis of depression. However, these EMRs pre-training methods cannot be used directly to solve the problem of lacking longitudinal EMR data in EMR-based medication recommendation:<list list-type="bullet"><list-item><p id="Par16">In data, existing EMRs pre-training methods relied on a large number of unlabeled data, which have the same source as labeled data. The existing researches above usually split experimental data and use most of them for pre-training. This method of obtaining pre-training data is not applicable to longitudinal EMR data that is lacking in itself.</p></list-item><list-item><p id="Par17">In the downstream task, existing EMRs pre-training methods mainly aiming at disease prediction, which is usually a binary classification problem. On the contrary, there are often hundreds of classifications in medication recommendation. Therefore, the application of EMRs pre-training in medication recommendation should be studied separately.</p></list-item><list-item><p id="Par18">In the fine-tuning process, existing EMRs pre-training methods focused on pre-training tasks and neglected the optimization of the fine-tuning process. However, the gap between pre-training and downstream tasks can bring the catastrophic forgetting problem [<xref ref-type="bibr" rid="CR35">35</xref>, <xref ref-type="bibr" rid="CR36">36</xref>]. With the increase of the number of fine-tuning iterations, the downstream tasks increasingly focuses on labelled data and leads to over-fitting of model. Therefore, it is necessary to improve the downstream models for optimizing the fine-tuning process of pre-training model.</p></list-item></list><table-wrap id="Tab1"><label>Table 1</label><caption><p>A Comparison of EMRs-based medication recommendation methods</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method/reference</th><th align="left">Classification</th><th align="left">Shallow/deep learning</th><th align="left">Strategy</th><th align="left">Data size</th></tr></thead><tbody><tr><td align="left">Smart Model [<xref ref-type="bibr" rid="CR33">33</xref>]</td><td align="left">Instance-based</td><td align="left">Shallow learning</td><td align="left">MPR<inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{a}$$\end{document}</tex-math><mml:math id="M4"><mml:msup><mml:mrow/><mml:mi>a</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq2.gif"/></alternatives></inline-formula> +CR<inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{b}$$\end{document}</tex-math><mml:math id="M6"><mml:msup><mml:mrow/><mml:mi>b</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq3.gif"/></alternatives></inline-formula></td><td align="left">103,480,000</td></tr><tr><td align="left">LEAP [<xref ref-type="bibr" rid="CR34">34</xref>]</td><td align="left">Instance-based</td><td align="left">Deep learning</td><td align="left">Recurrent Decoder</td><td align="left">50206(Mimic-3), 2415414 (Sutter)</td></tr><tr><td align="left">Retain [<xref ref-type="bibr" rid="CR17">17</xref>]</td><td align="left">Longitudinal sequential</td><td align="left">Deep learning</td><td align="left">RNN<inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{c}$$\end{document}</tex-math><mml:math id="M8"><mml:msup><mml:mrow/><mml:mi>c</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq4.gif"/></alternatives></inline-formula></td><td align="left">14,366,030</td></tr><tr><td align="left">RAHM [<xref ref-type="bibr" rid="CR13">13</xref>]</td><td align="left">Longitudinal sequential</td><td align="left">Deep learning</td><td align="left">R-LSTM<inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{d}$$\end{document}</tex-math><mml:math id="M10"><mml:msup><mml:mrow/><mml:mi>d</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq5.gif"/></alternatives></inline-formula></td><td align="left">/</td></tr><tr><td align="left">ARMR [<xref ref-type="bibr" rid="CR12">12</xref>]</td><td align="left">Longitudinal sequential</td><td align="left">Deep learning</td><td align="left">MedRec<inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{e}$$\end{document}</tex-math><mml:math id="M12"><mml:msup><mml:mrow/><mml:mi>e</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq6.gif"/></alternatives></inline-formula> +GAN</td><td align="left">Over 40,000(Mimic-3)</td></tr><tr><td align="left">MeSIN [<xref ref-type="bibr" rid="CR11">11</xref>]</td><td align="left">Longitudinal sequential</td><td align="left">Deep learning</td><td align="left">InLSTM<inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{f}$$\end{document}</tex-math><mml:math id="M14"><mml:msup><mml:mrow/><mml:mi>f</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq7.gif"/></alternatives></inline-formula> +ASM<inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{g}$$\end{document}</tex-math><mml:math id="M16"><mml:msup><mml:mrow/><mml:mi>g</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq8.gif"/></alternatives></inline-formula> +GSFM<inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{h}$$\end{document}</tex-math><mml:math id="M18"><mml:msup><mml:mrow/><mml:mi>h</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq9.gif"/></alternatives></inline-formula></td><td align="left">11,809(Mimic-3)</td></tr></tbody></table><table-wrap-foot><p><inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{a}$$\end{document}</tex-math><mml:math id="M20"><mml:msup><mml:mrow/><mml:mi>a</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq10.gif"/></alternatives></inline-formula>Mean Prescription Rank</p><p><inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{b}$$\end{document}</tex-math><mml:math id="M22"><mml:msup><mml:mrow/><mml:mi>b</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq11.gif"/></alternatives></inline-formula>Coverage Rate</p><p><inline-formula id="IEq12"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{c}$$\end{document}</tex-math><mml:math id="M24"><mml:msup><mml:mrow/><mml:mi>c</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq12.gif"/></alternatives></inline-formula>Recurrent Neural Networks</p><p><inline-formula id="IEq13"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{d}$$\end{document}</tex-math><mml:math id="M26"><mml:msup><mml:mrow/><mml:mi>d</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq13.gif"/></alternatives></inline-formula>Relation-aware LSTM</p><p><inline-formula id="IEq14"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{e}$$\end{document}</tex-math><mml:math id="M28"><mml:msup><mml:mrow/><mml:mi>e</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq14.gif"/></alternatives></inline-formula>The module contains the encoder and memory network</p><p><inline-formula id="IEq15"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{f}$$\end{document}</tex-math><mml:math id="M30"><mml:msup><mml:mrow/><mml:mi>f</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq15.gif"/></alternatives></inline-formula>Interactive Long-short Term Memory Network</p><p><inline-formula id="IEq16"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{g}$$\end{document}</tex-math><mml:math id="M32"><mml:msup><mml:mrow/><mml:mi>g</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq16.gif"/></alternatives></inline-formula> Attentional Selective Module</p><p><inline-formula id="IEq17"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{h}$$\end{document}</tex-math><mml:math id="M34"><mml:msup><mml:mrow/><mml:mi>h</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq17.gif"/></alternatives></inline-formula>A global selective fusion module</p></table-wrap-foot></table-wrap></p>
    <p id="Par19">In addition, the fusion of knowledge and big data is a recent research hotspot. Integrating formal domain knowledge, such as term ontology [<xref ref-type="bibr" rid="CR37">37</xref>, <xref ref-type="bibr" rid="CR38">38</xref>], knowledge graph (KG) [<xref ref-type="bibr" rid="CR39">39</xref>, <xref ref-type="bibr" rid="CR40">40</xref>] and so on into deep neural networks has become an important approach to improve feature expression in various applications of deep learning, such as finance [<xref ref-type="bibr" rid="CR41">41</xref>] and medicine [<xref ref-type="bibr" rid="CR42">42</xref>]. For EMR-based medication recommendation, fusing domain knowledge to improve feature expression of EMR has also received attention. For an example, Choi et al. represented the medical concept as a combination of its ancestors in the medical ontology using an attention mechanism for enriching the input of EMR-based medication recommendation [<xref ref-type="bibr" rid="CR17">17</xref>]. However, their studies still only depended on longitudinal EMR data. Though medical concepts enriched feature expression of EMR, model training still needed a large number of EMR data. The training datasets in Choi et al.’s study included three data sets, Sutter PAMF, Mimic-III and Sutter heart Failure (HF) cohort, in which the numbers of visit records were 13920759, 19911 and 572551 respectively.</p>
    <p id="Par20">In order to improve robustness and interpretability of the models, knowledge enhanced pre-training models (KEPTMs) are attracting attention. Yang et al. [<xref ref-type="bibr" rid="CR43">43</xref>] categorized existing KEPTMs into three groups: entity enhanced pre-trained models [<xref ref-type="bibr" rid="CR44">44</xref>, <xref ref-type="bibr" rid="CR45">45</xref>], triplet enhanced pre-trained models [<xref ref-type="bibr" rid="CR46">46</xref>, <xref ref-type="bibr" rid="CR47">47</xref>] and other knowledge enhanced pre-trained models [<xref ref-type="bibr" rid="CR48">48</xref>, <xref ref-type="bibr" rid="CR49">49</xref>]. However, all of these KEPTMs were oriented to text corpora. Though Shang et al. [<xref ref-type="bibr" rid="CR16">16</xref>] proposed G-Bert which modified Bert pre-training tasks to realize knowledge-enhanced pre-training on large-scale single-visit EMR data, G-Bert only considered two types of medical codes and pre-training tasks only focused on themselves and their relations of medical codes. Other important information, especially symptoms, and its prediction ability for medication recommendation were not considered in pre-training tasks. Moreover, their researches also neglected the gap between pre-training and downstream tasks, which is particularly serious when labelled data are obviously smaller than unlabeled pre-training data. As stated above, longitudinal EMR data only account for 6.9<inline-formula id="IEq18"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\%$$\end{document}</tex-math><mml:math id="M36"><mml:mo>%</mml:mo></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq18.gif"/></alternatives></inline-formula> of the total data and the remaining 93.1<inline-formula id="IEq19"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\%$$\end{document}</tex-math><mml:math id="M38"><mml:mo>%</mml:mo></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq19.gif"/></alternatives></inline-formula> were single-visit data, which was indeed the case. Therefore, it is necessary to improve the recommendation model for optimizing the fine-tuning process of the single-visit pre-training model.</p>
    <p id="Par21">Based on the above analysis, we propose the MR-KPA model which combines knowledge-enhanced pre-training with a deep adversarial network to improve medication recommendation from both feature expression and recommendation model structure, for realizing medication recommendation based on small-scale longitudinal EMR data. The details are introduced in the following sections.</p>
  </sec>
  <sec id="Sec3">
    <title>Medical codes and data sets</title>
    <sec id="Sec4">
      <title>Medical codes</title>
      <p id="Par22">Medical codes are usually categorized according to a tree-structured classification system for diagnosis and drug. Figure <xref rid="Fig1" ref-type="fig">1</xref> gives tree structures of ICD-10 ontology and NDC ontology. All codes are the lowest leaf nodes.</p>
      <p id="Par23">The left of Fig. <xref rid="Fig1" ref-type="fig">1</xref> is an example of ICD-10 J98.4 which is the ICD-10 code of “other lung diseases” and its sibling node J98.1 is the ICD-10 code of “Pulmonary collapse”. They have a common parent node J98. This means that both these two kinds of diseases belong to “other respiratory diseases” whose ICD-10 is J98.</p>
      <p id="Par24">The right of Fig. <xref rid="Fig1" ref-type="fig">1</xref> is an example of NDC(Chinese National Drug Code). 86900450000011(86,9,00450,00001,1) is the NDC code of “Ceftazidime for Injection”. The codes in line with Chinese national drug coding standards have 14 digits. The first 2 digits “86” are the drug country code and the third digit “9” represents the drug category code. The fourth to eighth “00450” represents the enterprise identifier and the ninth to thirteenth “00001” represents the product identifier. The last digit “1” represents different drugs.<fig id="Fig1"><label>Fig. 1</label><caption><p>Tree structures of ICD-10 and NDC</p></caption><graphic xlink:href="12859_2022_5102_Fig1_HTML" id="MO1"/></fig></p>
    </sec>
    <sec id="Sec5">
      <title>Data sets</title>
      <p id="Par25">In this study, the real EMRs are from medical and health institutions in Hainan Province, China. Six important fields, PATIENT ID, INPATIENT FORM NO, OUTPATIENT DIAG CODE, DRUG STANDARD CODE and CHIEF COMPLAINTS are extracted from the IN SUMMARY DISCHARGE DIAG table, IN SUMMARY DRUG DETAIL table and ADMISSION INFORMATION RECORD table in the electronic medical record system. PATIENT ID records the patient’s unique ID and INPATIENT FORM NO records the unique ID of one visit to hospital. OUTPATIENT DIAG CODE records the ICD-10 codes of diagnosis, DRUG STANDARD CODE records NDC codes of drug and CHIEF COMPLAINTS records the patient’s current symptoms. This study uses word segmentation to divide symptom description sentence into words, and then remove pause words during word segmentation to create the symptom set of each EMR. Table <xref rid="Tab2" ref-type="table">2</xref> gives the data statistics. The single-visit records were used for training the pre-training model and the multiple-visit records were used for training and testing the prediction model. Compared with those data sizes in Table <xref rid="Tab1" ref-type="table">1</xref>, our data set is very small.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Statistics of the data set</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Statistical field</th><th align="left">Single-visit</th><th align="left">Multiple-visit</th></tr></thead><tbody><tr><td align="left">Total number of records</td><td align="left">141,460</td><td align="left">3155</td></tr><tr><td align="left">Number of patients</td><td align="left">141,460</td><td align="left">1390</td></tr><tr><td align="left">Number of diagnosis codes</td><td align="left">1946</td><td align="left">754</td></tr><tr><td align="left">Number of drug codes</td><td align="left">12,993</td><td align="left">1467</td></tr><tr><td align="left">Number of symptoms</td><td align="left">6523</td><td align="left">2016</td></tr><tr><td align="left">Avg number of diagnosis codes</td><td align="left">2.233</td><td align="left">1.400</td></tr><tr><td align="left">Avg number of drug codes</td><td align="left">16.77</td><td align="left">3.943</td></tr><tr><td align="left">Avg number of symptoms</td><td align="left">1.000</td><td align="left">0.774</td></tr><tr><td align="left">Avg number of visit</td><td align="left">1.0</td><td align="left">2.270</td></tr><tr><td align="left">Max number of diagnosis codes</td><td align="left">26</td><td align="left">30</td></tr><tr><td align="left">Max number of drug codes</td><td align="left">345</td><td align="left">69</td></tr><tr><td align="left">Max number of symptoms</td><td align="left">2</td><td align="left">7</td></tr><tr><td align="left">Max number of visit</td><td align="left">1</td><td align="left">8</td></tr></tbody></table></table-wrap></p>
    </sec>
  </sec>
  <sec id="Sec6">
    <title>Method</title>
    <sec id="Sec7">
      <title>An overview</title>
      <p id="Par26">A longitudinal sequential medication recommendation task can be defined as follows:</p>
      <p id="Par27"><inline-formula id="IEq20"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\textit{Definition 1: Longitudinal EMR Data.}$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:mi mathvariant="italic">Definition</mml:mi><mml:mspace width="4pt"/><mml:mn mathvariant="italic">1</mml:mn><mml:mo>:</mml:mo><mml:mspace width="4pt"/><mml:mi mathvariant="italic">Longitudinal EMR</mml:mi><mml:mspace width="4pt"/><mml:mi mathvariant="italic">Data</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq20.gif"/></alternatives></inline-formula> In EMR data, each patient’s records can be represented as a sequence of multivariate observations: <inline-formula id="IEq21"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S^{n}=\left\{ P_1^{(n)},P_2^{(n)},\cdots P_{T^{(n)}}^{(n)} \right\}$$\end{document}</tex-math><mml:math id="M42"><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msubsup><mml:mi>P</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq21.gif"/></alternatives></inline-formula> where n represents the n-th patient and <inline-formula id="IEq22"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$T^{(n)}$$\end{document}</tex-math><mml:math id="M44"><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq22.gif"/></alternatives></inline-formula> is the number of visits of the n-th patient. The EMR record of the t-th visit is described as <inline-formula id="IEq23"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_t^{(n)}=\left\{ d_t^{(n)},m_t^{(n)},s_t^{(n)}\right\}$$\end{document}</tex-math><mml:math id="M46"><mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msubsup><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>m</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq23.gif"/></alternatives></inline-formula> where <inline-formula id="IEq24"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_t^{(n)}$$\end{document}</tex-math><mml:math id="M48"><mml:msubsup><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq24.gif"/></alternatives></inline-formula> is a collection of diagnostic codes for ICD-10, <inline-formula id="IEq25"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m_t^{(n)}$$\end{document}</tex-math><mml:math id="M50"><mml:msubsup><mml:mi>m</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq25.gif"/></alternatives></inline-formula> is a collection of drug codes for National Drug Codes (NDC), <inline-formula id="IEq26"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$s_t^{(n)}$$\end{document}</tex-math><mml:math id="M52"><mml:msubsup><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq26.gif"/></alternatives></inline-formula> is the collection of self-reported symptoms named as SYM, such as “fever”.</p>
      <p id="Par28"><inline-formula id="IEq27"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\textit{Definition 2: Longitudinal Sequential Medication Recommendation Task.}$$\end{document}</tex-math><mml:math id="M54"><mml:mrow><mml:mi mathvariant="italic">Definition</mml:mi><mml:mspace width="4pt"/><mml:mn mathvariant="italic">2</mml:mn><mml:mo>:</mml:mo><mml:mspace width="4pt"/><mml:mi mathvariant="italic">Longitudinal Sequential</mml:mi><mml:mspace width="4pt"/><mml:mi mathvariant="italic">Medication Recommendation</mml:mi><mml:mspace width="4pt"/><mml:mi mathvariant="italic">Task</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq27.gif"/></alternatives></inline-formula> Given the n-th patient’s history EMR records <inline-formula id="IEq28"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S_{1:t-1}^{(n)}=\left\{ P_1^{(n)},P_2^{(n)},\cdots P_{t-1}^{(n)} \right\}$$\end{document}</tex-math><mml:math id="M56"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msubsup><mml:mi>P</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq28.gif"/></alternatives></inline-formula>, diagnostic codes <inline-formula id="IEq29"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_t^{(n)}$$\end{document}</tex-math><mml:math id="M58"><mml:msubsup><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq29.gif"/></alternatives></inline-formula>, drug codes <inline-formula id="IEq30"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m_t^{(n)}$$\end{document}</tex-math><mml:math id="M60"><mml:msubsup><mml:mi>m</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq30.gif"/></alternatives></inline-formula> and symptoms <inline-formula id="IEq31"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$s_t^{(n)}$$\end{document}</tex-math><mml:math id="M62"><mml:msubsup><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq31.gif"/></alternatives></inline-formula> at the t-th visit, we want to recommend the drugs at the t-th visit by generating multi-label output <inline-formula id="IEq32"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{y_t}\in \left\{ 0,1\right\} ^{ML}$$\end{document}</tex-math><mml:math id="M64"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:msup><mml:mfenced close="}" open="{"><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mfenced><mml:mrow><mml:mi mathvariant="italic">ML</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq32.gif"/></alternatives></inline-formula>which ML represents the number of drug codes. That is to say, the output of the medication recommendation is a list of appropriate drugs. And the recommendation problem is transformed to a multi-label classification problem.</p>
      <p id="Par29">This study proposed a MR-KPA model to realize this task based on small-scale data. On the one hand, the proposed model adopts a knowledge-enhanced pre-training. A large number of single-visit EMR data is used as the pre-training data for avoiding segment limited longitudinal EMR data. The classification knowledge of diagnostic and drug codes was encoded as external domain features and then fused into EMR embeddings. On the other hand, this model integrated adversarial training into multi-layer perceptron (MLP) to avoid the over-fitting of model during the fine-tuning process.</p>
      <p id="Par30">The whole framework of MR-KPA is described in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. It includes three modules: input representation, pre-training and prediction. The input representation module transforms each EMR record into the diagnosis code embedding, the drug code embedding and the symptom embedding. Based on these three types of embeddings, the pre-training module creates a pre-training visit model by performing two types of pre-training tasks. Finally, the prediction module fine-tunes the pre-training visit model and obtains the predicted drug code based on patient’s multiple-visit records. The details will be described in the following subsections.<fig id="Fig2"><label>Fig. 2</label><caption><p>The whole framework of MR-KPA. It includes three modules: the input representation, pre-training and prediction</p></caption><graphic xlink:href="12859_2022_5102_Fig2_HTML" id="MO2"/></fig></p>
    </sec>
    <sec id="Sec8">
      <title>Input representation</title>
      <p id="Par31">The input representation module transforms each EMR into a group of multi-dimensional embeddings as the input of the subsequent module. As shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>, multiple-visit records are inputted into this module. Each record includes columns SUBJECT ID, HADM ID, ICD-10, NDC, and SYM, which represent the patient ID, hospital ID, diagnostic code, drug code, and symptom participle respectively. They are transformed into two ontology embeddings and one dictionary embedding.</p>
      <p id="Par32">For the EMR of n-th patient at t-th visit <inline-formula id="IEq33"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_t^{(n)}=\left\{ d_t^{(n)},m_t^{(n)},s_t^{(n)}\right\}$$\end{document}</tex-math><mml:math id="M66"><mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msubsup><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>m</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq33.gif"/></alternatives></inline-formula>, its input embedding can be obtained as follows.</p>
      <p id="Par33"><inline-formula id="IEq34"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\textit{Ontology embedding.}$$\end{document}</tex-math><mml:math id="M68"><mml:mrow><mml:mi mathvariant="italic">Ontology embedding</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq34.gif"/></alternatives></inline-formula> Ontology embedding is adopted to realize domain knowledge-based external feature fusion. Two types of code ontology embeddings are constructed from ICD-10 ontology <inline-formula id="IEq35"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O_{d}$$\end{document}</tex-math><mml:math id="M70"><mml:msub><mml:mi>O</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq35.gif"/></alternatives></inline-formula> and NDC ontology <inline-formula id="IEq36"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O_m$$\end{document}</tex-math><mml:math id="M72"><mml:msub><mml:mi>O</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq36.gif"/></alternatives></inline-formula>. Because medical codes in raw EMR data are leaf nodes in code ontology trees, code ontology embedding can be obtained by using graph attention network (GAT) [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR13">13</xref>]. It can encode the classification knowledge in diagnostic and drug code trees as external domain features. For each medical code <inline-formula id="IEq37"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c_*\in d_t^{(n)} \cup m_t^{(n)}$$\end{document}</tex-math><mml:math id="M74"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∪</mml:mo><mml:msubsup><mml:mi>m</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq37.gif"/></alternatives></inline-formula> is the embedding dimension, and then the procedure is performed to obtain its ontology embedding as follows:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} o_{c_*}=g(c_*,pa(c_* ),H_e)=\parallel _{k=1}^{k}\sigma \left( \sum _{j\in N_{c_*}}a_{c_*,j}^k W^k h_j\right) \end{aligned}$$\end{document}</tex-math><mml:math id="M76" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo stretchy="false">‖</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mi>σ</mml:mi><mml:mfenced close=")" open="("><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub></mml:msub></mml:mrow></mml:munder><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:msup><mml:mi>W</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq38"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$*\in \left\{ d,m\right\}$$\end{document}</tex-math><mml:math id="M78"><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq38.gif"/></alternatives></inline-formula>, <inline-formula id="IEq39"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N_{c_*}=\left\{ \left\{ c_*\right\} \cup \left\{ pa(c_* )\right\} \right\}$$\end{document}</tex-math><mml:math id="M80"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:mfenced close="}" open="{"><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub></mml:mfenced><mml:mo>∪</mml:mo><mml:mfenced close="}" open="{"><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mfenced></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq39.gif"/></alternatives></inline-formula> are the parent nodes of <inline-formula id="IEq40"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c_*$$\end{document}</tex-math><mml:math id="M82"><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq40.gif"/></alternatives></inline-formula> and itself, <inline-formula id="IEq41"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\parallel$$\end{document}</tex-math><mml:math id="M84"><mml:mo stretchy="false">‖</mml:mo></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq41.gif"/></alternatives></inline-formula> represents concatenation which enables the multi-head attention mechanism, <inline-formula id="IEq42"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M86"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq42.gif"/></alternatives></inline-formula> is a nonlinear activation function, <inline-formula id="IEq43"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W^k \in {\mathbb {R}}^{m\times d}$$\end{document}</tex-math><mml:math id="M88"><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq43.gif"/></alternatives></inline-formula> is the weight matrix for input transformation, and <inline-formula id="IEq44"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a_{c_*,j}^k$$\end{document}</tex-math><mml:math id="M90"><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq44.gif"/></alternatives></inline-formula> is the corresponding k-th normalized attention coefficient.</p>
      <p id="Par34"><inline-formula id="IEq45"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\textit{Dictionary embedding.}$$\end{document}</tex-math><mml:math id="M92"><mml:mrow><mml:mi mathvariant="italic">Dictionary embedding</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq45.gif"/></alternatives></inline-formula> Dictionary embedding is constructed from a symptom dictionary <inline-formula id="IEq46"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_s$$\end{document}</tex-math><mml:math id="M94"><mml:msub><mml:mi>D</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq46.gif"/></alternatives></inline-formula>, which contains all symptoms in EMR data. For each symptom <inline-formula id="IEq47"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$s_i\in s_t^{(n)},$$\end{document}</tex-math><mml:math id="M96"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq47.gif"/></alternatives></inline-formula> its dictionary embedding <inline-formula id="IEq48"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{s_i}$$\end{document}</tex-math><mml:math id="M98"><mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq48.gif"/></alternatives></inline-formula> is just its index value in <inline-formula id="IEq49"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_s$$\end{document}</tex-math><mml:math id="M100"><mml:msub><mml:mi>D</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq49.gif"/></alternatives></inline-formula>.<fig id="Fig3"><label>Fig. 3</label><caption><p>The framework of Input Representation. Both diagnose embedding and medicine embedding adopt ontology embeddings based on code trees. Symptom embedding adopts the dictionary embeddings</p></caption><graphic xlink:href="12859_2022_5102_Fig3_HTML" id="MO4"/></fig></p>
    </sec>
    <sec id="Sec9">
      <title>Pre-training</title>
      <p id="Par35">The pre-training module creates a pre-training visit model based on the input embedding transformed from single-visit records of EMR. By pre-training, a large number of single visit data are effectively used to mine the richer internal features of EMR.</p>
      <p id="Par36">Before pre-training, a multi-layer Transformer architecture [<xref ref-type="bibr" rid="CR50">50</xref>] is adopted to derive visit embedding from two ontology embedding and one dictionary embedding of each EMR data. For <inline-formula id="IEq50"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_t^{(n)}$$\end{document}</tex-math><mml:math id="M102"><mml:msubsup><mml:mi>P</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq50.gif"/></alternatives></inline-formula>, three types of visit embedding can be obtained as follows:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} v_d^t= &amp; {} Transformer\left( \left\{ [CLS]\right\} \cup \left\{ o_{d_i}\mid d_i\in d_t^{(n)}\right\} \right) \end{aligned}$$\end{document}</tex-math><mml:math id="M104" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mfenced close=")" open="("><mml:mfenced close="}" open="{"><mml:mo stretchy="false">[</mml:mo><mml:mi>C</mml:mi><mml:mi>L</mml:mi><mml:mi>S</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mfenced><mml:mo>∪</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mi>o</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfenced></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} v_m^t= &amp; {} Transformer\left( \left\{ [CLS]\right\} \cup \left\{ o_{m_i}\mid m_i\in m_t^{(n)}\right\} \right) \end{aligned}$$\end{document}</tex-math><mml:math id="M106" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mfenced close=")" open="("><mml:mfenced close="}" open="{"><mml:mo stretchy="false">[</mml:mo><mml:mi>C</mml:mi><mml:mi>L</mml:mi><mml:mi>S</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mfenced><mml:mo>∪</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mi>o</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>m</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfenced></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} v_s^t= &amp; {} Transformer\left( \left\{ [CLS]\right\} \cup \left\{ d_{s_i}\mid s_i\in s_t^{(n)}\right\} \right) \end{aligned}$$\end{document}</tex-math><mml:math id="M108" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mfenced close=")" open="("><mml:mfenced close="}" open="{"><mml:mo stretchy="false">[</mml:mo><mml:mi>C</mml:mi><mml:mi>L</mml:mi><mml:mi>S</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mfenced><mml:mo>∪</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfenced></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq51"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_d^t$$\end{document}</tex-math><mml:math id="M110"><mml:msubsup><mml:mi>v</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq51.gif"/></alternatives></inline-formula> is diagnostic visit embedding, <inline-formula id="IEq52"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_m^t$$\end{document}</tex-math><mml:math id="M112"><mml:msubsup><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>t</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq52.gif"/></alternatives></inline-formula> is drug visit embedding, <inline-formula id="IEq53"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_s^t$$\end{document}</tex-math><mml:math id="M114"><mml:msubsup><mml:mi>v</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq53.gif"/></alternatives></inline-formula> is symptom visit embedding, and [CLS] is the first tag of each sequence whose final hidden state will be used as an aggregate sequence representation of the classification task for enabling BERT to better handle various downstream tasks. In order to obtain the consistent length of the input token, it is necessary to align the tokens obtained by padding.</p>
      <p id="Par37">This paper conducts the following two kinds of pre-training tasks to make visit embedding absorb enough information about medication recommendation.</p>
      <p id="Par38"><inline-formula id="IEq54"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\textit{Mask EMR Field Task (Mask EF Task).}$$\end{document}</tex-math><mml:math id="M116"><mml:mrow><mml:mi mathvariant="italic">Mask EMR</mml:mi><mml:mspace width="4pt"/><mml:mi mathvariant="italic">Field Task</mml:mi><mml:mspace width="4pt"/><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">Mask EF</mml:mi><mml:mspace width="4pt"/><mml:mi mathvariant="italic">Task</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq54.gif"/></alternatives></inline-formula> This task randomly masks some of the embedding to better represent information about the composition of EMR records. By changing word token masking of sentences [<xref ref-type="bibr" rid="CR51">51</xref>] into field masking of EMR records, the following loss function is calculated:<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \mathrm {L}_{s}\left( v_*,C_*^{(n)}\right) =-logP\left( C_*^{(n)}\mid v_*\right) =-\sum _{c_*\in c_*^{(n)}} logP(c_*\mid v_*)+\sum _{c_*\in (c_*\setminus c_*^{(n)})} logP(c_*\mid v_*) \end{aligned}$$\end{document}</tex-math><mml:math id="M118" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="normal">L</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfenced><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>P</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:munder><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo lspace="0.15em" rspace="0.15em" stretchy="false">\</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq55"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C_*^{(n)}=\left( d_t^{(n)} \cup m_t^{(n)} \cup s_t^{(n)}\right)$$\end{document}</tex-math><mml:math id="M120"><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∪</mml:mo><mml:msubsup><mml:mi>m</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∪</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq55.gif"/></alternatives></inline-formula> is an union set of medical codes and symptoms of n-th patient, <inline-formula id="IEq56"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c_* \in C_*^{(n)}$$\end{document}</tex-math><mml:math id="M122"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq56.gif"/></alternatives></inline-formula> denotes a medical code or symptom involved in the n-th patient and <inline-formula id="IEq57"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c_*\in \left\{ c_*\setminus c_*^{(n)}\right\}$$\end{document}</tex-math><mml:math id="M124"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo lspace="0.15em" rspace="0.15em" stretchy="false">\</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq57.gif"/></alternatives></inline-formula>denotes the medical codes or symptoms not used for the n-th patient, <inline-formula id="IEq58"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$*\in \left\{ d,m,s\right\}$$\end{document}</tex-math><mml:math id="M126"><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq58.gif"/></alternatives></inline-formula>. We minimize the binary cross entropy loss <inline-formula id="IEq59"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_s$$\end{document}</tex-math><mml:math id="M128"><mml:msub><mml:mi>L</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq59.gif"/></alternatives></inline-formula> to make the model have stronger self-prediction ability.</p>
      <p id="Par39"><inline-formula id="IEq60"><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\textit{Correlation Prediction Task (CorP Task).}$$\end{document}</tex-math><mml:math id="M130"><mml:mrow><mml:mi mathvariant="italic">Correlation Prediction</mml:mi><mml:mspace width="4pt"/><mml:mi mathvariant="italic">Task</mml:mi><mml:mspace width="4pt"/><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">CorP Task</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq60.gif"/></alternatives></inline-formula> This task is used to represent information about the correlation among diagnostic codes, drug codes and symptoms. In BERT, the next sentence prediction (NSP) task facilitates the prediction of sentence relations. G-Bert revised the NSP task as the multidirectional prediction task for predicting unknown disease or drug codes of the sequence [<xref ref-type="bibr" rid="CR16">16</xref>]. This paper revises the NSP task [<xref ref-type="bibr" rid="CR52">52</xref>] as the CorP Task. For mutual prediction of diagnostic codes, drug codes and symptoms, the following three loss functions are calculated:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \mathrm {L}_{dm}= &amp; {} -logP\left( C_d^{(n)}\mid v_m\right) -logP\left( C_m^{(n)}\mid v_d\right) \end{aligned}$$\end{document}</tex-math><mml:math id="M132" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="normal">L</mml:mi><mml:mrow><mml:mi mathvariant="italic">dm</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mo>-</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>P</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>C</mml:mi><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mfenced><mml:mo>-</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>P</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>C</mml:mi><mml:mi>m</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \mathrm {L}_{ds}= &amp; {} -logP\left( C_d^{(n)}\mid v_s\right) -logP\left( C_s^{(n)}\mid v_d\right) \end{aligned}$$\end{document}</tex-math><mml:math id="M134" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="normal">L</mml:mi><mml:mrow><mml:mi mathvariant="italic">ds</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mo>-</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>P</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>C</mml:mi><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mfenced><mml:mo>-</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>P</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>C</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \mathrm {L}_{ms}= &amp; {} -logP\left( C_m^{(n)}\mid v_s\right) -logP\left( C_s^{(n)}\mid v_m\right) \end{aligned}$$\end{document}</tex-math><mml:math id="M136" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="normal">L</mml:mi><mml:mrow><mml:mi mathvariant="italic">ms</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mo>-</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>P</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>C</mml:mi><mml:mi>m</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mfenced><mml:mo>-</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>P</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>C</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>Finally, the pre-training optimization objective can simply be the combination of the aforementioned losses:<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \mathrm {L}_{pr}=\mathrm {L}_{s}\left( v_d,C_d^{(n)}\right) +\mathrm {L}_{s}\left( v_m,C_m^{(n)}\right) +\mathrm {L}_{s}\left( v_s,C_s^{(n)}\right) +\mathrm {L}_{dm}+\mathrm {L}_{s}+\mathrm {L}_{ms} \end{aligned}$$\end{document}</tex-math><mml:math id="M138" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="normal">L</mml:mi><mml:mrow><mml:mi mathvariant="italic">pr</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">L</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>v</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>C</mml:mi><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">L</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>v</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>C</mml:mi><mml:mi>m</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">L</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>v</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>C</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">L</mml:mi><mml:mrow><mml:mi mathvariant="italic">dm</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">L</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">L</mml:mi><mml:mrow><mml:mi mathvariant="italic">ms</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec10">
      <title>Prediction</title>
      <p id="Par40">A MLP module with adversarial training is used to achieve the final prediction task. Based on the pre-training model, multi-visit EMR sequences can be transformed to three types of visit embedding sequences. Concatenating the average of previous diagnostic visit embedding, drug visit embedding, and symptom visit embedding before the t-th visit, as well as the diagnostic visit embedding and symptom visit embedding at the t-th visit, the MLP [<xref ref-type="bibr" rid="CR53">53</xref>] can predict the recommended drug codes at the t-th visit as follows:<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} y_t=Sigmoid\left( W\left[ \left( \frac{1}{t-1} \sum _{\tau&lt;t}v_d^{\tau }\right) \parallel \left( \frac{1}{t-1} \sum _{\tau&lt;t}v_s^{\tau }\right) \parallel \left( \frac{1}{t-1} \sum _{\tau &lt;t}v_m^{\tau }\right) \parallel v_d^{\tau } \parallel v_s^{\tau }\right] +b\right) \end{aligned}$$\end{document}</tex-math><mml:math id="M140" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mfenced close=")" open="("><mml:mi>W</mml:mi><mml:mfenced close="]" open="["><mml:mfenced close=")" open="("><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>v</mml:mi><mml:mi>d</mml:mi><mml:mi>τ</mml:mi></mml:msubsup></mml:mfenced><mml:mo stretchy="false">‖</mml:mo><mml:mfenced close=")" open="("><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>v</mml:mi><mml:mi>s</mml:mi><mml:mi>τ</mml:mi></mml:msubsup></mml:mfenced><mml:mo stretchy="false">‖</mml:mo><mml:mfenced close=")" open="("><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>τ</mml:mi></mml:msubsup></mml:mfenced><mml:mo stretchy="false">‖</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mi>d</mml:mi><mml:mi>τ</mml:mi></mml:msubsup><mml:mo stretchy="false">‖</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mi>s</mml:mi><mml:mi>τ</mml:mi></mml:msubsup></mml:mfenced><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq61"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W\in {\mathbb {R}}^{\mid C_m \mid \times 3l}$$\end{document}</tex-math><mml:math id="M142"><mml:mrow><mml:mi>W</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mo>∣</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:mo>×</mml:mo><mml:mn>3</mml:mn><mml:mi>l</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq61.gif"/></alternatives></inline-formula>is a learnable transformation matrix.</p>
      <p id="Par41">Therefore, the loss function can be calculated as follows:<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L_n=-\frac{1}{T-1} \sum _{t=2}^T\left( y_t^T log\hat{(y_t)}+\left( 1-y_t^T\right) log\left( 1-y_t^T\right) \right) \end{aligned}$$\end{document}</tex-math><mml:math id="M144" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>y</mml:mi><mml:mi>t</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mover accent="true"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mfenced close=")" open="("><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>t</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mfenced><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mfenced close=")" open="("><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>t</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mfenced></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>where y is the predicted value sequence and <inline-formula id="IEq62"><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{y}}$$\end{document}</tex-math><mml:math id="M146"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq62.gif"/></alternatives></inline-formula> is the true value sequence. In this formula, t =2 means that the prediction starts from the second visit of the patient. The reason is that this paper focuses on longitudinal sequential medication recommendation which predicts the drugs currently suitable for the patient based on the patient’s historical and current diagnosis and symptom.</p>
      <p id="Par42">In order to avoid the over-fitting of model, this paper integrates the adversarial training FGM into the deep prediction model [<xref ref-type="bibr" rid="CR54">54</xref>]. Adversarial training can not only improve the defense ability of the model against adversarial samples, but also improve the generalization ability of the original samples. For the prediction task, the disturbance <inline-formula id="IEq63"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$r_{adv-d}$$\end{document}</tex-math><mml:math id="M148"><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mo>-</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq63.gif"/></alternatives></inline-formula> and <inline-formula id="IEq64"><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$r_{adv-m}$$\end{document}</tex-math><mml:math id="M150"><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mo>-</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq64.gif"/></alternatives></inline-formula> are added to the diagnostic ontology embedding and the drug ontology embedding respectively, in order to make the model wrong as much as possible and increase the robustness. Referring to [<xref ref-type="bibr" rid="CR54">54</xref>], the disturbance can be calculated as follows:<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \begin{aligned} r_{adv-d}=-\epsilon \frac{ \triangledown _x v_d^t}{\parallel \triangledown _x v_d^t \parallel _2} \\ r_{adv-m}=-\epsilon \frac{\triangledown _x v_m^t}{ \parallel \triangledown _x v_m^t \parallel _2} \end{aligned} \end{aligned}$$\end{document}</tex-math><mml:math id="M152" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mo>-</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mi>ϵ</mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mo>▿</mml:mo><mml:mi>x</mml:mi></mml:msub><mml:msubsup><mml:mi>v</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:msubsup></mml:mrow><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mo>▿</mml:mo><mml:mi>x</mml:mi></mml:msub><mml:msubsup><mml:mi>v</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:msub><mml:mo stretchy="false">‖</mml:mo><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow/><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mo>-</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mi>ϵ</mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mo>▿</mml:mo><mml:mi>x</mml:mi></mml:msub><mml:msubsup><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>t</mml:mi></mml:msubsup></mml:mrow><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mo>▿</mml:mo><mml:mi>x</mml:mi></mml:msub><mml:msubsup><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:msub><mml:mo stretchy="false">‖</mml:mo><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq65"><alternatives><tex-math id="M153">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\epsilon$$\end{document}</tex-math><mml:math id="M154"><mml:mi>ϵ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq65.gif"/></alternatives></inline-formula> is a constant. <inline-formula id="IEq66"><alternatives><tex-math id="M155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$r_{adv-d}$$\end{document}</tex-math><mml:math id="M156"><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mo>-</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq66.gif"/></alternatives></inline-formula> and <inline-formula id="IEq67"><alternatives><tex-math id="M157">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$r_{adv-m}$$\end{document}</tex-math><mml:math id="M158"><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mo>-</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq67.gif"/></alternatives></inline-formula> are normalized values with the gradient of <inline-formula id="IEq68"><alternatives><tex-math id="M159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_d^t$$\end{document}</tex-math><mml:math id="M160"><mml:msubsup><mml:mi>v</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq68.gif"/></alternatives></inline-formula> and <inline-formula id="IEq69"><alternatives><tex-math id="M161">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_m^t$$\end{document}</tex-math><mml:math id="M162"><mml:msubsup><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>t</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq69.gif"/></alternatives></inline-formula>. The drug sequence <inline-formula id="IEq70"><alternatives><tex-math id="M163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_t$$\end{document}</tex-math><mml:math id="M164"><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq70.gif"/></alternatives></inline-formula> is predicted from the disturbed <inline-formula id="IEq71"><alternatives><tex-math id="M165">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_d^{\tau '}$$\end{document}</tex-math><mml:math id="M166"><mml:msubsup><mml:mi>v</mml:mi><mml:mi>d</mml:mi><mml:msup><mml:mi>τ</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq71.gif"/></alternatives></inline-formula> and <inline-formula id="IEq72"><alternatives><tex-math id="M167">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_m^{\tau '}$$\end{document}</tex-math><mml:math id="M168"><mml:msubsup><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:msup><mml:mi>τ</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq72.gif"/></alternatives></inline-formula> which can be combined with the real drug sequence <inline-formula id="IEq73"><alternatives><tex-math id="M169">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{y_t}$$\end{document}</tex-math><mml:math id="M170"><mml:mover accent="true"><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq73.gif"/></alternatives></inline-formula> to construct a loss function. In back propagation, the gradient of counter training is accumulated on the basis of the normal gradient. Then the original values of <inline-formula id="IEq74"><alternatives><tex-math id="M171">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_d^{\tau }$$\end{document}</tex-math><mml:math id="M172"><mml:msubsup><mml:mi>v</mml:mi><mml:mi>d</mml:mi><mml:mi>τ</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq74.gif"/></alternatives></inline-formula> and <inline-formula id="IEq75"><alternatives><tex-math id="M173">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_m^{\tau }$$\end{document}</tex-math><mml:math id="M174"><mml:msubsup><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>τ</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq75.gif"/></alternatives></inline-formula> are restored. Finally, the parameters are updated according to the gradient of accumulated adversarial training. The loss function after adversarial training is defined in the same way as Eq. (<xref rid="Equ11" ref-type="">11</xref>) where <inline-formula id="IEq76"><alternatives><tex-math id="M175">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_t$$\end{document}</tex-math><mml:math id="M176"><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq76.gif"/></alternatives></inline-formula> is calculated from the disturbed diagnostic ontology embedding and drug ontology embedding on the basis of Eq. (<xref rid="Equ13" ref-type="">13</xref>) as follows:<disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="M177">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \begin{aligned} y_t=Sigmoid\left( W\left[ \left( \frac{1}{t-1} \sum _{\tau&lt;t}\left( v_d^{\tau }+r_{adv-d}\right) \right) \parallel \left( \frac{1}{t-1} \sum _{\tau&lt;t}v_s^{\tau }\right) \parallel \right. \right. \\\left. \left. \left( \frac{1}{t-1} \sum _{\tau &lt;t}\left( v_m^{\tau }+r_{adv-m}\right) \right) \parallel \left( v_d^{\tau }+r_{adv-d}\right) \parallel v_s^{\tau }\right] +b\right) \end{aligned} \end{aligned}$$\end{document}</tex-math><mml:math id="M178" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mfenced open="("><mml:mi>W</mml:mi><mml:mfenced open="["><mml:mfenced close=")" open="("><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>v</mml:mi><mml:mi>d</mml:mi><mml:mi>τ</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mo>-</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mfenced></mml:mfenced><mml:mo stretchy="false">‖</mml:mo><mml:mfenced close=")" open="("><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>v</mml:mi><mml:mi>s</mml:mi><mml:mi>τ</mml:mi></mml:msubsup></mml:mfenced><mml:mo stretchy="false">‖</mml:mo></mml:mfenced></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow/><mml:mfenced close=")"><mml:mfenced close="]"><mml:mfenced close=")" open="("><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>τ</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mo>-</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mfenced></mml:mfenced><mml:mo stretchy="false">‖</mml:mo><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>v</mml:mi><mml:mi>d</mml:mi><mml:mi>τ</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mo>-</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mfenced><mml:mo stretchy="false">‖</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mi>s</mml:mi><mml:mi>τ</mml:mi></mml:msubsup></mml:mfenced><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
  </sec>
  <sec id="Sec11">
    <title>Experiment</title>
    <sec id="Sec12">
      <title>Baselines</title>
      <p id="Par43">We compared the proposed MR-KPA with the following baseline methods. All methods were developed under Pytorch and implemented on Nvidia Quadro P2000:<list list-type="bullet"><list-item><p id="Par44">Learn to Prescribe (LEAP) [<xref ref-type="bibr" rid="CR34">34</xref>]: LEAP is an example based model that aims to prescribe effective and safe drug combinations for patients with recurrent diseases. It uses cyclic decoders to model labels and captures label instance maps using content-based attention in order to decompose treatment recommendations into a continuous decision-making process while automatically determining the appropriate drug quantity. The epoch of this model is set as 30.</p></list-item><list-item><p id="Par45">Logistic Regression (LR) [<xref ref-type="bibr" rid="CR55">55</xref>]: This study adopts a logistic regression model with L1/L2 regularization as the baseline method. We represented sequential multiple medical codes by summing up multiple hot vectors per visit.</p></list-item><list-item><p id="Par46">Reverse Time Attention Model (RETAIN) [<xref ref-type="bibr" rid="CR17">17</xref>]: RETAIN is a medication recommendation model based on a two-stage neuro attention that examines past influential visits and important clinical variables such as critical diagnoses within those visits. In this study, the epoch of the model is set to 30 which has the best performance by experiment. When the model predicts that the probability of a drug being recommended is greater than 30<inline-formula id="IEq77"><alternatives><tex-math id="M179">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\%$$\end{document}</tex-math><mml:math id="M180"><mml:mo>%</mml:mo></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq77.gif"/></alternatives></inline-formula>, the drug is recommended.</p></list-item></list></p>
    </sec>
    <sec id="Sec13">
      <title>Metrics</title>
      <p id="Par47">This paper uses the Jaccard Similarity Coefficient [<xref ref-type="bibr" rid="CR56">56</xref>] and average F1 [<xref ref-type="bibr" rid="CR57">57</xref>] to measure experimental results. They can be calculated as follows:<disp-formula id="Equ14"><label>14</label><alternatives><tex-math id="M181">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Jaccard=\frac{1}{\sum _k^N \sum _t^{T_k}1} \sum _k^N \sum _t^{T_k} \frac{\mid Y_t^{(k)} \cap {\hat{Y}}_t^{(k)}\mid }{\mid Y_t^{(k)} \cup {\hat{Y}}_t^{(k)}\mid } \end{aligned}$$\end{document}</tex-math><mml:math id="M182" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>J</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mi>k</mml:mi><mml:mi>N</mml:mi></mml:msubsup><mml:msubsup><mml:mo>∑</mml:mo><mml:mi>t</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msubsup><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mi>k</mml:mi><mml:mi>N</mml:mi></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mi>t</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:munderover><mml:mfrac><mml:mrow><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>Y</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∩</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo></mml:mrow><mml:mrow><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>Y</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∪</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ14.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq78"><alternatives><tex-math id="M183">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{Y}}_t^{(k)}$$\end{document}</tex-math><mml:math id="M184"><mml:msubsup><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq78.gif"/></alternatives></inline-formula> is the predicted set and <inline-formula id="IEq79"><alternatives><tex-math id="M185">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Y_t^{(k)}$$\end{document}</tex-math><mml:math id="M186"><mml:msubsup><mml:mi>Y</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq79.gif"/></alternatives></inline-formula> is the ground truth set.<disp-formula id="Equ15"><label>15</label><alternatives><tex-math id="M187">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} F1&amp;=\frac{1}{\sum _k^N \sum _t^{T_k}1} \sum _k^N \sum _t^{T_k} \frac{2 \times P_t^{(k)} \times R_t^{(k)}}{P_t{(k)}+R_t^{(k)}} \end{aligned}$$\end{document}</tex-math><mml:math id="M188" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mi>k</mml:mi><mml:mi>N</mml:mi></mml:msubsup><mml:msubsup><mml:mo>∑</mml:mo><mml:mi>t</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msubsup><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mi>k</mml:mi><mml:mi>N</mml:mi></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mi>t</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:munderover><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>×</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ15.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ16"><label>16</label><alternatives><tex-math id="M189">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} P_t^{(k)}&amp;=\frac{\mid Y_t^{(k)} \cap {\hat{Y}}_t^{(k)}\mid }{\mid Y_t^{(k)} \mid }, R_t^{(k)}=\frac{\mid Y_t^{(k)} \cap {\hat{Y}}_t^{(k)}\mid }{\mid {\hat{Y}}_t^{(k)} \mid } \end{aligned}$$\end{document}</tex-math><mml:math id="M190" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi>P</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>Y</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∩</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo></mml:mrow><mml:mrow><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>Y</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>Y</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∩</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo></mml:mrow><mml:mrow><mml:mo>∣</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5102_Article_Equ16.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq80"><alternatives><tex-math id="M191">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_t^{(k)}$$\end{document}</tex-math><mml:math id="M192"><mml:msubsup><mml:mi>P</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq80.gif"/></alternatives></inline-formula> is the precision rate, <inline-formula id="IEq81"><alternatives><tex-math id="M193">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$R_t^{(k)}$$\end{document}</tex-math><mml:math id="M194"><mml:msubsup><mml:mi>R</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq81.gif"/></alternatives></inline-formula> is the recall rate, N is the number of patients in the test set and <inline-formula id="IEq82"><alternatives><tex-math id="M195">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$T_k$$\end{document}</tex-math><mml:math id="M196"><mml:msub><mml:mi>T</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq82.gif"/></alternatives></inline-formula> is the number of visit of the k-th patient. And we also use Precision Recall AUC (PR-AUC) to evaluate the performance of the algorithm.</p>
    </sec>
    <sec id="Sec14">
      <title>Implementations</title>
      <p id="Par48">We used all single-visit data for pre-training, and randomly divided multi-visit data into the training set, the verification set and the test set in a 4:1:1 ratio. We set the number of attention heads in the GAT model as 4, and the hidden layers in the pre-training model as 2 with 4 attention heads. In the prediction model, the learning rate was set as 5e-4. In this paper, the prediction was not made after the pre-training model was fully trained. Instead, the pre-training was carried out first, and then the prediction with the pre-trained model was made in alternate cycles, so as to artificially imitate the way of multi-task. Although the two models were not trained together, the two models influenced each other and improved each other in the cycle process, which effectively solved the problem of parameter forgetting of the pre-training model and effectively improved the model generalization ability.</p>
    </sec>
    <sec id="Sec15">
      <title>Results</title>
      <p id="Par49">Table <xref rid="Tab3" ref-type="table">3</xref> shows the performance results of different models. LEAP is obviously less effective than other baseline models and the proposed MR-KPA. As an instance-based medication recommendation model, LEAP does not take into account longitudinal EMR data. Therefore, this results prove that it is necessary to adopt the longitudinal sequential method, namely medication recommendation based on longitudinal EMR data in this study. LR is a shallow machine learning model and widely used in medication recommendation. RETAIN is a medication recommendation model based on the deep neural network. Compared with their results, the Jaccard score and PR-AUC score of LR are significantly higher than those of RETAIN. This indicates that, the deep learning models are no better than traditional shallow machine learning models based on the small-scale longitudinal EMR data. Therefore, it is also necessary to adopt the knowledge-enhanced pre-training visit model for realizing few-shot learning in this study. Finally, the proposed MR-KPA obtains the best results on all evaluating indicators. This shows that the proposed model can effectively improve the accuracy of medication recommendation based on small-scale longitudinal EMR data.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Experimental results from MR-KPA and baselines</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Methods</th><th align="left">Jaccard</th><th align="left">F1</th><th align="left">PR-AUC</th></tr></thead><tbody><tr><td align="left">LEAP</td><td align="left">0.0945</td><td align="left">0.1188</td><td align="left">0.1650</td></tr><tr><td align="left">LR</td><td align="left">0.1618</td><td align="left">0.1722</td><td align="left">0.4120</td></tr><tr><td align="left">RETAIN</td><td align="left">0.1254</td><td align="left">0.2098</td><td align="left">0.3069</td></tr><tr><td align="left">MR-KPA</td><td align="left">0.4482</td><td align="left">0.5293</td><td align="left">0.5889</td></tr></tbody></table></table-wrap></p>
    </sec>
  </sec>
  <sec id="Sec16">
    <title>Discussion</title>
    <p id="Par50">Knowledge enhancement based on ontology embedding, the pre-training visit model and adversarial training are three core optimizations in this paper. This section will discuss their effectiveness by an ablation study. Seven MR-KPA variants are designed as follows:<list list-type="bullet"><list-item><p id="Par51"><inline-formula id="IEq83"><alternatives><tex-math id="M197">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-,P-,A-}$$\end{document}</tex-math><mml:math id="M198"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq83.gif"/></alternatives></inline-formula>: Compared with MR-KPA, this model deletes knowledge enhancement based on ontology embedding, the pre-training visit model and adversarial training, and only uses MLP to predict drug codes based on input embedding of diagnostic codes, drug codes and symptoms;</p></list-item><list-item><p id="Par52"><inline-formula id="IEq84"><alternatives><tex-math id="M199">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{P-,A-}$$\end{document}</tex-math><mml:math id="M200"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq84.gif"/></alternatives></inline-formula>: Compared to MR-KPA, this model deletes the pre-training visit model and adversarial training, and only keeps knowledge enhancement based on ontology embedding;</p></list-item><list-item><p id="Par53"><inline-formula id="IEq85"><alternatives><tex-math id="M201">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-,A-}$$\end{document}</tex-math><mml:math id="M202"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq85.gif"/></alternatives></inline-formula>: Compared to MR-KPA, this model deletes knowledge enhancement based on ontology embedding and adversarial training, and only keeps the pre-training visit model.</p></list-item><list-item><p id="Par54"><inline-formula id="IEq86"><alternatives><tex-math id="M203">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-,P-}$$\end{document}</tex-math><mml:math id="M204"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq86.gif"/></alternatives></inline-formula>: Compared to MR-KPA, this model deletes knowledge enhancement based on ontology embedding and the pre-training visit model, and only keeps adversarial training.</p></list-item><list-item><p id="Par55"><inline-formula id="IEq87"><alternatives><tex-math id="M205">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-}$$\end{document}</tex-math><mml:math id="M206"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq87.gif"/></alternatives></inline-formula>: Compared to MR-KPA, this model deletes knowledge enhancement based on ontology embedding, and keeps the pre-training visit model and adversarial training.</p></list-item><list-item><p id="Par56"><inline-formula id="IEq88"><alternatives><tex-math id="M207">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{P-}$$\end{document}</tex-math><mml:math id="M208"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq88.gif"/></alternatives></inline-formula>: Compared to MR-KPA, this model deletes the pre-training visit model, and keeps knowledge enhancement based on ontology embedding and adversarial training.</p></list-item><list-item><p id="Par57"><inline-formula id="IEq89"><alternatives><tex-math id="M209">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{A-}$$\end{document}</tex-math><mml:math id="M210"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq89.gif"/></alternatives></inline-formula>: Compared to MR-KPA, this model deletes adversarial training, and keeps knowledge enhancement based on ontology embedding and the pre-training visit model.</p></list-item></list></p>
    <sec id="Sec17">
      <title>All of three optimizations are effective and compatible</title>
      <p id="Par58">Table <xref rid="Tab4" ref-type="table">4</xref> gives the experimental results of the ablation study. Compare the baseline models, the result of <inline-formula id="IEq90"><alternatives><tex-math id="M211">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-,P-,A-}$$\end{document}</tex-math><mml:math id="M212"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq90.gif"/></alternatives></inline-formula>is similar to that of RETAIN. Its three evaluating indicators are significantly higher than those of LEAP and two evaluating indicators are lower than those of LR. This once again proves the necessity of adopting longitudinal sequential medication recommendation and the shortcomings of deep learning models in medication recommendation based on small-scale longitudinal EMR data.<table-wrap id="Tab4"><label>Table 4</label><caption><p>Experimental results of the ablation study</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Methods</th><th align="left">Jaccard</th><th align="left">F1</th><th align="left">PR-AUC</th></tr></thead><tbody><tr><td align="left"><inline-formula id="IEq91"><alternatives><tex-math id="M213">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-,P-,A-}$$\end{document}</tex-math><mml:math id="M214"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq91.gif"/></alternatives></inline-formula></td><td align="left">0.1553</td><td align="left">0.2142</td><td align="left">0.2792</td></tr><tr><td align="left"><inline-formula id="IEq92"><alternatives><tex-math id="M215">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{P-,A-}$$\end{document}</tex-math><mml:math id="M216"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq92.gif"/></alternatives></inline-formula></td><td align="left">0.1720</td><td align="left">0.2304</td><td align="left">0.2860</td></tr><tr><td align="left"><inline-formula id="IEq93"><alternatives><tex-math id="M217">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-,A-}$$\end{document}</tex-math><mml:math id="M218"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq93.gif"/></alternatives></inline-formula></td><td align="left">0.3266</td><td align="left">0.4151</td><td align="left">0.4899</td></tr><tr><td align="left"><inline-formula id="IEq94"><alternatives><tex-math id="M219">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-,P-}$$\end{document}</tex-math><mml:math id="M220"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq94.gif"/></alternatives></inline-formula></td><td align="left">0.2184</td><td align="left">0.2853</td><td align="left">0.3348</td></tr><tr><td align="left"><inline-formula id="IEq95"><alternatives><tex-math id="M221">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-}$$\end{document}</tex-math><mml:math id="M222"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq95.gif"/></alternatives></inline-formula></td><td align="left">0.4037</td><td align="left">0.4893</td><td align="left">0.5515</td></tr><tr><td align="left"><inline-formula id="IEq96"><alternatives><tex-math id="M223">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{P-}$$\end{document}</tex-math><mml:math id="M224"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq96.gif"/></alternatives></inline-formula></td><td align="left">0.2275</td><td align="left">0.2966</td><td align="left">0.3791</td></tr><tr><td align="left"><inline-formula id="IEq97"><alternatives><tex-math id="M225">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{A-}$$\end{document}</tex-math><mml:math id="M226"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq97.gif"/></alternatives></inline-formula></td><td align="left">0.3643</td><td align="left">0.4570</td><td align="left">0.5392</td></tr><tr><td align="left"><inline-formula id="IEq98"><alternatives><tex-math id="M227">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA$$\end{document}</tex-math><mml:math id="M228"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq98.gif"/></alternatives></inline-formula></td><td align="left">0.4482</td><td align="left">0.5293</td><td align="left">0.5889</td></tr></tbody></table></table-wrap></p>
      <p id="Par59">Compared with <inline-formula id="IEq99"><alternatives><tex-math id="M229">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-,P-,A-}$$\end{document}</tex-math><mml:math id="M230"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq99.gif"/></alternatives></inline-formula>, the result of <inline-formula id="IEq100"><alternatives><tex-math id="M231">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{P-,A-}$$\end{document}</tex-math><mml:math id="M232"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq100.gif"/></alternatives></inline-formula>,<inline-formula id="IEq101"><alternatives><tex-math id="M233">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-,A-}$$\end{document}</tex-math><mml:math id="M234"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq101.gif"/></alternatives></inline-formula> and <inline-formula id="IEq102"><alternatives><tex-math id="M235">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-,P-}$$\end{document}</tex-math><mml:math id="M236"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq102.gif"/></alternatives></inline-formula> achieve the better performance, which indicates that knowledge enhancement based on ontology embedding, the pre-training visit model and adversarial training, which are three core optimizations in this paper, are very effective. Furthermore, the results of <inline-formula id="IEq103"><alternatives><tex-math id="M237">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-}$$\end{document}</tex-math><mml:math id="M238"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq103.gif"/></alternatives></inline-formula>, <inline-formula id="IEq104"><alternatives><tex-math id="M239">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{P-}$$\end{document}</tex-math><mml:math id="M240"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq104.gif"/></alternatives></inline-formula> and <inline-formula id="IEq105"><alternatives><tex-math id="M241">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{A-}$$\end{document}</tex-math><mml:math id="M242"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq105.gif"/></alternatives></inline-formula> are also significantly improved than those of <inline-formula id="IEq106"><alternatives><tex-math id="M243">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-,P-,A-}$$\end{document}</tex-math><mml:math id="M244"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>-</mml:mo><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq106.gif"/></alternatives></inline-formula>. Finally, the proposed MR-KPA model achieved the best results. This indicates that these three optimizations are compatible with each other and their combination can greatly improve EMR-based medication recommendation.</p>
    </sec>
    <sec id="Sec18">
      <title>The pre-training visit model are the most effective optimization</title>
      <p id="Par60">Referring to [<xref ref-type="bibr" rid="CR54">54</xref>], this section will further discuss the training effects of the three optimizations through the analysis of training loss curve. Figure <xref rid="Fig4" ref-type="fig">4</xref> gives the learning curves of training loss of MR-KPA, <inline-formula id="IEq107"><alternatives><tex-math id="M245">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-}$$\end{document}</tex-math><mml:math id="M246"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq107.gif"/></alternatives></inline-formula>, <inline-formula id="IEq108"><alternatives><tex-math id="M247">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{P-}$$\end{document}</tex-math><mml:math id="M248"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq108.gif"/></alternatives></inline-formula> and <inline-formula id="IEq109"><alternatives><tex-math id="M249">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{A-}$$\end{document}</tex-math><mml:math id="M250"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq109.gif"/></alternatives></inline-formula>. As shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>a, the training loss of <inline-formula id="IEq110"><alternatives><tex-math id="M251">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-}$$\end{document}</tex-math><mml:math id="M252"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq110.gif"/></alternatives></inline-formula> drops a little faster than that of MR-KPA in the early stage, but it basically fits the training loss curve of MR-KPA in the later stage. This indicates knowledge enhancement based on ontology embedding affects the training speed in the early stage, but it has little impact on the recommendation results of the whole model. This is consistent with the results in Table <xref rid="Tab3" ref-type="table">3</xref>. <inline-formula id="IEq111"><alternatives><tex-math id="M253">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-}$$\end{document}</tex-math><mml:math id="M254"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq111.gif"/></alternatives></inline-formula> has the closest result to MR-KPA. This indicates that knowledge enhancement based on ontology embedding has the minimal improvement effect on the EMR-based medication recommendation task.<fig id="Fig4"><label>Fig. 4</label><caption><p>The change of training loss values in MR-KPA and three variants</p></caption><graphic xlink:href="12859_2022_5102_Fig4_HTML" id="MO20"/></fig></p>
      <p id="Par61">Figure <xref rid="Fig4" ref-type="fig">4</xref>b gives the comparison of training loss between MR-KPA and <inline-formula id="IEq112"><alternatives><tex-math id="M255">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{P-}$$\end{document}</tex-math><mml:math id="M256"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq112.gif"/></alternatives></inline-formula>. With the increase of iteration times, the loss of MR-KPA gradually decreased, but the loss change of <inline-formula id="IEq113"><alternatives><tex-math id="M257">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{P-}$$\end{document}</tex-math><mml:math id="M258"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq113.gif"/></alternatives></inline-formula> is not obvious. This indicates that the pre-training visit model is the key to ensure the convergence of the model on relatively small-scale longitudinal EMR data. It has a significant effect on improving the edication recommendation based on small-scale longitudinal EMR data. This is also consistent with the results in Table <xref rid="Tab3" ref-type="table">3</xref>. Among <inline-formula id="IEq114"><alternatives><tex-math id="M259">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-}$$\end{document}</tex-math><mml:math id="M260"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq114.gif"/></alternatives></inline-formula>,<inline-formula id="IEq115"><alternatives><tex-math id="M261">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{P-}$$\end{document}</tex-math><mml:math id="M262"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq115.gif"/></alternatives></inline-formula> and <inline-formula id="IEq116"><alternatives><tex-math id="M263">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{A-}$$\end{document}</tex-math><mml:math id="M264"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq116.gif"/></alternatives></inline-formula>, <inline-formula id="IEq117"><alternatives><tex-math id="M265">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{P}$$\end{document}</tex-math><mml:math id="M266"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq117.gif"/></alternatives></inline-formula> has the worst results.</p>
      <p id="Par62">Figure <xref rid="Fig4" ref-type="fig">4</xref>c gives the comparison of training loss between MR-KPA and <inline-formula id="IEq118"><alternatives><tex-math id="M267">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{A-}$$\end{document}</tex-math><mml:math id="M268"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq118.gif"/></alternatives></inline-formula>. With the increase of iteration times, the downward trend of loss of <inline-formula id="IEq119"><alternatives><tex-math id="M269">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{A-}$$\end{document}</tex-math><mml:math id="M270"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq119.gif"/></alternatives></inline-formula>is much slower than that of MR-KPA. The loss values MR-KPA are always below that of <inline-formula id="IEq120"><alternatives><tex-math id="M271">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{A-}$$\end{document}</tex-math><mml:math id="M272"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq120.gif"/></alternatives></inline-formula> in the later. This indicates adversarial training has played a role in preventing the model from over-fitting on small-scale longitudinal EMR data. Therefore, it can effectively improve medication recommendation based on small-scale longitudinal EMR data, as shown in Table <xref rid="Tab3" ref-type="table">3</xref>.</p>
      <p id="Par63">Comparing Fig. <xref rid="Fig4" ref-type="fig">4</xref>a–c, only the loss curve of <inline-formula id="IEq121"><alternatives><tex-math id="M273">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{P-}$$\end{document}</tex-math><mml:math id="M274"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq121.gif"/></alternatives></inline-formula> decreases slowly, and even has an upward trend in the later period, indicating that the model does not converge. Therefore, <inline-formula id="IEq122"><alternatives><tex-math id="M275">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{P-}$$\end{document}</tex-math><mml:math id="M276"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq122.gif"/></alternatives></inline-formula> has the worst result among <inline-formula id="IEq123"><alternatives><tex-math id="M277">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{K-}$$\end{document}</tex-math><mml:math id="M278"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq123.gif"/></alternatives></inline-formula>,<inline-formula id="IEq124"><alternatives><tex-math id="M279">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{P-}$$\end{document}</tex-math><mml:math id="M280"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq124.gif"/></alternatives></inline-formula> and <inline-formula id="IEq125"><alternatives><tex-math id="M281">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MR-KPA_{A-}$$\end{document}</tex-math><mml:math id="M282"><mml:mrow><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mi>P</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5102_Article_IEq125.gif"/></alternatives></inline-formula>, as shown in Table <xref rid="Tab3" ref-type="table">3</xref>. That is to say, the pre-training visit model are the most effective optimization in this study.</p>
    </sec>
    <sec id="Sec19">
      <title>Limitations of this study</title>
      <p id="Par64">There are still some limitations in this study. Due to the addition of adversarial training, the computational complexity of the proposed MR-KPA inevitably increases, and the running time also increases. However, due to the small-scale training data, this limitation of recommendation model can be compensated partly. Another limitation of this study is that the temporal features of longitudinal data are not fully utilized. Therefore, an important future work is to effectively mine temporal features by various deep neural network, such as linear networks.</p>
    </sec>
  </sec>
  <sec id="Sec20">
    <title>Conclusion</title>
    <p id="Par65">In this paper, we propose a new EMR-based medication recommendation model called MR-KPA. By combining knowledge-enhanced pre-training with the deep adversarial network, MR-KPA improves both feature representation and the fine-tuning process to realize effectively medication recommendation based on small-scale EMR data. To our best knowledge, MR-KPA is real first that integrates current popular graph neural network, pre-training and adversarial training for EMR-based medication recommendation. The ablation experiments and comparative experiments prove that these three technologies are complementary and their integration makes the proposed MR-KPA model effectively realize medication recommendation on small-scale longitudinal EMR data. By reducing the dependence on high-quality labelled data, this study can greatly reduce the time and economic costs required for model construction, and help to promote the comprehensive application of EMRs based medication recommendation.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <notes notes-type="author-contribution">
    <title>Author Contributions</title>
    <p>Conceptualization, SL and JC; methodology, SL, MW and JC; software, MW and JC; validation, SL and JC; investigation, MW and CS; data curation, MW; writing-original draft preparation, MW; writing-review and editing, JC, MW, SL, ZX, LC, and QG; visualization, MW; All authors read and approved to the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This study was supported by National Key Research and Development Program of China (Grant No. 2020YFB2104402) and Beijing Natural Science Foundation (No. 4222022).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The datasets generated and analysed during the current study are not publicly available due to privacy restriction from hospitals but are available from the corresponding author on reasonable request. The source codes are publicly available in the GitHub repository, <ext-link ext-link-type="uri" xlink:href="https://github.com/MengzhenWangmz/MR-KPA">https://github.com/MengzhenWangmz/MR-KPA</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par66">The authors declare the data used in our research were anonymized before its use.</p>
    </notes>
    <notes id="FPar2" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par67">The authors declare no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <mixed-citation publication-type="other">Raghavan P, Liang JJ, Mahajan D, Chandra R, Szolovits P. emrkbqa: a clinical knowledge-base question answering dataset. In: Proceedings of the 20th workshop on biomedical language processing 2021, 2021. p. 64–73.</mixed-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <mixed-citation publication-type="other">Park J, Cho Y, Lee H, Choo J, Choi E. Knowledge graph-based question answering with electronic health records. In: MLHC 2021.</mixed-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <mixed-citation publication-type="other">Fang M, Chen Y, Xue R, Wang H, Chakraborty N, Su T, Dai Y. A hybrid machine learning approach for hypertension risk prediction. Neural Comput Appl. 2021;1–11.</mixed-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <mixed-citation publication-type="other">Zhao H, Ma Z, Sun Y. A hypertension risk prediction model based on bp neural network. In: 2019 International conference on networking and network applications (NaNA), 2019. p. 464–9. 10.1109/NaNA.2019.00085</mixed-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <mixed-citation publication-type="other">Feng R, Cao Y, Liu X, Chen T, Chen J, Chen DZ, Gao H, Wu J. Chronet: A multi-task learning based approach for prediction of multiple chronic diseases. Multim Tools Appl. 2021;1–15.</mixed-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">Zhang XS, Tang F, Dodge HH, Zhou J, Wang F. Metapred: Meta-learning for clinical risk prediction with limited patient electronic health records. In: Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining, 2019. p. 2487–95.</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hsu</surname>
            <given-names>J-L</given-names>
          </name>
          <name>
            <surname>Hsu</surname>
            <given-names>T-J</given-names>
          </name>
          <name>
            <surname>Hsieh</surname>
            <given-names>C-H</given-names>
          </name>
          <name>
            <surname>Singaravelan</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Applying convolutional neural networks to predict the icd-9 codes of medical records</article-title>
        <source>Sensors</source>
        <year>2020</year>
        <volume>20</volume>
        <issue>24</issue>
        <fpage>7116</fpage>
        <pub-id pub-id-type="doi">10.3390/s20247116</pub-id>
        <pub-id pub-id-type="pmid">33322566</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Singaravelan</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hsieh</surname>
            <given-names>C-H</given-names>
          </name>
          <name>
            <surname>Liao</surname>
            <given-names>Y-K</given-names>
          </name>
          <name>
            <surname>Hsu</surname>
            <given-names>J-L</given-names>
          </name>
        </person-group>
        <article-title>Predicting icd-9 codes using self-report of patients</article-title>
        <source>Appl Sci</source>
        <year>2021</year>
        <volume>11</volume>
        <issue>21</issue>
        <fpage>10046</fpage>
        <pub-id pub-id-type="doi">10.3390/app112110046</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Ghasemi SH, Etminani K, Dehghan H, Eslami S, Hasibian MR, Vakili-Arki H, Saberi MR, Aghabagheri M, Namayandeh SM. Design and evaluation of a smart medication recommendation system for the electronic prescription. In: dHealth, 2019. p. 128–35.</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Palchik</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Traverso</surname>
            <given-names>ML</given-names>
          </name>
          <name>
            <surname>Colautti</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bianchi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dolza</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Catena</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Salamano</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Oncology medications prescription in a cancer service: appropriateness to clinical practice guidelines</article-title>
        <source>Farmacia Hospitalaria: Organo Oficial de Expresion Cientifica de la Sociedad Espanola de Farmacia Hospitalaria</source>
        <year>2016</year>
        <volume>40</volume>
        <issue>n06</issue>
        <fpage>491</fpage>
        <lpage>5</lpage>
        <pub-id pub-id-type="pmid">27894223</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>An</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>You</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Jin</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Mesin: Multilevel selective and interactive network for medication recommendation</article-title>
        <source>Knowledge-Based Syst</source>
        <year>2021</year>
        <volume>233</volume>
        <fpage>107534</fpage>
        <pub-id pub-id-type="doi">10.1016/j.knosys.2021.107534</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Pi</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Yue</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Adversarially regularized medication recommendation model with multi-hop memory network</article-title>
        <source>Knowl Inf Syst</source>
        <year>2021</year>
        <volume>63</volume>
        <issue>1</issue>
        <fpage>125</fpage>
        <lpage>42</lpage>
        <pub-id pub-id-type="doi">10.1007/s10115-020-01513-9</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>An</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Mao</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Jin</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Rahm: relation augmented hierarchical multi-task learning framework for reasonable medication stocking</article-title>
        <source>J Biomed Inf</source>
        <year>2020</year>
        <volume>108</volume>
        <fpage>103502</fpage>
        <pub-id pub-id-type="doi">10.1016/j.jbi.2020.103502</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Choi E, Bahadori MT, Song L, Stewart WF, Sun J. Gram: graph-based attention model for healthcare representation learning. In: Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining, 2017. p. 787–95.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Su</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Gate: graph-attention augmented temporal neural network for medication recommendation</article-title>
        <source>IEEE Access</source>
        <year>2020</year>
        <volume>8</volume>
        <fpage>125447</fpage>
        <lpage>58</lpage>
        <pub-id pub-id-type="doi">10.1109/ACCESS.2020.3007835</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Shang J, Ma T, Xiao C, Sun J. Pre-training of graph augmented transformers for medication recommendation. In: Twenty-eighth international joint conference on artificial intelligence 2019.</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Choi E, Bahadori MT, Sun J, Kulas J, Schuetz A, Stewart W. Retain: an interpretable predictive model for healthcare using reverse time attention mechanism. Adv Neural Inf Process Syst. 2016;29.</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bhoi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>ML</given-names>
          </name>
          <name>
            <surname>Hsu</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>HSA</given-names>
          </name>
          <name>
            <surname>Tan</surname>
            <given-names>NC</given-names>
          </name>
        </person-group>
        <article-title>Personalizing medication recommendation with a graph-based approach</article-title>
        <source>ACM Trans Inf Syst</source>
        <year>2021</year>
        <volume>40</volume>
        <issue>3</issue>
        <fpage>1</fpage>
        <lpage>23</lpage>
        <pub-id pub-id-type="doi">10.1145/3488668</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Wu R, Qiu Z, Jiang J, Qi G, Wu X. Conditional generation net for medication recommendation. In: Proceedings of the ACM web conference 2022, 2022. p. 935–45.</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Zhang S, Li J, Zhou H, Zhu Q, Zhang S, Wang D. Merits: medication recommendation for chronic disease with irregular time-series. In: 2021 IEEE international conference on data mining (ICDM), 2021. p. 1481–1486. IEEE.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Joshua Lin</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Jin</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Gagne</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Glynn</surname>
            <given-names>RJ</given-names>
          </name>
          <name>
            <surname>Murphy</surname>
            <given-names>SN</given-names>
          </name>
          <name>
            <surname>Tong</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Schneeweiss</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Longitudinal data discontinuity in electronic health records and consequences for medication effectiveness studies</article-title>
        <source>Clin Pharmacol Therap</source>
        <year>2022</year>
        <volume>111</volume>
        <issue>1</issue>
        <fpage>243</fpage>
        <lpage>51</lpage>
        <pub-id pub-id-type="doi">10.1002/cpt.2400</pub-id>
        <pub-id pub-id-type="pmid">34424534</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Kwok</surname>
            <given-names>JT</given-names>
          </name>
          <name>
            <surname>Ni</surname>
            <given-names>LM</given-names>
          </name>
        </person-group>
        <article-title>Generalizing from a few examples: a survey on few-shot learning</article-title>
        <source>ACM Comput Surv (csur)</source>
        <year>2020</year>
        <volume>53</volume>
        <issue>3</issue>
        <fpage>1</fpage>
        <lpage>34</lpage>
        <pub-id pub-id-type="doi">10.1145/3386252</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Xian Y, Sharma S, Schiele B, Akata Z. f-vaegan-d2: a feature generating framework for any-shot learning. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2019. p. 10275–84</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">Gao T, Han X, Liu Z, Sun M. Hybrid attention-based prototypical networks for noisy few-shot relation classification. In: Proceedings of the AAAI conference on artificial intelligence, vol. 33, 2019. p. 6407–14.</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Nakamura A, Harada T. Revisiting fine-tuning for few-shot learning. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1910.00216">arXiv:1910.00216</ext-link> 2019.</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Lan Z, Chen M, Goodman S, Gimpel K, Sharma P, Soricut R. Albert: a lite bert for self-supervised learning of language representations. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1909.11942">arXiv:1909.11942</ext-link> 2019.</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rasmy</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Xiang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Xie</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Tao</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Zhi</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Med-bert: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction</article-title>
        <source>NPJ Digit Med</source>
        <year>2021</year>
        <volume>4</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>13</lpage>
        <pub-id pub-id-type="doi">10.1038/s41746-021-00455-y</pub-id>
        <pub-id pub-id-type="pmid">33398041</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Ren H, Wang J, Zhao WX, Wu N. Rapt: Pre-training of time-aware transformer for learning robust healthcare representation. In: Proceedings of the 27th ACM SIGKDD conference on knowledge discovery &amp; data mining, 2021. p. 3503–11.</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meng</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Speier</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Ong</surname>
            <given-names>MK</given-names>
          </name>
          <name>
            <surname>Arnold</surname>
            <given-names>CW</given-names>
          </name>
        </person-group>
        <article-title>Bidirectional representation learning from transformers using multimodal electronic health record data to predict depression</article-title>
        <source>IEEE J Biomed Health Inf</source>
        <year>2021</year>
        <volume>25</volume>
        <issue>8</issue>
        <fpage>3121</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1109/JBHI.2021.3063721</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Wang M, Chen J, Lin S. Medication recommendation based on a knowledge-enhanced pre-training model. In: IEEE/WIC/ACM international conference on web intelligence and intelligent agent technology, 2021. p. 290–4.</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Forouzandeh</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Berahmand</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Rostami</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Presentation of a recommender system with ensemble learning and graph embedding: a case on movielens</article-title>
        <source>Multim Tools Appl</source>
        <year>2021</year>
        <volume>80</volume>
        <issue>5</issue>
        <fpage>7805</fpage>
        <lpage>32</lpage>
        <pub-id pub-id-type="doi">10.1007/s11042-020-09949-5</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Jin</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Artificial intelligence in recommender systems</article-title>
        <source>Complex Intell Syst</source>
        <year>2021</year>
        <volume>7</volume>
        <issue>1</issue>
        <fpage>439</fpage>
        <lpage>57</lpage>
        <pub-id pub-id-type="doi">10.1007/s40747-020-00212-w</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Syed-Abdul</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Jian</surname>
            <given-names>W-S</given-names>
          </name>
          <name>
            <surname>Iqbal</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Hsu</surname>
            <given-names>M-H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y-C</given-names>
          </name>
        </person-group>
        <article-title>A smart medication recommendation model for the electronic prescription</article-title>
        <source>Comput Methods Progr Biomed</source>
        <year>2014</year>
        <volume>117</volume>
        <issue>2</issue>
        <fpage>218</fpage>
        <lpage>24</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cmpb.2014.06.019</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <mixed-citation publication-type="other">Zhang Y, Chen R, Tang J, Stewart WF, Sun J. Leap: learning to prescribe effective and safe treatment combinations for multimorbidity. In: Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining, 2017. p. 1315–24.</mixed-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">McCloskey M, Cohen NJ. Catastrophic interference in connectionist networks: The sequential learning problem. In: Psychology of learning and motivation vol. 24. Elsevier; 1989. p. 109–65.</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kirkpatrick</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Pascanu</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Rabinowitz</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Veness</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Desjardins</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Rusu</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Milan</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Quan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ramalho</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Grabska-Barwinska</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Overcoming catastrophic forgetting in neural networks</article-title>
        <source>Proc Natl Acad Sci</source>
        <year>2017</year>
        <volume>114</volume>
        <issue>13</issue>
        <fpage>3521</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1611835114</pub-id>
        <pub-id pub-id-type="pmid">28292907</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nitsuwat</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Paoin</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Development of icd-10-tm ontology for a semi-automated morbidity coding system in thailand</article-title>
        <source>Methods Inf Med</source>
        <year>2012</year>
        <volume>51</volume>
        <issue>06</issue>
        <fpage>519</fpage>
        <lpage>28</lpage>
        <pub-id pub-id-type="doi">10.3414/ME11-02-0024</pub-id>
        <pub-id pub-id-type="pmid">22935742</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Wang M, Zhang J, Liu J, Hu W, Wang S, Li X, Liu W. Pdd graph: Bridging electronic medical records and biomedical knowledge graphs via entity linking. In: International semantic web conference. Springer; 2017. p. 219–27.</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">Palumbo E, Rizzo G, Troncy R, Baralis E, Osella M, Ferro E. Knowledge graph embeddings with node2vec for item recommendation. In: European semantic web conference. Springer; 2018. p. 117–20.</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nguyen</surname>
            <given-names>HL</given-names>
          </name>
          <name>
            <surname>Vu</surname>
            <given-names>DT</given-names>
          </name>
          <name>
            <surname>Jung</surname>
            <given-names>JJ</given-names>
          </name>
        </person-group>
        <article-title>Knowledge graph fusion for smart systems: a survey</article-title>
        <source>Inf Fusion</source>
        <year>2020</year>
        <volume>61</volume>
        <fpage>56</fpage>
        <lpage>70</lpage>
        <pub-id pub-id-type="doi">10.1016/j.inffus.2020.03.014</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Long</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Ren</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>An integrated framework of deep learning and knowledge graph for prediction of stock price trend: An application in chinese stock exchange market</article-title>
        <source>Appl Soft Comput</source>
        <year>2020</year>
        <volume>91</volume>
        <fpage>106205</fpage>
        <pub-id pub-id-type="doi">10.1016/j.asoc.2020.106205</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <mixed-citation publication-type="other">Lin X, Quan Z, Wang Z-J, Ma T, Zeng X. Kgnn: Knowledge graph neural network for drug-drug interaction prediction. In: IJCAI, vol. 380, 2020. p. 2739–45.</mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">Yang J, Xiao G, Shen Y, Jiang W, Hu X, Zhang Y, Peng J. A survey of knowledge enhanced pre-trained models. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2110.00269">arXiv:2110.00269</ext-link> 2021.</mixed-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <mixed-citation publication-type="other">Levine Y, Lenz B, Dagan O, Ram O, Padnos D, Sharir O, Shalev-Shwartz S, Shashua A, Shoham Y. SenseBERT: Driving Some Sense into BERT. In: Proceedings of the 58th annual meeting of the association for computational linguistics, 2020. p. 4656–67.</mixed-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <mixed-citation publication-type="other">Shen T, Mao Y, He P, Long G, Trischler A, Chen W. Exploiting structured knowledge in text via graph-guided representation learning. In: Proceedings of the 2020 conference on empirical methods in natural language processing (EMNLP), 2020. p. 8980–94.</mixed-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <mixed-citation publication-type="other">Zhang Z, Han X, Liu Z, Jiang X, Sun M, Liu Q. ERNIE: Enhanced language representation with informative entities. In: Proceedings of the 57th annual meeting of the association for computational linguistics, Florence, Italy, 2019. p. 1441–51.</mixed-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <mixed-citation publication-type="other">Verga P, Sun H, Soares LB, Cohen W. Adaptable and interpretable neural memoryover symbolic knowledge. In: Proceedings of the 2021 conference of the north american chapter of the association for computational linguistics: human language technologies, 2021. p. 3678–91.</mixed-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <mixed-citation publication-type="other">Wang R, Tang D, Duan N, Wei Z, Huang X, Cao G, Jiang D, Zhou M, et al. K-adapter: infusing knowledge into pre-trained models with adapters. In: Findings of the association for computational linguistics 2021.</mixed-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <mixed-citation publication-type="other">Guu K, Lee K, Tung Z, Pasupat P, Chang M. Retrieval augmented language model pre-training. In: International conference on machine learning, 2020. p. 3929–38. PMLR.</mixed-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <mixed-citation publication-type="other">Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser Ł. Polosukhin I. Attention is all you need. In: Advances in neural information processing systems 2017;30.</mixed-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <mixed-citation publication-type="other">Ma X, Guo J, Zhang R, Fan Y, Ji X, Cheng X. Prop: pre-training with representative words prediction for ad-hoc retrieval. In: Proceedings of the 14th ACM international conference on web search and data mining, 2021. p. 283–91.</mixed-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <mixed-citation publication-type="other">Sun Y, Zheng Y, Hao C, Qiu H. Nsp-bert: a prompt-based zero-shot learner through an original pre-training task–next sentence prediction. COLING 2022.</mixed-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <mixed-citation publication-type="other">Mantey EA, Zhou C, Anajemba JH, Okpalaoguchi IM, Chiadika OD-M. Blockchain-secured recommender system for special need patients using deep learning. Front Public Health 2021;9.</mixed-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <mixed-citation publication-type="other">Miyato T, Dai AM, Goodfellow I. Adversarial training methods for semi-supervised text classification. In: International conference on learning representations 2017.</mixed-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luaces</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Díez</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Barranquero</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Coz</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bahamonde</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Binary relevance efficacy for multilabel classification</article-title>
        <source>Prog Artif Intell</source>
        <year>2012</year>
        <volume>1</volume>
        <issue>4</issue>
        <fpage>303</fpage>
        <lpage>13</lpage>
        <pub-id pub-id-type="doi">10.1007/s13748-012-0030-x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <mixed-citation publication-type="other">Fernando B, Herath S. Anticipating human actions by correlating past with the future with jaccard similarity measures. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2021. p. 13224–33</mixed-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>DeVries</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Locke</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Hoda</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Moravek</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Phan</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Stratton</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kingwell</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Wai</surname>
            <given-names>EK</given-names>
          </name>
          <name>
            <surname>Phan</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Using a national surgical database to predict complications following posterior lumbar surgery and comparing the area under the curve and f1-score for the assessment of prognostic capability</article-title>
        <source>Spine J</source>
        <year>2021</year>
        <volume>21</volume>
        <issue>7</issue>
        <fpage>1135</fpage>
        <lpage>42</lpage>
        <pub-id pub-id-type="doi">10.1016/j.spinee.2021.02.007</pub-id>
        <pub-id pub-id-type="pmid">33601012</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
