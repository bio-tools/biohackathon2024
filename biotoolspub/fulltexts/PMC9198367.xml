<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Pharmacol</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Pharmacol</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Pharmacol.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Pharmacology</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1663-9812</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9198367</article-id>
    <article-id pub-id-type="publisher-id">907676</article-id>
    <article-id pub-id-type="doi">10.3389/fphar.2022.907676</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Pharmacology</subject>
        <subj-group>
          <subject>Original Research</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DACPGTN: Drug ATC Code Prediction Method Based on Graph Transformer Network for Drug Discovery</article-title>
      <alt-title alt-title-type="left-running-head">Yan et al.</alt-title>
      <alt-title alt-title-type="right-running-head">Drug ATC Code Prediction Method</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Yan</surname>
          <given-names>Chaokun</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/787100/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Suo</surname>
          <given-names>Zhihao</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1811881/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Jianlin</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1154238/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Ge</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1154273/overview"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Luo</surname>
          <given-names>Huimin</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="c001" ref-type="corresp">*</xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1034463/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>School of Computer and Information Engineering</institution>, <institution>Henan University</institution>, <addr-line>Kaifeng</addr-line>, <country>China</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Henan Key Laboratory of Big Data Analysis and Processing</institution>, <institution>Henan University</institution>, <addr-line>Kaifeng</addr-line>, <country>China</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p><bold>Edited by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/59633/overview" ext-link-type="uri">FangXiang Wu</ext-link>, University of Saskatchewan, Canada</p>
      </fn>
      <fn fn-type="edited-by">
        <p><bold>Reviewed by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/702668/overview" ext-link-type="uri">Pi-Jing Wei</ext-link>, Anhui University, China</p>
        <p><ext-link xlink:href="https://loop.frontiersin.org/people/1076640/overview" ext-link-type="uri">Xiaoqing Peng</ext-link>, Central South University, China</p>
      </fn>
      <corresp id="c001">*Correspondence: Huimin Luo, <email>luohuimin@henu.edu.cn</email>
</corresp>
      <fn fn-type="other">
        <p>This article was submitted to Experimental Pharmacology and Drug Discovery, a section of the journal Frontiers in Pharmacology</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>01</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>13</volume>
    <elocation-id>907676</elocation-id>
    <history>
      <date date-type="received">
        <day>30</day>
        <month>3</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>06</day>
        <month>5</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2022 Yan, Suo, Wang, Zhang and Luo.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Yan, Suo, Wang, Zhang and Luo</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>The Anatomical Therapeutic Chemical (ATC) classification system is a drug classification scheme proposed by the World Health Organization, which is widely used for drug screening, repositioning, and similarity research. The ATC system assigns different ATC codes to drugs based on their anatomy, pharmacological, therapeutics and chemical properties. Predicting the ATC code of a given drug helps to understand the indication and potential toxicity of the drug, thus promoting its use in the therapeutic phase and accelerating its development. In this article, we propose an end-to-end model DACPGTN to predict the ATC code for the given drug. DACPGTN constructs composite features of drugs, diseases and targets by applying diverse biomedical information. Inspired by the application of Graph Transformer Network, we learn potential novel interactions among drugs diseases and targets from the known interactions to construct drug-target-disease heterogeneous networks containing comprehensive interaction information. Based on the constructed composite features and learned heterogeneous networks, we employ graph convolution network to generate the embedding of drug nodes, which are further used for the multi-label learning tasks in drug discovery. Experiments on the benchmark datasets demonstrate that the proposed DACPGTN model can achieve better prediction performance than the existing methods. The source codes of our method are available at <ext-link xlink:href="https://github.com/Szhgege/DACPGTN" ext-link-type="uri">https://github.com/Szhgege/DACPGTN</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>drug ATC code</kwd>
      <kwd>multi-label classification</kwd>
      <kwd>interaction information</kwd>
      <kwd>drug discovery</kwd>
      <kwd>graph transformer network</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source id="cn001">
          <institution-wrap>
            <institution>National Natural Science Foundation of China
</institution>
            <institution-id institution-id-type="doi">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source id="cn002">
          <institution-wrap>
            <institution>Education Department of Henan Province
</institution>
            <institution-id institution-id-type="doi">10.13039/501100009101</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
  </article-meta>
</front>
<body>
  <sec id="s1">
    <title>1 Introduction</title>
    <p>Drug research and development is time-consuming and costly. A new drug, from development to launch, takes decades of research and hundreds of millions of dollars. How to find new indications from existing approved drugs and reduce the cost of research discovery is a hot field in bioinformatics (<xref rid="B30" ref-type="bibr">Pushpakom et al., 2019</xref>; <xref rid="B18" ref-type="bibr">Jarada et al., 2020</xref>). The World Health Organization has established a complete drug classification system, Anatomical Therapeutic Chemical (ATC) (<xref rid="B27" ref-type="bibr">MacDonald and Potvin, 2004</xref>). Specifically, the standard ATC code in the ATC system can be used to represent drug class information, which facilitates the use of drugs during the treatment phase. When the ATC code of a drug compound is known, can be inferred its active ingredient, therapeutic, pharmacological, and chemical properties. Therefore, predicting the ATC code of a drug helps to use the drug correctly or identify novel potential indications, and speed up the drug development process, which is a common idea for drug repositioning research. (<xref rid="B17" ref-type="bibr">Hutchinson et al., 2004</xref>). The ATC code system divides drugs into five levels, based on the first-level of ATC codes, drugs are classified into 14 anatomical classes including Alimentary tract and metabolism, Blood and blood forming organs, Cardiovascular system, Dermatologicals, Genitourinary system and sex hormones, Systemic hormonal preparations, excluding sex hormones and insulins, Anti-infectives for systemic use, Antineoplastic and immunomodulating agents, Musculoskeletal system, Nervous system, Antiparasitic products, insecticides and repellents, Respiratory system, Sensory organs, Various. For a drug, it may belong to more than one class in first-level at the same time.</p>
    <p>There are a large number of drugs without ATC codes in widely used drug information databases. ATC code prediction of new or existing drugs using traditional experimental methods is cumbersome and time-consuming. The development and application of machine learning provide the possibility to realize the rapid classification of drugs ATC code (<xref rid="B15" ref-type="bibr">Dunkel et al., 2008</xref>; <xref rid="B45" ref-type="bibr">Wu et al., 2013</xref>). In recent years, some multi-label classification methods have been proposed for drug ATC Code prediction. <xref rid="B5" ref-type="bibr">Chen et al. (2012)</xref>, firstly proposed a method to classify drug ATC code by integrating drug chemistry-chemistry interaction information and chemistry-chemistry similarity information, and constructed benchmark dataset for the first-level code prediction of drug ATC code. Based on this benchmark dataset, some classification methods integrating multiple drug information to predict drug ATC codes are proposed. <xref rid="B8" ref-type="bibr">Cheng et al. (2017b)</xref> proposed a multi-label Gaussian kernel regression classifier named iATC-mISF. Based on medicinal chemical–chemical interaction, structure, and fingerprint similarity, assign the first-level ATC code to drugs. After that, <xref rid="B7" ref-type="bibr">Cheng et al. (2017a)</xref> improved the classifier’s performance by further integrating the predictor iATC-mDO based on the drug ontology information (<xref rid="B14" ref-type="bibr">Degtyarenko et al., 2007</xref>). Based on this, iATC-mISF has been upgraded to iATC-mHyb. <xref rid="B28" ref-type="bibr">Nanni and Brahnam (2017)</xref> developed a multi-label classifier EnsLIF based on gradient histogram algorithm, which constructs the one-dimensional feature vector of drug compounds into a two-dimensional matrix. <xref rid="B50" ref-type="bibr">Zhou et al. (2020a)</xref> constructed multiple drug interaction networks, extracted the drug features in the network through the network embedding algorithm Mashup (<xref rid="B10" ref-type="bibr">Cho et al., 2016</xref>), and transformed the original multi-label classification problem into multiple binary classification problems by using Random k-labelsets (RAKEL) algorithm (<xref rid="B41" ref-type="bibr">Tsoumakas and Vlahavas, 2007</xref>). In the classification stage, the classical machine learning algorithm support vector machine (SVM) (<xref rid="B12" ref-type="bibr">Cortes and Vapnik, 1995</xref>) is used to construct the classifier iATC-NRAKEL, which has achieved good results. Based on the iATC-NRAKEL classifier, <xref rid="B51" ref-type="bibr">Zhou et al. (2020b)</xref> proposed a multi-label classifier iATC-FRAKEL only used the fingerprints of drugs as feature. In addition, web services are provided. By integrating drug-drug interaction information, structural similarity, and fingerprint similarity, and using the NLSP method (<xref rid="B39" ref-type="bibr">Szymański et al., 2016</xref>) to explore the correlation between labels. <xref rid="B42" ref-type="bibr">Wang et al. (2019b)</xref> proposed a method ATC-NLSP, to predict the first-level ATC code of drugs, which uses a machine learning framework to provide better prediction results.</p>
    <p>With the successful application of deep learning technology in many fields, <xref rid="B29" ref-type="bibr">Nanni et al. (2020)</xref> proposed a first-level ATC code multi-label classifier system (FUS3) by integrating multiple deep learning methods. The model used convolutional neural network (CNN) and Long-Short-Term Memory network (LSTM) (<xref rid="B16" ref-type="bibr">Hochreiter and Schmidhuber, 1997</xref>) to extract implicit features, then train two calssifiers to identify the ATC codes of drugs using extracted features. In the latest study, <xref rid="B49" ref-type="bibr">Zhao et al. (2021)</xref> proposed a new drug ATC code end-to-end prediction model CGATCPred, which utilized a multi-layer Convolutional Neural Network (CNN) to extract composite features from multiple types of drug features. The association graph structure of ATC code labels is established and combined with the word embedding information, the GCN (<xref rid="B20" ref-type="bibr">Kipf and Welling, 2016</xref>) network is applied to extract the label information. New features were obtained based on composite features and the generated label information. The generated features were spliced with the composite features extracted from the CNN layer, and then were input to the fully connected neural network layer to predict the ATC code of the drugs.</p>
    <p>For the ATC code prediction problem, most of the existing classification methods generally consider the information of the drug itself or the relationships between the ATC code and drugs. These approaches ignore the potential importance of other relevant information in drug ATC code prediction, such as target protein and disease information associated with drugs. Several studies have demonstrated that similar drugs have similar in chemical properties, indications, etc (<xref rid="B9" ref-type="bibr">Chiang and Butte, 2009</xref>; <xref rid="B23" ref-type="bibr">Li and Lu, 2012</xref>). Based on this property, the general hypothesis is that when two drugs act on the same target protein or disease, or they have multiple interactions between two drugs and target protein or disease, they may have the same ATC code labels.</p>
    <p>In this article, to improve the performance of drug ATC code identification, we proposed a novel drug ATC code prediction method based on the Graph Transformer Network (<xref rid="B46" ref-type="bibr">Yun et al., 2019</xref>). Traditional deep learning frameworks have some limitations (<xref rid="B47" ref-type="bibr">Zhang et al., 2018</xref>; <xref rid="B43" ref-type="bibr">Wang et al., 2019a</xref>). For example, it cannot effectively exploit the interaction information in heterogeneous networks or requires predefined fixed interactions between nodes. GTN model is a self-learning method for heterogeneous graphs. It uses graph transformer layer to learn potential interactions information between different nodes from multiple heterogeneous graphs (<xref rid="B33" ref-type="bibr">Shi et al., 2016</xref>) and apply learned information to node classification tasks. The crucial idea of GTN is heterogeneous network representation learning, which is suitable for exploring the interaction between different types of nodes is helpful for the performance improvement of classification tasks. For drug ATC code prediction, we integrate drugs and drug-related biomedical entities including targets and diseases. Then, we use the known interactions information to construct a set of heterogeneous networks, which contains information about different nodes. GTN model can be used to find potential interactions between different entities from these constructed heterogeneous networks, and these potential interactions can help to predict the ATC code of drugs. Therefore, a new first-level drug ATC code prediction model DACPGTN is proposed based on GTN.</p>
    <p>DACPGTN predicts the first-level ATC code for a given drug by applying biomedial features and interactions of drugs, diseases and targets. In the study, drug-drug similarity information was obtained by integrating different types of compound interactions. Meanwhile, the similarity information of drug-related target proteins and diseases is calculated based on the known interactions between biomedical entities. The similarity information was used to construct a composite feature matrix. Next, we consider the introduction of drug-target protein, drug-disease and target protein-disease interactions information. Based on the known interactions information, a set of interaction heterogeneous networks between different biomedical entities are constructed. Then, the graph structure of the potential interactions information between drug-target protein-disease can be obtained by using the graph transformer layer. Finally, the composite feature matrix and the learned potential interactions information networks are fed into the prediction module for learning. According to the above steps, we can obtain the final prediction of the drug ATC code. Experiments on the benchmark datasets demonstrate that the DACPGTN model can achieve better prediction performance than the existing methods.</p>
    <p>The main contributions of this article are as follows:<list list-type="simple"><list-item><p>1) For the drug ATC code prediction task, the DACPGTN model considers the impact of integration drug-related biomedical entity information including target proteins and diseases on drug ATC code prediction performance.</p></list-item><list-item><p>2) By utilizing graph transformer network and multiple heterogeneous networks, DACPGTN learns potential valuable interactions information for identifying ATC code for drugs.</p></list-item><list-item><p>3) In this study, the GTN model is improved to address the problem of drug ATC code prediction. The previous research transformed the drug ATC code prediction problem into multiple independent binary classification problems (<xref rid="B21" ref-type="bibr">Kumari and Srivastava, 2017</xref>). By using cross-entropy loss function and softmax function, we improved the GTN model and solved the class-imbalance and complex parameter settings for model training. Moreover, prediction performance can be improved by using linear layers and adding Dropout layers between layers.</p></list-item></list>
</p>
  </sec>
  <sec id="s2">
    <title>2 Materials</title>
    <sec id="s2-1">
      <title>2.1 Dataset</title>
      <sec id="s2-1-1">
        <title>2.1.1 Drugs and Anatomical Therapeutic Chemical Codes</title>
        <p>For the ATC Code prediction problem, <xref rid="B5" ref-type="bibr">Chen et al. (2012)</xref> constructed benchmark dataset to facilitate comparison of models at the first-level of the ATC code. The benchmark dataset contains 3,883 drugs with one or more first-level classes of the ATC code. Moreover, we have collected drug related target proteins and diseases from the KEGG (<xref rid="B19" ref-type="bibr">Kanehisa and Goto, 2000</xref>) and Drugbank (<xref rid="B44" ref-type="bibr">Wishart et al., 2008</xref>), which are publicly available databases involving substantial data describing drugs, diseases, target proteins and interactions among them. Filtering the collected data revealed that 1,749 out of 3,883 drugs have target or disease information. Then, these 1,749 drugs were used as the benchmark dataset in our experiments. In this study, the prediction of a drug’s first-level ATC code is formulated as a multi-label problem (<xref rid="B40" ref-type="bibr">Tsoumakas and Katakis, 2007</xref>). For each given drug, it may have two or more labels to annotate its classification. The statistics for ATC code label information of all drugs in our dataset is shown in <xref rid="F1" ref-type="fig">Figure 1</xref>.</p>
        <fig position="float" id="F1">
          <label>FIGURE 1</label>
          <caption>
            <p>Benchmark dataset label information analysis.</p>
          </caption>
          <graphic xlink:href="fphar-13-907676-g001" position="float"/>
        </fig>
        <p>Meanwhile, the dataset can be represented as a set of elements as: <italic>S</italic> = <italic>S</italic>
<sub>1</sub> ∪ <italic>S</italic>
<sub>2</sub> ∪ <italic>S</italic>
<sub>3</sub>⋯ ∪ <italic>S</italic>
<sub>13</sub> ∪ <italic>S</italic>
<sub>14</sub>, where <italic>S</italic>
<sub><italic>i</italic></sub> represents drugs in the <italic>i</italic>th class. Let <italic>D</italic>
<sub><italic>i</italic></sub> represents the <italic>i</italic>th drug, and <inline-formula id="inf1"><mml:math id="m1" overflow="scroll"><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mfenced open="{" close="}"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3333em" class="nbsp"/><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3333em" class="nbsp"/><mml:mo>⋯</mml:mo><mml:mspace width="0.17em"/><mml:mo>,</mml:mo><mml:mspace width="0.3333em" class="nbsp"/><mml:mn>14</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> represents the label of drug-class. The 1,749 drug compounds in the dataset can be classified into 14 ATC classes, as shown in <xref rid="T1" ref-type="table">Table 1</xref>. The ATC code labels for each given drug can be represented by a 14-bit binary vector defined as <inline-formula id="inf2"><mml:math id="m2" overflow="scroll"><mml:mi>L</mml:mi><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced open="[" close="]"><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.3333em" class="nbsp"/><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.3333em" class="nbsp"/><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mspace width="0.3333em" class="nbsp"/><mml:mo>,</mml:mo><mml:mspace width="0.3333em" class="nbsp"/><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">i13</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.3333em" class="nbsp"/><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">i14</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mspace width="0.3333em" class="nbsp"/><mml:mspace width="0.3333em" class="nbsp"/><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1,2,3</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mn>1749</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>. Where <italic>L</italic>
<sub><italic>ij</italic></sub> represents the relationship between drug <italic>D</italic>
<sub><italic>i</italic></sub> and first-level ATC code class <italic>j</italic>. The value of <italic>L</italic>
<sub><italic>ij</italic></sub> is defined as follows:<disp-formula id="equ1"><mml:math id="m3" overflow="scroll"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="{" close=""><mml:mrow><mml:mtable class="cases"><mml:mtr><mml:mtd columnalign="left"><mml:mtable class="array"><mml:mtr><mml:mtd columnalign="left"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.3333em" class="nbsp"/><mml:mspace width="0.3333em" class="nbsp"/><mml:mi>D</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>g</mml:mi><mml:mspace width="0.3333em" class="nbsp"/><mml:mspace width="0.3333em" class="nbsp"/><mml:mi>i</mml:mi><mml:mspace width="0.3333em" class="nbsp"/><mml:mspace width="0.3333em" class="nbsp"/><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mi>s</mml:mi><mml:mspace width="0.3333em" class="nbsp"/><mml:mspace width="0.3333em" class="nbsp"/><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mspace width="0.3333em" class="nbsp"/><mml:mspace width="0.3333em" class="nbsp"/><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mspace width="0.3333em" class="nbsp"/><mml:mspace width="0.3333em" class="nbsp"/><mml:mi>j</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mspace width="1em"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mtable class="array"><mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mspace width="1em"/></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math></disp-formula>
</p>
        <table-wrap position="float" id="T1">
          <label>TABLE 1</label>
          <caption>
            <p>The 1749 drug compounds in the benchmark dataset are broken down into 14 ATC classes.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead valign="top">
              <tr>
                <th align="left" rowspan="1" colspan="1">Subset</th>
                <th align="center" rowspan="1" colspan="1">Name</th>
                <th align="center" rowspan="1" colspan="1">Number of Drugs</th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <italic>S</italic>
                  <sub>1</sub>
                </td>
                <td align="left" rowspan="1" colspan="1">Alimentary tract and metabolism</td>
                <td align="char" char="." rowspan="1" colspan="1">221</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <italic>S</italic>
                  <sub>2</sub>
                </td>
                <td align="left" rowspan="1" colspan="1">Blood and blood forming organs</td>
                <td align="char" char="." rowspan="1" colspan="1">44</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <italic>S</italic>
                  <sub>3</sub>
                </td>
                <td align="left" rowspan="1" colspan="1">Cardiovascular system</td>
                <td align="char" char="." rowspan="1" colspan="1">287</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <italic>S</italic>
                  <sub>4</sub>
                </td>
                <td align="left" rowspan="1" colspan="1">Dermatologicals</td>
                <td align="char" char="." rowspan="1" colspan="1">182</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <italic>S</italic>
                  <sub>5</sub>
                </td>
                <td align="left" rowspan="1" colspan="1">Genitourinary system and sex hormones</td>
                <td align="char" char="." rowspan="1" colspan="1">127</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <italic>S</italic>
                  <sub>6</sub>
                </td>
                <td align="left" rowspan="1" colspan="1">Systemic hormonal preparations, excluding sex hormones and insulins</td>
                <td align="char" char="." rowspan="1" colspan="1">68</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <italic>S</italic>
                  <sub>7</sub>
                </td>
                <td align="left" rowspan="1" colspan="1">Anti-infectives for systemic use</td>
                <td align="char" char="." rowspan="1" colspan="1">273</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <italic>S</italic>
                  <sub>8</sub>
                </td>
                <td align="left" rowspan="1" colspan="1">Antineoplastic and immunomodulating agents</td>
                <td align="char" char="." rowspan="1" colspan="1">129</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <italic>S</italic>
                  <sub>9</sub>
                </td>
                <td align="left" rowspan="1" colspan="1">Musculo-skeletal system</td>
                <td align="char" char="." rowspan="1" colspan="1">91</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <italic>S</italic>
                  <sub>10</sub>
                </td>
                <td align="left" rowspan="1" colspan="1">Nervous system</td>
                <td align="char" char="." rowspan="1" colspan="1">382</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <italic>S</italic>
                  <sub>11</sub>
                </td>
                <td align="left" rowspan="1" colspan="1">Antiparasitic products, insecticides and repellents</td>
                <td align="char" char="." rowspan="1" colspan="1">48</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <italic>S</italic>
                  <sub>12</sub>
                </td>
                <td align="left" rowspan="1" colspan="1">Respiratory system</td>
                <td align="char" char="." rowspan="1" colspan="1">189</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <italic>S</italic>
                  <sub>13</sub>
                </td>
                <td align="left" rowspan="1" colspan="1">Sensory organs</td>
                <td align="char" char="." rowspan="1" colspan="1">222</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <italic>S</italic>
                  <sub>14</sub>
                </td>
                <td align="left" rowspan="1" colspan="1">Various</td>
                <td align="char" char="." rowspan="1" colspan="1">45</td>
              </tr>
              <tr>
                <td colspan="2" align="left" rowspan="1">Number of total virtual drugs</td>
                <td align="char" char="." rowspan="1" colspan="1">2308<xref rid="Tfn1" ref-type="table-fn"><sup>a</sup></xref>
</td>
              </tr>
              <tr>
                <td colspan="2" align="left" rowspan="1">Number of total structural different drugs</td>
                <td align="char" char="." rowspan="1" colspan="1">1749</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="Tfn1">
              <label>a</label>
              <p>The number of virtual drugs is calculated as follows: when a drug belongs to two different classes at the same time, it is counted as two virtual drugs. If a drug belongs to three different classes at the same time, it is counted as three virtual drugs, and so on.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec id="s2-1-2">
        <title>2.1.2 Drug Targets and Indications</title>
        <p>As mentioned above, the target proteins and diseases associated with 1749 drugs in the experiment were extracted from KEGG (<xref rid="B19" ref-type="bibr">Kanehisa and Goto, 2000</xref>) and Drugbank (<xref rid="B44" ref-type="bibr">Wishart et al., 2008</xref>), the two most widely used drug information databases. Specifically, the drug-related target proteins in the experiment were obtained from Drugbank, and we pre-processed the available information using the conversion tool provided on the Uniprot website to obtain 982 targets associated with the 1,749 drugs. Then, the drug-related diseases in the experiment were obtained from the KEGG database, and based on the known interactions information, a total of 355 related diseases were obtained. <xref rid="T2" ref-type="table">Table 2</xref> summarizes the dataset in terms of numbers of drugs, target proteins, and diseases, as well as the interactions among them.</p>
        <table-wrap position="float" id="T2">
          <label>TABLE 2</label>
          <caption>
            <p>Statistics of the Benchmark standard dataset used in this study.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead valign="top">
              <tr>
                <th align="left" rowspan="1" colspan="1">Dataset</th>
                <th align="center" rowspan="1" colspan="1">Drugs</th>
                <th align="center" rowspan="1" colspan="1">Targets</th>
                <th align="center" rowspan="1" colspan="1">Diseases</th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">1749</td>
                <td align="center" rowspan="1" colspan="1">982</td>
                <td align="center" rowspan="1" colspan="1">355</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Interactions</td>
                <td align="center" rowspan="1" colspan="1">Drug-Target</td>
                <td align="center" rowspan="1" colspan="1">Drug-Disease</td>
                <td align="center" rowspan="1" colspan="1">Target-Disease</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">6,370</td>
                <td align="center" rowspan="1" colspan="1">1,285</td>
                <td align="center" rowspan="1" colspan="1">288</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
    </sec>
    <sec id="s2-2">
      <title>2.2 Construction of Similarity Matrix and Heterogeneous Networks</title>
      <sec id="s2-2-1">
        <title>2.2.1 Drug, Target, and Disease Similarity Matrix</title>
        <p>In this study, seven types of drug-drug similarity information for 1749 drugs extracted from the previous literature (<xref rid="B49" ref-type="bibr">Zhao et al., 2021</xref>). <italic>SM</italic>
<sub><italic>Sim</italic></sub>, <italic>SM</italic>
<sub>Exp</sub>, <italic>SM</italic>
<sub><italic>Dat</italic></sub>, <italic>SM</italic>
<sub><italic>Tex</italic></sub>, <italic>SM</italic>
<sub><italic>Com</italic></sub> were obtained from the interaction information of “similarity”, “experimental”, “database”, “text mining” and “Combined score” between drug pairs. <italic>SM</italic>
<sub><italic>cp</italic></sub> and <italic>SM</italic>
<sub><italic>sub</italic></sub> were obtained using the compound similarity calculation tools SIMCOMP and SUBCOMP provided by the KEGG dataset. A single data source may be incomplete or limited, and it is extremely important to integrate various biomedical data from multiple sources in practice (<xref rid="B25" ref-type="bibr">Luo et al., 2021</xref>). Data integration helps to improve the accuracy of the data and the performance of drug repositioning, and we used averaging operations on the seven similarity matrices to obtain the final drug-drug similarity score matrix <italic>M</italic>
<sub><italic>RR</italic></sub>.</p>
        <p>For the 982 target proteins used in the experiments, combined score between proteins were obtained from the String library (<xref rid="B37" ref-type="bibr">Szklarczyk et al., 2019</xref>) to construct a protein-protein interaction score matrix. The combined score represents interaction strength between the two proteins. The larger the combined score, the stronger the interaction between the two proteins. After processing with the min-max normalization method, protein-protein similarity scores matrix <italic>M</italic>
<sub><italic>TT</italic></sub> is obtained.</p>
        <p>Based on the hypothesis that similar drugs may treat similar diseases, we integrated disease similarity information for identifying the key features of drugs to assist the ATC code prediction in our study. Disease similarity is calculated by utilizing known interaction information between diseases and drugs (<xref rid="B26" ref-type="bibr">Luo et al., 2016</xref>). Specifically, for the 355 diseases in our experiments, we construct a drug-disease interactions matrix by using all drugs in the <xref rid="B5" ref-type="bibr">Chen et al. (2012)</xref> benchmark dataset. As for this drug-disease interactions matrix, if there exists an interaction between drug <italic>R</italic>
<sub><italic>i</italic></sub> and disease <italic>D</italic>
<sub><italic>j</italic></sub>, the edge weight of <italic>R</italic>
<sub><italic>i</italic></sub> and <italic>D</italic>
<sub><italic>j</italic></sub> is initially assigned as 1 and otherwise 0. Finally, the Pearson correlation coefficient (<xref rid="B3" ref-type="bibr">Benesty et al., 2009</xref>) of the matrix is calculated to obtain the disease-disease similarity matrix <italic>M</italic>
<sub><italic>DD</italic></sub>.</p>
      </sec>
      <sec id="s2-2-2">
        <title>2.2.2 Drug-Target-Disease Heterogeneous Networks</title>
        <p>We collected the known interactions information of the three biomedical entity nodes of drugs, target proteins, and diseases in the KEGG and Drugbank databases. The known interactions information is used to construct the corresponding heterogeneous network.</p>
        <p>More specifically, we let <inline-formula id="inf3"><mml:math id="m4" overflow="scroll"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mspace width="0.3333em" class="nbsp"/><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> denotes <italic>m</italic> drugs, <inline-formula id="inf4"><mml:math id="m5" overflow="scroll"><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mspace width="0.3333em" class="nbsp"/><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> denotes the <italic>q</italic> targets and <inline-formula id="inf5"><mml:math id="m6" overflow="scroll"><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mspace width="0.3333em" class="nbsp"/><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> denotes the <italic>n</italic> disease. The drug-target network contains <italic>m</italic> drugs and <italic>q</italic> targets, if there exists an interaction between drug <italic>R</italic>
<sub><italic>i</italic></sub> and target <italic>T</italic>
<sub><italic>j</italic></sub>, the edge weight of <italic>R</italic>
<sub><italic>i</italic></sub> and <italic>T</italic>
<sub><italic>j</italic></sub> is initially assigned as 1 and otherwise 0. Likewise, the drug-disease network includes <italic>m</italic> drugs and <italic>n</italic> diseases, if there exists an interaction between drug <italic>R</italic>
<sub><italic>i</italic></sub> and disease <italic>D</italic>
<sub><italic>j</italic></sub>, the edge weight of <italic>R</italic>
<sub><italic>i</italic></sub> and <italic>D</italic>
<sub><italic>j</italic></sub> is initially assigned as 1 and otherwise 0. Meanwhile, the target-disease network consists of <italic>q</italic> targets and <italic>n</italic> diseases, if there exists an interaction between target <italic>T</italic>
<sub><italic>i</italic></sub> and disease <italic>D</italic>
<sub><italic>j</italic></sub>, the edge weight of <italic>T</italic>
<sub><italic>i</italic></sub> and <italic>D</italic>
<sub><italic>j</italic></sub> is initially assigned as 1 and otherwise 0. <italic>H</italic>
<sub><italic>RT</italic></sub>, <italic>H</italic>
<sub><italic>DD</italic></sub> and <italic>H</italic>
<sub><italic>TD</italic></sub> are defined as the interaction matrices of drug-target network, drug-disease network and target-disease network, respectively.</p>
      </sec>
    </sec>
  </sec>
  <sec id="s3">
    <title>3 Drug Anatomical Therapeutic Chemical Code Prediction Model Based on GTN</title>
    <p>In this study, we have proposed a DACPGTN model for multi-label prediction of drug ATC code based on the GTN model. We first integrate the drugs and their associated target proteins and diseases, and construct a composite feature matrix by using the similarity information of the three biomedical entities as features. Meanwhile, a set of heterogeneous networks are constructed based on the known interactions information between different biomedical entities. Based on the Graph Transformer Network (<xref rid="B46" ref-type="bibr">Yun et al., 2019</xref>), the potential interactions information between drug-target-disease is obtained from these heterogeneous networks, which has an impact on the prediction of drug ATC code. Then, the constructed composite feature matrix and the learned potential interactions information between biomedical entities are fed into the end-to-end prediction module to obtain the ATC code prediction results for a given drug. The overall framework of the DACPGTN model is shown in <xref rid="F2" ref-type="fig">Figure 2</xref>.</p>
    <fig position="float" id="F2">
      <label>FIGURE 2</label>
      <caption>
        <p>Overall framework of DACPGTN. The feature information of different biomedical entities is integrated to construct a composite feature matrix as the node feature input of the prediction module (Part A). The graph transformer layer is used to obtain the potential interactions information between different biomedical entities from heterogeneous networks set (Part B). The prediction stage uses the composite feature matrix and the learned Potential Interactions Information Networks to obtain prediction results (Part C).</p>
      </caption>
      <graphic xlink:href="fphar-13-907676-g002" position="float"/>
    </fig>
    <sec id="s3-1">
      <title>3.1 Construction of Composite Feature Matrix</title>
      <p>The similarity information of the three biomedical entities including drugs, targets and diseases is used to construct similarity matrix representing their features. Principal component analysis (PCA) (<xref rid="B1" ref-type="bibr">Abdi and Williams, 2010</xref>), commonly used technique for dimension reduction, is used to project drugs, targets and diseases into a low-dimensional space. Then, these low-dimensional matrices are unified to obtain the corresponding feature matrix. Using PCA can remove the noise data to a certain extent, maximize the retention features at the same time, provide valuable information for drug ATC code prediction. It is verified experimentally that the model has the best training effect when the dimension is 300. After unifying the feature dimensions, the feature matrices of the three biomedical entities are spliced to obtain the final node composite feature matrix <inline-formula id="inf6"><mml:math id="m7" overflow="scroll"><mml:mi>F</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mtext>_</mml:mtext><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="[" close="]"><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> (Part A of <xref rid="F2" ref-type="fig">Figure 2</xref>).</p>
    </sec>
    <sec id="s3-2">
      <title>3.2 Learning Potential Interactions Between Entities Based on Graph Transformer Layer</title>
      <p>In this study, the graph transformer model is applied to learn valuable interactions information between drugs, targets and diseases from the heterogeneous networks constructed above. The constructed drug-target heterogeneous network, drug-disease heterogeneous network, and target-disease heterogeneous network are sequentially transposed and the dimensions are unified. Then, the set of heterogeneous networks <inline-formula id="inf7"><mml:math id="m8" overflow="scroll"><mml:mi mathvariant="double-struck">A</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula>is obtained. The graph transformer layer is used for set <inline-formula id="inf8"><mml:math id="m9" overflow="scroll"><mml:mi mathvariant="double-struck">A</mml:mi></mml:math></inline-formula> to obtain networks of potential interactions information between three biomedical entities: drugs, target proteins and diseases. The transfer of interaction information between nodes is achieved by multiplication operations between different associated heterogeneous networks (<xref rid="B43" ref-type="bibr">Wang et al., 2019a</xref>) (Part B of <xref rid="F2" ref-type="fig">Figure 2</xref>).</p>
      <p>Specifically, the graph transformer layer is used to perform a soft selection of different edge types and composite relations (<xref rid="B6" ref-type="bibr">Chen et al., 2018</xref>) to find new graph structures from multiple candidate heterogeneous networks. The graph transformer layer is implemented as <xref rid="e1" ref-type="disp-formula">formula (1)</xref>:<disp-formula id="e1"><mml:math id="m10" overflow="scroll"><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="double-struck">A</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>ϕ</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="double-struck">A</mml:mi><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math><label>(1)</label></disp-formula>Where <italic>ϕ</italic> is the convolution layer and <italic>W</italic>
<sub><italic>ϕ</italic></sub> ∈ <bold>R</bold>
<sup>1×1×<italic>K</italic>
</sup> is the parameter of the convolution layer <italic>ϕ</italic>.</p>
      <p>The graph transformer layer selects different types of interaction matrices from the set <inline-formula id="inf9"><mml:math id="m11" overflow="scroll"><mml:mi mathvariant="double-struck">A</mml:mi></mml:math></inline-formula>. Then, a new graph structure is learned by matrix multiplication of the selected interaction matrices <italic>Q</italic>
<sub>1</sub> and <italic>Q</italic>
<sub>2</sub>. The soft selection of the interaction matrix refers to obtaining non-negative weights from <inline-formula id="inf10"><mml:math id="m12" overflow="scroll"><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>φ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, and perform 1 × 1 convolution weighted summation over the candidate matrices in the heterogeneous network set <inline-formula id="inf11"><mml:math id="m13" overflow="scroll"><mml:mi mathvariant="double-struck">A</mml:mi></mml:math></inline-formula>. In the implementation process, the constructed interaction matrix is operated on graph transformer layer by <xref rid="e2" ref-type="disp-formula">Eq. 2</xref>–<xref rid="e4" ref-type="disp-formula">4</xref>, each <italic>Q</italic>
<sub>1</sub> can be expressed as <inline-formula id="inf12"><mml:math id="m14" overflow="scroll"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">T</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula id="inf13"><mml:math id="m15" overflow="scroll"><mml:msup><mml:mrow><mml:mi mathvariant="script">T</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> represents the set of networks, <italic>l</italic> represents the <italic>l</italic>-th graph transformer layer, and <inline-formula id="inf14"><mml:math id="m16" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math></inline-formula> represents the weight of the current network matrix in the <italic>l</italic>th layer. The connection between different nodes is obtained by multiplication of different types of interaction matrices. For <inline-formula id="inf15"><mml:math id="m17" overflow="scroll"><mml:mi mathvariant="double-struck">A</mml:mi></mml:math></inline-formula>, the graph transformer layer is used to learn potential interactions information between the three biomedical entities to obtain a new graph information matrix.</p>
      <p>When the weight-based graph structure is obtained, the multiplication operation between the new graph structures is performed. To improve numerical stability, the interaction matrix obtained for each layer is normalized by its degree matrix <italic>D</italic>
<sup>−1</sup>.<disp-formula id="e2"><mml:math id="m18" overflow="scroll"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="double-struck">A</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>ϕ</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="double-struck">A</mml:mi><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math><label>(2)</label></disp-formula>
<disp-formula id="e3"><mml:math id="m19" overflow="scroll"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="double-struck">A</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>ϕ</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="double-struck">A</mml:mi><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math><label>(3)</label></disp-formula>
<disp-formula id="e4"><mml:math id="m20" overflow="scroll"><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><label>(4)</label></disp-formula>
</p>
      <p>The graph transformer layer can also learn a variety of connection relationships between different node types. To learn multiple potential interaction information networks between biomedical entities simultaneously, we use <italic>C</italic> channels in parallel to accomplish this operation and add the identity matrix <italic>I</italic> to <inline-formula id="inf16"><mml:math id="m21" overflow="scroll"><mml:mi mathvariant="double-struck">A</mml:mi></mml:math></inline-formula> for learning variable-length interaction information. By setting the output channels of the 1 × 1 convolution in the graph transformer layer to multi-channel <italic>C</italic>, the adjacency matrices <italic>Q</italic>
<sub>1</sub>, <italic>Q</italic>
<sub>2</sub> become adjacency tensor <inline-formula id="inf17"><mml:math id="m22" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="double-struck">Q</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="double-struck">Q</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>. After stacking <italic>l</italic> graph transformer layers, the tensor <inline-formula id="inf18"><mml:math id="m23" overflow="scroll"><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is obtained.</p>
      <p>In order to discover potential interactions between different nodes to inform the label prediction of drug nodes, the graph transformation layer is applied to the heterogeneous network sets <inline-formula id="inf19"><mml:math id="m24" overflow="scroll"><mml:mi mathvariant="double-struck">A</mml:mi></mml:math></inline-formula> to learn the node interactions information in each associated heterogeneous network. For example, according to the relationship of drug-target protein, target protein-disease, etc., we can learn the interactions between the drug and potential disease, such as <inline-formula id="inf20"><mml:math id="m25" overflow="scroll"><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>D</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mover><mml:mrow><mml:mo>→</mml:mo></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mtext>_</mml:mtext><mml:mi>T</mml:mi></mml:mrow></mml:mover></mml:mrow><mml:mi>T</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mover><mml:mrow><mml:mo>→</mml:mo></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mtext>_</mml:mtext><mml:mi>D</mml:mi></mml:mrow></mml:mover></mml:mrow><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, etc.</p>
    </sec>
    <sec id="s3-3">
      <title>3.3 Realization of End-To-End Prediction of DACPGTN Model</title>
      <p>For the prediction module of the DACPGTN model, we use GCN as the feature extractor of the end-to-end module, and then take the node composite feature matrix and the learned potential interactions information as the input of the end-to-end prediction module. Embeddings of drug nodes are extracted through GCN, multiple linear layers and Dropout (<xref rid="B34" ref-type="bibr">Srivastava et al., 2014</xref>) layers are combined to predict the final drug ATC code. A novel loss function is introduced to complete the training of the model in this experiment. The detailed implementation process of the end-to-end prediction module is shown in Part C of <xref rid="F2" ref-type="fig">Figure 2</xref>.</p>
      <sec id="s3-3-1">
        <title>3.3.1 Graph Convolutional Neural Network Learning on Composite Feature Matrix and New Graph Structure</title>
        <p>Graph Convolutional Neural Network (GCN) (<xref rid="B20" ref-type="bibr">Kipf and Welling, 2016</xref>) is a semi-supervised learning algorithm, which is used for the convolutional operation of the associated information graph structure and the composite feature matrix. For the GCN network, layer-to-layer propagation is performed according to <xref rid="e5" ref-type="disp-formula">formula (5)</xref>:<disp-formula id="e5"><mml:math id="m26" overflow="scroll"><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math><label>(5)</label></disp-formula>Where <inline-formula id="inf21"><mml:math id="m27" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is a new graph matrix generated by graph transformer layer, <inline-formula id="inf22"><mml:math id="m28" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is the degree matrix of <inline-formula id="inf23"><mml:math id="m29" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, <italic>H</italic> is the input feature of the current GCN network layer, that is, the constructed node feature matrix, <italic>W</italic>
<sup>(<italic>l</italic>)</sup> ∈ <bold>R</bold>
<sup><italic>d</italic>×<italic>d</italic></sup> is a trainable weight matrix, <italic>H</italic>
<sup>(<italic>l</italic>+1)</sup> is the output of the feature matrix of the GCN network layer, and <italic>σ</italic> represents the activation function Relu. When the output channel of the graph transformer layer 1 × 1 convolution is set to multi-channel <italic>C</italic>, the GCN layer is applied to each channel of the tensor, and the multi-channel operation is performed through <xref rid="e6" ref-type="disp-formula">formula (6)</xref>.<disp-formula id="e6"><mml:math id="m30" overflow="scroll"><mml:mi>Z</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msubsup><mml:mi>σ</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mi>X</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:mfenced></mml:math><label>(6)</label></disp-formula>Where ∥ represents the connection operator, <italic>C</italic> represents the number of output channels, <inline-formula id="inf24"><mml:math id="m31" overflow="scroll"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>I</mml:mi></mml:math></inline-formula> represents the <italic>i</italic>th adjacency matrix of the tensor <inline-formula id="inf25"><mml:math id="m32" overflow="scroll"><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:math></inline-formula> add the identity matrix <italic>I</italic>, <inline-formula id="inf26"><mml:math id="m33" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> represents the degree matrix of <inline-formula id="inf27"><mml:math id="m34" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math></inline-formula>, <italic>W</italic> ∈ <bold>R</bold>
<sup><italic>d</italic>×<italic>d</italic></sup> represents the trainable cross-channel shared weight matrix, <italic>X</italic> ∈ <bold>R</bold>
<sup><italic>N</italic>×<italic>d</italic></sup> represents the feature matrix <italic>Feature</italic>_<italic>A</italic>, <italic>N</italic> and <italic>d</italic> represent the number of biomedical entity nodes and the node features dimension in <italic>Feature</italic>_<italic>A</italic>, respectively.</p>
        <p>The GCN network obtain dimension-specific drug node embeddings after a convolution operation on the node feature matrix <italic>Feature</italic>_<italic>A</italic> and the adjacency tensors <inline-formula id="inf28"><mml:math id="m35" overflow="scroll"><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:math></inline-formula>. For the case of networks with few nodes, it has been shown in the literature that if a GCN network is stacked with multiple layers, the output features may be over-smoothed and vertices from different clusters may become indistinguishable (<xref rid="B24" ref-type="bibr">Li et al., 2018</xref>; <xref rid="B22" ref-type="bibr">Li et al., 2019</xref>). In this study, limited by few nodes, the GCN network used in the feature extraction module has only one layer. The drug nodes embedding extracted by the GCN network is used as the input information for the next part of the linear layers.</p>
      </sec>
      <sec id="s3-3-2">
        <title>3.3.2 Transformation of Multi-Label Problem</title>
        <p>As a multi-label classification problem, drug ATC code prediction differs from the traditional single-label multi-classification task. It requires that the prediction output of the model is not a fixed value. For a given drug, it may have one or more labels representing its classification information at the same time, which further increases the requirements of the classifier. For this problem, the common idea of previous research is to transform the multi-label classification problem into multiple independent binary classification problems. Each binary classification problem corresponds to a label in the label vector and determines the drug’s ATC code. For multiple independent binary classification problems, the sigmoid activation function with binary classification cross-entropy loss (BCEloss) is used to average the loss of all binary classifications, which is applied to model training to obtain the final prediction result. When the real class of the sample is far less than the number of all classes of the problem, there will be a class-imbalance problem, and some balance strategies are generally used to solve this problem. For example, setting a threshold for each binary classification problem or manually adjusting the weights of positive and negative samples, etc. To simplify the complex series of operations after transforming a multi-label problem into multiple independent binary classification problems, we refer to Su’s use of Circle loss (<xref rid="B35" ref-type="bibr">Su, 2020</xref>; <xref rid="B36" ref-type="bibr">Sun et al., 2020</xref>). The softmax activation function is combined with the Cross-Entropy Loss function for multi-label classification problems. The implementation is as follows:</p>
        <p>In a single-label classification problem, assuming that the scores of each class are <inline-formula id="inf29"><mml:math id="m36" overflow="scroll"><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, and the target class is <italic>t</italic> ∈ {1, 2, … , <italic>n</italic>}, its cross-entropy loss function is defined as <xref rid="e7" ref-type="disp-formula">formula (7)</xref>:<disp-formula id="e7"><mml:math id="m37" overflow="scroll"><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mo movablelimits="false" form="prefix">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mo movablelimits="false" form="prefix">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math><label>(7)</label></disp-formula>
</p>
        <p>It can be derived as an approximation of the max function as shown in <xref rid="e8" ref-type="disp-formula">formula (8)</xref>:<disp-formula id="e8"><mml:math id="m38" overflow="scroll"><mml:mi>log</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>≈</mml:mo><mml:mi>max</mml:mi><mml:mfenced open="{" close="}"><mml:mrow><mml:mtable class="matrix"><mml:mtr><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math><label>(8)</label></disp-formula>
</p>
        <p>In this loss, all non-target class scores <inline-formula id="inf30"><mml:math id="m39" overflow="scroll"><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mspace width="0.3333em" class="nbsp"/><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mspace width="0.3333em" class="nbsp"/><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> are compared with target class scores <italic>S</italic>
<sub><italic>t</italic></sub> and their maximum difference should be less than zero, thus ensuring that target class score is greater than each non-target class score. In the multi-label classification problem, we also want each target class score to be no less than the score of each non-target class, and the generalization of Loss is obtained according to the same principle (<xref rid="B36" ref-type="bibr">Sun et al., 2020</xref>), as <xref rid="e9" ref-type="disp-formula">formula (9)</xref>:<disp-formula id="e9"><mml:math id="m40" overflow="scroll"><mml:mi>log</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">neg</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">neg</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math><label>(9)</label></disp-formula>Where Ω<sub><italic>pos</italic></sub> and Ω<sub><italic>neg</italic></sub> are the set of target and non-target classes for a given sample in the multi-label problem, respectively.</p>
        <p>When the samples have a fixed number of labels <italic>k</italic> in a multi-label classification problem, the above formula can be used directly to output the <italic>k</italic> classes with the top score in the prediction stage. In the actual multi-label prediction problem, the number of labels <italic>k</italic> owned by the sample is a constant with non-fixed value, and a threshold is needed to determine all classes of the sample. To this end, an additional class of <italic>S</italic>
<sub>0</sub> is introduced, and it is desired that all scores of the target class are greater than <italic>S</italic>
<sub>0</sub> and all scores of the non-target class are less than <italic>S</italic>
<sub>0</sub>, which is obtained as <xref rid="e10" ref-type="disp-formula">formula (10)</xref>:<disp-formula id="e10"><mml:math id="m41" overflow="scroll"><mml:mi>log</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">neg</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">neg</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">neg</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math><label>(10)</label></disp-formula>
</p>
        <p>Setting the threshold <italic>S</italic>
<sub>0</sub> to the default value of 0, we can get the simplified <xref rid="e10" ref-type="disp-formula">formula (10)</xref> of <xref rid="e11" ref-type="disp-formula">formula (11)</xref>:<disp-formula id="e11"><mml:math id="m42" overflow="scroll"><mml:mi>log</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">neg</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math><label>(11)</label></disp-formula>
</p>
        <p>The final Loss is obtained as a generalization of the softmax activation function with the cross-entropy loss function on the multi-label classification problem, as <xref rid="e12" ref-type="disp-formula">formula (12)</xref>:<disp-formula id="e12"><mml:math id="m43" overflow="scroll"><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">true</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">pred</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mspace width="0.3333em" class="nbsp"/><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">pred−neg</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">pred−pos</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced></mml:math><label>(12)</label></disp-formula>
</p>
        <p>In this experiment, <xref rid="e12" ref-type="disp-formula">formula(12)</xref> is used to calculate the loss. Once the loss is obtained, backpropagation is performed to train the model. In the prediction stage of the model, classes with target scores greater than 0 are output. Compared with the methods in previous ATC code prediction studies, the multi-label problem is no longer transformed into multiple binary classifications, but into the comparison of target class scores and non-target class scores. In the optimization process, the logsumexp function (<xref rid="B4" ref-type="bibr">Blanchard et al., 2019</xref>) automatically takes part with the largest loss for learning. The logsumexp function will reduce the weight of the items that have been optimized well, and highlight the items with larger errors, and the class-imbalance problem is solved to some extent.</p>
      </sec>
      <sec id="s3-3-3">
        <title>3.3.3 Predicting Drug Anatomical Therapeutic Chemical Code</title>
        <p>After extracting the feature embedding of nodes through the GCN(<xref rid="B20" ref-type="bibr">Kipf and Welling, 2016</xref>) network, we further process the embedding of drug nodes using linear layers and Dropout (<xref rid="B34" ref-type="bibr">Srivastava et al., 2014</xref>) layers to obtain better drug ATC code prediction performance. Specifically, the drug nodes embedding extracted by the GCN module is used as the input of the first linear layer. The output dimension of the last linear layer is the same as the dimension of the drug ATC label vector, which is used as the prediction result of the drug ATC code, and the model is optimized using the loss function introduced above. To solve the problem of multi-layer network stacking, a Relu activation function (<xref rid="B2" ref-type="bibr">Agarap, 2018</xref>) is used after the first linear layer, and Dropout layers are added between subsequent linear layers. The Dropout layer removes the neuron nodes from the network with a certain probability. In random gradient descent, the randomly removed neurons can make each iteration train a different network and increase the diversification of the network, thus improving the generalization ability of the model.</p>
      </sec>
    </sec>
  </sec>
  <sec id="s4">
    <title>4 Experiments and Results</title>
    <p>In this section, our experiments are performed on the benchmark dataset. First, the evaluation metrics used in this study are introduced. Then, the performance of DACPGTN is evaluated in comparison with several state-of-the-art drug ATC code prediction methods. Next, the effects of parameters and multiple sources of information on the DACPGTN model are analyzed through experiments.</p>
    <sec id="s4-1">
      <title>4.1 Evaluation Metrics</title>
      <p>For multi-label classification problems, since the samples have one or more labels at the same time, traditional single-label evaluation metrics are not applicable here. Compared with the traditional single-label evaluation metrics, the evaluation metrics for multi-label problems are more complex and complete. Five evaluation metrics for evaluating the performance of multi-label classifiers are defined in the literature published by Chou (<xref rid="B11" ref-type="bibr">Chou, 2013</xref>), and previous studies of the drug ATC label classification problem have used this evaluation criterion for comparison. To ensure the fairness of the experiments, we also use this evaluation criterion in our experiments. The definitions of the evaluation metrics are given in <xref rid="e13" ref-type="disp-formula">Equation (13</xref>–<xref rid="e17" ref-type="disp-formula">17)</xref>:<disp-formula id="e13"><mml:math id="m44" overflow="scroll"><mml:mi>A</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mfenced open="(" close=")"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∩</mml:mo><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mfenced open="|" close="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math><label>(13)</label></disp-formula>
<disp-formula id="e14"><mml:math id="m45" overflow="scroll"><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mfenced open="(" close=")"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∩</mml:mo><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mfenced open="|" close="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math><label>(14)</label></disp-formula>
<disp-formula id="e15"><mml:math id="m46" overflow="scroll"><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mfenced open="(" close=")"><mml:mrow><mml:mfrac><mml:mrow><mml:mfenced open="|" close="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∩</mml:mo><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mfenced open="|" close="|"><mml:mrow><mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math><label>(15)</label></disp-formula>
<disp-formula id="e16"><mml:math id="m47" overflow="scroll"><mml:mi>A</mml:mi><mml:mi>b</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mo>−</mml:mo><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>K</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math><label>(16)</label></disp-formula>
<disp-formula id="e17"><mml:math id="m48" overflow="scroll"><mml:mi>A</mml:mi><mml:mi>b</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mo>−</mml:mo><mml:mi>F</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mfenced open="(" close=")"><mml:mrow><mml:mfrac><mml:mrow><mml:mfenced open="|" close="|"><mml:mrow><mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>−</mml:mo><mml:mfenced open="|" close="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mspace width="0.3333em"/><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∩</mml:mo><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math><label>(17)</label></disp-formula>where <italic>N</italic> is the total number of samples, <italic>M</italic> is the number of labels, the operator <inline-formula id="inf31"><mml:math id="m49" overflow="scroll"><mml:mfenced open="|" close="|"><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> is used to calculate the number of elements in the set, ∪/∩ represents the merge/intersection operation of the set, <italic>Y</italic>
<sub><italic>i</italic></sub> represents the true label vector of the current sample <italic>i</italic>, <inline-formula id="inf32"><mml:math id="m50" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> represents the predicted label vector of the current sample <italic>i</italic> after the model, and <italic>K</italic> represents the function to determine whether the two vectors are identical, through <xref rid="e18" ref-type="disp-formula">formula (18)</xref>:<disp-formula id="e18"><mml:math id="m51" overflow="scroll"><mml:mi>K</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced open="{" close=""><mml:mrow><mml:mtable class="matrix"><mml:mtr><mml:mtd columnalign="center"><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mspace width="0.3333em" class="nbsp"/><mml:mspace width="0.3333em" class="nbsp"/><mml:mspace width="0.3333em" class="nbsp"/><mml:mfenced open="(" close=")"><mml:mfrac linethickness="0.0pt"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.3333em" class="nbsp"/><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mspace width="0.3333em" class="nbsp"/><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>l</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.3333em" class="nbsp"/><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.3333em" class="nbsp"/><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.3333em" class="nbsp"/><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mspace width="0.3333em" class="nbsp"/><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mfrac></mml:mfenced></mml:math><label>(18)</label></disp-formula>
</p>
      <p>For our experiments, we used the 10-fold cross-validation (<xref rid="B32" ref-type="bibr">Refaeilzadeh et al., 2009</xref>) to evaluate the model’s performance. K-fold cross-validation is a rigorous evaluation method. In each fold, the dataset is divided into (training set: validation set): test set = (9:1):1. The performance of the model is evaluated by taking the average of 10 times repeated 10-fold cross-validations to ensure that the error in the experimental results is as small as possible.</p>
    </sec>
    <sec id="s4-2">
      <title>4.2 DACPGTN Model Settings</title>
      <p>This section lists the parameter settings of the experiment in <xref rid="T3" ref-type="table">Table 3</xref>. The learning rate is adapted by Adam optimizer (<xref rid="B48" ref-type="bibr">Zhang, 2018</xref>). This algorithm has an excellent performance in deep learning and has significant advantages compared with other types of random optimization algorithms. The model selection is based on the performance of the validation sets. We set the model training iterations for 250 epochs. Before each training, the performance of the current model on the validation set is compared with the performance of the previous epoch. Finally, select the model that achieves the best performance on the validation set to save. Setting of model parameters, based on the GTN model. The GCN network output dimensions that affect prediction performance are discussed in detail in <xref rid="s4-4" ref-type="sec">Section 4.4</xref>. The overall DACPGTN model was implemented using the Python-based Pytorch 1.5.1 framework. These experiments were implemented on Windows 10 using python 3.6 and executed on a PC with a 2.90 GHz Intel Core i7-10700 processor and 32.0 GB RAM.</p>
      <table-wrap position="float" id="T3">
        <label>TABLE 3</label>
        <caption>
          <p>DACPGTN model parameter settings.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1">Parameter</th>
              <th align="center" rowspan="1" colspan="1">Detailed Settings</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" rowspan="1" colspan="1">Number of Graph Transformer Layer</td>
              <td align="char" char="." rowspan="1" colspan="1">1</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Number of channels</td>
              <td align="char" char="." rowspan="1" colspan="1">2</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Training epochs</td>
              <td align="char" char="." rowspan="1" colspan="1">250</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Learning rate</td>
              <td align="char" char="." rowspan="1" colspan="1">0.005</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Weight decay</td>
              <td align="char" char="." rowspan="1" colspan="1">0.001</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Number of GCN</td>
              <td align="char" char="." rowspan="1" colspan="1">1</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Feature Input dim</td>
              <td align="char" char="." rowspan="1" colspan="1">300</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">GCN Output dim</td>
              <td align="char" char="." rowspan="1" colspan="1">150</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">FC1</td>
              <td align="char" char="." rowspan="1" colspan="1">150</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">FC2</td>
              <td align="char" char="." rowspan="1" colspan="1">128</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">FC3</td>
              <td align="char" char="." rowspan="1" colspan="1">64</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">FC4</td>
              <td align="char" char="." rowspan="1" colspan="1">14</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Dropout</td>
              <td align="char" char="." rowspan="1" colspan="1">0.2</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="s4-3">
      <title>4.3 Comparison With Other Anatomical Therapeutic Chemical Code Multi-Label Classifiers</title>
      <p>In this section, the DACPGTN model was compared with some of the state-of-the-art methods in drug ATC code prediction. We compared three state-of-the-art methods, 1) CGATCPred (<xref rid="B49" ref-type="bibr">Zhao et al., 2021</xref>), it uses a multi-layer convolutional neural network (CNN) to extract composite features from multiple types of drug-drug similarities, and uses a GCN network to learn the information between ATC Code labels. All the information learned is integrated and a neural network is used to make the final prediction. 2) iATC-NRAKEL (<xref rid="B50" ref-type="bibr">Zhou et al., 2020a</xref>), have constructed multiple drug-drug interaction networks, extracted the drug features by the network embedding algorithm Mashup. In the classification stage, the classic machine learning algorithm support vector machine was used. 3) iATC-mISF(<xref rid="B8" ref-type="bibr">Cheng et al., 2017b</xref>), a multi-label Gaussian kernel regression classifier. The first-level ATC Code for a given drug is predicted based on drug chemistry-chemistry interactions, drug structure similarity and drug fingerprint similarity. At the same time, in order to verify that deep learning method can provide better prediction performance than traditional multi-label classifiers, we also compare two basic multi-label classification methods ML-KNN(<xref rid="B38" ref-type="bibr">Szymanski and Kajdanowicz, 2017</xref>) and ML-RandomForest (<xref rid="B38" ref-type="bibr">Szymanski and Kajdanowicz, 2017</xref>). The parameter settings of all comparison models are the same as the optimal parameters in the original article, and the traditional classifier parameters are set as default. The comparative experiments are carried out on the dataset we constructed, and the results are shown in <xref rid="T4" ref-type="table">Table 4</xref>.</p>
      <table-wrap position="float" id="T4">
        <label>TABLE 4</label>
        <caption>
          <p>Comparison with other ATC Code multi-label classifiers (10 × 10-fold CV).</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1">Classfier</th>
              <th align="center" rowspan="1" colspan="1">Aiming</th>
              <th align="center" rowspan="1" colspan="1">Coverage</th>
              <th align="center" rowspan="1" colspan="1">Accuracy</th>
              <th align="center" rowspan="1" colspan="1">Absolute True</th>
              <th align="center" rowspan="1" colspan="1">Absolute False</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" rowspan="1" colspan="1">DACPGTN</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8543</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8517</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8320</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7902</td>
              <td align="char" char="." rowspan="1" colspan="1">0.0241</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">CGATCPred</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7864</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8022</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7711</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7290</td>
              <td align="char" char="." rowspan="1" colspan="1">0.0338</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">iATC-NRAKEL</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7744</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8020</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7550</td>
              <td align="char" char="." rowspan="1" colspan="1">0.6947</td>
              <td align="char" char="." rowspan="1" colspan="1">0.0376</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">iATC-mISF</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7094</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7127</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7036</td>
              <td align="char" char="." rowspan="1" colspan="1">0.6306</td>
              <td align="char" char="." rowspan="1" colspan="1">0.0244</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ML-KNN</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7293</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7071</td>
              <td align="char" char="." rowspan="1" colspan="1">0.6861</td>
              <td align="char" char="." rowspan="1" colspan="1">0.6300</td>
              <td align="char" char="." rowspan="1" colspan="1">0.0433</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ML-RandomForest</td>
              <td align="char" char="." rowspan="1" colspan="1">0.6723</td>
              <td align="char" char="." rowspan="1" colspan="1">0.6533</td>
              <td align="char" char="." rowspan="1" colspan="1">0.6471</td>
              <td align="char" char="." rowspan="1" colspan="1">0.6187</td>
              <td align="char" char="." rowspan="1" colspan="1">0.0368</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>As shown in <xref rid="T4" ref-type="table">Table 4</xref>, our proposed DACPGTN model has the best performance on the Benchmark dataset. Compared with the optimal model CGATCPred in drug ATC Code prediction problem, the improvement is 6.8% in Aiming,5% in Coverage,6% in Accuracy, and 6.1% in Absolute true. Accuracy and Absolute true are the most important among the five evaluation metrics (<xref rid="B31" ref-type="bibr">Qiu et al., 2016</xref>), and our model achieves a certain degree of improvement in these two metrics. To clearly show the performance of DACPGTN with 10 times repeated10-fold cross-validation, we illustrated a boxplot of accuracy and absolute true in <xref rid="F3" ref-type="fig">Figure 3</xref>. The two measurements did not vary considerably, representing the stability of DACPGTN under different divisions of drugs. These results suggest that the DACPGTN model, which can learn potential interactions information between different biomedical entities from multiple heterogeneous graphs by using graph transformer layer. DACPGTN integrated potential interactions information and composite features between these nodes, which can achieve better performance in drug ATC code prediction.</p>
      <fig position="float" id="F3">
        <label>FIGURE 3</label>
        <caption>
          <p>Boxplot showing the absolute trues and accuracies of DACPGTN with 10-fold cross-validation for 10 times.</p>
        </caption>
        <graphic xlink:href="fphar-13-907676-g003" position="float"/>
      </fig>
    </sec>
    <sec id="s4-4">
      <title>4.4 The Effect of GCN Network Output Dimension</title>
      <p>In this experiment, the GCN network as a feature extractor provides classification information for the end-to-end prediction stage by learning the composite feature matrix and the potential interactions information matrix obtained from the graph transformer layer. In order to verify the effect of the GCN network node feature output size on the experimental results, the following experiments were conducted. The results are shown in <xref rid="F4" ref-type="fig">Figure 4</xref>.</p>
      <fig position="float" id="F4">
        <label>FIGURE 4</label>
        <caption>
          <p>GCN network Output dimension selection.</p>
        </caption>
        <graphic xlink:href="fphar-13-907676-g004" position="float"/>
      </fig>
      <p>For the results of the experiments, we compare the performance of the GCN network in different output dimensions on five evaluation metrics. As shown in <xref rid="F4" ref-type="fig">Figure 4</xref>, the model achieves the best prediction performance when the output dimension of the GCN network is 150. Therefore, the GCN network output dimension was set to 150, and all experiments were performed on this parameter.</p>
    </sec>
    <sec id="s4-5">
      <title>4.5 The Effect of Multi-Source Interaction Information</title>
      <p>To obtain drug-target protein interaction information and drug-disease interaction information on the impact of the drug ATC prediction problem. We used the drug-target protein interaction information and drug-disease interaction information as the input of the heterogeneous network, respectively, and reconstructed the feature matrix. The parameters of the experiments are the same as those in <xref rid="s4-2" ref-type="sec">Section 4.2</xref>, and the results are shown in <xref rid="T5" ref-type="table">Table 5</xref>.</p>
      <table-wrap position="float" id="T5">
        <label>TABLE 5</label>
        <caption>
          <p>Experimental results of single-source interaction information.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1">Classfier</th>
              <th align="center" rowspan="1" colspan="1">Aiming</th>
              <th align="center" rowspan="1" colspan="1">Coverage</th>
              <th align="center" rowspan="1" colspan="1">Accuracy</th>
              <th align="center" rowspan="1" colspan="1">Absolute True</th>
              <th align="center" rowspan="1" colspan="1">Absolute False</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" rowspan="1" colspan="1">DACPGTN-Disease</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8442</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8437</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8231</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7782</td>
              <td align="char" char="." rowspan="1" colspan="1">0.02516</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DACPGTN-Target</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8327</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8307</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8051</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7536</td>
              <td align="char" char="." rowspan="1" colspan="1">0.02875</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>As shown in <xref rid="T5" ref-type="table">Table 5</xref>, the performance of the model degrades when only drug-target protein interaction information or only drug-disease interaction information is used as candidate adjacency matrix for heterogeneous networks. Meanwhile, only drug-target protein interaction information was used better than only drug-disease interaction information, and the experiment results were consistent with our expectation. Compared with single interaction information, the DACPGTN model obtained better prediction performance by considering multiple sources of interactions information. It is fully demonstrated that the DACPGTN model can extract useful information from multi-source interaction information for prediction. That is, new graph structures obtained by learning different heterogeneous graphs can contribute to the drug ATC code prediction problem.</p>
    </sec>
    <sec id="s4-6">
      <title>4.6 Predicting Anatomical Therapeutic Chemical Code for New Drugs</title>
      <p>To evaluate the capability of the DACPGTN model in predicting ATC Code for new drugs, we have conducted the following series of experiments. For a given new drug, it may not be possible to obtain information on its known targets or disease interactions. We consider three potential cases: 1) Drugs have interactions with targets. 2) Drugs have only interactions with diseases. 3) Drugs have no interactions with targets and diseases. For each potential case, we sequentially masked the interactions information for all drugs in the test set. The known interaction information of drugs in the heterogeneous network is removed, and the heterogeneous network set is reconstructed. Specifically, we set all elements of the row in the drug correspondence heterogeneous network to 0. When the known interactions information is removed, the given drug thus becomes a new drug with only drug-target interaction information or drug-disease interaction information or without any known interaction information. We performed the ten times repeated 10-fold cross-validation experiments for each case and took the average value to ensure that the error was sufficiently small. The experimental results are shown in <xref rid="T6" ref-type="table">Table 6</xref>. The experimental results show that the performance of the DACPGTN model decreases when the new drugs have different degrees of missing interaction information, but the performance of the model remains at a high level. This good performance may be related to the principle of the GCN network. When the test node learns fewer potential interactions by graph transformer layer or only self-interaction information, the GCN network can still transform the node features on the whole graph space. New drugs prediction experiments have demonstrated that the DACPGTN model has practical application. When a new drug is given, its target or disease interaction information is missing, or the interaction information between the new drug and these two types of biomedical nodes is unknown. We can still integrate existing heterogeneous networks to make well-performing ATC code predictions for new drugs using only drug-drug similarity information or partially known interactions information.</p>
      <table-wrap position="float" id="T6">
        <label>TABLE 6</label>
        <caption>
          <p>New drugs prediction experiment results.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1">Interactions</th>
              <th align="center" rowspan="1" colspan="1">Aiming</th>
              <th align="center" rowspan="1" colspan="1">Coverage</th>
              <th align="center" rowspan="1" colspan="1">Accuracy</th>
              <th align="center" rowspan="1" colspan="1">Absolute True</th>
              <th align="center" rowspan="1" colspan="1">Absolute False</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" rowspan="1" colspan="1">None-Disease</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8458</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8443</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8233</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7802</td>
              <td align="char" char="." rowspan="1" colspan="1">0.0250</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">None-Target</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8439</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8423</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8206</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7764</td>
              <td align="char" char="." rowspan="1" colspan="1">0.0252</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">None-Target-Disease</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8406</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8376</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8175</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7747</td>
              <td align="char" char="." rowspan="1" colspan="1">0.0258</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="s4-7">
      <title>4.7 Case Studies</title>
      <p>To further validate the reliability capability of DACPGTN, we selected some representative drugs for detailed case studies. Due to the early construction of the benchmark dataset and the limited information on drugs ATC code included, the DACPGTN model will give false positives of ATC code for some drugs in the prediction phase. As drug discovery research progresses, the pharmacological properties and ATC code of some drugs in the experimental dataset will be newly validated and supplemented. We have analyzed and validated some representative drugs predicted by our model with false positive ATC code through authoritative public databases, such as DrugBank (<xref rid="B44" ref-type="bibr">Wishart et al., 2008</xref>), CTD (<xref rid="B13" ref-type="bibr">Davis et al., 2021</xref>) and KEGG (<xref rid="B19" ref-type="bibr">Kanehisa and Goto, 2000</xref>). The predicted results and the supporting evidences are summarized in <xref rid="T7" ref-type="table">Table 7</xref>. For example, Brinzolamide (D00652) is a highly specific, non-competitive, reversible carbonic anhydrase inhibitor. It is indicated in the treatment of elevated intraocular pressure in patients with ocular hypertension or open-angle glaucoma. This drug was originally classified under the Sensory Organs, and new studies suggest it has been added to the cardiovascular class of the KEGG database. Carisoprodol (D00768) is a centrally acting skeletal muscle relaxant that does not act directly on skeletal muscle but acts directly on the central nervous system (CNS). Overdose of carisoprodol can depress the CNS and in severe cases induce coma. In the Drugbank database, based on studies in animal models, carisoprodol-induced muscle relaxation is associated with changes in the activity of interneurons in the spinal cord and descending reticulum located in the brain. Homatropine methylbromide (D02070) is a quaternary ammonium muscarinic acetylcholine receptor antagonist belonging to the group of medicines called anti-muscarinics. Research in the DrugBank database shows that it is used to treat duodenal or gastric ulcers or intestinal problems and prevent nausea, vomiting, and motion sickness. Meanwhile, Homatropine methylbromide is classed explicitly as Alimentary tract and metabolism in the KEGG database. These successful prediction result show that our model can provide valuable information for drug discovery and predict the potential pharmacological properties of drugs.</p>
      <table-wrap position="float" id="T7">
        <label>TABLE 7</label>
        <caption>
          <p>Eight inferred drugs ATC class based on the DACPGTN model.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1">Drug ID</th>
              <th align="center" rowspan="1" colspan="1">Chemical Name</th>
              <th align="center" rowspan="1" colspan="1">Original ATC Class</th>
              <th align="center" rowspan="1" colspan="1">Inferred ATC Class</th>
              <th align="center" rowspan="1" colspan="1">Evidences</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" rowspan="1" colspan="1">D00302</td>
              <td align="left" rowspan="1" colspan="1">Dipyridamole</td>
              <td align="left" rowspan="1" colspan="1">
                <italic>S</italic>
                <sub>2</sub>
              </td>
              <td align="left" rowspan="1" colspan="1">
                <inline-formula id="inf33">
                  <mml:math id="m52" overflow="scroll">
                    <mml:msup>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>S</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mn>3</mml:mn>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>*</mml:mo>
                      </mml:mrow>
                    </mml:msup>
                  </mml:math>
                </inline-formula>
              </td>
              <td align="left" rowspan="1" colspan="1">KEGG/CTD</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">D02070</td>
              <td align="left" rowspan="1" colspan="1">Homatropine methylbromide</td>
              <td align="left" rowspan="1" colspan="1">
                <italic>S</italic>
                <sub>13</sub>
              </td>
              <td align="left" rowspan="1" colspan="1">
                <inline-formula id="inf34">
                  <mml:math id="m53" overflow="scroll">
                    <mml:msup>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>S</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>*</mml:mo>
                      </mml:mrow>
                    </mml:msup>
                  </mml:math>
                </inline-formula>
              </td>
              <td align="left" rowspan="1" colspan="1">KEGG/DrugBank</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">D00768</td>
              <td align="left" rowspan="1" colspan="1">Carisoprodol</td>
              <td align="left" rowspan="1" colspan="1">
                <italic>S</italic>
                <sub>9</sub>
              </td>
              <td align="left" rowspan="1" colspan="1">
                <inline-formula id="inf35">
                  <mml:math id="m54" overflow="scroll">
                    <mml:msup>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>S</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mn>10</mml:mn>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>*</mml:mo>
                      </mml:mrow>
                    </mml:msup>
                  </mml:math>
                </inline-formula>
              </td>
              <td align="left" rowspan="1" colspan="1">DrugBank/CTD</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">D00652</td>
              <td align="left" rowspan="1" colspan="1">Brinzolamide</td>
              <td align="left" rowspan="1" colspan="1">
                <italic>S</italic>
                <sub>13</sub>
              </td>
              <td align="left" rowspan="1" colspan="1">
                <inline-formula id="inf36">
                  <mml:math id="m55" overflow="scroll">
                    <mml:msup>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>S</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mn>3</mml:mn>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>*</mml:mo>
                      </mml:mrow>
                    </mml:msup>
                  </mml:math>
                </inline-formula>
              </td>
              <td align="left" rowspan="1" colspan="1">KEGG</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">D00131</td>
              <td align="left" rowspan="1" colspan="1">Disulfiram</td>
              <td align="left" rowspan="1" colspan="1"><italic>S</italic><sub>10</sub>, <italic>S</italic><sub>11</sub></td>
              <td align="left" rowspan="1" colspan="1"><inline-formula id="inf37"><mml:math id="m56" overflow="scroll"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, <italic>S</italic><sub>14</sub></td>
              <td align="left" rowspan="1" colspan="1">KEGG/CTD</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">D01192</td>
              <td align="left" rowspan="1" colspan="1">Olopatadine hydrochloride</td>
              <td align="left" rowspan="1" colspan="1"><italic>S</italic><sub>12</sub>, <italic>S</italic><sub>13</sub></td>
              <td align="left" rowspan="1" colspan="1">
                <inline-formula id="inf38">
                  <mml:math id="m57" overflow="scroll">
                    <mml:msup>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>S</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mn>3</mml:mn>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>*</mml:mo>
                      </mml:mrow>
                    </mml:msup>
                  </mml:math>
                </inline-formula>
              </td>
              <td align="left" rowspan="1" colspan="1">CTD</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">D00314</td>
              <td align="left" rowspan="1" colspan="1">Etidronate disodium</td>
              <td align="left" rowspan="1" colspan="1">
                <italic>S</italic>
                <sub>9</sub>
              </td>
              <td align="left" rowspan="1" colspan="1">
                <inline-formula id="inf39">
                  <mml:math id="m58" overflow="scroll">
                    <mml:msup>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>S</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mn>10</mml:mn>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>*</mml:mo>
                      </mml:mrow>
                    </mml:msup>
                  </mml:math>
                </inline-formula>
              </td>
              <td align="left" rowspan="1" colspan="1">CTD</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">D00525</td>
              <td align="left" rowspan="1" colspan="1">Pilocarpine</td>
              <td align="left" rowspan="1" colspan="1"><italic>S</italic><sub>10</sub>, <italic>S</italic><sub>13</sub></td>
              <td align="left" rowspan="1" colspan="1"><inline-formula id="inf40"><mml:math id="m59" overflow="scroll"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula id="inf41"><mml:math id="m60" overflow="scroll"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula id="inf42"><mml:math id="m61" overflow="scroll"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula></td>
              <td align="left" rowspan="1" colspan="1">CTD</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p><sup>*</sup>This symbol indicates that evidences can be found to support the chemical belonging to the ATC class.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
  </sec>
  <sec id="s5">
    <title>5 Conclusion</title>
    <p>Considering drug ATC code identification can play an important role in drug discovery and development, we proposed an end-to-end model DACPGTN based on graph transformer network to predict the ATC code for drugs effectively in this study. DACPGTN formulated the ATC code prediction of drugs as a multi-label classification problem. By applying transformer network, DACPGTN learned comprehensive interactions among drugs, diseases and targets to construct drug-target-disease heterogeneous networks. Moreover, DACPGTN integrated various biomedical information to obtain more representative features of drugs, diseases and targets. Based on the learned heterogeneous network and features, graph convolution network was used to obtain network embedding of drugs for drug ATC code multi-label classification task. For the drug ATC code multi-label prediction problem, we transformed it into the calculation of the difference between the score of the target class and the score of the non-target class, which solves the class-imbalance problem to a certain extent. The results of cross-validation experiments have demonstrated that DACPGTN is an effective approach to identify the ATC code of drugs, which can help the pharmacological discovery of drugs. In the future work, more high-quality data and biomedical entities can be incorporated to obtain more effective features of drugs. In addition, the performance and usefulness of the DACPGTN model can be further improved by utilizing attention-based mechanisms.</p>
  </sec>
</body>
<back>
  <sec sec-type="data-availability" id="s6">
    <title>Data Availability Statement</title>
    <p>The datasets for this study can be found in the <ext-link xlink:href="https://github.com/Szhgege/DACPGTN/tree/main/data" ext-link-type="uri">https://github.com/Szhgege/DACPGTN/tree/main/data</ext-link>.</p>
  </sec>
  <sec id="s7">
    <title>Author Contributions</title>
    <p>CY and ZS conceived and designed the approach. ZS performed the experiments. GZ and HL analyzed the data. CY and ZS wrote the manuscript. HL and JW supervised the whole study process and revised the manuscript. All authors have read and approved the final version of manuscript.</p>
  </sec>
  <sec id="s8">
    <title>Funding</title>
    <p>This work was supported by the National Natural Science Foundation of China under Grant number (No. 61802113 and No. 61802114); Education Department of Henan Province (No. 222102210238).</p>
  </sec>
  <sec sec-type="COI-statement" id="s9">
    <title>Conflict of Interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="s10">
    <title>Publisher’s Note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abdi</surname><given-names>H.</given-names></name><name><surname>Williams</surname><given-names>L. J.</given-names></name></person-group> (<year>2010</year>). <article-title>Principal Component Analysis</article-title>. <source>WIREs Comp. Stat.</source>
<volume>2</volume>, <fpage>433</fpage>–<lpage>459</lpage>. <pub-id pub-id-type="doi">10.1002/wics.101</pub-id>
</mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agarap</surname><given-names>A. F.</given-names></name></person-group> (<year>2018</year>). <article-title>Deep Learning Using Rectified Linear Units (Relu)</article-title>. <comment>CoRR abs/1803.08375</comment>. </mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Benesty</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>J.</given-names></name><name><surname>Huang</surname><given-names>Y.</given-names></name><name><surname>Cohen</surname><given-names>I.</given-names></name></person-group> (<year>2009</year>). “<article-title>Pearson Correlation Coefficient</article-title>,” in <source>Noise Reduction in Speech Processing</source> (<publisher-loc>Berlin, Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>1</fpage>–<lpage>4</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-642-00296-0_5</pub-id>
</mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blanchard</surname><given-names>P.</given-names></name><name><surname>Higham</surname><given-names>D. J.</given-names></name><name><surname>Higham</surname><given-names>N. J.</given-names></name></person-group> (<year>2019</year>). <article-title>Accurate Computation of the Log-Sum-Exp and Softmax Functions</article-title>. <comment>arXiv preprint arXiv:1909.03469</comment>. </mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>L.</given-names></name><name><surname>Zeng</surname><given-names>W. M.</given-names></name><name><surname>Cai</surname><given-names>Y. D.</given-names></name><name><surname>Feng</surname><given-names>K. Y.</given-names></name><name><surname>Chou</surname><given-names>K. C.</given-names></name></person-group> (<year>2012</year>). <article-title>Predicting Anatomical Therapeutic Chemical (Atc) Classification of Drugs by Integrating Chemical-Chemical Interactions and Similarities</article-title>. <source>PLoS One</source>
<volume>7</volume>, <fpage>e35254</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0035254</pub-id>
<pub-id pub-id-type="pmid">22514724</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Y.</given-names></name><name><surname>Kalantidis</surname><given-names>Y.</given-names></name><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Yan</surname><given-names>S.</given-names></name><name><surname>Feng</surname><given-names>J.</given-names></name></person-group> (<year>2018</year>). “<article-title>Aˆ-Nets: Double Attention Networks</article-title>,” in <source>Advances in Neural Information Processing Systems</source>. Editors <person-group person-group-type="editor"><name><surname>Bengio</surname><given-names>S.</given-names></name><name><surname>Wallach</surname><given-names>H.</given-names></name><name><surname>Larochelle</surname><given-names>H.</given-names></name><name><surname>Grauman</surname><given-names>K.</given-names></name><name><surname>Cesa-Bianchi</surname><given-names>N.</given-names></name><name><surname>Garnett</surname><given-names>R.</given-names></name></person-group> (<publisher-loc>Montréal Canada</publisher-loc>: <publisher-name>Curran Associates, Inc.</publisher-name>), <volume>31</volume>. </mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>X.</given-names></name><name><surname>Zhao</surname><given-names>S. G.</given-names></name><name><surname>Xiao</surname><given-names>X.</given-names></name><name><surname>Chou</surname><given-names>K. C.</given-names></name></person-group> (<year>2017a</year>). <article-title>Iatc-Mhyb: A Hybrid Multi-Label Classifier for Predicting the Classification of Anatomical Therapeutic Chemicals</article-title>. <source>Oncotarget</source>
<volume>8</volume>, <fpage>58494</fpage>–<lpage>58503</lpage>. <pub-id pub-id-type="doi">10.18632/oncotarget.17028</pub-id>
<pub-id pub-id-type="pmid">28938573</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>X.</given-names></name><name><surname>Zhao</surname><given-names>S. G.</given-names></name><name><surname>Xiao</surname><given-names>X.</given-names></name><name><surname>Chou</surname><given-names>K. C.</given-names></name></person-group> (<year>2017b</year>). <article-title>Iatc-Misf: A Multi-Label Classifier for Predicting the Classes of Anatomical Therapeutic Chemicals</article-title>. <source>Bioinformatics</source>
<volume>33</volume>, <fpage>341</fpage>–<lpage>346</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btw644</pub-id>
<pub-id pub-id-type="pmid">28172617</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiang</surname><given-names>A. P.</given-names></name><name><surname>Butte</surname><given-names>A. J.</given-names></name></person-group> (<year>2009</year>). <article-title>Systematic Evaluation of Drug-Disease Relationships to Identify Leads for Novel Drug Uses</article-title>. <source>Clin. Pharmacol. Ther.</source>
<volume>86</volume>, <fpage>507</fpage>–<lpage>510</lpage>. <pub-id pub-id-type="doi">10.1038/clpt.2009.103</pub-id>
<pub-id pub-id-type="pmid">19571805</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>H.</given-names></name><name><surname>Berger</surname><given-names>B.</given-names></name><name><surname>Peng</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>Compact Integration of Multi-Network Topology for Functional Analysis of Genes</article-title>. <source>Cell Syst.</source>
<volume>3</volume>, <fpage>540</fpage>–<lpage>548</lpage>. <pub-id pub-id-type="doi">10.1016/j.cels.2016.10.017</pub-id>
<pub-id pub-id-type="pmid">27889536</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chou</surname><given-names>K. C.</given-names></name></person-group> (<year>2013</year>). <article-title>Some Remarks on Predicting Multi-Label Attributes in Molecular Biosystems</article-title>. <source>Mol. Biosyst.</source>
<volume>9</volume>, <fpage>1092</fpage>–<lpage>1100</lpage>. <pub-id pub-id-type="doi">10.1039/C3MB25555G</pub-id>
<pub-id pub-id-type="pmid">23536215</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cortes</surname><given-names>C.</given-names></name><name><surname>Vapnik</surname><given-names>V.</given-names></name></person-group> (<year>1995</year>). <article-title>Support-Vector Networks</article-title>. <source>Mach. Learn</source>
<volume>20</volume>, <fpage>273</fpage>–<lpage>297</lpage>. <pub-id pub-id-type="doi">10.1007/BF00994018</pub-id>
</mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>A. P.</given-names></name><name><surname>Grondin</surname><given-names>C. J.</given-names></name><name><surname>Johnson</surname><given-names>R. J.</given-names></name><name><surname>Sciaky</surname><given-names>D.</given-names></name><name><surname>Wiegers</surname><given-names>J.</given-names></name><name><surname>Wiegers</surname><given-names>T. C.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Comparative Toxicogenomics Database (Ctd): Update 2021</article-title>. <source>Nucleic Acids Res.</source>
<volume>49</volume>, <fpage>D1138</fpage>–<lpage>D1143</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkaa891</pub-id>
<pub-id pub-id-type="pmid">33068428</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Degtyarenko</surname><given-names>K.</given-names></name><name><surname>De Matos</surname><given-names>P.</given-names></name><name><surname>Ennis</surname><given-names>M.</given-names></name><name><surname>Hastings</surname><given-names>J.</given-names></name><name><surname>Zbinden</surname><given-names>M.</given-names></name><name><surname>McNaught</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2007</year>). <article-title>Chebi: A Database and Ontology for Chemical Entities of Biological Interest</article-title>. <source>Nucleic Acids Res.</source>
<volume>36</volume>, <fpage>D344</fpage>–<lpage>D350</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkm791</pub-id>
<pub-id pub-id-type="pmid">17932057</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunkel</surname><given-names>M.</given-names></name><name><surname>Günther</surname><given-names>S.</given-names></name><name><surname>Ahmed</surname><given-names>J.</given-names></name><name><surname>Wittig</surname><given-names>B.</given-names></name><name><surname>Preissner</surname><given-names>R.</given-names></name></person-group> (<year>2008</year>). <article-title>Superpred: Drug Classification and Target Prediction</article-title>. <source>Nucleic Acids Res.</source>
<volume>36</volume>, <fpage>W55</fpage>–<lpage>W59</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkn307</pub-id>
<pub-id pub-id-type="pmid">18499712</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S.</given-names></name><name><surname>Schmidhuber</surname><given-names>J.</given-names></name></person-group> (<year>1997</year>). <article-title>Long Short-Term Memory</article-title>. <source>Neural Comput.</source>
<volume>9</volume>, <fpage>1735</fpage>–<lpage>1780</lpage>. <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
<pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hutchinson</surname><given-names>J. M.</given-names></name><name><surname>Patrick</surname><given-names>D. M.</given-names></name><name><surname>Marra</surname><given-names>F.</given-names></name><name><surname>Ng</surname><given-names>H.</given-names></name><name><surname>Bowie</surname><given-names>W. R.</given-names></name><name><surname>Heule</surname><given-names>L.</given-names></name><etal/></person-group> (<year>2004</year>). <article-title>Measurement of Antibiotic Consumption: A Practical Guide to the Use of the Anatomical Thgerapeutic Chemical Classification and Definied Daily Dose System Methodology in Canada</article-title>. <source>Can. J. Infect. Dis.</source>
<volume>15</volume>, <fpage>29</fpage>–<lpage>35</lpage>. <pub-id pub-id-type="doi">10.1155/2004/389092</pub-id>
<pub-id pub-id-type="pmid">18159441</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jarada</surname><given-names>T. N.</given-names></name><name><surname>Rokne</surname><given-names>J. G.</given-names></name><name><surname>Alhajj</surname><given-names>R.</given-names></name></person-group> (<year>2020</year>). <article-title>A Review of Computational Drug Repositioning: Strategies, Approaches, Opportunities, Challenges, and Directions</article-title>. <source>J. Cheminform</source>
<volume>12</volume>, <fpage>46</fpage>. <pub-id pub-id-type="doi">10.1186/s13321-020-00450-7</pub-id>
<pub-id pub-id-type="pmid">33431024</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanehisa</surname><given-names>M.</given-names></name><name><surname>Goto</surname><given-names>S.</given-names></name></person-group> (<year>2000</year>). <article-title>Kegg: Kyoto Encyclopedia of Genes and Genomes</article-title>. <source>Nucleic Acids Res.</source>
<volume>28</volume>, <fpage>27</fpage>–<lpage>30</lpage>. <pub-id pub-id-type="doi">10.1093/nar/28.1.27</pub-id>
<pub-id pub-id-type="pmid">10592173</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kipf</surname><given-names>T. N.</given-names></name><name><surname>Welling</surname><given-names>M.</given-names></name></person-group> (<year>2016</year>). <article-title>Semi-Supervised Classification with Graph Convolutional Networks</article-title>. <comment>arXiv preprint arXiv:1609.02907</comment>. </mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumari</surname><given-names>R.</given-names></name><name><surname>Srivastava</surname><given-names>S. K.</given-names></name></person-group> (<year>2017</year>). <article-title>Machine Learning: A Review on Binary Classification</article-title>. <source>Int. J. Comput. Appl.</source>
<volume>160</volume>, <fpage>11</fpage>–<lpage>15</lpage>. <pub-id pub-id-type="doi">10.5120/ijca2017913083</pub-id>
</mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Li</surname><given-names>G.</given-names></name><name><surname>Muller</surname><given-names>M.</given-names></name><name><surname>Thabet</surname><given-names>A.</given-names></name><name><surname>Ghanem</surname><given-names>B.</given-names></name></person-group> (<year>2019</year>). “<article-title>Deepgcns: Can Gcns Go as Deep as Cnns?</article-title>,” in <conf-name>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</conf-name>, <conf-loc>Seoul, Korea (South)</conf-loc>, <conf-date>27 October-02 November, 2019</conf-date>. </mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Lu</surname><given-names>Z.</given-names></name></person-group> (<year>2012</year>). “<article-title>A New Method for Computational Drug Repositioning Using Drug Pairwise Similarity</article-title>,” in <conf-name>2012 IEEE International Conference on Bioinformatics and Biomedicine</conf-name>, <conf-loc>Philadelphia, USA</conf-loc>, <conf-date>October 4-7, 2012</conf-date> (<publisher-name>IEEE</publisher-name>), <fpage>1</fpage>–<lpage>4</lpage>. <pub-id pub-id-type="doi">10.1109/BIBM.2012.6392722</pub-id>
</mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Q.</given-names></name><name><surname>Han</surname><given-names>Z.</given-names></name><name><surname>Wu</surname><given-names>X.-M.</given-names></name></person-group> (<year>2018</year>). “<article-title>Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning</article-title>,” in <conf-name>Thirty-Second AAAI Conference on Artificial Intelligence</conf-name>, <conf-loc>New Orleans, Louisiana, USA</conf-loc>, <conf-date>February 2‐7, 2018</conf-date>. </mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>H.</given-names></name><name><surname>Li</surname><given-names>M.</given-names></name><name><surname>Yang</surname><given-names>M.</given-names></name><name><surname>Wu</surname><given-names>F. X.</given-names></name><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name></person-group> (<year>2021</year>). <article-title>Biomedical Data and Computational Models for Drug Repositioning: A Comprehensive Review</article-title>. <source>Brief. Bioinform</source>
<volume>22</volume>, <fpage>1604</fpage>–<lpage>1619</lpage>. <pub-id pub-id-type="doi">10.1093/bib/bbz176</pub-id>
<pub-id pub-id-type="pmid">32043521</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>H.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Li</surname><given-names>M.</given-names></name><name><surname>Luo</surname><given-names>J.</given-names></name><name><surname>Peng</surname><given-names>X.</given-names></name><name><surname>Wu</surname><given-names>F. X.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>Drug Repositioning Based on Comprehensive Similarity Measures and Bi-Random Walk Algorithm</article-title>. <source>Bioinformatics</source>
<volume>32</volume>, <fpage>2664</fpage>–<lpage>2671</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btw228</pub-id>
<pub-id pub-id-type="pmid">27153662</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacDonald</surname><given-names>K.</given-names></name><name><surname>Potvin</surname><given-names>K.</given-names></name></person-group> (<year>2004</year>). <article-title>Interprovincial Variation in Access to Publicly Funded Pharmaceuticals: A Review Based on the Who Anatomical Therapeutic Chemical Classification System</article-title>. <source>Can. Pharm. J.</source>
<volume>137</volume>, <fpage>29</fpage>–<lpage>34</lpage>. <pub-id pub-id-type="doi">10.1177/171516350413700703</pub-id>
</mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nanni</surname><given-names>L.</given-names></name><name><surname>Brahnam</surname><given-names>S.</given-names></name></person-group> (<year>2017</year>). <article-title>Multi-Label Classifier Based on Histogram of Gradients for Predicting the Anatomical Therapeutic Chemical Class/Classes of a Given Compound</article-title>. <source>Bioinformatics</source>
<volume>33</volume>, <fpage>2837</fpage>–<lpage>2841</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btx278</pub-id>
<pub-id pub-id-type="pmid">28444139</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nanni</surname><given-names>L.</given-names></name><name><surname>Brahnam</surname><given-names>S.</given-names></name><name><surname>Lumini</surname><given-names>A.</given-names></name></person-group> (<year>2020</year>). “<article-title>Ensemble of Deep Learning Approaches for Atc Classification</article-title>,” in <source>Smart Intelligent Computing and Applications</source>. Editors <person-group person-group-type="editor"><name><surname>Satapathy</surname><given-names>S.</given-names></name><name><surname>Bhateja</surname><given-names>V.</given-names></name><name><surname>Mohanty</surname><given-names>J.</given-names></name><name><surname>Udgata</surname><given-names>S.</given-names></name></person-group> (<publisher-loc>Singapore</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>117</fpage>–<lpage>125</lpage>. <pub-id pub-id-type="doi">10.1007/978-981-13-9282-5_12</pub-id>
</mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pushpakom</surname><given-names>S.</given-names></name><name><surname>Iorio</surname><given-names>F.</given-names></name><name><surname>Eyers</surname><given-names>P. A.</given-names></name><name><surname>Escott</surname><given-names>K. J.</given-names></name><name><surname>Hopper</surname><given-names>S.</given-names></name><name><surname>Wells</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Drug Repurposing: Progress, Challenges and Recommendations</article-title>. <source>Nat. Rev. Drug Discov.</source>
<volume>18</volume>, <fpage>41</fpage>–<lpage>58</lpage>. <pub-id pub-id-type="doi">10.1038/nrd.2018.168</pub-id>
<pub-id pub-id-type="pmid">30310233</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qiu</surname><given-names>W. R.</given-names></name><name><surname>Sun</surname><given-names>B. Q.</given-names></name><name><surname>Xiao</surname><given-names>X.</given-names></name><name><surname>Xu</surname><given-names>Z. C.</given-names></name><name><surname>Chou</surname><given-names>K. C.</given-names></name></person-group> (<year>2016</year>). <article-title>Iptm-Mlys: Identifying Multiple Lysine Ptm Sites and Their Different Types</article-title>. <source>Bioinformatics</source>
<volume>32</volume>, <fpage>3116</fpage>–<lpage>3123</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btw380</pub-id>
<pub-id pub-id-type="pmid">27334473</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Refaeilzadeh</surname><given-names>P.</given-names></name><name><surname>Tang</surname><given-names>L.</given-names></name><name><surname>Liu</surname><given-names>H.</given-names></name></person-group> (<year>2009</year>). “<article-title>Cross-Validation</article-title>,” in <source>Encyclopedia of Database Systems</source>. Editors <person-group person-group-type="editor"><name><surname>Liu</surname><given-names>L.</given-names></name><name><surname>Özsu</surname><given-names>M. T.</given-names></name></person-group> (<publisher-loc>Boston, MA</publisher-loc>: <publisher-name>Springer</publisher-name>), <volume>5</volume>, <fpage>532</fpage>–<lpage>538</lpage>. <pub-id pub-id-type="doi">10.1007/978-0-387-39940-9_565</pub-id>
</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shi</surname><given-names>C.</given-names></name><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Sun</surname><given-names>Y.</given-names></name><name><surname>Philip</surname><given-names>S. Y.</given-names></name></person-group> (<year>2016</year>). <article-title>A Survey of Heterogeneous Information Network Analysis</article-title>. <source>IEEE Trans. Knowl. Data Eng.</source>
<volume>29</volume>, <fpage>17</fpage>–<lpage>37</lpage>. <pub-id pub-id-type="doi">10.1109/TKDE.2016.2598561</pub-id>
</mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srivastava</surname><given-names>N.</given-names></name><name><surname>Hinton</surname><given-names>G.</given-names></name><name><surname>Krizhevsky</surname><given-names>A.</given-names></name><name><surname>Sutskever</surname><given-names>I.</given-names></name><name><surname>Salakhutdinov</surname><given-names>R.</given-names></name></person-group> (<year>2014</year>). <article-title>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</article-title>. <source>J. Mach. Learn. Res.</source>
<volume>15</volume>, <fpage>1929</fpage>–<lpage>1958</lpage>. </mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="book"><comment>[Dataset]</comment><person-group person-group-type="author"><name><surname>Su</surname><given-names>J.</given-names></name></person-group> (<year>2020</year>). <source>Extending ”softmax+cross Entropy” to Multi-Label Classification Problems</source>. <ext-link xlink:href="https://github.com/bojone/bert4keras" ext-link-type="uri">https://github.com/bojone/bert4keras</ext-link>. </mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>Y.</given-names></name><name><surname>Cheng</surname><given-names>C.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>C.</given-names></name><name><surname>Zheng</surname><given-names>L.</given-names></name><name><surname>Wang</surname><given-names>Z.</given-names></name><etal/></person-group> (<year>2020</year>). “<article-title>Circle Loss: A Unified Perspective of Pair Similarity Optimization</article-title>,” in <conf-name>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</conf-name>, <conf-loc>Seattle, WA, USA</conf-loc>, <conf-date>June 16 - 19, 2020</conf-date>. <pub-id pub-id-type="doi">10.1109/cvpr42600.2020.00643</pub-id>
</mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szklarczyk</surname><given-names>D.</given-names></name><name><surname>Gable</surname><given-names>A. L.</given-names></name><name><surname>Lyon</surname><given-names>D.</given-names></name><name><surname>Junge</surname><given-names>A.</given-names></name><name><surname>Wyder</surname><given-names>S.</given-names></name><name><surname>Huerta-Cepas</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>STRING V11: Protein-Protein Association Networks with Increased Coverage, Supporting Functional Discovery in Genome-wide Experimental Datasets</article-title>. <source>Nucleic Acids Res.</source>
<volume>47</volume>, <fpage>D607</fpage>–<lpage>D613</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gky1131</pub-id>
<pub-id pub-id-type="pmid">30476243</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szymanski</surname><given-names>P.</given-names></name><name><surname>Kajdanowicz</surname><given-names>T.</given-names></name></person-group> (<year>2017</year>). <article-title>A Scikit-Based Python Environment for Performing Multi-Label Classification</article-title>. <source>J. Mach. Learn. Res.</source>
<volume>20</volume> (<issue>6</issue>), <fpage>01460</fpage>. </mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szymański</surname><given-names>P.</given-names></name><name><surname>Kajdanowicz</surname><given-names>T.</given-names></name><name><surname>Kersting</surname><given-names>K.</given-names></name></person-group> (<year>2016</year>). <article-title>How is a Data-Driven Approach Better Than Random Choice in Label Space Division for Multi-Label Classification?</article-title>
<source>Entropy</source>
<volume>18</volume>, <fpage>282</fpage>. <pub-id pub-id-type="doi">10.3390/e18080282</pub-id>
</mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsoumakas</surname><given-names>G.</given-names></name><name><surname>Katakis</surname><given-names>I.</given-names></name></person-group> (<year>2007</year>). <article-title>Multi-Label Classification: An Overview</article-title>. <source>Int. J. Data Warehous. Min. (IJDWM)</source>
<volume>3</volume>, <fpage>1</fpage>–<lpage>13</lpage>. <pub-id pub-id-type="doi">10.4018/jdwm.2007070101</pub-id>
</mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Tsoumakas</surname><given-names>G.</given-names></name><name><surname>Vlahavas</surname><given-names>I.</given-names></name></person-group> (<year>2007</year>). “<article-title>Random K-Labelsets: An Ensemble Method for Multilabel Classification</article-title>,” in <conf-name>European Conference on Machine Learning</conf-name>, <conf-loc>Warsaw, Poland</conf-loc>, <conf-date>September 17-21, 2007</conf-date> (<publisher-name>Springer</publisher-name>), <fpage>406</fpage>–<lpage>417</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-540-74958-5_38</pub-id>
</mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Xu</surname><given-names>Z.</given-names></name><name><surname>Xiong</surname><given-names>Y.</given-names></name><name><surname>Wei</surname><given-names>D. Q.</given-names></name></person-group> (<year>2019b</year>). <article-title>Atc-nlsp: Prediction of the Classes of Anatomical Therapeutic Chemicals Using a Network-Based Label Space Partition Method</article-title>. <source>Front. Pharmacol.</source>
<volume>10</volume>, <fpage>971</fpage>. <pub-id pub-id-type="doi">10.3389/fphar.2019.00971</pub-id>
<pub-id pub-id-type="pmid">31543820</pub-id></mixed-citation>
    </ref>
    <ref id="B43">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Ji</surname><given-names>H.</given-names></name><name><surname>Shi</surname><given-names>C.</given-names></name><name><surname>Wang</surname><given-names>B.</given-names></name><name><surname>Ye</surname><given-names>Y.</given-names></name><name><surname>Cui</surname><given-names>P.</given-names></name><etal/></person-group> (<year>2019a</year>). “<article-title>Heterogeneous Graph Attention Network</article-title>,” in <conf-name>The World Wide Web Conference</conf-name>, <conf-loc>San Francisco CA USA</conf-loc>, <conf-date>May 13 - 17, 2019</conf-date>, <fpage>2022</fpage>–<lpage>2032</lpage>. <pub-id pub-id-type="doi">10.1145/3308558.3313562</pub-id>
</mixed-citation>
    </ref>
    <ref id="B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wishart</surname><given-names>D. S.</given-names></name><name><surname>Knox</surname><given-names>C.</given-names></name><name><surname>Guo</surname><given-names>A. C.</given-names></name><name><surname>Cheng</surname><given-names>D.</given-names></name><name><surname>Shrivastava</surname><given-names>S.</given-names></name><name><surname>Tzur</surname><given-names>D.</given-names></name><etal/></person-group> (<year>2008</year>). <article-title>Drugbank: A Knowledgebase for Drugs, Drug Actions and Drug Targets</article-title>. <source>Nucleic Acids Res.</source>
<volume>36</volume>, <fpage>D901</fpage>–<lpage>D906</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkm958</pub-id>
<pub-id pub-id-type="pmid">18048412</pub-id></mixed-citation>
    </ref>
    <ref id="B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>L.</given-names></name><name><surname>Ai</surname><given-names>N.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Fan</surname><given-names>X.</given-names></name></person-group> (<year>2013</year>). <article-title>Relating Anatomical Therapeutic Indications by the Ensemble Similarity of Drug Sets</article-title>. <source>J. Chem. Inf. Model</source>
<volume>53</volume>, <fpage>2154</fpage>–<lpage>2160</lpage>. <pub-id pub-id-type="doi">10.1021/ci400155x</pub-id>
<pub-id pub-id-type="pmid">23889502</pub-id></mixed-citation>
    </ref>
    <ref id="B46">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yun</surname><given-names>S.</given-names></name><name><surname>Jeong</surname><given-names>M.</given-names></name><name><surname>Kim</surname><given-names>R.</given-names></name><name><surname>Kang</surname><given-names>J.</given-names></name><name><surname>Kim</surname><given-names>H. J.</given-names></name></person-group> (<year>2019</year>). “<article-title>Graph Transformer Networks</article-title>,” in <source>Advances in Neural Information Processing Systems</source>. Editors <person-group person-group-type="editor"><name><surname>Wallach</surname><given-names>H.</given-names></name><name><surname>Larochelle</surname><given-names>H.</given-names></name><name><surname>Beygelzimer</surname><given-names>A.</given-names></name><name><surname>d'Alché-Buc</surname><given-names>F.</given-names></name><name><surname>Fox</surname><given-names>E.</given-names></name><name><surname>Garnett</surname><given-names>R.</given-names></name></person-group> (<publisher-loc>Vancouver Canada</publisher-loc>: <publisher-name>Curran Associates, Inc.</publisher-name>), <volume>32</volume>. </mixed-citation>
    </ref>
    <ref id="B47">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Xiong</surname><given-names>Y.</given-names></name><name><surname>Kong</surname><given-names>X.</given-names></name><name><surname>Li</surname><given-names>S.</given-names></name><name><surname>Mi</surname><given-names>J.</given-names></name><name><surname>Zhu</surname><given-names>Y.</given-names></name></person-group> (<year>2018</year>). “<article-title>Deep Collective Classification in Heterogeneous Information Networks</article-title>,” in <conf-name>Proceedings of the 2018 World Wide Web Conference</conf-name>, <conf-loc>Lyon, France</conf-loc>, <conf-date>April 23 - 27, 2018</conf-date>, <fpage>399</fpage>–<lpage>408</lpage>. <pub-id pub-id-type="doi">10.1145/3178876.3186106</pub-id>
</mixed-citation>
    </ref>
    <ref id="B48">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Z.</given-names></name></person-group> (<year>2018</year>). “<article-title>Improved Adam Optimizer for Deep Neural Networks</article-title>,” in <conf-name>2018 IEEE/ACM 26th International Symposium on Quality of Service (IWQoS)</conf-name>, <conf-loc>Banff, Canada</conf-loc>, <conf-date>June 4-6, 2018</conf-date> (<publisher-name>IEEE</publisher-name>), <fpage>1</fpage>–<lpage>2</lpage>. <pub-id pub-id-type="doi">10.1109/IWQoS.2018.8624183</pub-id>
</mixed-citation>
    </ref>
    <ref id="B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>H.</given-names></name><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name></person-group> (<year>2021</year>). <article-title>A Convolutional Neural Network and Graph Convolutional Network-Based Method for Predicting the Classification of Anatomical Therapeutic Chemicals</article-title>. <source>Bioinformatics</source>
<volume>37</volume>, <fpage>2841</fpage>–<lpage>2847</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btab204</pub-id>
</mixed-citation>
    </ref>
    <ref id="B50">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>J. P.</given-names></name><name><surname>Chen</surname><given-names>L.</given-names></name><name><surname>Guo</surname><given-names>Z. H.</given-names></name></person-group> (<year>2020a</year>). <article-title>Iatc-Nrakel: An Efficient Multi-Label Classifier for Recognizing Anatomical Therapeutic Chemical Classes of Drugs</article-title>. <source>Bioinformatics</source>
<volume>36</volume>, <fpage>1391</fpage>–<lpage>1396</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btz757</pub-id>
<pub-id pub-id-type="pmid">31593226</pub-id></mixed-citation>
    </ref>
    <ref id="B51">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>J. P.</given-names></name><name><surname>Chen</surname><given-names>L.</given-names></name><name><surname>Wang</surname><given-names>T.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name></person-group> (<year>2020b</year>). <article-title>Iatc-Frakel: A Simple Multi-Label Web Server for Recognizing Anatomical Therapeutic Chemical Classes of Drugs with Their Fingerprints Only</article-title>. <source>Bioinformatics</source>
<volume>36</volume>, <fpage>3568</fpage>–<lpage>3569</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa166</pub-id>
<pub-id pub-id-type="pmid">32154836</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
