<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName archivearticle.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Plant Sci</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Plant Sci</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Plant Sci.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Plant Science</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1664-462X</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10025408</article-id>
    <article-id pub-id-type="doi">10.3389/fpls.2023.1112973</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Plant Science</subject>
        <subj-group>
          <subject>Methods</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>PhytoOracle: Scalable, modular phenomics data processing pipelines</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Gonzalez</surname>
          <given-names>Emmanuel M.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2209532"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zarei</surname>
          <given-names>Ariyan</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hendler</surname>
          <given-names>Nathanial</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Simmons</surname>
          <given-names>Travis</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2218229"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zarei</surname>
          <given-names>Arman</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Demieville</surname>
          <given-names>Jeffrey</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/770546"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Strand</surname>
          <given-names>Robert</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2216951"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rozzi</surname>
          <given-names>Bruno</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2218349"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Calleja</surname>
          <given-names>Sebastian</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2216834"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ellingson</surname>
          <given-names>Holly</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cosi</surname>
          <given-names>Michele</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff5" ref-type="aff">
          <sup>5</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2200681"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Davey</surname>
          <given-names>Sean</given-names>
        </name>
        <xref rid="aff6" ref-type="aff">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lavelle</surname>
          <given-names>Dean O.</given-names>
        </name>
        <xref rid="aff7" ref-type="aff">
          <sup>7</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2217261"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Truco</surname>
          <given-names>Maria José</given-names>
        </name>
        <xref rid="aff7" ref-type="aff">
          <sup>7</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1245757"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Swetnam</surname>
          <given-names>Tyson L.</given-names>
        </name>
        <xref rid="aff5" ref-type="aff">
          <sup>5</sup>
        </xref>
        <xref rid="aff8" ref-type="aff">
          <sup>8</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/419790"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Merchant</surname>
          <given-names>Nirav</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="aff5" ref-type="aff">
          <sup>5</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Michelmore</surname>
          <given-names>Richard W.</given-names>
        </name>
        <xref rid="aff7" ref-type="aff">
          <sup>7</sup>
        </xref>
        <xref rid="aff9" ref-type="aff">
          <sup>9</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/26262"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lyons</surname>
          <given-names>Eric</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="aff5" ref-type="aff">
          <sup>5</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Pauli</surname>
          <given-names>Duke</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="fn001" ref-type="author-notes">
          <sup>*</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/422166"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>School of Plant Sciences, University of Arizona</institution>, <addr-line>Tucson, AZ</addr-line>, <country>United States</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Department of Computer Science, University of Arizona</institution>, <addr-line>Tucson, AZ</addr-line>, <country>United States</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Department of Computer Engineering, Sharif University of Technology</institution>, <addr-line>Tehran</addr-line>, <country>Iran</country></aff>
    <aff id="aff4"><sup>4</sup><institution>Data Science Institute, University of Arizona</institution>, <addr-line>Tucson, AZ</addr-line>, <country>United States</country></aff>
    <aff id="aff5"><sup>5</sup><institution>BIO5 Institute, University of Arizona</institution>, <addr-line>Tucson, AZ</addr-line>, <country>United States</country></aff>
    <aff id="aff6"><sup>6</sup><institution>Department of Cellular and Molecular Medicine, University of Arizona</institution>, <addr-line>Tucson, AZ</addr-line>, <country>United States</country></aff>
    <aff id="aff7"><sup>7</sup><institution>The Genome and Biomedical Sciences Facility, University of California, Davis</institution>, <addr-line>Davis, CA</addr-line>, <country>United States</country></aff>
    <aff id="aff8"><sup>8</sup><institution>School of Natural Resources and the Environment, University of Arizona</institution>, <addr-line>Tucson, AZ</addr-line>, <country>United States</country></aff>
    <aff id="aff9"><sup>9</sup><institution>Department of Plant Sciences, University of California, Davis</institution>, <addr-line>Davis, CA</addr-line>, <country>United States</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Sindhuja Sankaran, Washington State University, United States</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Nelson Nazzicari, Council for Agricultural and Economics Research (CREA), Italy; Max Feldman, Agricultural Research Service (USDA), United States</p>
      </fn>
      <corresp id="fn001">*Correspondence: Duke Pauli, <email xlink:href="mailto:dukepauli@arizona.edu">dukepauli@arizona.edu</email>
</corresp>
      <fn fn-type="other" id="fn002">
        <p>This article was submitted to Technical Advances in Plant Science, a section of the journal Frontiers in Plant Science</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>06</day>
      <month>3</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>14</volume>
    <elocation-id>1112973</elocation-id>
    <history>
      <date date-type="received">
        <day>30</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>2</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2023 Gonzalez, Zarei, Hendler, Simmons, Zarei, Demieville, Strand, Rozzi, Calleja, Ellingson, Cosi, Davey, Lavelle, Truco, Swetnam, Merchant, Michelmore, Lyons and Pauli</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Gonzalez, Zarei, Hendler, Simmons, Zarei, Demieville, Strand, Rozzi, Calleja, Ellingson, Cosi, Davey, Lavelle, Truco, Swetnam, Merchant, Michelmore, Lyons and Pauli</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>As phenomics data volume and dimensionality increase due to advancements in sensor technology, there is an urgent need to develop and implement scalable data processing pipelines. Current phenomics data processing pipelines lack modularity, extensibility, and processing distribution across sensor modalities and phenotyping platforms. To address these challenges, we developed PhytoOracle (PO), a suite of modular, scalable pipelines for processing large volumes of field phenomics RGB, thermal, PSII chlorophyll fluorescence 2D images, and 3D point clouds. PhytoOracle aims to (<italic>i</italic>) improve data processing efficiency; (<italic>ii</italic>) provide an extensible, reproducible computing framework; and (<italic>iii</italic>) enable data fusion of multi-modal phenomics data. PhytoOracle integrates open-source distributed computing frameworks for parallel processing on high-performance computing, cloud, and local computing environments. Each pipeline component is available as a standalone container, providing transferability, extensibility, and reproducibility. The PO pipeline extracts and associates individual plant traits across sensor modalities and collection time points, representing a unique multi-system approach to addressing the genotype-phenotype gap. To date, PO supports lettuce and sorghum phenotypic trait extraction, with a goal of widening the range of supported species in the future. At the maximum number of cores tested in this study (1,024 cores), PO processing times were: 235 minutes for 9,270 RGB images (140.7 GB), 235 minutes for 9,270 thermal images (5.4 GB), and 13 minutes for 39,678 PSII images (86.2 GB). These processing times represent end-to-end processing, from raw data to fully processed numerical phenotypic trait data. Repeatability values of 0.39-0.95 (bounding area), 0.81-0.95 (axis-aligned bounding volume), 0.79-0.94 (oriented bounding volume), 0.83-0.95 (plant height), and 0.81-0.95 (number of points) were observed in Field Scanalyzer data. We also show the ability of PO to process drone data with a repeatability of 0.55-0.95 (bounding area).</p>
    </abstract>
    <kwd-group>
      <kwd>phenomics</kwd>
      <kwd>morphological phenotyping</kwd>
      <kwd>physiological phenotyping</kwd>
      <kwd>distributed computing</kwd>
      <kwd>high performance computing</kwd>
      <kwd>image analysis</kwd>
      <kwd>point cloud analysis</kwd>
      <kwd>data management</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source id="cn001">
          <institution-wrap>
            <institution>U.S. Department of Energy
</institution>
            <institution-id institution-id-type="doi">10.13039/100000015</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id award-type="contract" rid="cn001">DE-SC0020401</award-id>
      </award-group>
      <award-group>
        <funding-source id="cn002">
          <institution-wrap>
            <institution>U.S. Department of Energy
</institution>
            <institution-id institution-id-type="doi">10.13039/100000015</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id award-type="contract" rid="cn002">DE-AR0001101</award-id>
      </award-group>
      <award-group>
        <funding-source id="cn003">
          <institution-wrap>
            <institution>National Science Foundation
</institution>
            <institution-id institution-id-type="doi">10.13039/100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id award-type="contract" rid="cn003">DBI-1743442, IOS-2023310, IOS-2102120</award-id>
      </award-group>
      <award-group>
        <funding-source id="cn004">
          <institution-wrap>
            <institution>Cotton Incorporated
</institution>
            <institution-id institution-id-type="doi">10.13039/100006481</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id award-type="contract" rid="cn004">18-384, 20-720, 21-830</award-id>
      </award-group>
      <award-group>
        <funding-source id="cn005">
          <institution-wrap>
            <institution>National Institute of Food and Agriculture
</institution>
            <institution-id institution-id-type="doi">10.13039/100005825</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id award-type="contract" rid="cn005">2021-51181-35903</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <funding-statement>This research was supported by the following grants: U.S. Department of Energy Biological and Environmental Research (DE-SC0020401) and Advanced Research Projects Agency - Energy OPEN (DE-AR0001101); National Science Foundation CyVerse project (DBI-1743442); National Science Foundation (IOS-2102120 and IOS-2023310); Cotton Incorporated (18-384, 20-720, and 21-830); and U.S. Department of Agriculture National Institute of Food and Agriculture Specialty Crop Research Initiative (2021-51181-35903).</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="8"/>
      <table-count count="4"/>
      <equation-count count="13"/>
      <ref-count count="82"/>
      <page-count count="20"/>
      <word-count count="12698"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="s1">
    <label>1</label>
    <title>Introduction</title>
    <p>The world population is expected to reach 10 billion people by 2050 with a projected 50% decrease in global freshwater resources (<xref rid="B62" ref-type="bibr">Searchinger et al., 2019</xref>; <xref rid="B28" ref-type="bibr">Gupta et al., 2020</xref>). Although existing crop improvement methods have maintained stable increases in crop yields, a continuation of these trends is not sustainable (<xref rid="B26" ref-type="bibr">Grassini et al., 2013</xref>). Crop improvement methods continue to rely on subjective, manually collected phenotype data. However, advances in sensor technology have contributed to the emergence of plant phenomics, the study of plant phenotypes, over the last decade (<xref rid="B3" ref-type="bibr">Andrade-Sanchez et al., 2014</xref>; <xref rid="B4" ref-type="bibr">Araus and Cairns, 2014</xref>; <xref rid="B49" ref-type="bibr">Pauli et al., 2016</xref>). Low-cost, user-friendly sensors now enable the collection of objective data at high throughput. The resulting data volumes are substantial and reveal bottlenecks in data processing, data management, and data storage. To date, a variety of phenomics bottlenecks related to data collection have been resolved, but computational bottlenecks related to data volume and velocity have been largely overlooked (<xref rid="B23" ref-type="bibr">Furbank and Tester, 2011</xref>). The volume and velocity of plant phenomics data collection makes it difficult to extract phenotypic trait data using existing software at the scale required for breeding programs and basic research. Therefore, addressing bottlenecks in computational throughput would enable the efficient processing of data and, as a result, the study of variation and plasticity of fine-scale traits at high temporal resolution. These high-resolution datasets may improve the elucidation of genetic components controlling agronomic and functional traits (<xref rid="B23" ref-type="bibr">Furbank and Tester, 2011</xref>).</p>
    <p>Phenotyping, various marker technologies, and statistical methods have enabled the prediction of genotypic values and genetic mapping (<xref rid="B8" ref-type="bibr">Bernardo, 2020</xref>). The application of these methods allows for the dissection of the genetic and environmental components of phenotypic trait variance. Such studies require the measurement of quantitative traits that are often collected visually, in the case of observational data, and manually using handheld devices such as PAM fluorometers for chlorophyll fluorescence measurements, spectroradiometers for UV-VIS-NIR, protractors for leaf angle, rulers for plant height, and weight scales for yield. Visual and manual phenotyping are common due to having low initial investment costs, but these approaches lack throughput and reproducibility due to the labor required and subjectivity of measurements (<xref rid="B59" ref-type="bibr">Reynolds et al., 2019</xref>). Emerging technologies, such as automated high-throughput plant phenotyping platforms, often have higher initial investment costs compared to traditional phenotype collection, but this is quickly changing. High-throughput platforms are diverse, including robots, drones, phones, and carts (<xref rid="B75" ref-type="bibr">White and Conley, 2013</xref>; <xref rid="B5" ref-type="bibr">Bai et al., 2016</xref>; <xref rid="B68" ref-type="bibr">Thompson et al., 2018</xref>; <xref rid="B69" ref-type="bibr">Thorp et al., 2018</xref>; <xref rid="B76" ref-type="bibr">Yuan et al., 2018</xref>; <xref rid="B27" ref-type="bibr">Guo et al., 2020</xref>; <xref rid="B61" ref-type="bibr">Roth et al., 2020</xref>). Compared with traditional methods, these platforms improve data collection throughput, reduce subjectivity through varying levels of automation, and enable higher phenotyping resolution, referred to here as fine-scale phenotyping (<xref rid="B59" ref-type="bibr">Reynolds et al., 2019</xref>). The resolution provided by fine-scale phenotyping has enabled studies revealing genetic loci associated with drought resistance (<xref rid="B43" ref-type="bibr">Li et al., 2020</xref>), stomatal conductance (<xref rid="B53" ref-type="bibr">Prado et al., 2018</xref>), temporal salinity responses (<xref rid="B10" ref-type="bibr">Campbell et al., 2015</xref>), and panicle architecture (<xref rid="B57" ref-type="bibr">Rebolledo et al., 2016</xref>). Other studies have captured natural variation in photosynthetic efficiency (<xref rid="B71" ref-type="bibr">van Bezouw et al., 2019</xref>; <xref rid="B38" ref-type="bibr">Khan et al., 2020</xref>) as well as highlighted the feasibility of phenomics selection (<xref rid="B60" ref-type="bibr">Rincent et al., 2018</xref>; <xref rid="B48" ref-type="bibr">Parmley et al., 2019</xref>; <xref rid="B79" ref-type="bibr">Zhu et al., 2021</xref>) based on traits such as stay-green (<xref rid="B56" ref-type="bibr">Rebetzke et al., 2016</xref>) and spectral reflectance (<xref rid="B1" ref-type="bibr">Aguate et al., 2017</xref>; <xref rid="B42" ref-type="bibr">Lane et al., 2020</xref>).</p>
    <p>The high temporal and spatial resolution of fine-scale phenotyping using automated plant phenotyping platforms provide new opportunities to study dynamic patterns in phenotype expression in response to varying conditions. For example, the phenotypic effects of induced variation can be assessed in mutant populations and natural variation in diversity panels (<xref rid="B38" ref-type="bibr">Khan et al., 2020</xref>), allowing for the detection of temporal fluctuations in trait expression and associations between morphological and physiological phenotypic traits. Future research and development in computational plant phenomics could help improve selection accuracy due, in part, to increasingly precise extraction of fine-scale phenotypes enabled by complementary analytical methods and algorithms. In plant phenomics, the level of extraction required to dissect agronomic and functional traits would involve processing large volumes of image, spectral, and point cloud raw data across thousands of plants and time points to identify unique, obscure patterns of morphophysiological responses to various environments. The integration of these fine scale phenomics datasets within and across projects would further expand our knowledge of traits and aid in hypothesis generation (<xref rid="B14" ref-type="bibr">Coppens et al., 2017</xref>).</p>
    <p>The data volumes generated by biological sciences research outpace existing computing infrastructure (<xref rid="B11" ref-type="bibr">Chen et al., 2013</xref>; <xref rid="B54" ref-type="bibr">Qin et al., 2015</xref>; <xref rid="B64" ref-type="bibr">Stephens et al., 2015</xref>; <xref rid="B63" ref-type="bibr">Sivarajah et al., 2017</xref>). Additionally, data variety within biological sciences research is widening due to the emergence of phenomics, particularly in plant science research (<xref rid="B23" ref-type="bibr">Furbank and Tester, 2011</xref>; <xref rid="B22" ref-type="bibr">Furbank et al., 2019</xref>; <xref rid="B29" ref-type="bibr">Harfouche et al., 2019</xref>). The increasing availability and diversity of modular, high-quality sensors mounted on automated phenotyping platforms has led to the collection of large volumes of various data types, including morphological and physiological traits (<xref rid="B14" ref-type="bibr">Coppens et al., 2017</xref>). These expanding data volumes pose new challenges related to computation, data integration, and data management – a problem that is likely to be exacerbated by continued improvements and widespread use of sensor technology (<xref rid="B39" ref-type="bibr">Kim et al., 2017</xref>). In information science, it has long been recognized that existing computational techniques are inadequate in dealing with big data, primarily due to bottlenecks in the extraction of information from large volumes of data and the associated bottlenecks of scalability and data management. The bottleneck in information extraction is actively being addressed through the development of methods including machine learning (ML) and artificial intelligence (AI), while parallel processing is addressing scalability (<xref rid="B11" ref-type="bibr">Chen et al., 2013</xref>; <xref rid="B36" ref-type="bibr">Jukić et al., 2015</xref>; <xref rid="B63" ref-type="bibr">Sivarajah et al., 2017</xref>). Although these methods improve scalability and information extraction, they do not address data management. Parallel computing systems (PCSs) are characterized by the co-location of input data and processing code, representation of processing in terms of data flows and transformations, and scalability. Collectively, these characteristics facilitate the processing of datasets once considered intractable due to previous limitations in computing (<xref rid="B37" ref-type="bibr">Kale, 2020</xref>). The required computational resources in PCSs are commonly data-dependent, meaning that each dataset requires a different set of computational resources. To increase processing efficiency and reduce computing costs, PCSs could allow users to tailor CPU/GPU, high-memory/high-processor nodes, and other computational resources to specific datasets. This capability may become increasingly important as expanding data volumes pose a higher cost if computational resources are used inefficiently.</p>
    <p>For phenomics data to provide actionable genome-phenome insights in combination with other -omics data, large scale phenomics data must be processed in a scalable and reproducible manner, stored in publicly accessible data stores, and be interoperable with other data types (<xref rid="B14" ref-type="bibr">Coppens et al., 2017</xref>; <xref rid="B39" ref-type="bibr">Kim et al., 2017</xref>). To address these requisites, a variety of established resources can be leveraged. For example, data management systems such as the CyVerse Data Store, a cloud-based data management system built on the Integrated Rule-Oriented Data System (iRODS), provides storage and cross-platform command line interface (CLI) access to data (<xref rid="B25" ref-type="bibr">Goff et al., 2011</xref>; <xref rid="B46" ref-type="bibr">Merchant et al., 2016</xref>). Container technologies, such as Docker and Singularity, serve as stand-alone environments with required dependencies pre-installed by software developers for increased extensibility (<xref rid="B41" ref-type="bibr">Kurtzer et al., 2017</xref>). High performance computers (HPCs) supply numerous processors, dual in-line memory modules (DIMMs), internal disk, and networking ports to scale up processing tasks. Container technology and data management systems coupled with HPCs provide reproducible and scalable environments, respectively (<xref rid="B18" ref-type="bibr">Devisetty et al., 2016</xref>; <xref rid="B41" ref-type="bibr">Kurtzer et al., 2017</xref>). Large volume datasets further require advanced PCSs capable of leveraging thousands of computers or cluster nodes for parallel processing on local, cloud, and/or HPC compute resources. A suite of computing tools for deploying scalable applications known as the Cooperative Computing Tools (CCTools) consists of Makeflow and Work Queue, a language and computational resource management framework for distributed computing, respectively (<xref rid="B2" ref-type="bibr">Albrecht et al., 2012</xref>). When coordinated, the above-mentioned computational resources can improve the processing and management of raw data and enable large scale analyses of extracted phenomics data.</p>
    <p>Several image analysis pipelines exist for morphological and physiological phenotype trait extraction including: ImageHarvest (<xref rid="B40" ref-type="bibr">Knecht et al., 2016</xref>); Greenotyper (<xref rid="B66" ref-type="bibr">Tausen et al., 2020</xref>); and PlantCV (<xref rid="B20" ref-type="bibr">Fahlgren et al., 2015</xref>; <xref rid="B24" ref-type="bibr">Gehan et al., 2017</xref>). Most of these software were developed for automated phenotyping platforms in controlled greenhouse environments and would require significant modification for processing field phenomics data due to variations in image illumination and the lack of spacing between plants in field settings. Although some pipelines integrate multi-processing or distributed computing capabilities, there is currently no published pipeline that integrates data management systems, container technologies, PCSs, and multi-system deployment within a single framework. Importantly, many existing image analysis software were not designed to enable customization of computational resources, a critical component for efficiently processing phenomics’ expanding data volumes (<xref rid="B37" ref-type="bibr">Kale, 2020</xref>).</p>
    <p>Here, we present PhytoOracle (PO), a suite of data processing pipelines for phenomics data processing. PhytoOracle combines data management systems, container technologies, distributed computing, and multi-system deployment into a single framework capable of processing phenomics data collected with RGB cameras (RGB), photosystem II chlorophyll fluorescence imagers (PSII), thermal cameras (thermal), structured-light laser scanners (3D). Each pipeline component is containerized and can be removed, replaced, rearranged, or deployed in isolation. PhytoOracle provides advanced PCS and automation capabilities for processing large phenomics datasets across HPC, cloud, and/or local computing environments. The PO suite organizes all processing tasks and computational resource specifications within a single YAML file, which enables customization of computational resources, processing modules, and data management systems. Users can target pipelines to the optimal computational resources whether that be high-memory, high-processor, and/or GPU nodes. The modularity and distributed computing capabilities of PO enable the efficient extraction of time series, individual plant phenotypic trait data from large, multi-modal phenomics datasets. The PCSs like PO improve data analysis and information processing, providing large scale data that can help answer questions that were previously intractable due to data volumes outpacing computing systems’ capacities.</p>
  </sec>
  <sec sec-type="materials|methods" id="s2">
    <label>2</label>
    <title>Materials and methods</title>
    <sec id="s2_1">
      <label>2.1</label>
      <title>Plant material</title>
      <p>For this study, a panel of 241 lettuce genotypes were evaluated at the University of Arizona’s Maricopa Agricultural Center (MAC) in Maricopa, Arizona (33°04’24.8” N 111°58’25.7” W). The soil type is a Casa Grande sandy loam (fine-loamy, mixed, superactive, hyperthermic Typic Natrargids). The panel consisted of two subpopulations of lettuce, a diversity panel (147 genotypes) that represented all major market classes of lettuce and a recombinant inbred line (RIL) mapping population (94 genotypes) developed from a cross of the cultivars “Iceberg” and “Grand Rapids.” The population was organized in a randomized incomplete block design with three replications of both lettuce panels per irrigation treatment level with common checks used throughout the field. The borders around each irrigation treatment were of the cultivar “Green Towers.” The three irrigation treatments were: well-watered (WW), level 1 drought (D1), and level 2 drought (D2) (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Figure 1</bold></xref>). The WW treatment was defined as 24% volumetric soil water content (VSWC) which represents field capacity. To achieve the D1 and D2 conditions, 75% and 50% of the WW irrigation amounts were applied to the plots, respectively. Raised vegetable beds on 1.02 m row spacing were shaped to have a surface width of 0.56 m with two seed lines per bed spaced at 0.31 m; plots were 4.00 m in length. Experimental plots consisted of one of the individual seed lines per raised bed so that two genotypes were planted per raised bed.</p>
      <p>The crop was established using sprinkler irrigation for the first 35 days before switching to subsurface drip irrigation. Buried within each bed, at a depth of 0.20 m, was pressure compensated drip tape (Model 06D63613.16-12, Netafim, Tel Aviv, Israel) supplying a constant 0.38 liters per hour of water. Soil moisture conditions were recorded using a neutron probe (Model 503, Campbell Pacific Nuclear, CPN, Martinez, CA, USA) with readings taken at depths of 10, 30, 50, 70, and 90 cm on a weekly basis. Neutron probe access tubes were distributed throughout the field to capture the VSWC across the different irrigation treatments over the growing period. Once plants were established and being irrigated with subsurface irrigation, plots were thinned to a density of 10 equidistant plants to facilitate individual plant phenotyping. After thinning, approximately 26,000 plants were present in the field, with each treatment containing approximately 9,000 plants. Standard cultivation practices and agronomic management for lettuce production in the Southwest were followed. A total of 1,472 plants, one from each plot within the WW and D2 treatments, were harvested and their fresh weights were recorded at the end of the growing period (2020-03-03).</p>
    </sec>
    <sec id="s2_2">
      <label>2.2</label>
      <title>Phenotyping platforms</title>
      <p>The Field Scanalyzer (FS) is a ground-based, automated phenotyping platform that moves along rails that are 394.1 m in length running North-South with 28 m separation between the rails; the area covered by the FS is approximately 1.11 hectares. This area is split into two fields with scannable areas of 0.37 hectare for the north field and 0.46 hectare for the south field; for the purposes of the present research, only the south field was used (<xref rid="f1" ref-type="fig"><bold>Figure 1A</bold></xref>). The FS is equipped with a ventilated sensor box that holds multiple imagers and cameras including the following: Allied Vision Prosilica GT3300C stereo RGB cameras (RGB), LemnaTec photosystem II chlorophyll fluorescence prototype imager (PSII), FLIR A615 thermal camera (Thermal), pair of Fraunhofer structured-light laser scanners (3D), and two Headwall HyperSpec Inspector pushbroom hyperspectral imagers (visible to near infrared [VNIR] and short-wave infrared [SWIR]) (<xref rid="f1" ref-type="fig"><bold>Figure 1B</bold></xref> and <xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Table 1</bold></xref>). The sensor box can move vertically from 0.43 to 6.26 m above ground level to accommodate varying scanning distance requirements for each sensor and to maintain a consistent distance from the instrument to plant canopy throughout the growing season.</p>
      <fig position="float" id="f1">
        <label>Figure 1</label>
        <caption>
          <p>Overview of the Field Scanalyzer (FS) and DJI Phantom 4 Pro V2 drone (DR) phenotyping platforms, the components that make up each platform’s sensor array and resulting data types. <bold>(A)</bold> An aerial photograph showing the area scanned by the FS which totals 0.63 hectare. Orange dots indicate the ground control point (GCPs) configuration, consisting of five sets of four GCPs running east to west for a total of 20 GCPs. (Top <bold>B</bold>) The FS sensor box contains a photosystem II (PSII) chlorophyll fluorescence imager, stereo RGB cameras, a thermal camera, two pushbroom hyperspectral imagers (visible near-infrared [VNIR] and shortwave near-infrared [SWIR]), a pair of structured-light laser scanners, and environmental sensors. (Botton <bold>B</bold>) Collected data included RGB, thermal, and PSII 2D image data and 3D point cloud data. (Top <bold>C</bold>) The DJI Phantom 4 Pro V2 drone (DR) was equipped with a 20-megapixel RGB camera and flown with automated flight mapping software at an altitude of 15 meters. (Bottom <bold>C</bold>) Collected data included RGB 2D image data.</p>
        </caption>
        <graphic xlink:href="fpls-14-1112973-g001" position="float"/>
      </fig>
      <p>The FS scanning scheme is controlled by custom operating scripts that specify the scan area, pattern, and scheduling for data collection of each sensor. These operating scripts are set to collect data on specific regions of the field, agricultural plots, or the entire field by the FS operator. The RGB, thermal, and PSII sensors collect binary (BIN) format images, while the 3D laser scanners collect depth and reflectance imagery from which point clouds are generated using manufacturer-provided software (<xref rid="T1" ref-type="table"><bold>Table 1</bold></xref>). Each data collection is accompanied by metadata files in JavaScript Object Notation (JSON) format containing FS variable position, sensor fixed position (location of sensors within sensor box), preset scanning area, and timestamps. Positioning information is collected by a series of barcodes along the rails (X and Y axes) and a string encoder (Z axis) using a right-handed coordinate system (+X South-to-North, +Y East-to-West, and +Z 0.76 cm above soil upwards). Additionally, environmental sensors collect and log information on downwelling irradiance, photosynthetically active radiation, air temperature, relative humidity, brightness, ambient air carbon dioxide concentration, precipitation, and wind velocity and direction all at 5-second intervals in JSON format.</p>
      <table-wrap position="float" id="T1">
        <label>Table 1</label>
        <caption>
          <p>Data collection summary for Field Scanalyzer (FS) and drone (DR) phenotyping platforms of data types supported by PhytoOracle.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="middle" align="left" rowspan="1" colspan="1">Data</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Collection time</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Concurrent scan</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Scanning area</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Data type</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Benchmark data size</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Total scans</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Total size</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="middle" align="left" rowspan="1" colspan="1">RGB-FS</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">5</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Thermal-FS</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Full field</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">BIN</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">140</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">36</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">2.91</td>
            </tr>
            <tr>
              <td valign="middle" align="left" rowspan="1" colspan="1">Thermal-FS</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">5</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">RGB-FS</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Full field</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">BIN</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">5</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">36</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.10</td>
            </tr>
            <tr>
              <td valign="middle" align="left" rowspan="1" colspan="1">PSII-FS</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">5</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">–</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Paired-plot center</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">BIN</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">80</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">18</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">1.00</td>
            </tr>
            <tr>
              <td valign="middle" align="left" rowspan="1" colspan="1">3D-FS</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">9</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">–</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Full field</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">PLY</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">350</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">32</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">8.37</td>
            </tr>
            <tr>
              <td valign="middle" align="left" rowspan="1" colspan="1">RGB-DR</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.5</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">–</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Full field</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">JPEG</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">3</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">19</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.059</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>The scanning area listed as full field encompassed the south portion of the field (0.63 hectare). Benchmark data size, gigabytes; total size, terabytes.</p>
          </fn>
        </table-wrap-foot>
        <table-wrap-foot>
          <fn>
            <p>Collection duration (hours) represents the time from first data capture to final data capture.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <sec id="s2_2_1">
        <label>2.2.1</label>
        <title>Data collection and management</title>
        <p>For this study, the FS scanned the south field during the day and night throughout a growing season, collecting high-resolution, time-series images and point cloud data. The total number of RGB, thermal, PSII, and 3D data collections were 36, 36, 13, and 46, respectively. The RGB, thermal, and 3D laser scanner data collections covered the entire field while PSII data collections covered the center of each bed within a single treatment (<xref rid="T1" ref-type="table"><bold>Table 1</bold></xref>). The FS total raw data sizes for each sensor were as follows: 0.12 terabytes (TBs) for thermal, 1.19 TBs for PSII, 3.20 TBs for RGB, and 8.77 TBs for 3D. Altogether, the FS data collections resulted in 13.36 TBs of raw data for the lettuce trial (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Figure 2</bold></xref>).</p>
        <p>In addition to FS data, drone (DR) flights were conducted over the same 0.46-hectare south field on a weekly basis using a DJI Phantom 4 Pro V2 (DJI, Nanshan, Shenzhen, China) and DroneDeploy software (v. 4.2.1; DroneDeploy, San Francisco, CA, USA) installed on an Apple iPad Mini 4 (Model #MK9P2LL/A; Apple, Cupertino, CA, USA) (<xref rid="f1" ref-type="fig"><bold>Figure 1</bold></xref>). The flight mission settings were as follows: 15 m altitude, 80% front - 80% side overlaps, 0.41 cm/pixel ground sample distance, resulting in approximately 450 images per flight. In total, the DR collections resulted in 0.08 TBs of raw image data for the lettuce trial (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Figure 2</bold></xref>). For a complete list of FS and DR data collection dates, refer to <xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Table 2</bold></xref>.</p>
      </sec>
      <sec id="s2_2_2">
        <label>2.2.2</label>
        <title>Data management</title>
        <p>The FS data collections were temporarily stored on a platform-mounted server and transferred to a cache server located at MAC. After a three-day retention period, each data collection was programmatically archived, producing a single “.tar.gz” archive file per data collection (one sensor’s scan), and programmatically transferred to the CyVerse Data Store servers located in Tucson, AZ using Internet2. Each DR data collection was uploaded to the CyVerse Data Store manually. The DR and FS archives were placed in a publicly available location in the CyVerse Data Store for general use and CLI access during data processing (<xref rid="B25" ref-type="bibr">Goff et al., 2011</xref>) (see Data Availability Statement).</p>
      </sec>
    </sec>
    <sec id="s2_3">
      <label>2.3</label>
      <title>Parallel computing system</title>
      <p>The PO pipelines require ML models for object detection and point cloud segmentation during data processing. Data must be annotated, models trained, and performance assessed before data processing can be performed. As such, a description of model training is presented before describing PO processing pipelines in detail. Together with a season-specific GeoJSON containing plot boundaries, a YAML file specifying processing tasks, and computational resources, PO can distribute tasks across processing nodes of an HPC.</p>
      <sec id="s2_3_1">
        <label>2.3.1</label>
        <title>Training and assessing performance of machine learning models</title>
        <sec id="s2_3_1_1">
          <label>2.3.1.1</label>
          <title>2D object detection</title>
          <p>To prepare image data for manual annotation, RGB and thermal data collections were processed up to the plot clip step to produce plot clipped orthomosaics (<xref rid="f2" ref-type="fig"><bold>Figure 2A</bold></xref>, Steps 1-4). Thermal and RGB plot clipped orthomosaics were converted from georeferenced Tag Image File Format (GeoTIFF) to PNG format (GeoTIFFs are not supported by annotation tools). Thermal image pixel values were normalized to the range of 0 to 255 to enhance visible features for manual annotation. Heat map images, with each pixel representing height, were generated from 3D point cloud data. The scripts for each of these steps is publicly accessible (see Code Availability Statement).</p>
          <fig position="float" id="f2">
            <label>Figure 2</label>
            <caption>
              <p>PhytoOracle two-dimensional (2D) image processing workflow. <bold>(A)</bold> The 2D pre-processing steps include the conversion of binary (BIN) files (RGB, thermal, PSII chlorophyll fluorescence) to GeoTIFF files, correction of georeferencing information within each GeoTIFF metadata using Megastitch for RGB and thermal data, clipping corrected GeoTIFF images to plots using a GeoJSON file with plot boundary information, and generation of plot level orthomosaics (<xref rid="B77" ref-type="bibr">Zarei et al., 2022</xref>). <bold>(B)</bold> RGB &amp; thermal plot level orthomosaics are run through a Faster R-CNN detection model for plant detection and phenotype extraction; PSII images are run through FLIP for extraction of minimum (F<sub>0</sub>) and maximum (F<sub>M</sub>) fluorescence values, variable fluorescence (F<sub>V</sub>), and maximum yield of primary photochemical efficiency (F<sub>V</sub>/F<sub>M</sub>). <bold>(C)</bold> Upon completion of data processing for a single experiment, individual plant detections from RGB and thermal data are associated over time using agglomerative clustering. Agglomerative clustering uses longitude and latitude to associate multiple plant observations, giving them a shared, unique plant identifier. <bold>(D)</bold> The growth and temperature of individual plants can be tracked and visualized using the unique plant identifier. A merged, full season RGB and thermal data file can then be combined with PSII (plot level) and 3D laser phenotype data using the unique plant/plot identifiers. <bold>(E)</bold> The results of PhytoOracle are time series datasets with plant geographical coordinates of the bounding box predictions and plant centers; bounding area (BA); median and mean canopy temperatures (MEDT and MEAT, respectively); plant height (PH), axis-aligned and oriented bounding box volumes (AABV and OBV, respectively), and convex hull volume (CHV); and plot level F<sub>0</sub>, F<sub>V</sub>, F<sub>M</sub>, and F<sub>V</sub>/F<sub>M</sub> for each detected plant.</p>
            </caption>
            <graphic xlink:href="fpls-14-1112973-g002" position="float"/>
          </fig>
          <p>To train object detection ML models for RGB and thermal imagery, a total of 2,000 images per sensor type were randomly selected for developing training data (see Code Availability Statement). A total of 200 3D-derived heatmap images were randomly generated to train object detection ML models. The RGB, thermal, and 3D-derived heatmap image datasets were uploaded to Labelbox (<ext-link xlink:href="http://labelbox.com" ext-link-type="uri">http://labelbox.com</ext-link>; Labelbox, San Francisco, CA, USA) and manually labeled with a single bounding box around each plant. All images were manually reviewed to ensure label quality. A JSON file containing label bounding box coordinates for all images in a dataset was programmatically converted to XML files, resulting in one XML file per image (see Code Availability Statement). The RGB and thermal datasets were each randomly split into training, validation, and test sets (80%, 10%, and 10%, respectively). Transfer learning was employed to train a Faster R-CNN (region-based convolutional neural network) ResNet-50 FPN pre-trained model for RGB, thermal, and 3D-derived image datasets, separately, using the Detecto Python package (v. 1.2.1, <ext-link xlink:href="http://github.com/alankbi/detecto" ext-link-type="uri">http://github.com/alankbi/detecto</ext-link>) (<xref rid="B58" ref-type="bibr">Ren et al., 2017</xref>). The models for all data types were trained on a single label (“plant”). Training was performed on a HPC compute node with two AMD Zen2 48-core processors (AMD, Santa Clara, CA, USA), 512 GB of RAM, sixteen 32 GB memory DIMM, 2 TB SSD disk, and a V100S graphics processing unit (GPU) (NVIDIA, Santa Clara, CA, USA) with 32 GB memory. The selected setting of training parameters was 10 epochs, batch size of one, learning rate of 5 x 10<sup>-3</sup>, 5 x 10<sup>-4</sup> weight decay (L2 regularization), and step size of three.</p>
          <p>Model performance was assessed by calculating Intersection over Union (IoU), recall, precision, and F1 scores for RGB, thermal, and 3D-derived test datasets. To determine model performance more finely across the developmental stages of lettuce, we assessed IoU of randomly selected plots over the course of the season for RGB and thermal models. The IoU values were calculated as follows:</p>
          <disp-formula>
            <label>(1)</label>
            <mml:math id="M1" display="block" overflow="scroll">
              <mml:mrow>
                <mml:mi>I</mml:mi>
                <mml:mi>o</mml:mi>
                <mml:mi>U</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mo>|</mml:mo>
                      <mml:mrow>
                        <mml:mi>A</mml:mi>
                        <mml:mo>∩</mml:mo>
                        <mml:mi>B</mml:mi>
                      </mml:mrow>
                      <mml:mo>|</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mo>|</mml:mo>
                      <mml:mrow>
                        <mml:mi>A</mml:mi>
                        <mml:mo>∪</mml:mo>
                        <mml:mi>B</mml:mi>
                      </mml:mrow>
                      <mml:mo>|</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mfrac>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <p>where <italic>A</italic> is the area of the predicted bounding box, <italic>B</italic> is the area of the ground truth bounding box, and ∩ is the intersection and ∪ is the union of predicted and ground truth boxes. Detections with an IoU ≥ 0.5 were classified as true positives (TP, correctly detected plant), those with an IoU&lt; 0.5 were classified as false positives (FP, plant is not present but detected), and detections with an IoU = 0 were classified as false negative (FN, plant is present but not detected). Recall, precision, and F1-score were calculated as follows:</p>
          <disp-formula>
            <label>(2)</label>
            <mml:math id="M2" display="block" overflow="scroll">
              <mml:mrow>
                <mml:mi>R</mml:mi>
                <mml:mi>e</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>a</mml:mi>
                <mml:mi>l</mml:mi>
                <mml:mi>l</mml:mi>
                <mml:mtext> </mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi>F</mml:mi>
                    <mml:mi>N</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <disp-formula>
            <label>(3)</label>
            <mml:math id="M3" display="block" overflow="scroll">
              <mml:mrow>
                <mml:mi>P</mml:mi>
                <mml:mi>r</mml:mi>
                <mml:mi>e</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>i</mml:mi>
                <mml:mi>s</mml:mi>
                <mml:mi>i</mml:mi>
                <mml:mi>o</mml:mi>
                <mml:mi>n</mml:mi>
                <mml:mtext> </mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi>F</mml:mi>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <disp-formula>
            <label>(4)</label>
            <mml:math id="M4" display="block" overflow="scroll">
              <mml:mrow>
                <mml:mi>F</mml:mi>
                <mml:mn>1</mml:mn>
                <mml:mtext> </mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mn>2</mml:mn>
                <mml:mo>·</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>P</mml:mi>
                    <mml:mi>r</mml:mi>
                    <mml:mi>e</mml:mi>
                    <mml:mi>c</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>s</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>o</mml:mi>
                    <mml:mi>n</mml:mi>
                    <mml:mo>·</mml:mo>
                    <mml:mi>R</mml:mi>
                    <mml:mi>e</mml:mi>
                    <mml:mi>c</mml:mi>
                    <mml:mi>a</mml:mi>
                    <mml:mi>l</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>P</mml:mi>
                    <mml:mi>r</mml:mi>
                    <mml:mi>e</mml:mi>
                    <mml:mi>c</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>s</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>o</mml:mi>
                    <mml:mi>n</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi>R</mml:mi>
                    <mml:mi>e</mml:mi>
                    <mml:mi>c</mml:mi>
                    <mml:mi>a</mml:mi>
                    <mml:mi>l</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
              </mml:mrow>
            </mml:math>
          </disp-formula>
        </sec>
        <sec id="s2_3_1_2">
          <label>2.3.1.2</label>
          <title>3D segmentation</title>
          <p>To train segmentation ML models, a random sample of individual plant point clouds were collected and labeled using a model-assisted labeling (MAL) approach (Model-assisted labeling (MAL); <xref rid="B35" ref-type="bibr">Huxohl and Kummert, 2021</xref>). The MAL script fit a plane to each point cloud and resulted in the labeling of two classes: plant and soil (see Code Availability Statement). The results were visualized, and segmentation errors were manually corrected, resulting in a total of 160 annotated individual plant point clouds; plant point clouds were randomly split into train, validation, and test sets (80%, 10%, and 10%, respectively). A Dynamic Graph CNN (DGCNN) was trained on a server with four AMD EPYC 7702 64-Core processors (AMD, Santa Clara, CA, USA), 1 TB of RAM, and three NVIDIA Tesla T4 GPUs (NVIDIA, Santa Clara, CA, USA) (<xref rid="B1002" ref-type="bibr">Wang et al., 2019</xref>). The following training parameters were selected: 30 epochs, learning rate of 0.01, 1 x 10<sup>-4</sup>, momentum of 0.9, and batch size of 32. The classes predicted by the DGCNN model for each point were compared with manually annotated data to collect TP, FP, TN, FN values, which were used to calculate the point-wise accuracy as follows:</p>
          <disp-formula>
            <label>(5)</label>
            <mml:math id="M5" display="block" overflow="scroll">
              <mml:mrow>
                <mml:mi>P</mml:mi>
                <mml:mi>o</mml:mi>
                <mml:mi>i</mml:mi>
                <mml:mi>n</mml:mi>
                <mml:mi>t</mml:mi>
                <mml:mtext> </mml:mtext>
                <mml:mo>−</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mi>w</mml:mi>
                <mml:mi>i</mml:mi>
                <mml:mi>s</mml:mi>
                <mml:mi>e</mml:mi>
                <mml:mtext> </mml:mtext>
                <mml:mi>a</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>u</mml:mi>
                <mml:mi>r</mml:mi>
                <mml:mi>a</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>y</mml:mi>
                <mml:mtext>  </mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mtext>  </mml:mtext>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi>T</mml:mi>
                    <mml:mi>N</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi>F</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi>T</mml:mi>
                    <mml:mi>N</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi>F</mml:mi>
                    <mml:mi>N</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
              </mml:mrow>
            </mml:math>
          </disp-formula>
        </sec>
      </sec>
      <sec id="s2_3_2">
        <label>2.3.2</label>
        <title>Multimodal pipeline deployment</title>
        <p>The processing instructions for PO data processing are defined in a Yet Another Markup Language (YAML) file (<xref rid="B7" ref-type="bibr">Ben-Kiki and Evans, 2001</xref>). The PO YAML template consists of four sections: “tags”, “modules”, “workload_manager”, and “paths”. The “tags” section allows users to define season-specific metadata for documentation purposes. The “modules” section is where users define their processing tasks by specifying the container to be used, the command to be run within the container, and the inputs and outputs. The user can select to run the workflow locally or remotely, that is using existing local cores or remote worker cores. The “workload_manager” key defines computational resource specifications required by pipeline worker nodes including the cores per worker, number of workers, and memory per core. The information provided within the “workload_manager” key is used to request jobs using the Slurm workload manager. Importantly, this allows users to customize the computing system to accommodate datasets of varying levels of processing scales and computational complexities. The “paths” section defines CyVerse Data Store paths for raw data download, including ML models to be used within the processing steps, and output data uploads. At the moment, only CyVerse Data Store paths are supported, but other storage providers can be supported with a few changes to the code. Users can specify their project-specific CyVerse Data Store paths or keep data locally without uploading it onto a data store. Users can select to use data transfer nodes, if running PO on HPC systems. Examples of YAML files for data processing of RGB, PSII, thermal, and 3D phenomics data of lettuce and sorghum are publicly available (see Code Availability Statement).</p>
        <sec id="s2_3_2_1">
          <label>2.3.2.1</label>
          <title>RGB processing pipeline</title>
          <p>The full field RGB-FS datasets each consisted of 9,270 BIN files. Each image capture collected two BIN files, one from each RGB camera, and an associated JSON metadata file. Due to the physical arrangement of the stereo RGB cameras and the resulting high image overlap, only one image of each capture was used in this study. The RGB pipeline consisted of four containerized components (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Table 3</bold></xref> and <xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Figure 3</bold></xref>). The first container converted BIN files to GeoTIFF images with approximate GPS bounding coordinates calculated from barcode positioning information contained within the JSON metadata file generated by the FS. The second container deployed MegaStitch, which is a software for efficient image stitching of large-scale image datasets (<xref rid="B77" ref-type="bibr">Zarei et al., 2022</xref>). Megastitch was run in a non-distributed manner as all images are required for the global optimization stitching method, which generated geometrically corrected GeoTIFFs. The third container clipped GeoTIFFs to plot boundaries using a GeoJSON file that delimits plots within the field. The fourth container deployed a Faster R-CNN model to detect individual plants within each plot-clipped orthomosaic, which output bounding box coordinates. Bounding box coordinates were converted from pixel coordinates to geographic coordinates using the geotransform information of each plot-clipped orthomosaic. All georeferencing was calculated in the World Geodetic System (WGS84) coordinate reference system (<xref rid="B44" ref-type="bibr">Lohmar, 1988</xref>). Longitude was calculated as follows:</p>
          <disp-formula>
            <label>(6)</label>
            <mml:math id="M6" display="block" overflow="scroll">
              <mml:mrow>
                <mml:mtext>Longitude</mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mi>a</mml:mi>
                <mml:mo>·</mml:mo>
                <mml:mi>x</mml:mi>
                <mml:mo>+</mml:mo>
                <mml:mi>b</mml:mi>
                <mml:mo>·</mml:mo>
                <mml:mi>y</mml:mi>
                <mml:mo>+</mml:mo>
                <mml:mi>a</mml:mi>
                <mml:mo>·</mml:mo>
                <mml:mn>0.5</mml:mn>
                <mml:mo>+</mml:mo>
                <mml:mi>b</mml:mi>
                <mml:mo>·</mml:mo>
                <mml:mn>0.5</mml:mn>
                <mml:mo>+</mml:mo>
                <mml:mi>c</mml:mi>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <p>where <italic>c</italic> is the upper left Easting coordinate of the image, <italic>a</italic> is the E-W pixel spacing, <italic>c</italic> is the rotation, and <italic>x</italic> and <italic>y</italic> are the bounding box image coordinates. Latitude was calculated as follows:</p>
          <disp-formula>
            <label>(7)</label>
            <mml:math id="M7" display="block" overflow="scroll">
              <mml:mrow>
                <mml:mtext>Latitude </mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mi>d</mml:mi>
                <mml:mo>·</mml:mo>
                <mml:mi>x</mml:mi>
                <mml:mo>+</mml:mo>
                <mml:mi>e</mml:mi>
                <mml:mo>·</mml:mo>
                <mml:mi>y</mml:mi>
                <mml:mo>+</mml:mo>
                <mml:mi>d</mml:mi>
                <mml:mo>·</mml:mo>
                <mml:mn>0.5</mml:mn>
                <mml:mo>+</mml:mo>
                <mml:mi>e</mml:mi>
                <mml:mo>·</mml:mo>
                <mml:mn>0.5</mml:mn>
                <mml:mo>+</mml:mo>
                <mml:mi>f</mml:mi>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <p>where <italic>d</italic> is the rotation, <italic>e</italic> is the N-S pixel spacing, <italic>f</italic> is the upper left Northing coordinate, and <italic>x</italic> and <italic>y</italic> are the bounding box image coordinates. The four geographical corner coordinates were converted to UTM coordinates and used to calculate plant bounding area (BA) as follows:</p>
          <disp-formula>
            <label>(8)</label>
            <mml:math id="M8" display="block" overflow="scroll">
              <mml:mrow>
                <mml:mtext>Plant bounding area </mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mo>(</mml:mo>
                <mml:mi>S</mml:mi>
                <mml:msub>
                  <mml:mi>E</mml:mi>
                  <mml:mi>e</mml:mi>
                </mml:msub>
                <mml:mtext> </mml:mtext>
                <mml:mo>-</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mi>N</mml:mi>
                <mml:msub>
                  <mml:mi>W</mml:mi>
                  <mml:mi>e</mml:mi>
                </mml:msub>
                <mml:mo>)</mml:mo>
                <mml:mo>·</mml:mo>
                <mml:mo>(</mml:mo>
                <mml:mi>S</mml:mi>
                <mml:msub>
                  <mml:mi>E</mml:mi>
                  <mml:mi>n</mml:mi>
                </mml:msub>
                <mml:mtext> </mml:mtext>
                <mml:mo>-</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mi>N</mml:mi>
                <mml:msub>
                  <mml:mi>W</mml:mi>
                  <mml:mi>n</mml:mi>
                </mml:msub>
                <mml:mo>)</mml:mo>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <p>where <italic>SE<sub>e</sub>
</italic> is the southeast corner Easting coordinate of the image, <italic>NW<sub>e</sub>
</italic> is the northwest corner Easting coordinate, <italic>SE<sub>n</sub>
</italic> is the southeast corner Northing coordinate, and <italic>NW<sub>n</sub>
</italic> is the northwest corner Northing coordinate.</p>
          <p>The RGB drone (RGB-DR) images from each data collection were processed using Pix4DMapper software (Pix4D S.A., Prilly, Switzerland). For each collection date, the “3D Maps” processing template was used, which generated an orthomosaic, point cloud, and depth maps. The “GCP/MTP Manager” interface was used to load GCP coordinates, co-align GCPs within images to known GCP coordinates, and confirm adequate placement of GCPs within the generated ray cloud. The resulting orthomosaics were processed using PO containers described above starting with the third container that clipped GeoTIFFs to plot boundaries.</p>
        </sec>
        <sec id="s2_3_2_2">
          <label>2.3.2.2</label>
          <title>Thermal processing pipeline</title>
          <p>The full field thermal-FS datasets each consisted of 9,270 BIN files. Each image capture collected one BIN file and an associated JSON metadata file. Each pixel within a thermal-FS image represents an uncalibrated digital number (DN), a dimensionless value corresponding to the output of the detector’s analog-digital conversion. The thermal pipeline consisted of four components (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Table 3</bold></xref> and <xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Figure 3</bold></xref>). The first container converted BIN files to GeoTIFFs with approximate GPS bounding coordinates calculated from barcode positioning information contained within the JSON metadata file. Thermal calibration measurements were applied to each pixel, converting the DN value to Celsius. The second container deployed MegaStitch (<xref rid="B77" ref-type="bibr">Zarei et al., 2022</xref>) in a non-distributed manner, which generated geometrically corrected GeoTIFFs. The third container clipped GeoTIFFs to plot boundaries specified within a GeoJSON file. The fourth container deployed a Faster R-CNN model to detect individual plants within each plot clipped GeoTIFF, which outputted bounding box coordinates. To collect individual plant canopy temperatures, each predicted bounding box, representing a single plant, was programmatically cropped from plot level GeoTIFF orthomosaics and <italic>K</italic>-means clustering was used with <italic>K</italic> = 3 (<xref rid="B45" ref-type="bibr">MacQueen, 1967</xref>; <xref rid="B51" ref-type="bibr">Poblete-Echeverría et al., 2017</xref>). The median and mean canopy temperatures (MEDT and MEAT, respectively) were collected from the plant pixel clusters for each plant along with corresponding distribution statistics. A 10x10 pixel region of interest (ROI) centered within each plant detection was analyzed for median temperature, referred to as the ROI temperature. The longitude and latitude for each plant detection were calculated using Equations 6, 7 respectively for subsequent plant tracking and multi-modal data association.</p>
        </sec>
        <sec id="s2_3_2_3">
          <label>2.3.2.3</label>
          <title>PSII chlorophyll fluorescence processing pipeline</title>
          <p>The PSII-FS datasets each consisted of 39,678 BIN files. Each data capture resulted in a 101-image stack over a 2-second interval along with an associated JSON metadata using a validated chlorophyll fluorescence imaging sensor (<xref rid="B31" ref-type="bibr">Herritt et al., 2020</xref>). Unlike RGB and thermal, these images captured the center of each plot instead of the full field. One image was captured shortly before LED light saturation, 50 images during the one-second saturating pulse of light, and 50 images after the pulse of light. The illuminating LED flash has a dominant wavelength in the range of 620-630 nm with an intensity of up to 7,000 μmol photosynthetically active radiation (PAR) at 70 cm from plant canopies. A modified version of the FLuorescence Imaging Pipeline (FLIP) software was used to extract plot level minimum fluorescence (<italic>F<sub>0</sub>
</italic>), variable fluorescence (<italic>F<sub>V</sub>
</italic>), maximum fluorescence (<italic>F<sub>M</sub>
</italic>), and maximum yield of primary photochemical efficiency (<italic>F<sub>V</sub>/F<sub>M</sub>
</italic>) (<xref rid="B30" ref-type="bibr">Herritt et al., 2021</xref>). Modifications included two containers that converted BIN files to GeoTIFF images and clipped GeoTIFF images to plot boundaries using a GeoJSON file. The modification facilitated multi-modal data merging by acquiring geographical coordinates instead of pixel coordinates and enabled the integration of the software into the distributed computing framework. The PSII chlorophyll fluorescence pipeline consists of four components (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Table 3</bold></xref> and <xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Figure 3</bold></xref>). The first container converted 101 BIN files to 101 GeoTIFFs with approximate GPS bounding coordinates calculated from barcode positioning information contained within the associated JSON metadata file. The second container clipped GeoTIFFs to plot boundaries specified within a GeoJSON file. The third container segmented each pixel within an image into one of five <italic>F<sub>M</sub>
</italic> experimentally derived contribution thresholds (<xref rid="B30" ref-type="bibr">Herritt et al., 2021</xref>). The fourth container applied the contribution thresholds to extract <italic>F<sub>0</sub>
</italic> and <italic>F<sub>M</sub>
</italic> values for each image pixel, which were used to calculate <italic>F<sub>V</sub>
</italic> and <italic>F<sub>V</sub>/F<sub>M</sub>
</italic> for each stack of 101 images were calculated as follows:</p>
          <disp-formula>
            <label>(9)</label>
            <mml:math id="M9" display="block" overflow="scroll">
              <mml:mrow>
                <mml:msub>
                  <mml:mi>F</mml:mi>
                  <mml:mi>V</mml:mi>
                </mml:msub>
                <mml:mtext> </mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:msub>
                  <mml:mi>F</mml:mi>
                  <mml:mi>M</mml:mi>
                </mml:msub>
                <mml:mo>−</mml:mo>
                <mml:msub>
                  <mml:mi>F</mml:mi>
                  <mml:mn>0</mml:mn>
                </mml:msub>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <disp-formula>
            <label>(10)</label>
            <mml:math id="M10" display="block" overflow="scroll">
              <mml:mrow>
                <mml:msub>
                  <mml:mi>F</mml:mi>
                  <mml:mi>V</mml:mi>
                </mml:msub>
                <mml:mo stretchy="false">/</mml:mo>
                <mml:msub>
                  <mml:mi>F</mml:mi>
                  <mml:mi>M</mml:mi>
                </mml:msub>
                <mml:mtext> </mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mi>F</mml:mi>
                      <mml:mi>M</mml:mi>
                    </mml:msub>
                    <mml:mo>−</mml:mo>
                    <mml:msub>
                      <mml:mi>F</mml:mi>
                      <mml:mn>0</mml:mn>
                    </mml:msub>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mi>F</mml:mi>
                      <mml:mi>M</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                </mml:mfrac>
              </mml:mrow>
            </mml:math>
          </disp-formula>
        </sec>
        <sec id="s2_3_2_4">
          <label>2.3.2.4</label>
          <title>3D laser scanner processing pipeline</title>
          <p>The 3D-FS datasets consist of 320 pairs of PLY files. A pair of structured-light laser scanners captured depth and reflectance imagery for preprocessing to point clouds, resulting in two PLY files per data capture (640 total PLY files). Pre-processing of image data to point clouds was performed by the manufacturer-provided software PlyWorker before the data was transmitted offsite. The pair of scanners captured the 3D structure of plants from east and west directions, thereby minimizing occlusions. Each pair of PLY files had an associated JSON metadata file. The 3D laser scanner pipeline, utilizing the output of the PlyWorker software as an input, consisted of six components (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Table 3</bold></xref> and <xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Figure 3</bold></xref>). The first container corrected the orientation and scale of the point cloud tiles and applied the RANSAC algorithm implemented in the Open3D Python package (v. 0.11.2) to find a simple translation (X and Y axes) to reduce misalignment (<xref rid="B1000" ref-type="bibr">Fischler and Bolles, 1981</xref>; <xref rid="B13" ref-type="bibr">Choi et al., 2015</xref>; <xref rid="B78" ref-type="bibr">Zhou et al., 2018</xref>; <xref rid="B78" ref-type="bibr">Zhou et al., 2018</xref>) (<xref rid="f3" ref-type="fig"><bold>Figure 3A</bold></xref>). The second step co-aligned 3D point clouds to RGB-derived plant detections. A custom graphical user interface (GUI) was developed to download and visualize 3D point cloud data and RGB orthomosaic data on local computers after selecting a scan date to manually georeference (see Code Availability Statement). The purpose of this tool was to co-align 3D and RGB by identifying shared landmark features between 3D point clouds and RGB data. This co-alignment allows for individual plant clipping using RGB-derived plant detections (<xref rid="f3" ref-type="fig"><bold>Figure 3B</bold></xref>). Selected features included plot stakes, ground control point (GCP) lids, or distinguishable plants in the field. The GUI (<italic>i</italic>) shows the RGB orthomosaic region, (<italic>ii</italic>) prompts the user to select a landmark feature, (<italic>iii)</italic> displays the point cloud tile region that neighbors the selected landmark feature, (<italic>iv</italic>) prompts the user to select the corresponding landmark feature within the point cloud tile. This process is repeated until an adequate number of landmark features are selected (<xref rid="f3" ref-type="fig"><bold>Figure 3C</bold></xref>). After RGB and 3D data are co-registered by the user, an affine transformation is calculated from the correspondences between the selected landmark features. This transformation maps a point in the original space of the 3D point cloud into the space of the georeferenced RGB orthomosaic. This transformation was then saved to a JSON file. The third container applied the calculated transformation to the point cloud tiles, resulting in co-aligned, georeferenced point cloud tiles (<xref rid="f3" ref-type="fig"><bold>Figure 3D</bold></xref>). The fourth container used RGB-derived plant detections to clip individual plants from large point clouds tiles (<xref rid="f3" ref-type="fig"><bold>Figure 3E</bold></xref>). The fifth container merged multiple tiles containing the same plant using the iterative closest point (ICP) method implemented in the Open3D Python package (v. 0.11.2) (<xref rid="B9" ref-type="bibr">Besl and McKay, 1992</xref>; <xref rid="B78" ref-type="bibr">Zhou et al., 2018</xref>) (<xref rid="f3" ref-type="fig"><bold>Figure 3F</bold></xref>). The sixth container deployed a Faster R-CNN model to localize the focal plant on 3D-derived heat map images (<xref rid="f3" ref-type="fig"><bold>Figure 3G</bold></xref>). The seventh container segmented soil and plant points, which allowed for the isolation of plant points within each point cloud (<xref rid="f3" ref-type="fig"><bold>Figure 3H</bold></xref>). The eighth container removed any residual neighbor plant points using the DBSCAN clustering algorithm implemented in the Open3D Python package (v. 0.11.2) (<xref rid="B19" ref-type="bibr">Ester et al., 1996</xref>; <xref rid="B78" ref-type="bibr">Zhou et al., 2018</xref>) (<xref rid="f3" ref-type="fig"><bold>Figure 3I</bold></xref>). Lastly, the ninth container created persistence diagrams for a single plant point cloud using the Giotto-tda Python package (v. 0.5.1) (<xref rid="B67" ref-type="bibr">Tauzin et al., 2021</xref>), from which the following topological data analysis (TDA) values were collected: persistence entropy and amplitude (with distance functions of landscape, bottleneck, Wasserstein, Betti, silhouette, heat, and persistence image). Plant height (PH) was calculated as follows:</p>
          <fig position="float" id="f3">
            <label>Figure 3</label>
            <caption>
              <p>PhytoOracle 3D point cloud processing workflow. <bold>(A)</bold> Two raw point cloudscollected simultaneously were rotated, scaled, and georeferenced using positioning information from the Field Scanalyzer (FS) metadata file. <bold>(B)</bold> Time series plant detection from RGB data processing were coregistered with 3D point clouds by landmark selection. <bold>(C)</bold> Landmark selection involved selecting landmark features in point clouds and selecting the same landmark feature in RGB images. This step resulted in the co-registration of 3D point clouds with RGB data types. <bold>(D)</bold> Co-registered point clouds and plant detections were visualized by painting each plant detection with a green dot and ground control points (GCPs) with a blue dot. <bold>(E)</bold> Large point cloud tiles were clipped to known plant locations and <bold>(F)</bold> merged using the iterative closest point (ICP) algorithm. <bold>(G)</bold> Focal plants were further isolated by deploying a trained Faster R-CNN detection model to form a tight bounding box around the focal plant, eliminating neighboring plants. <bold>(H)</bold> Plant and soil points were segmented by deploying a trained DGCNN model on focal plant clips, resulting in a point cloud containing only plant points. <bold>(I)</bold> Residual neighbor plant points were removed by using the DBSCAN unsupervised clustering algorithm, resulting in a point cloud containing only focal plant points. <bold>(J)</bold> Focal plant point clouds were analyzed for morphometric phenotypes such as axis-aligned and oriented bounding box volumes (AABV and OBV, respectively) and convex hull volume (CHV), plant height (PH), and number of points (NP) as well as topological data analysis values calculated from persistence diagrams.</p>
            </caption>
            <graphic xlink:href="fpls-14-1112973-g003" position="float"/>
          </fig>
          <disp-formula>
            <label>(11)</label>
            <mml:math id="M11" display="block" overflow="scroll">
              <mml:mrow>
                <mml:mtext>Plant height </mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:msub>
                  <mml:mi>Z</mml:mi>
                  <mml:mrow>
                    <mml:mi>m</mml:mi>
                    <mml:mi>a</mml:mi>
                    <mml:mi>x</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mtext> </mml:mtext>
                <mml:mo>−</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:msub>
                  <mml:mi>Z</mml:mi>
                  <mml:mrow>
                    <mml:mi>m</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>n</mml:mi>
                  </mml:mrow>
                </mml:msub>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <p>Where <italic>Z<sub>max</sub>
</italic> is the maximum Z-axis plant point value and <italic>Z<sub>min</sub>
</italic> is the minimum Z-axis plant point value. In addition, the oriented bounding box volume (OBV), axis-aligned bounding box volume (AABV), and number of points (NP) were calculated using the Open3D Python package (v. 0.11.2) (<xref rid="B78" ref-type="bibr">Zhou et al., 2018</xref>) (<xref rid="f3" ref-type="fig"><bold>Figure 3J</bold></xref>).</p>
        </sec>
      </sec>
      <sec id="s2_3_3">
        <label>2.3.3</label>
        <title>Pipeline benchmarking</title>
        <p>The RGB, thermal, and PSII pipelines were benchmarked using a single data collection for each sensor (<xref rid="T2" ref-type="table"><bold>Table 2</bold></xref>). Benchmarking consisted of manager and worker compute nodes using CCTools Makeflow and Work Queue (<xref rid="B2" ref-type="bibr">Albrecht et al., 2012</xref>). A single HPC compute node equipped with two AMD Zen2 processors x 48 cores (94 total cores), 512 GB of RAM, sixteen 32 GB memory DIMM, and 2 TB SSD disk served as the manager node. Worker nodes, with the same computational resources mentioned above, were requested on which the command <italic>work_queue_factory</italic> (CCTools v. 7.1.12) was run to request one worker per core, resulting in a total of 94 Work Queue workers per node each with 5 GB of RAM. A Makeflow file containing information for each data input file was created programmatically using the PO automation script, which allowed for parallel distribution of tasks. In addition, this automation script provided a detailed workflow to each worker, specifying the processing step to be performed on each input file using Singularity v3.6 for running containers (<xref rid="B33" ref-type="bibr">Hunt and Larus, 2007</xref>; <xref rid="B41" ref-type="bibr">Kurtzer et al., 2017</xref>). A single task was performed per worker to allow for maximum distribution of tasks. Importantly, each pipeline differs in its definition of a single task input: RGB and thermal consist of one BIN file; 3D of two PLY files; and PSII of 101 BIN files, each with an associated metadata JSON file. Upon completion of assigned tasks, the manager compute node assigned additional tasks in queue to available workers. The benchmark dataset for RGB, thermal, and PSII sensors was processed over the following range of available workers: 1, 4, 8, 16, 32, 64, 128, 256, 512, and 1024. Each configuration was replicated three times, for a total of 30 benchmark data points per sensor. A log file with information on processing times and number of workers during processing was collected during processing.</p>
        <table-wrap position="float" id="T2">
          <label>Table 2</label>
          <caption>
            <p>Information on each benchmarking dataset’s collection date, size, and number of images.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th valign="middle" align="center" rowspan="1" colspan="1">Sensor</th>
                <th valign="middle" align="center" rowspan="1" colspan="1">Date</th>
                <th valign="middle" align="center" rowspan="1" colspan="1">Start time</th>
                <th valign="middle" align="center" rowspan="1" colspan="1">End time</th>
                <th valign="middle" align="center" rowspan="1" colspan="1">Elapsed time</th>
                <th valign="middle" align="center" rowspan="1" colspan="1">Total size</th>
                <th valign="middle" align="center" rowspan="1" colspan="1">Image count</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="middle" align="center" rowspan="1" colspan="1">RGB</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">03/03/2020</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">08:45</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">13:27</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">04:42</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">140.7</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">9270</td>
              </tr>
              <tr>
                <td valign="middle" align="center" rowspan="1" colspan="1">Thermal</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">03/03/2020</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">08:45</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">13:27</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">04:42</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">5.4</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">9270</td>
              </tr>
              <tr>
                <td valign="middle" align="center" rowspan="1" colspan="1">PSII</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">02/27/2020</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">19:58</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">00:37</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">04:39</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">86.2</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">39678</td>
              </tr>
              <tr>
                <td valign="middle" align="center" rowspan="1" colspan="1">3D laser</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">03/01/2020</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">18:59</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">03:54</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">08:55</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">308.5</td>
                <td valign="middle" align="center" rowspan="1" colspan="1">640</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <p>Elapsed time, HH : MM; total size, gigabytes.</p>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec id="s2_3_4">
        <label>2.3.4</label>
        <title>Multi-modal data merging and association</title>
        <p>To allow for identification of single plants throughout the growing period and across sensor modalities, individual plant detections from each collection date need to be grouped. Two phases were carried out to accomplish this: (<italic>i</italic>) data cleaning to remove any outliers and (<italic>ii</italic>) a series of sequential clustering steps to combine multi-modal datasets and enable individual plant tracking.</p>
        <sec id="s2_3_4_1">
          <label>2.3.4.1</label>
          <title>Removal of outlier plants</title>
          <p>The first phase involved the removal of overlapping plants, hereafter termed outliers, which were the result of two or more plants growing in proximity and merging into what appeared to be a single plant. These outliers resulted in a single plant detection for this pair of plants, leading to errors in subsequent analyses. To remove these outliers, the field was manually assessed at the end of the season for outliers, which were manually marked with spray paint for easy visual identification in imagery collected right before harvesting. A GeoJSON vector layer containing a point for each outlier was manually created on QGIS (<ext-link xlink:href="http://www.qgis.org" ext-link-type="uri">www.qgis.org</ext-link>) and the end-of-season orthomosaic containing the marked outlier canopies, which were used to identify these outliers in the multi-modal dataset.</p>
        </sec>
        <sec id="s2_3_4_2">
          <label>2.3.4.2</label>
          <title>Grouping plant phenotypes for individual plant tracking</title>
          <p>The second phase involved the sequential clustering of phenotypic trait data from various sensor modalities. First, the full season RGB dataset was combined with the GeoJSON file containing manually marked outlier plant points generated in the first phase. Individual plant detections throughout the season were then clustered using agglomerative clustering, a form of hierarchical clustering algorithm implemented in the scikit-learn Python package v0.24.2 (<xref rid="B15" ref-type="bibr">Cox, 1957</xref>; <xref rid="B21" ref-type="bibr">Fisher, 1958</xref>; <xref rid="B73" ref-type="bibr">Ward, 1963</xref>; <xref rid="B50" ref-type="bibr">Pedregosa et al., 2011</xref>). Agglomerative clustering requires a threshold value, which was empirically derived based on having the lowest number of outliers grouped into a cluster and reduced fluctuations in growth curves. The optimal threshold value of 6 x 10<sup>-7</sup> was used to maximize the number of clustered observations of a single plant and minimize the clustering of weeds and/or neighboring plants. The full season RGB plant detections were clustered using the empirically derived threshold value and results were assessed in QGIS. Each cluster, representing a single plant time series, was given a unique identifier denoting the plant’s genotype and the clustering number (“genotype”_”cluster number”). All clusters containing an outlier point were given the label ‘double’ for the identification and exclusion of these data points from subsequent analyses (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Figure 4</bold></xref>). Second, the resulting grouped RGB dataset was then clustered with the full season thermal data. Full season RGB and thermal outputs were merged using the same technique used during clustering of the full season RGB data. This clustering step resulted in a single dataset containing RGB and thermal data with a shared unique plant identified. Third, the merged dataset, containing clustered RGB and thermal phenotypic trait data, was combined with PSII chlorophyll fluorescence and 3D laser full season files using plot numbers and unique plant identifiers, respectively. The final output was a time-series, multi-modal phenotypic trait dataset at the individual plant level for RGB, thermal, and 3D phenotype data and plot level for PSII chlorophyll fluorescence phenotype data.</p>
        </sec>
      </sec>
      <sec id="s2_3_5">
        <label>2.3.5</label>
        <title>Analysis of extracted phenotypes</title>
        <sec id="s2_3_5_1">
          <label>2.3.5.1</label>
          <title>Assessing accuracy of plant detection across growing period</title>
          <p>To assess plant detection performance, the median IoU throughout various time points were quantified for RGB and thermal image data. Canopy temperature extraction performance was assessed by manually extracting median canopy temperature across all time points of a random sample of 200 selected plots, with each plot containing a minimum of five plants across 19 collection dates resulting in 1,481 data points. We examined the correlation between manually extracted canopy temperature and pipeline extracted MEDT over an entire season for these selected plots. The BA extraction performance was evaluated by assessing its Pearson correlation with harvested, fresh weight biomass for each plot in the field trial. The median individual plant BA was used for correlation assessments. A similar assessment of correlation was conducted for AABV extraction.</p>
        </sec>
        <sec id="s2_3_5_2">
          <label>2.3.5.2</label>
          <title>Assessing grouping of plant phenotypes performance</title>
          <p>The results from the proposed clustering association method were visualized across 200 plots as a vector layer overlaid on an end-of-season orthomosaic in which the outliers were marked. Each plot was imaged over 19 time points, resulting in a total of 3,800 images. If an identification was marked and the overlaid detection was identified as an outlier by the clustering algorithm, then the identification was classified as a true positive (TP). If the plant was marked and the overlaid detection was not determined to be an outlier by the clustering script, then the identification was classified as a false negative (FN). If the plant was not marked and the overlaid detection was determined to be an outlier by the clustering script, then the overlaid identification was classified as a false positive (FP). If the plant was not marked and the overlaid detection was determined to not be an outlier by the clustering script, then the overlaid identification was classified as a true negative (TN).</p>
        </sec>
        <sec id="s2_3_5_3">
          <label>2.3.5.3</label>
          <title>Statistical analysis and data visualization</title>
          <p>The BA, NP, OBV, AABV, and PH phenotype trait data were analyzed after first checking for residual normality and error variance homogeneity at each collection event. For each trait, collection time points were analyzed separately using the lme4 package (<xref rid="B6" ref-type="bibr">Bates et al., 2015</xref>) in the R programming language (<xref rid="B55" ref-type="bibr">R Core Team, 2022</xref>). Spatial effects were modeled on a row and column basis. The following linear mixed model was fitted to trait data for the estimation of variance components:</p>
          <disp-formula>
            <label>(12)</label>
            <mml:math id="M12" display="block" overflow="scroll">
              <mml:mrow>
                <mml:msub>
                  <mml:mi>y</mml:mi>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mi>j</mml:mi>
                    <mml:mi>k</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mtext> </mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mi>μ</mml:mi>
                <mml:mtext> </mml:mtext>
                <mml:mo>+</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:msub>
                  <mml:mi>g</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:mtext> </mml:mtext>
                <mml:mo>+</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mi>i</mml:mi>
                <mml:mi>r</mml:mi>
                <mml:msub>
                  <mml:mi>g</mml:mi>
                  <mml:mi>j</mml:mi>
                </mml:msub>
                <mml:mo>+</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mi>g</mml:mi>
                <mml:mtext> </mml:mtext>
                <mml:mo>×</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mi>i</mml:mi>
                <mml:mi>r</mml:mi>
                <mml:msub>
                  <mml:mi>g</mml:mi>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mi>j</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mtext> </mml:mtext>
                <mml:mo>+</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mi>r</mml:mi>
                <mml:mi>e</mml:mi>
                <mml:mi>p</mml:mi>
                <mml:msub>
                  <mml:mrow>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>i</mml:mi>
                    <mml:mi>r</mml:mi>
                    <mml:mi>g</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>k</mml:mi>
                    <mml:mi>j</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mtext> </mml:mtext>
                <mml:mo>+</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mi>r</mml:mi>
                <mml:mi>o</mml:mi>
                <mml:mi>w</mml:mi>
                <mml:msub>
                  <mml:mrow>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>r</mml:mi>
                    <mml:mi>e</mml:mi>
                    <mml:mi>p</mml:mi>
                    <mml:mo>×</mml:mo>
                    <mml:mi>i</mml:mi>
                    <mml:mi>r</mml:mi>
                    <mml:mi>g</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>l</mml:mi>
                    <mml:mi>k</mml:mi>
                    <mml:mi>j</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mtext> </mml:mtext>
                <mml:mo>+</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mi>c</mml:mi>
                <mml:mi>o</mml:mi>
                <mml:mi>l</mml:mi>
                <mml:msub>
                  <mml:mrow>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>r</mml:mi>
                    <mml:mi>e</mml:mi>
                    <mml:mi>p</mml:mi>
                    <mml:mo>×</mml:mo>
                    <mml:mi>i</mml:mi>
                    <mml:mi>r</mml:mi>
                    <mml:mi>r</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>m</mml:mi>
                    <mml:mi>k</mml:mi>
                    <mml:mi>j</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mtext> </mml:mtext>
                <mml:mo>+</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:msub>
                  <mml:mi>ϵ</mml:mi>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mi>j</mml:mi>
                    <mml:mi>k</mml:mi>
                    <mml:mi>l</mml:mi>
                    <mml:mi>m</mml:mi>
                  </mml:mrow>
                </mml:msub>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <p>where <italic>y<sub>ijk</sub>
</italic> is an individual phenotypic observation; <italic>μ</italic> is the overall mean; <italic>g<sub>i</sub>
</italic> is the effect of the <italic>i</italic>-th genotype; <italic>irg<sub>j</sub>
</italic> is the effect of the <italic>j</italic>-th irrigation treatment which was either WW, D1 or D2; <italic>g</italic> × <italic>irg<sub>ij</sub>
</italic> is the interaction effect between the <italic>i</italic>-th genotype and the <italic>j</italic>-th irrigation treatment; <italic>rep</italic>(<italic>irg</italic>)<italic><sub>kj</sub></italic> is the effect of the <italic>k</italic>-th replication nested within the <italic>j</italic>-th irrigation treatment; <italic>row</italic>(<italic>rep</italic> × <italic>irg</italic>)<italic><sub>lkj</sub></italic> is the effect of the <italic>l</italic>-th plot grid row nested with <italic>k</italic>-th replication within the <italic>j</italic>-th irrigation treatment; <italic>col</italic>(<italic>rep</italic> × <italic>irr</italic>)<italic><sub>mkj</sub></italic> is the effect of the <italic>m</italic>-th plot grid column nested within the <italic>k</italic>-th replication within the <italic>j</italic>-th irrigation treatment; and <italic>ε<sub>ijklm</sub>
</italic> is the residual effect. The variance component estimates from the full model were used to estimate repeatability (<italic>r</italic>) as follows:</p>
          <disp-formula>
            <label>(13)</label>
            <mml:math id="M13" display="block" overflow="scroll">
              <mml:mrow>
                <mml:mi>r</mml:mi>
                <mml:mtext> </mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mtext> </mml:mtext>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mi>σ</mml:mi>
                      <mml:mi>g</mml:mi>
                      <mml:mn>2</mml:mn>
                    </mml:msubsup>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mi>σ</mml:mi>
                      <mml:mi>g</mml:mi>
                      <mml:mn>2</mml:mn>
                    </mml:msubsup>
                    <mml:mtext> </mml:mtext>
                    <mml:mo>+</mml:mo>
                    <mml:mtext> </mml:mtext>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:msubsup>
                          <mml:mi>σ</mml:mi>
                          <mml:mrow>
                            <mml:mi>g</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:mrow>
                          <mml:mn>2</mml:mn>
                        </mml:msubsup>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>n</mml:mi>
                          <mml:mrow>
                            <mml:mi>i</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>g</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:mfrac>
                    <mml:mtext> </mml:mtext>
                    <mml:mo>+</mml:mo>
                    <mml:mtext> </mml:mtext>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:msubsup>
                          <mml:mi>σ</mml:mi>
                          <mml:mo>∈</mml:mo>
                          <mml:mn>2</mml:mn>
                        </mml:msubsup>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>n</mml:mi>
                          <mml:mrow>
                            <mml:mi>p</mml:mi>
                            <mml:mi>l</mml:mi>
                            <mml:mi>o</mml:mi>
                            <mml:mi>t</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:mfrac>
                  </mml:mrow>
                </mml:mfrac>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <p>where <inline-formula><mml:math id="im1" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> is the genotypic variance due to genotypes, <inline-formula><mml:math id="im2" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> is the estimated variance with the genotype-by-irrigation treatment variation, and <inline-formula><mml:math id="im3" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mo>∈</mml:mo><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> and residual variances, respectively. The variable <italic>n<sub>irg</sub>
</italic> is the number of irrigation treatments in which each genotype was observed and <italic>n<sub>plot</sub>
</italic> is the number of plots in which the genotype was observed. </p>
          <p>All plots presented in this study were generated using the Seaborn, Matplotlib, and Plotly Python packages using Python v3.9 (<xref rid="B34" ref-type="bibr">Hunter, 2007</xref>; <xref rid="B32" ref-type="bibr">Hossain, 2019</xref>; <xref rid="B74" ref-type="bibr">Waskom, 2021</xref>). Pearson correlations presented in the plots were calculated using the SciPy Python package (v0.15.1) (<xref rid="B1001" ref-type="bibr">Virtanen et al., 2020</xref>).</p>
        </sec>
      </sec>
    </sec>
  </sec>
  <sec sec-type="results" id="s3">
    <label>3</label>
    <title>Results</title>
    <sec id="s3_1">
      <label>3.1</label>
      <title>Environmental conditions during growing period</title>
      <p>Weather data mean values for the growing season between 2019-11-13 and 2020-03-03 were: 10.72 °C air temperature, 61.88% relative humidity, 0.62 kPa vapor pressure deficit, and 0.55 MJ/m<sup>2</sup> solar radiation (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Figure 5</bold></xref>). The irrigation treatments resulted in contrasting VSWC, with minimum values at 10 cm of 19.2, 14.7, and 12.8 in irrigation treatments WW, D1, and D2, respectively. At 30 cm, minimum values were 21.3, 21.5, and 17.2 for WW, D1, and D2, respectively (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Figure 1</bold></xref>).</p>
    </sec>
    <sec id="s3_2">
      <label>3.2</label>
      <title>Model performance metrics</title>
      <p>Faster R-CNN models were separately trained to identify single plants in RGB and thermal imagery, each trained and evaluated with 2,000 and 250 images, respectively. Performance was assessed without any prediction confidence threshold, resulting in 2,752 and 1,450 ‘plant’ class detections for RGB and thermal, respectively. The RGB detection model detected plants with a 0.98 recall, 0.93 precision, 0.96 F1-score, and 0.96 overall accuracy when tested on FS (RGB-FS) image data. The RGB detection model performance was further evaluated with a 400-image RGB-DR test dataset and resulted in 0.98 recall, 0.96 precision, 0.97 F1-score, and 0.97 overall accuracy. The thermal detection model performed better than the RGB detection model with a 0.98 recall, 0.99 precision, 0.98 F1-score, and 0.98 overall accuracy. A single DGCNN model was trained to segment points corresponding to plant and soil classes in point clouds containing a single plant. The model was trained and evaluated with 128 point clouds and 16 point clouds, respectively. The DGCNN model was assessed for point-wise accuracy using the test set, which was calculated at 0.98 (<xref rid="T3" ref-type="table"><bold>Table 3</bold></xref>).</p>
      <table-wrap position="float" id="T3">
        <label>Table 3</label>
        <caption>
          <p>Performance metrics for Faster R-CNN detection models for image processing of Field Scanalyzer RGB (RGB-FS), drone RGB (RGB-DR), and Field Scanalyzer thermal (Thermal-FS).</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="middle" align="center" rowspan="1" colspan="1">Model</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Data</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Type</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Detections</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">TP</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">FP</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">FN</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Recall</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Precision</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">F1-score</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Accuracy</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="middle" align="center" rowspan="1" colspan="1">A</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">RGB - DR</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Detection</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">4356</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">4097</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">182</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">77</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.98</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.96</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.97</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.97</td>
            </tr>
            <tr>
              <td valign="middle" align="center" rowspan="1" colspan="1">A</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">RGB - FS</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Detection</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">2752</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">2519</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">178</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">54</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.98</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.93</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.96</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.96</td>
            </tr>
            <tr>
              <td valign="middle" align="center" rowspan="1" colspan="1">B</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Thermal - FS</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Detection</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">1450</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">1404</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">10</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">36</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.98</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.99</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.98</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.98</td>
            </tr>
            <tr>
              <td valign="middle" align="center" rowspan="1" colspan="1">C</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">3D - FS</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Segmentation</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">–</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">–</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">–</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">–</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">–</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">–</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">–</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.98</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>FS, Field Scanalyzer; DR, drone; TP, true positive; FP, false positive; and FN, false negative. For the 3D-FS model, the accuracy reported is a point-wise accuracy collected across points within the test dataset, as such values for columns Total detections through F1-score are not presented.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>The median IoU was calculated separately for each distinct collection time point represented in a 250-image test set to assess temporal effects on bounding box accuracy. Overall, the median IoU was 0.84, 0.84, and 0.88 for RGB-FS, RGB-DR, and thermal-FS, respectively. The median IoU differed between dates, with an increasing trend as time progressed (<xref rid="f4" ref-type="fig"><bold>Figure 4</bold></xref>). This trend was stronger in the RGB-FS and RGB-DR data as these data were collected earlier in the season when plants were small with fewer distinguishable features as compared to thermal scans.</p>
      <fig position="float" id="f4">
        <label>Figure 4</label>
        <caption>
          <p>Change in median Intersection over Union (IoU) across the collection dates represented in RGB and thermal test data sets for the Field Scanalizer (FS) and Drone (DR) systems. Both RGB Field Scanalyzer scans (RGB-FS) and drone flights (RGB-DR), began earlier than thermal, allowing to capture the temporal effect of collection date, a proxy to plant size, on the median IoU. Error bands represent 95% confidence intervals around the median.</p>
        </caption>
        <graphic xlink:href="fpls-14-1112973-g004" position="float"/>
      </fig>
    </sec>
    <sec id="s3_3">
      <label>3.3</label>
      <title>Validation of pipeline-extracted phenotypes and multimodal data association</title>
      <p>Across the entire time series clustering test set, the agglomerative clustering method grouped plant detections into individual plant, time-series data with 0.99 recall, 0.93 precision, 0.96 F1-score, and 0.96 overall accuracy. The observed coefficient of determination (<italic>r</italic>
<sup>2</sup>) between individual plant fresh weight collected at harvest and pipeline-extracted 3D-FS AABV were 0.29 for Batavia (p&lt; 0.01), 0.36 for Butterhead (p&lt; 0.0001), 0.55 for Cutting/Crisp (p&lt; 0.0001), 0.59 for Iceberg (p&lt; 0.0001), 0.61 for Leaf (p&lt; 0.0001), and 0.48 for Romaine (p&lt; 0.0001) (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Figure 6</bold></xref>). The observed coefficient of determination (<italic>r</italic>
<sup>2</sup>) between individual plant fresh weight and pipeline-extracted RGB-FS BA were 0.21 for Batavia (p&lt; 0.01), 0.39 for Butterhead (p&lt; 0.0001), 0.56 for Cutting/Crisp (p&lt; 0.0001), 0.62 for Iceberg (p&lt; 0.0001), 0.61 for Leaf (p&lt; 0.0001), and 0.29 for Romaine (p&lt; 0.0001) (<xref rid="f5" ref-type="fig"><bold>Figure 5</bold></xref>). The observed range of <italic>r</italic>
<sup>2</sup> values between manually extracted and pipeline-extracted median canopy temperatures (MEDT) over 12 unique collection dates was 0.43-0.94 (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Figure 7</bold></xref>). The overall observed <italic>r</italic>
<sup>2</sup> was 0.95 when considering all dates (p&lt; 0.0001) (<xref rid="f6" ref-type="fig"><bold>Figure 6</bold></xref>).</p>
      <fig position="float" id="f5">
        <label>Figure 5</label>
        <caption>
          <p>Correlation between individual plant fresh weight and pipeline-extracted bounding area (RGB-FS BA, m<sup>2</sup>) for all plots in the field trial. Genotypes were grouped by horticultural type, resulting in 6 groups which are Batavia, Butterhead, Cutting/crisp, Iceberg, Leaf, and Romaine. *** = P value ≤ 0.001.</p>
        </caption>
        <graphic xlink:href="fpls-14-1112973-g005" position="float"/>
      </fig>
      <fig position="float" id="f6">
        <label>Figure 6</label>
        <caption>
          <p>Correlation between validation and pipeline-extracted median canopy temperatures (MEDT). Each point represents an individual plant temperature collected at a single time point, with the complete dataset consisting of 12 distinct collection dates.</p>
        </caption>
        <graphic xlink:href="fpls-14-1112973-g006" position="float"/>
      </fig>
    </sec>
    <sec id="s3_4">
      <label>3.4</label>
      <title>Collection and processing benchmarks</title>
      <sec id="s3_4_1">
        <label>3.4.1</label>
        <title>Field scanalyzer data collection</title>
        <p>Benchmark datasets were collected using the FS, with varying operation times depending on the sensor. The file size of benchmark datasets ranged from 5.4 GB to 308.5 GB in size and consisted of 640 to 39,678 files. The data collection of RGB and thermal image data, which occurs simultaneously, took a total of 4 hours and 42 minutes to complete resulting in 9,270 raw images per sensor. The PSII data collection took 4 hours and 39 minutes, resulting in the largest raw file count (39, 678 images).</p>
      </sec>
      <sec id="s3_4_2">
        <label>3.4.2</label>
        <title>PhytoOracle data processing</title>
        <p>The RGB and PSII processing times saw the largest reduction from computational parallelization, at 61% and 95% respectively, at the maximum number of 1024 workers. Thermal processing time saw the smallest reduction of 22% at the maximum number of 1024 workers. At the maximum number of workers tested in this study, RGB and thermal each processed in 235 minutes and PSII in 13 minutes (<xref rid="f7" ref-type="fig"><bold>Figure 7</bold></xref>).</p>
        <fig position="float" id="f7">
          <label>Figure 7</label>
          <caption>
            <p>Average tasks process per minute and processing times for each PhytoOracle pipeline. (Top) Average tasks processed (tasks/minute) as a function of the number of worker cores. (Bottom) Total processing time (minutes) as a function of the number of workers (one CPU core per work). Available workers ranged from 1 to 1024 and the values represent the average of three runs with the same configuration. Error bars represent 95% confidence intervals.</p>
          </caption>
          <graphic xlink:href="fpls-14-1112973-g007" position="float"/>
        </fig>
      </sec>
    </sec>
    <sec id="s3_5">
      <label>3.5</label>
      <title>Phenotypic repeatability estimates at individual sampling events</title>
      <p>The mean repeatability values for each pipeline are as follows: 0.86 (RGB-DR BA), 0.81 (RGB-FS BA), 0.90 (3D-FS AABV), 0.90 (3D-FS OBV), 0.90 (3D-FS PH), and 0.89 (3D-FS NP) (<xref rid="T4" ref-type="table"><bold>Table 4</bold></xref>). In general, the repeatability of RGB and 3D phenotypic trait data had increasing trends over the growing season (<xref rid="f8" ref-type="fig"><bold>Figure 8</bold></xref>).</p>
      <table-wrap position="float" id="T4">
        <label>Table 4</label>
        <caption>
          <p>Repeatability of pipeline extracted phenotypes collected from Field Scanalyzer (FS) and drone (DR) platforms.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="middle" align="center" rowspan="1" colspan="1">Data</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Trait</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Min.</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Mean</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Max.</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="middle" align="center" rowspan="1" colspan="1">RGB-DR</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Bounding area</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.55</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.86</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.95</td>
            </tr>
            <tr>
              <td valign="middle" align="center" rowspan="1" colspan="1">RGB-FS</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Bounding area</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.39</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.81</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.95</td>
            </tr>
            <tr>
              <td valign="middle" align="center" rowspan="1" colspan="1">3D-FS</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Axis-aligned bounding volume</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.81</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.90</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.95</td>
            </tr>
            <tr>
              <td valign="middle" align="center" rowspan="1" colspan="1">3D-FS</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Oriented bounding volume</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.79</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.90</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.94</td>
            </tr>
            <tr>
              <td valign="middle" align="center" rowspan="1" colspan="1">3D-FS</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Plant height</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.83</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.90</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.95</td>
            </tr>
            <tr>
              <td valign="middle" align="center" rowspan="1" colspan="1">3D-FS</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">Number of points</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.81</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.89</td>
              <td valign="middle" align="center" rowspan="1" colspan="1">0.95</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>Minimum, Min.; Max., Maximum.</p>
        </table-wrap-foot>
      </table-wrap>
      <fig position="float" id="f8">
        <label>Figure 8</label>
        <caption>
          <p>Repeatability estimates for pipeline-extracted phenotypes collected during a single year trial. Bounding area, BA; axis-aligned bounding box volume, AABV; number of points, NP; oriented bounding box volume, OBV; plant height, PH; Field Scanalyzer, FS; drone, DR.</p>
        </caption>
        <graphic xlink:href="fpls-14-1112973-g008" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s4">
    <label>4</label>
    <title>Discussion</title>
    <p>The proliferation of phenomics technology has led to large data volumes that need to be processed. Challenges related to computation of phenomics big data reduce its full application and efficacy in providing actionable genome-phenome insights into plant morphophysiological traits. Among the significant bottlenecks in plant phenomics, we address the lack of scalable, modular processing pipelines capable of processing expanding data volumes to extract morphological and physiological phenotypic trait data. Although other pipelines, such as Image Harvest and Greenotyper, have considered and implemented distributed computing systems, these capabilities have not been fully developed for general use on HPC clusters or multiple node deployment. Instead, it is left to the user to undertake that implementation (<xref rid="B40" ref-type="bibr">Knecht et al., 2016</xref>; <xref rid="B66" ref-type="bibr">Tausen et al., 2020</xref>). The PhytoOracle suite of scalable, modular data processing pipelines addresses critical bottlenecks within plant phenomics including data diversity, scalability, reproducibility, and extensibility. PhytoOracle accomplishes this by integrating distributed computing, container technology, data management systems, and machine learning into a single suite of phenomics data processing pipelines.</p>
    <sec id="s4_1">
      <label>4.1</label>
      <title>PhytoOracle addresses neglected bottlenecks in phenomics data processing</title>
      <p>The PO suite can process data from multiple sensors including RGB, thermal, and PSII chlorophyll fluorescence 2D image data and 3D point cloud data. Except for PSII chlorophyll fluorescence, PO data processing pipelines result in individual plant phenotypic trait data that can be associated using our agglomerative clustering approach (<xref rid="f2" ref-type="fig"><bold>Figure 2</bold></xref> and <xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Figure 5</bold></xref>). To date, the only other published pipeline capable of handling such diverse data types is PlantCV. However, PlantCV’s approach to individual plant phenotyping does not translate well to field phenomics data (<xref rid="B20" ref-type="bibr">Fahlgren et al., 2015</xref>; <xref rid="B24" ref-type="bibr">Gehan et al., 2017</xref>). In field phenomics data, plant spacing creates challenges for individual plant phenotype extraction. The threshold-based contour approach used by much software, including PlantCV, works well in controlled environments, however, most imaging approaches outside of controlled environments often capture multiple overlapping plants under highly variable lighting conditions. These variable conditions make threshold-based contour approaches difficult to implement in processing field phenomics data. For this reason, PO leverages ML models that are better able to handle overlapping plants and variable lighting conditions.</p>
      <p>To resolve time series, multi-plant measurements to the individual plant level, PO leverages ML approaches, such as Faster R-CNN for object detection and DGCNN for point cloud segmentation. These ML models make PO robust and generalizable to other crops. For instance, if a user wants to process a new crop species, a model could be trained and deployed within PO, requiring little to no code development. Furthermore, the ML models presented here can be used by other researchers and/or new models can be trained using our labeled data and existing containers. PO also provides a general use solution to training of Faster R-CNN object detection models.</p>
      <p>The PO suite provides scalability through a distributed computing framework leveraging the open-source CCTools’ Makeflow and Work Queue software (<xref rid="B2" ref-type="bibr">Albrecht et al., 2012</xref>), which provides the language and computational resource management necessary to scale tasks beyond traditional job arrays and local computing resources. Importantly, this enables users to leverage dataset-specific resources across multiple computing environments during data processing, providing a path to maximize and optimize computational resource use. For example, the manager can be launched on an HPC cluster to ensure adequate storage space while workers could be launched on a lab workstation. The benefit of this approach is that computational resources beyond one computer or even one cluster can be leveraged to process thousands of tasks in parallel. Data processing on a single computer or server constrains users to locally available memory and processors, preventing scalability. On the other hand, distributed computing systems allow users to access processors and memory on remote nodes, allowing the system to, in theory, linearly scale the processing task at hand. The PO benchmarking focused on HPC nodes instead of local nodes and cloud-native options, such as XSEDE, due to those resources not having the storage space required to store raw and intermediate data. This is important, as it highlights that computational resources must consider not only CPU/GPU availability but also storage space capabilities as large-scale phenomics data processing results in many intermediate outputs that must be temporarily stored to serve as input to subsequent steps. In the end, these intermediate data can be deleted, but they must be able to be temporarily stored during data processing.</p>
      <p>As data volumes increase, scalability will become a higher priority within research fields aimed at extracting relevant insights from big data (<xref rid="B11" ref-type="bibr">Chen et al., 2013</xref>; <xref rid="B63" ref-type="bibr">Sivarajah et al., 2017</xref>). However, this is likely to exacerbate existing network IO bottlenecks, which prevent linear scaling (<xref rid="B1003" ref-type="bibr">Zhang et al., 2020</xref>). For example, the presented benchmarking information shows that although the average number of tasks completed continued to increase, the total processing time remained relatively stable after 32 workers. These results highlight limitations in scaling likely associated with network and data transfer bottlenecks. Improving the utilization of local, cloud, or HPC systems is a major concern and area of active research (<xref rid="B65" ref-type="bibr">Tanash et al., 2019</xref>). Generally, there are seemingly two options for further improvements to computational throughput: (<italic>i</italic>) identifying the optimal worker configurations per pipeline and/or (<italic>ii</italic>) moving pipelines closer to where the data are collected. An analysis of big data environments using Docker containers found that adding nodes (workers) beyond a certain threshold decreased performance due to an increase in the time for a network request to be sent and received (round trip time), which is similar to the results presented here (<xref rid="B12" ref-type="bibr">China Venkanna Varma et al., 2016</xref>). Moving pipelines closer to the data seems more feasible than finding optimal worker configurations as there may not be an optimal worker configuration to mitigate scaling plateaus until network bottlenecks are resolved. Network bandwidth is commonly associated with a lack of linear scaling; oftentimes, the processing phase is efficient and would theoretically allow for linear scaling, but the communication phase creates a bottleneck preventing linear scaling (<xref rid="B1003" ref-type="bibr">Zhang et al., 2020</xref>). In our case, raw data is stored on the CyVerse Data Store due to its volume, velocity, and variety–making it intractable to keep these data on local servers for processing. This results in data being located “far” (CyVerse Data Store servers) from the processing pipeline (HPC), resulting in significant network requests that negatively impact data processing throughput. In the future, improvements to network capabilities may help to further improve processing efficiency.</p>
      <p>The PO suite leverages container technology to ensure consistent, immutable data processing. Each PO processing step is containerized using Docker and deployable on HPC, cloud, and local computers on which either Docker or Singularity is installed. As opposed to running non-containerized processing code, containers ensure that each processing step is reproducible by controlling code versions and processing environments. Instead of users having to install over 40 Python packages to run PO, we provide containers that contain these libraries, significantly reducing the barrier to entry (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Table 4</bold></xref>). Additionally, the PO automation script automatically downloads and configures CCTools, and requires no additional third-party Python packages. The only requirements for running PO are Singularity or Docker, iRODS, and Python. These tools are generally found on HPC clusters, except for iRODS which can be installed by system administrators.</p>
      <p>The PO suite provides a general use framework through our automation script. Together with our suite of processing containers, this automation script automates the complexity of developing a PCSs, allowing users with little computer programming experience to leverage PO for processing their own phenomics data. The PO suite has four existing YAML files that can be customized by other researchers to process their own data. Users with advanced programming and command line experience can develop their own containers for data processing and integrate them into PO by including each container as a module within the YAML file, specifying the location of raw data on the CyVerse Data Store or local storage, and outlining the expected output files. The use of a generalizable automation script and a customizable YAML file makes it possible for users to run PO on various datasets, allowing researchers to spend more time on analysis than software development and data processing.</p>
    </sec>
    <sec id="s4_2">
      <label>4.2</label>
      <title>PhytoOracle extracts repeatable phenotypes from distinct platforms</title>
      <p>The phenotypic trait data extracted from the FS and DR platforms align with values reported in the literature. Morphological trait repeatability values collected by the 3D-FS sensor align with the range of values reported in wheat (<xref rid="B16" ref-type="bibr">Deery et al., 2019</xref>; <xref rid="B72" ref-type="bibr">Walter et al., 2019</xref>; <xref rid="B17" ref-type="bibr">Deery et al., 2020</xref>). Similar values for 3D-FS phenotypes are reported here: 0.81-0.95 (AABV), 0.79-0.94 (OBV), 0.83-0.95 (PH), and 0.81-0.95 (NP). These values highlight the usefulness and applicability of PO for phenotype extraction, particularly morphological phenotypes. Additionally, similar trends of repeatability values were found across two distinct datasets: 0.55-0.95 and 0.39-0.95 for RGB-DR and RGB-FS platforms, respectively. These overlapping repeatability values demonstrate the applicability of PO to multiple platforms. The lower limit for repeatability for bounding area is an artifact of varying data collection start dates: 2019-12-10 for RGB-FS, 2019-12-12 for RGB-DR, and 2020-01-21 for 3D-FS. These earlier dates had a greater number of plants per plot, lowering the ability to accurately extract individual plant phenotypes due to overlap between plants. The number of plants per plot was reduced to approximately ten on 2020-01-16. Notably, all 3D-FS scans were collected after this date, resulting in a narrower range of repeatability values due to all scans being collected on well-spaced, lower overlap conditions.</p>
      <p>Repeatability is dependent on data and algorithms, meaning that any system could result in similar repeatability values as PO. However, an important difference is the ease at which these other systems handle and process large volumes of data to extract those repeatable phenotypic trait values. The PO system addresses this issue by allowing the extraction of highly repeatable traits in a few hours. Furthermore, the PO system also provides extensibility. Each module within PO collectively results in highly repeatable phenotypic traits across sensor data types. Even in cases where scalability is not necessary, such as small volumes of drone data, these repeatability values across sensors and phenotyping platforms highlight PO’s wide range of applications. The PO system, therefore, accelerates data processing of diverse data types from across phenotyping platforms, enabling the extraction of highly repeatable phenotypic traits that would otherwise have to be extracted using various, disparate systems or software that make it difficult to analyze, interpret, or combine resulting outputs.</p>
    </sec>
    <sec id="s4_3">
      <label>4.3</label>
      <title>PO enables deployment of future algorithms across species</title>
      <p>The PO suite addresses challenges in scalability and modularity to improve plant phenomics data processing. This was accomplished by leveraging existing and emerging technologies to process large volumes of phenomics data in a scalable, modular manner. Existing technologies include container technology, distributed computing frameworks, and data management systems, while emerging technologies include ML models for trait extraction. By coordinating this combination of technologies, PO processes data in an automated, efficient manner across platforms and sensors. The PO suite serves as a tool for others in plant phenomics to leverage within their research groups. This is made possible by the diverse availability of processing containers which can be deployed on any system on which Docker, Singularity, iRODS, and CCTools are installed. The phenotypic data processed by PO show high repeatability values across platforms, indicating PO’s utility within plant science and plant breeding programs. Importantly, the PO suite provides large volumes of phenotypic trait data that can be combined with other -omics data for applications in selection, dissection of functional and adaptive traits, and characterization of temporal patterns in trait expression (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Figure 8</bold></xref>).</p>
      <p>As ML methods mature, new models can be implemented within PO due to its customizable YAML configuration file. For example, models for leaf segmentation and extraction of traits such as leaf curling at scale, are the next steps of PO development. Furthermore, the training of these models is possible due to the large volume of intermediate data generated by pipelines like PO, which can serve as (<italic>i</italic>) training data for these next-generation models and (<italic>ii</italic>) as samples for model-generated data to further increase training data sizes. Containers that deploy these next-generation ML models could then be added to existing PO pipelines to provide organ-level phenotypic trait data that complements existing whole plant phenotypic trait data. This volume and diversity of phenomics data would enable fine-scale phenotyping at scale, which may uncover details on the temporal patterns in trait expression.</p>
      <p>PhytoOracle addresses many phenomics bottlenecks, but there are outstanding bottlenecks such as enviromic capabilities and multi-species support. Enviromic capabilities are limited within PO, which are important to account for the environmental noise encountered in field phenomics data. In the future, PO pipelines will be further developed to output environmental data directly from the Field Scanalyzer and neighboring weather stations alongside phenotypic trait data. As this would be difficult to generalize across users, we decided not to provide this capability at present. However, the authors understand that these complementing data would enhance interpretability and interoperability of processed phenotypic trait data, therefore, we plan to support these capabilities in the future. Although the present study focuses on lettuce, PO has been refactored to process sorghum phenomics data with the same containers used to process lettuce phenomics data (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Figure 9</bold></xref>). Further research and development will lead to the extraction of species-specific traits, and it is our goal to publish updates on these added functionalities.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="s5">
    <label>5</label>
    <title>Conclusion</title>
    <p>The scalable, modular PhytoOracle data processing pipelines enable the extraction of large, time-series phenotypic trait data in an automated and reproducible manner, key factors required to process projected data volumes. The resulting traits extracted by PO from both FS and DR platforms show high repeatability, highlighting the usefulness of PO across phenotyping platforms. The intermediate processed data, such as individual plant point clouds, extracted by PO opens new opportunities to extract fine-scale phenotypes at multiple resolutions (plot, plant, and organ levels). Importantly, the PO pipelines can be refactored to process phenomics data from other crops species, as discussed here with sorghum phenomics data. In the future, these time-series datasets may provide biological insight into morphological and physiological responses to drought conditions at the individual plant level across multiple crop species. This information could enable new species-specific targets for genetic improvement based on time-series, fine-scale phenotypic trait data.</p>
  </sec>
  <sec id="s6">
    <title>Code availability statement</title>
    <p>The Python scripts used to prepare RGB training data can be accessed here: <ext-link xlink:href="http://github.com/phytooracle/automation/blob/main/ml/collect_rgb_data.py" ext-link-type="uri">http://github.com/phytooracle/automation/blob/main/ml/collect_rgb_data.py</ext-link>. The Python script used to prepare thermal training data can be accessed here: <ext-link xlink:href="http://github.com/phytooracle/automation/blob/main/ml/collect_flir_data.py" ext-link-type="uri">http://github.com/phytooracle/automation/blob/main/ml/collect_flir_data.py</ext-link>. The Python script used to prepare 3D-derived images can be found here: <ext-link xlink:href="http://github.com/phytooracle/3d_heat_map/blob/main/3d_heat_map.py" ext-link-type="uri">http://github.com/phytooracle/3d_heat_map/blob/main/3d_heat_map.py</ext-link>. The code used to train object detection models can be found here: <ext-link xlink:href="http://github.com/phytooracle/ezobde" ext-link-type="uri">http://github.com/phytooracle/ezobde</ext-link>. Examples of YAML files used for data processing can be accessed here: <ext-link xlink:href="http://github.com/phytooracle/automation/tree/main/yaml_files" ext-link-type="uri">http://github.com/phytooracle/automation/tree/main/yaml_files</ext-link>. The automation script and data processing repositories can be accessed at: <ext-link xlink:href="http://github.com/phytooracle" ext-link-type="uri">http://github.com/phytooracle</ext-link>. Each PhytoOracle container built from data processing repositories can be accessed at: <ext-link xlink:href="http://hub.docker.com/orgs/phytooracle" ext-link-type="uri">http://hub.docker.com/orgs/phytooracle</ext-link>. For a detailed description of each data processing3repository and associated container, refer to the <xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Material</bold></xref>.</p>
  </sec>
  <sec sec-type="data-availability" id="s7">
    <title>Data availability statement</title>
    <p>The datasets presented in this study can be found in online repositories. The names of the repository/repositories and accession number(s) can be found below: <ext-link xlink:href="https://datacommons.cyverse.org/browse/iplant/home/shared/phytooracle/season_10_lettuce_yr_2020" ext-link-type="uri">https://datacommons.cyverse.org/browse/iplant/home/shared/phytooracle/season_10_lettuce_yr_2020</ext-link>.</p>
  </sec>
  <sec sec-type="author-contributions" id="s8">
    <title>Author contributions</title>
    <p>EMG conceptualized and developed processing code, analyzed data, and wrote the manuscript. AriZ, NH, TS conceptualized and developed processing code, and contributed to manuscript preparation. ArmZ, MC conceptualized and developed processing code. JD conceptualized and developed code related to data acquisition, oversaw the Field Scanalyzer operation, and contributed to manuscript preparation. HE contributed to the development of processing code and oversaw data labeling. SD conceptualized and developed processing code related to data transfer from Field Scanalyzer to the CyVerse Data Store. DL and MT contributed to the field design, harvesting, and manual collection of ground truth data. RM, TLS, NM, and EL contributed to project conceptualization, overseeing processing code development, and manuscript preparation. DP conceptualized, designed, and oversaw all aspects of the project including acquisition of funds and manuscript preparation. All authors contributed to the review of the manuscript and all authors have read the manuscript.</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>The authors would like to thank numerous members of the Pauli and Michelmore labs for their help in field set up, field management, and harvesting; CyVerse staff including Reetu Tuteja, Ryan Bartelme, Edwin Skidmore, and Tony Edgin for their help in implementing iRODS; UArizona High Performance Computing staff including Blake Joyce, Sara Marie Willis, and Chris Reidy for their help in computation; Pauli lab undergraduate students including Victoria Ramsay, Brenda Esmeralda Jimenez, Hanna April Lawson, Hassan Alnamer, Jordan Pettiford, and Nimet Beyza Bozdag for their help in image annotation, workflow development, and data processing; the Fall 2019 Applied Concepts in Cyberinfrastructure class at the University of Arizona for their participation in the initial development of this project; and Benjamin Tovar, Douglas Thain, and the entire CCTools team for their support in implementing CCTools.</p>
  </ack>
  <sec sec-type="COI-statement" id="s10">
    <title>Conflict of interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="s11">
    <title>Publisher’s note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
  <sec sec-type="supplementary-material" id="s12">
    <title>Supplementary material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link xlink:href="https://www.frontiersin.org/articles/10.3389/fpls.2023.1112973/full#supplementary-material" ext-link-type="uri">https://www.frontiersin.org/articles/10.3389/fpls.2023.1112973/full#supplementary-material</ext-link>
</p>
    <supplementary-material id="SM1" position="float" content-type="local-data">
      <media xlink:href="DataSheet_1.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aguate</surname><given-names>F. M.</given-names></name><name><surname>Trachsel</surname><given-names>S.</given-names></name><name><surname>Pérez</surname><given-names>L. G.</given-names></name><name><surname>Burgueño</surname><given-names>J.</given-names></name><name><surname>Crossa</surname><given-names>J.</given-names></name><name><surname>Balzarini</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>Use of hyperspectral image data outperforms vegetation indices in prediction of maize yield</article-title>. <source>Crop Sci.</source><volume>57</volume>, <fpage>2517</fpage>–<lpage>2524</lpage>. doi: <pub-id pub-id-type="doi">10.2135/cropsci2017.01.0007</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Albrecht</surname><given-names>M.</given-names></name><name><surname>Donnelly</surname><given-names>P.</given-names></name><name><surname>Bui</surname><given-names>P.</given-names></name><name><surname>Thain</surname><given-names>D.</given-names></name></person-group> (<year>2012</year>). <article-title>Makeflow: a portable abstraction for data intensive computing on clusters, clouds, and grids</article-title>. In <source>Proceedings of the 1st ACM SIGMOD Workshop on Scalable Workflow Execution Engines and Technologies</source> (<publisher-loc>Scottsdale, Arizona, USA</publisher-loc>: <publisher-name>Association for Computing Machinery</publisher-name>), <fpage>1</fpage>–<lpage>13</lpage>. doi: <pub-id pub-id-type="doi">10.1145/2443416.2443417</pub-id>
</mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrade-Sanchez</surname><given-names>P.</given-names></name><name><surname>Gore</surname><given-names>M. A.</given-names></name><name><surname>Heun</surname><given-names>J. T.</given-names></name><name><surname>Thorp</surname><given-names>K. R.</given-names></name><name><surname>Carmo-Silva</surname><given-names>A. E.</given-names></name><name><surname>French</surname><given-names>A. N.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>Development and evaluation of a field-based high-throughput phenotyping platform</article-title>. <source>Funct. Plant Biol.</source><volume>41</volume>, <fpage>68</fpage>–<lpage>79</lpage>. doi: <pub-id pub-id-type="doi">10.1071/FP13126</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Araus</surname><given-names>J. L.</given-names></name><name><surname>Cairns</surname><given-names>J. E.</given-names></name></person-group> (<year>2014</year>). <article-title>Field high-throughput phenotyping: The new crop breeding frontier</article-title>. <source>Trends Plant Sci.</source>
<volume>19</volume>, <fpage>52</fpage>–<lpage>61</lpage>. doi: <pub-id pub-id-type="doi">10.1016/J.TPLANTS.2013.09.008</pub-id>
<pub-id pub-id-type="pmid">24139902</pub-id></mixed-citation>
    </ref>
    <ref id="B47">
      <mixed-citation publication-type="webpage"><source>Model-assisted labeling (MAL)</source>. Available at: <uri xlink:href="https://docs.labelbox.com/docs/model-assisted-labeling">https://docs.labelbox.com/docs/model-assisted-labeling</uri> (Accessed <date-in-citation content-type="access-date">July 3, 2022</date-in-citation>).</mixed-citation>
    </ref>
    <ref id="B70">
      <mixed-citation publication-type="webpage"><source>Total data volume worldwide 2010-2025 statista</source>. Available at: <uri xlink:href="https://www.statista.com/statistics/871513/worldwide-data-created/">https://www.statista.com/statistics/871513/worldwide-data-created/</uri> (Accessed <date-in-citation content-type="access-date">April 25, 2022</date-in-citation>).</mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bai</surname><given-names>G.</given-names></name><name><surname>Ge</surname><given-names>Y.</given-names></name><name><surname>Hussain</surname><given-names>W.</given-names></name><name><surname>Baenziger</surname><given-names>P. S.</given-names></name><name><surname>Graef</surname><given-names>G.</given-names></name></person-group> (<year>2016</year>). <article-title>A multi-sensor system for high throughput field phenotyping in soybean and wheat breeding</article-title>. <source>Comput. Electron. Agric.</source>
<volume>128</volume>, <fpage>181</fpage>–<lpage>192</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.compag.2016.08.021</pub-id>
</mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>D.</given-names></name><name><surname>Mächler</surname><given-names>M.</given-names></name><name><surname>Bolker</surname><given-names>B.</given-names></name><name><surname>Walker</surname><given-names>S.</given-names></name></person-group> (<year>2015</year>). <article-title>Fitting linear mixed-effects models using lme4</article-title>. <source>J. Stat. Software</source>
<volume>67</volume>, <fpage>1</fpage>–<lpage>48</lpage>. doi: <pub-id pub-id-type="doi">10.18637/jss.v067.i01</pub-id>
</mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Ben-Kiki</surname><given-names>O.</given-names></name><name><surname>Evans</surname><given-names>C.</given-names></name></person-group> (<year>2001</year>) <source>YAML ain’t markup language (YAMLTM) version 1.2</source>. Available at: <uri xlink:href="http://yaml.org/spec/1.2/spec.html">http://yaml.org/spec/1.2/spec.html</uri> (Accessed <date-in-citation content-type="access-date">October 4, 2022</date-in-citation>).</mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bernardo</surname><given-names>R.</given-names></name></person-group> (<year>2020</year>). <article-title>Reinventing quantitative genetics for plant breeding: something old, something new, something borrowed, something BLUE</article-title>. <source>Heredity</source>
<volume>125</volume>, <fpage>375</fpage>–<lpage>385</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41437-020-0312-1</pub-id>
<pub-id pub-id-type="pmid">32296132</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Besl</surname><given-names>P. J.</given-names></name><name><surname>McKay</surname><given-names>N. D.</given-names></name></person-group> (<year>1992</year>). <article-title>A method for registration of 3-d shapes</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell.</source>
<volume>14</volume>, <fpage>239</fpage>–<lpage>256</lpage>. doi: <pub-id pub-id-type="doi">10.1109/34.121791</pub-id>
</mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campbell</surname><given-names>M. T.</given-names></name><name><surname>Knecht</surname><given-names>A. C.</given-names></name><name><surname>Berger</surname><given-names>B.</given-names></name><name><surname>Brien</surname><given-names>C. J.</given-names></name><name><surname>Wang</surname><given-names>D.</given-names></name><name><surname>Walia</surname><given-names>H.</given-names></name></person-group> (<year>2015</year>). <article-title>Integrating image-based phenomics and association analysis to dissect the genetic architecture of temporal salinity responses in rice</article-title>. <source>Plant Physiol.</source>
<volume>168</volume>, <fpage>1476</fpage>–<lpage>1489</lpage>. doi: <pub-id pub-id-type="doi">10.1104/pp.15.00450</pub-id>
<pub-id pub-id-type="pmid">26111541</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name><name><surname>Du</surname><given-names>X.</given-names></name><name><surname>Li</surname><given-names>C.</given-names></name><name><surname>Lu</surname><given-names>J.</given-names></name><name><surname>Zhao</surname><given-names>S.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>Big data challenge: a data management perspective</article-title>. <source>Front. Comput. Sci.</source><volume>7</volume>, <fpage>157</fpage>–<lpage>164</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s11704-013-3903-7</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>China Venkanna Varma</surname><given-names>P.</given-names></name><name><surname>Venkata Kalyan Chakravarthy</surname><given-names>K.</given-names></name><name><surname>Valli Kumari</surname><given-names>V.</given-names></name><name><surname>Viswanadha Raju</surname><given-names>S.</given-names></name></person-group> (<year>2016</year>). <article-title>Analysis of a network IO bottleneck in big data environments based on docker containers</article-title>. <source>Big Data Res.</source>
<volume>3</volume>, <fpage>24</fpage>–<lpage>28</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.bdr.2015.12.002</pub-id>
</mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Choi</surname><given-names>S.</given-names></name><name><surname>Zhou</surname><given-names>Q. Y.</given-names></name><name><surname>Koltun</surname><given-names>V.</given-names></name></person-group> (<year>2015</year>). “<article-title>Robust reconstruction of indoor scenes</article-title>,” in <conf-name>Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</conf-name>, (<publisher-loc>Boston, MA, USA</publisher-loc>: <publisher-name>IEEE</publisher-name>), <conf-date>07-12-June-2015</conf-date>. <fpage>5556</fpage>–<lpage>5565</lpage>. doi: <pub-id pub-id-type="doi">10.1109/CVPR.2015.7299195</pub-id>
</mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coppens</surname><given-names>F.</given-names></name><name><surname>Wuyts</surname><given-names>N.</given-names></name><name><surname>Inzé</surname><given-names>D.</given-names></name><name><surname>Dhondt</surname><given-names>S.</given-names></name></person-group> (<year>2017</year>). <article-title>Unlocking the potential of plant phenotyping data through integration and data-driven approaches</article-title>. <source>Curr. Opin. Syst. Biol.</source>
<volume>4</volume>, <fpage>58</fpage>–<lpage>63</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.coisb.2017.07.002</pub-id>
<pub-id pub-id-type="pmid">32923745</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>D. R.</given-names></name></person-group> (<year>1957</year>). <article-title>Note on grouping</article-title>. <source>J. Am. Stat. Assoc.</source>
<volume>52</volume>, <fpage>543</fpage>–<lpage>547</lpage>. doi: <pub-id pub-id-type="doi">10.1080/01621459.1957.10501411</pub-id>
</mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deery</surname><given-names>D. M.</given-names></name><name><surname>Rebetzke</surname><given-names>G. J.</given-names></name><name><surname>Jimenez-Berni</surname><given-names>J. A.</given-names></name><name><surname>Bovill</surname><given-names>W. D.</given-names></name><name><surname>James</surname><given-names>R. A.</given-names></name><name><surname>Condon</surname><given-names>A. G.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Evaluation of the phenotypic repeatability of canopy temperature in wheat using continuous-terrestrial and airborne measurements</article-title>. <source>Front. Plant Sci.</source><volume>10</volume>. doi: <pub-id pub-id-type="doi">10.3389/fpls.2019.00875</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deery</surname><given-names>D. M.</given-names></name><name><surname>Rebetzke</surname><given-names>G. J.</given-names></name><name><surname>Jimenez-Berni</surname><given-names>J. A.</given-names></name><name><surname>Condon</surname><given-names>A. G.</given-names></name><name><surname>Smith</surname><given-names>D. J.</given-names></name><name><surname>Bechaz</surname><given-names>K. M.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Ground-based LiDAR improves phenotypic repeatability of above-ground biomass and crop growth rate in wheat</article-title>. <source>Plant Phenomics</source><volume>2020</volume>, <fpage>1</fpage>–<lpage>11</lpage>. doi: <pub-id pub-id-type="doi">10.34133/2020/8329798</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devisetty</surname><given-names>U. K.</given-names></name><name><surname>Kennedy</surname><given-names>K.</given-names></name><name><surname>Sarando</surname><given-names>P.</given-names></name><name><surname>Merchant</surname><given-names>N.</given-names></name><name><surname>Lyons</surname><given-names>E.</given-names></name></person-group> (<year>2016</year>). <article-title>Bringing your tools to CyVerse discovery environment using docker</article-title>. <source>F1000Research</source>
<volume>5</volume> (<issue>1442</issue>), <fpage>1442</fpage>. doi: <pub-id pub-id-type="doi">10.12688/F1000RESEARCH.8935.1</pub-id>
<pub-id pub-id-type="pmid">27803802</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ester</surname><given-names>M.</given-names></name><name><surname>Kriegel</surname><given-names>H.-P.</given-names></name><name><surname>Xu</surname><given-names>X.</given-names></name></person-group> (<year>1996</year>). <source>A density-based algorithm for discovering clusters in Large spatial databases with noise</source>. <volume>96</volume>(<issue>34</issue>), <fpage>26</fpage>–<lpage>231</lpage>.</mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fahlgren</surname><given-names>N.</given-names></name><name><surname>Feldman</surname><given-names>M.</given-names></name><name><surname>Gehan</surname><given-names>M. A.</given-names></name><name><surname>Wilson</surname><given-names>M. S.</given-names></name><name><surname>Shyu</surname><given-names>C.</given-names></name><name><surname>Bryant</surname><given-names>D. W.</given-names></name><etal/></person-group>. (<year>2015</year>). <article-title>A versatile phenotyping system and analytics platform reveals diverse temporal responses to water availability in setaria</article-title>. <source>Mol. Plant</source><volume>8</volume>, <fpage>1520</fpage>–<lpage>1535</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.molp.2015.06.005</pub-id><pub-id pub-id-type="pmid">26099924</pub-id></mixed-citation>
    </ref>
    <ref id="B1000">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischler</surname><given-names>M. A.</given-names></name><name><surname>Bolles</surname><given-names>R. C.</given-names></name></person-group> (<year>1981</year>). <article-title>Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography</article-title>. <source>Communications of the ACM</source>
<volume>24</volume>(<issue>6</issue>), <fpage>381</fpage>–<lpage>395</lpage>.</mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>W. D.</given-names></name></person-group> (<year>1958</year>). <article-title>On grouping for maximum homogeneity</article-title>. <source>J. Am. Stat. Assoc.</source>
<volume>53</volume>, <fpage>789</fpage>–<lpage>798</lpage>. doi: <pub-id pub-id-type="doi">10.1080/01621459.1958.10501479</pub-id>
</mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Furbank</surname><given-names>R. T.</given-names></name><name><surname>Jimenez-Berni</surname><given-names>J. A.</given-names></name><name><surname>George-Jaeggli</surname><given-names>B.</given-names></name><name><surname>Potgieter</surname><given-names>A. B.</given-names></name><name><surname>Deery</surname><given-names>D. M.</given-names></name></person-group> (<year>2019</year>). <article-title>Field crop phenomics: enabling breeding for radiation use efficiency and biomass in cereal crops</article-title>. <source>New Phytol.</source>
<volume>223</volume>, <fpage>1714</fpage>–<lpage>1727</lpage>. doi: <pub-id pub-id-type="doi">10.1111/nph.15817</pub-id>
<pub-id pub-id-type="pmid">30937909</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Furbank</surname><given-names>R. T.</given-names></name><name><surname>Tester</surname><given-names>M.</given-names></name></person-group> (<year>2011</year>). <article-title>Phenomics - technologies to relieve the phenotyping bottleneck</article-title>. <source>Trends Plant Sci.</source>
<volume>16</volume>, <fpage>635</fpage>–<lpage>644</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.tplants.2011.09.005</pub-id>
<pub-id pub-id-type="pmid">22074787</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gehan</surname><given-names>M. A.</given-names></name><name><surname>Fahlgren</surname><given-names>N.</given-names></name><name><surname>Abbasi</surname><given-names>A.</given-names></name><name><surname>Berry</surname><given-names>J. C.</given-names></name><name><surname>Callen</surname><given-names>S. T.</given-names></name><name><surname>Chavez</surname><given-names>L.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>PlantCV v2: Image analysis software for high-throughput plant phenotyping</article-title>. <source>PeerJ</source><volume>5</volume>, <fpage>e4088</fpage>. doi: <pub-id pub-id-type="doi">10.7717/peerj.4088</pub-id><pub-id pub-id-type="pmid">29209576</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goff</surname><given-names>S. A.</given-names></name><name><surname>Vaughn</surname><given-names>M.</given-names></name><name><surname>McKay</surname><given-names>S.</given-names></name><name><surname>Lyons</surname><given-names>E.</given-names></name><name><surname>Stapleton</surname><given-names>A. E.</given-names></name><name><surname>Gessler</surname><given-names>D.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>The iPlant collaborative: Cyberinfrastructure for plant biology</article-title>. <source>Front. Plant Sci.</source><volume>2</volume>. doi: <pub-id pub-id-type="doi">10.3389/fpls.2011.00034</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grassini</surname><given-names>P.</given-names></name><name><surname>Eskridge</surname><given-names>K. M.</given-names></name><name><surname>Cassman</surname><given-names>K. G.</given-names></name></person-group> (<year>2013</year>). <article-title>Distinguishing between yield advances and yield plateaus in historical crop production trends</article-title>. <source>Nat. Commun.</source>
<volume>4</volume>, (<issue>1</issue>), <elocation-id>2918</elocation-id>. doi: <pub-id pub-id-type="doi">10.1038/ncomms3918</pub-id>
<pub-id pub-id-type="pmid">24346131</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>W.</given-names></name><name><surname>Fukano</surname><given-names>Y.</given-names></name><name><surname>Noshita</surname><given-names>K.</given-names></name><name><surname>Ninomiya</surname><given-names>S.</given-names></name></person-group> (<year>2020</year>). <article-title>Field-based individual plant phenotyping of herbaceous species by unmanned aerial vehicle</article-title>. <source>Ecol. Evol.</source>
<volume>10</volume>, <fpage>12318</fpage>–<lpage>12326</lpage>. doi: <pub-id pub-id-type="doi">10.1002/ece3.6861</pub-id>
<pub-id pub-id-type="pmid">33209290</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gupta</surname><given-names>A.</given-names></name><name><surname>Rico-Medina</surname><given-names>A.</given-names></name><name><surname>Caño-Delgado</surname><given-names>A. I.</given-names></name></person-group> (<year>2020</year>). <article-title>The physiology of plant responses to drought</article-title>. <source>Science</source>
<volume>368</volume>, <fpage>266</fpage>–<lpage>269</lpage>. doi: <pub-id pub-id-type="doi">10.1126/science.aaz7614</pub-id>
<pub-id pub-id-type="pmid">32299946</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harfouche</surname><given-names>A. L.</given-names></name><name><surname>Jacobson</surname><given-names>D. A.</given-names></name><name><surname>Kainer</surname><given-names>D.</given-names></name><name><surname>Romero</surname><given-names>J. C.</given-names></name><name><surname>Harfouche</surname><given-names>A. H.</given-names></name><name><surname>Scarascia Mugnozza</surname><given-names>G.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Accelerating climate resilient plant breeding by applying next-generation artificial intelligence</article-title>. <source>Trends Biotechnol. Regul. Ed</source><volume>37</volume>, <fpage>1217</fpage>–<lpage>1235</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.tibtech.2019.05.007</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herritt</surname><given-names>M. T.</given-names></name><name><surname>Long</surname><given-names>J. C.</given-names></name><name><surname>Roybal</surname><given-names>M. D.</given-names></name><name><surname>Moller</surname><given-names>D. C.</given-names></name><name><surname>Mockler</surname><given-names>T. C.</given-names></name><name><surname>Pauli</surname><given-names>D.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>FLIP: FLuorescence imaging pipeline for field-based chlorophyll fluorescence images</article-title>. <source>SoftwareX</source><volume>14</volume>, <elocation-id>100685</elocation-id>. doi: <pub-id pub-id-type="doi">10.1016/j.softx.2021.100685</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herritt</surname><given-names>M. T.</given-names></name><name><surname>Pauli</surname><given-names>D.</given-names></name><name><surname>Mockler</surname><given-names>T. C.</given-names></name><name><surname>Thompson</surname><given-names>A. L.</given-names></name></person-group> (<year>2020</year>). <article-title>Chlorophyll fluorescence imaging captures photochemical efficiency of grain sorghum (Sorghum bicolor) in a field setting</article-title>. <source>Plant Methods</source>
<volume>16</volume>, <fpage>1</fpage>-<lpage>13</lpage>. doi: <pub-id pub-id-type="doi">10.1186/s13007-020-00650-0</pub-id>
<pub-id pub-id-type="pmid">31911810</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hossain</surname><given-names>S.</given-names></name></person-group> (<year>2019</year>). <article-title>Visualization of bioinformatics data with dash bio</article-title>. <source>Proceedings of the 18th Python in Science Conference</source> (<publisher-loc>Austin, Texas</publisher-loc>: <publisher-loc>Proceedings of the Python in Science Conferences</publisher-loc>). <fpage>126</fpage>–<lpage>133</lpage>. doi: <pub-id pub-id-type="doi">10.25080/Majora-7ddc1dd1-012</pub-id>
</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunt</surname><given-names>G. C.</given-names></name><name><surname>Larus</surname><given-names>J. R.</given-names></name></person-group> (<year>2007</year>). <article-title>Singularity: rethinking the software stack</article-title>. <source>ACM SIGOPS Oper. Syst. Rev.</source>
<volume>41</volume>, <fpage>37</fpage>–<lpage>49</lpage>. doi: <pub-id pub-id-type="doi">10.1145/1243418.1243424</pub-id>
</mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunter</surname><given-names>J. D.</given-names></name></person-group> (<year>2007</year>). <article-title>Matplotlib: A 2D graphics environment</article-title>. <source>Comput. Sci. Eng.</source>
<volume>9</volume>, <fpage>90</fpage>–<lpage>95</lpage>. doi: <pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id>
</mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huxohl</surname><given-names>T.</given-names></name><name><surname>Kummert</surname><given-names>F.</given-names></name></person-group> (<year>2021</year>). <article-title>Model-assisted labeling and self-training for label noise reduction in the detection of stains on images of laundry</article-title>. <source>Mathematics</source>
<volume>9</volume>(<issue>19</issue>), <fpage>1</fpage>–<lpage>16</lpage>. doi: <pub-id pub-id-type="doi">10.3390/MATH9192498</pub-id>
</mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jukić</surname><given-names>N.</given-names></name><name><surname>Sharma</surname><given-names>A.</given-names></name><name><surname>Nestorov</surname><given-names>S.</given-names></name><name><surname>Jukić</surname><given-names>B.</given-names></name></person-group> (<year>2015</year>). <article-title>Augmenting data warehouses with big data</article-title>. <source>Inf. Syst. Manage.</source>
<volume>32</volume>, <fpage>200</fpage>–<lpage>209</lpage>. doi: <pub-id pub-id-type="doi">10.1080/10580530.2015.1044338</pub-id>
</mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kale</surname><given-names>V.</given-names></name></person-group> (<year>2020</year>). <source>Parallel computing architectures and APIs: IoT big data stream processing</source> (<publisher-loc>New York</publisher-loc>: <publisher-name>CRC Press</publisher-name>). doi: <pub-id pub-id-type="doi">10.1201/9781351029223</pub-id>
</mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khan</surname><given-names>N.</given-names></name><name><surname>Essemine</surname><given-names>J.</given-names></name><name><surname>Hamdani</surname><given-names>S.</given-names></name><name><surname>Qu</surname><given-names>M.</given-names></name><name><surname>Lyu</surname><given-names>M.-J. A.</given-names></name><name><surname>Perveen</surname><given-names>S.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Natural variation in the fast phase of chlorophyll a fluorescence induction curve (OJIP) in a global rice minicore panel</article-title>. <source>Photosynth. Res</source><volume>150</volume>, <fpage>137</fpage>-<lpage>158</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s11120-020-00794-z</pub-id><pub-id pub-id-type="pmid">33159615</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>S.-L.</given-names></name><name><surname>Solehati</surname><given-names>N.</given-names></name><name><surname>Choi</surname><given-names>I.-C.</given-names></name><name><surname>Kim</surname><given-names>K.-H.</given-names></name><name><surname>Kwon</surname><given-names>T.-R.</given-names></name></person-group> (<year>2017</year>). <article-title>Data management for plant phenomics</article-title>. <source>J. Plant Biol.</source>
<volume>60</volume>, <fpage>285</fpage>–<lpage>297</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s12374-017-0027-x</pub-id>
</mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knecht</surname><given-names>A. C.</given-names></name><name><surname>Campbell</surname><given-names>M. T.</given-names></name><name><surname>Caprez</surname><given-names>A.</given-names></name><name><surname>Swanson</surname><given-names>D. R.</given-names></name><name><surname>Walia</surname><given-names>H.</given-names></name></person-group> (<year>2016</year>). <article-title>Image harvest: An open-source platform for high-throughput plant image processing and analysis</article-title>. <source>J. Exp. Bot.</source>
<volume>67</volume>, <fpage>3587</fpage>–<lpage>3599</lpage>. doi: <pub-id pub-id-type="doi">10.1093/jxb/erw176</pub-id>
<pub-id pub-id-type="pmid">27141917</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurtzer</surname><given-names>G. M.</given-names></name><name><surname>Sochat</surname><given-names>V.</given-names></name><name><surname>Bauer</surname><given-names>M. W.</given-names></name></person-group> (<year>2017</year>). <article-title>Singularity: Scientific containers for mobility of compute</article-title>. <source>PloS One</source>
<volume>12</volume>, <elocation-id>e0177459</elocation-id>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0177459</pub-id>
<pub-id pub-id-type="pmid">28494014</pub-id></mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lane</surname><given-names>H. M.</given-names></name><name><surname>Murray</surname><given-names>S. C.</given-names></name><name><surname>Montesinos-López</surname><given-names>O. A.</given-names></name><name><surname>Montesinos-López</surname><given-names>A.</given-names></name><name><surname>Crossa</surname><given-names>J.</given-names></name><name><surname>Rooney</surname><given-names>D. K.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Phenomic selection and prediction of maize grain yield from near-infrared reflectance spectroscopy of kernels</article-title>. <source>Plant Phenome J.</source><volume>3</volume>(<issue>1</issue>), <elocation-id>e20002</elocation-id>. doi: <pub-id pub-id-type="doi">10.1002/ppj2.20002</pub-id></mixed-citation>
    </ref>
    <ref id="B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>B.</given-names></name><name><surname>Chen</surname><given-names>L.</given-names></name><name><surname>Sun</surname><given-names>W.</given-names></name><name><surname>Wu</surname><given-names>D.</given-names></name><name><surname>Wang</surname><given-names>M.</given-names></name><name><surname>Yu</surname><given-names>Y.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Phenomics-based GWAS analysis reveals the genetic architecture for drought resistance in cotton</article-title>. <source>Plant Biotechnol. J.</source><volume>18</volume>, <fpage>2533</fpage>–<lpage>2544</lpage>. doi: <pub-id pub-id-type="doi">10.1111/pbi.13431</pub-id><pub-id pub-id-type="pmid">32558152</pub-id></mixed-citation>
    </ref>
    <ref id="B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lohmar</surname><given-names>F. J.</given-names></name></person-group> (<year>1988</year>). <article-title>World geodetic system 1984 — geodetic reference system of GPS orbits</article-title>. <source>GPS-Techniques Appl. to Geodesy Survey.</source>, <fpage>476</fpage>–<lpage>486</lpage>. doi: <pub-id pub-id-type="doi">10.1007/BFB0011360</pub-id>
</mixed-citation>
    </ref>
    <ref id="B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacQueen</surname><given-names>J.</given-names></name></person-group> (<year>1967</year>). <article-title>Some methods for classification and analysis of multivariate observations</article-title>. <source>Proc. Fifth Berkeley Symp. Math. Stat. Probab.</source>
<volume>19</volume>, <fpage>281</fpage>–<lpage>297</lpage>.</mixed-citation>
    </ref>
    <ref id="B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merchant</surname><given-names>N.</given-names></name><name><surname>Lyons</surname><given-names>E.</given-names></name><name><surname>Goff</surname><given-names>S.</given-names></name><name><surname>Vaughn</surname><given-names>M.</given-names></name><name><surname>Ware</surname><given-names>D.</given-names></name><name><surname>Micklos</surname><given-names>D.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>The iPlant collaborative: Cyberinfrastructure for enabling data to discovery for the life sciences</article-title>. <source>PloS Biol.</source><volume>14</volume> (<issue>1</issue>), <elocation-id>e1002342</elocation-id>. doi: <pub-id pub-id-type="doi">10.1371/JOURNAL.PBIO.1002342</pub-id>
<pub-id pub-id-type="pmid">26752627</pub-id></mixed-citation>
    </ref>
    <ref id="B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parmley</surname><given-names>K.</given-names></name><name><surname>Nagasubramanian</surname><given-names>K.</given-names></name><name><surname>Sarkar</surname><given-names>S.</given-names></name><name><surname>Ganapathysubramanian</surname><given-names>B.</given-names></name><name><surname>Singh</surname><given-names>A. K.</given-names></name></person-group> (<year>2019</year>). <article-title>Development of optimized phenomic predictors for efficient plant breeding decisions using phenomic-assisted selection in soybean</article-title>. <source>Plant Phenomics</source>
<volume>2019</volume>, <fpage>1</fpage>–<lpage>15</lpage>. doi: <pub-id pub-id-type="doi">10.34133/2019/5809404</pub-id>
</mixed-citation>
    </ref>
    <ref id="B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pauli</surname><given-names>D.</given-names></name><name><surname>Chapman</surname><given-names>S. C.</given-names></name><name><surname>Bart</surname><given-names>R.</given-names></name><name><surname>Topp</surname><given-names>C. N.</given-names></name><name><surname>Lawrence-Dill</surname><given-names>C. J.</given-names></name><name><surname>Poland</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>The quest for understanding phenotypic variation <italic>via</italic> integrated approaches in the field environment</article-title>. <source>Plant Physiol.</source><volume>172</volume>, <fpage>622</fpage>–<lpage>634</lpage>. doi: <pub-id pub-id-type="doi">10.1104/PP.16.00592</pub-id><pub-id pub-id-type="pmid">27482076</pub-id></mixed-citation>
    </ref>
    <ref id="B50">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F.</given-names></name><name><surname>Varoquaux</surname><given-names>G.</given-names></name><name><surname>Gramfort</surname><given-names>A.</given-names></name><name><surname>Michel</surname><given-names>V.</given-names></name><name><surname>Thirion</surname><given-names>B.</given-names></name><name><surname>Grisel</surname><given-names>O.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Scikit-learn: Machine learning in Python</article-title>. <source>J. Mach. Learn. Res.</source><volume>12</volume>, <fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
    </ref>
    <ref id="B51">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poblete-Echeverría</surname><given-names>C.</given-names></name><name><surname>Olmedo</surname><given-names>G.</given-names></name><name><surname>Ingram</surname><given-names>B.</given-names></name><name><surname>Bardeen</surname><given-names>M.</given-names></name></person-group> (<year>2017</year>). <article-title>Detection and segmentation of vine canopy in ultra-high spatial resolution RGB imagery obtained from unmanned aerial vehicle (UAV): A case study in a commercial vineyard</article-title>. <source>Remote Sens.</source>
<volume>9</volume>, <elocation-id>268</elocation-id>. doi: <pub-id pub-id-type="doi">10.3390/rs9030268</pub-id>
</mixed-citation>
    </ref>
    <ref id="B53">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prado</surname><given-names>S. A.</given-names></name><name><surname>Cabrera-Bosquet</surname><given-names>L.</given-names></name><name><surname>Grau</surname><given-names>A.</given-names></name><name><surname>Coupel-Ledru</surname><given-names>A.</given-names></name><name><surname>Millet</surname><given-names>E. J.</given-names></name><name><surname>Welcker</surname><given-names>C.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Phenomics allows identification of genomic regions affecting maize stomatal conductance with conditional effects of water deficit and evaporative demand</article-title>. <source>Plant Cell Environ.</source><volume>41</volume>, <fpage>314</fpage>–<lpage>326</lpage>. doi: <pub-id pub-id-type="doi">10.1111/pce.13083</pub-id><pub-id pub-id-type="pmid">29044609</pub-id></mixed-citation>
    </ref>
    <ref id="B54">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qin</surname><given-names>Y.</given-names></name><name><surname>Yalamanchili</surname><given-names>H. K.</given-names></name><name><surname>Qin</surname><given-names>J.</given-names></name><name><surname>Yan</surname><given-names>B.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name></person-group> (<year>2015</year>). <article-title>The current status and challenges in computational analysis of genomic big data</article-title>. <source>Big Data Res.</source>
<volume>2</volume>, <fpage>12</fpage>–<lpage>18</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.bdr.2015.02.005</pub-id>
</mixed-citation>
    </ref>
    <ref id="B55">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><collab>R Core Team</collab></person-group> (<year>2022</year>) <source>R: The r project for statistical computing</source>. Available at: <uri xlink:href="https://www.r-project.org/">https://www.r-project.org/</uri> (Accessed <date-in-citation content-type="access-date">October 4, 2022</date-in-citation>).</mixed-citation>
    </ref>
    <ref id="B56">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rebetzke</surname><given-names>G. J.</given-names></name><name><surname>Jimenez-Berni</surname><given-names>J. A.</given-names></name><name><surname>Bovill</surname><given-names>W. D.</given-names></name><name><surname>Deery</surname><given-names>D. M.</given-names></name><name><surname>James</surname><given-names>R. A.</given-names></name></person-group> (<year>2016</year>). <article-title>High-throughput phenotyping technologies allow accurate selection of stay-green</article-title>. <source>J. Exp. Bot.</source>
<volume>67</volume>, <fpage>4919</fpage>–<lpage>4924</lpage>. doi: <pub-id pub-id-type="doi">10.1093/jxb/erw301</pub-id>
<pub-id pub-id-type="pmid">27604804</pub-id></mixed-citation>
    </ref>
    <ref id="B57">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rebolledo</surname><given-names>M. C.</given-names></name><name><surname>Peña</surname><given-names>A. L.</given-names></name><name><surname>Duitama</surname><given-names>J.</given-names></name><name><surname>Cruz</surname><given-names>D. F.</given-names></name><name><surname>Dingkuhn</surname><given-names>M.</given-names></name><name><surname>Grenier</surname><given-names>C.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>Combining image analysis, genome wide association studies and different field trials to reveal stable genetic regions related to panicle architecture and the number of spikelets per panicle in rice</article-title>. <source>Front. Plant Sci.</source><volume>7</volume>. doi: <pub-id pub-id-type="doi">10.3389/fpls.2016.01384</pub-id></mixed-citation>
    </ref>
    <ref id="B58">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ren</surname><given-names>S.</given-names></name><name><surname>He</surname><given-names>K.</given-names></name><name><surname>Girshick</surname><given-names>R.</given-names></name><name><surname>Sun</surname><given-names>J.</given-names></name></person-group> (<year>2017</year>). <article-title>Faster r-CNN: Towards real-time object detection with region proposal networks</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell.</source>
<volume>39</volume>, <fpage>1137</fpage>–<lpage>1149</lpage>. doi: <pub-id pub-id-type="doi">10.1109/TPAMI.2016.2577031</pub-id>
<pub-id pub-id-type="pmid">27295650</pub-id></mixed-citation>
    </ref>
    <ref id="B59">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname><given-names>D.</given-names></name><name><surname>Baret</surname><given-names>F.</given-names></name><name><surname>Welcker</surname><given-names>C.</given-names></name><name><surname>Bostrom</surname><given-names>A.</given-names></name><name><surname>Ball</surname><given-names>J.</given-names></name><name><surname>Cellini</surname><given-names>F.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>What is cost-efficient phenotyping? optimizing costs for different scenarios</article-title>. <source>Plant Sci.</source><volume>282</volume>, <fpage>14</fpage>–<lpage>22</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.plantsci.2018.06.015</pub-id><pub-id pub-id-type="pmid">31003607</pub-id></mixed-citation>
    </ref>
    <ref id="B60">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rincent</surname><given-names>R.</given-names></name><name><surname>Charpentier</surname><given-names>J.-P.</given-names></name><name><surname>Faivre-Rampant</surname><given-names>P.</given-names></name><name><surname>Paux</surname><given-names>E.</given-names></name><name><surname>Le Gouis</surname><given-names>J.</given-names></name><name><surname>Bastien</surname><given-names>C.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Phenomic selection is a low-cost and high-throughput method based on indirect predictions: Proof of concept on wheat and poplar</article-title>. <source>G3 GenesGenomesGenetics</source><volume>8</volume>, <fpage>3961</fpage>–<lpage>3972</lpage>. doi: <pub-id pub-id-type="doi">10.1534/g3.118.200760</pub-id></mixed-citation>
    </ref>
    <ref id="B61">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roth</surname><given-names>L.</given-names></name><name><surname>Camenzind</surname><given-names>M.</given-names></name><name><surname>Aasen</surname><given-names>H.</given-names></name><name><surname>Kronenberg</surname><given-names>L.</given-names></name><name><surname>Barendregt</surname><given-names>C.</given-names></name><name><surname>Camp</surname><given-names>K. H.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Repeated multiview imaging for estimating seedling tiller counts of wheat genotypes using drones</article-title>. <source>Plant Phenomics</source><volume>2020</volume>, <fpage>1</fpage>-<lpage>20</lpage>. doi: <pub-id pub-id-type="doi">10.34133/2020/3729715</pub-id></mixed-citation>
    </ref>
    <ref id="B62">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Searchinger</surname><given-names>T.</given-names></name><name><surname>Waite</surname><given-names>R.</given-names></name><name><surname>Hanson</surname><given-names>C.</given-names></name><name><surname>Ranganathan</surname><given-names>J.</given-names></name><name><surname>Dumas</surname><given-names>P.</given-names></name><name><surname>Matthews</surname><given-names>E.</given-names></name><etal/></person-group>. (<year>2019</year>) <source>World resources report: Creating a sustainable food future</source>. Available at: <uri xlink:href="http://www.SustainableFoodFuture.org">www.SustainableFoodFuture.org</uri>.</mixed-citation>
    </ref>
    <ref id="B63">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sivarajah</surname><given-names>U.</given-names></name><name><surname>Kamal</surname><given-names>M. M.</given-names></name><name><surname>Irani</surname><given-names>Z.</given-names></name><name><surname>Weerakkody</surname><given-names>V.</given-names></name></person-group> (<year>2017</year>). <article-title>Critical analysis of big data challenges and analytical methods</article-title>. <source>J. Bus. Res.</source>
<volume>70</volume>, <fpage>263</fpage>–<lpage>286</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.jbusres.2016.08.001</pub-id>
</mixed-citation>
    </ref>
    <ref id="B64">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stephens</surname><given-names>Z. D.</given-names></name><name><surname>Lee</surname><given-names>S. Y.</given-names></name><name><surname>Faghri</surname><given-names>F.</given-names></name><name><surname>Campbell</surname><given-names>R. H.</given-names></name><name><surname>Zhai</surname><given-names>C.</given-names></name><name><surname>Efron</surname><given-names>M. J.</given-names></name><etal/></person-group>. (<year>2015</year>). <article-title>Big data: Astronomical or genomical</article-title>? <source>PloS Biol.</source><volume>13</volume>, <elocation-id>e1002195</elocation-id>. doi: <pub-id pub-id-type="doi">10.1371/journal.pbio.1002195</pub-id><pub-id pub-id-type="pmid">26151137</pub-id></mixed-citation>
    </ref>
    <ref id="B65">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanash</surname><given-names>M.</given-names></name><name><surname>Dunn</surname><given-names>B.</given-names></name><name><surname>Andresen</surname><given-names>D.</given-names></name><name><surname>Hsu</surname><given-names>W.</given-names></name><name><surname>Yang</surname><given-names>H.</given-names></name><name><surname>Okanlawon</surname><given-names>A.</given-names></name></person-group> (<year>2019</year>). <article-title>Improving HPC system performance by predicting job resources <italic>via</italic> supervised machine learning</article-title>. <source>PEARC19</source>
<volume>2019</volume>, <fpage>69</fpage>. doi: <pub-id pub-id-type="doi">10.1145/3332186.3333041</pub-id>. Rise Mach. Learn. July 28-August 1 2019 Chic. Ill. Pract. Exp. Adv. Res. Comput. Conf. 2019 Chic. Il.<pub-id pub-id-type="pmid">35308798</pub-id></mixed-citation>
    </ref>
    <ref id="B66">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tausen</surname><given-names>M.</given-names></name><name><surname>Clausen</surname><given-names>M.</given-names></name><name><surname>Moeskjær</surname><given-names>S.</given-names></name><name><surname>Shihavuddin</surname><given-names>A. S. M.</given-names></name><name><surname>Dahl</surname><given-names>A. B.</given-names></name><name><surname>Janss</surname><given-names>L.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Greenotyper: Image-based plant phenotyping using distributed computing and deep learning</article-title>. <source>Front. Plant Sci.</source><volume>11</volume>. doi: <pub-id pub-id-type="doi">10.3389/fpls.2020.01181</pub-id></mixed-citation>
    </ref>
    <ref id="B67">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tauzin</surname><given-names>G.</given-names></name><name><surname>Lupo</surname><given-names>U.</given-names></name><name><surname>Tunstall</surname><given-names>L.</given-names></name><name><surname>Perez</surname><given-names>J. B.</given-names></name><name><surname>Caorsi</surname><given-names>M.</given-names></name><name><surname>Medina-Mardones</surname><given-names>A. M.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Giotto-tda: A topological data analysis toolkit for machine learning and data exploration</article-title>. <source>The Journal of Machine Learning Research</source>
<volume>22</volume>(<issue>1</issue>), <fpage>1834</fpage>–<lpage>1839</lpage>.</mixed-citation>
    </ref>
    <ref id="B68">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>A. L.</given-names></name><name><surname>Thorp</surname><given-names>K. R.</given-names></name><name><surname>Conley</surname><given-names>M.</given-names></name><name><surname>Andrade-Sanchez</surname><given-names>P.</given-names></name><name><surname>Heun</surname><given-names>J. T.</given-names></name><name><surname>Dyer</surname><given-names>J. M.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Deploying a proximal sensing cart to identify drought-adaptive traits in upland cotton for high-throughput phenotyping</article-title>. <source>Front. Plant Sci.</source><volume>9</volume>. doi: <pub-id pub-id-type="doi">10.3389/fpls.2018.00507</pub-id></mixed-citation>
    </ref>
    <ref id="B69">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thorp</surname><given-names>K. R.</given-names></name><name><surname>Thompson</surname><given-names>A. L.</given-names></name><name><surname>Harders</surname><given-names>S. J.</given-names></name><name><surname>French</surname><given-names>A. N.</given-names></name><name><surname>Ward</surname><given-names>R. W.</given-names></name></person-group> (<year>2018</year>). <article-title>High-throughput phenotyping of crop water use efficiency <italic>via</italic> multispectral drone imagery and a daily soilwater balance model</article-title>. <source>Remote Sens.</source>
<volume>10</volume>(<issue>1</issue>), <fpage>1682</fpage>. doi: <pub-id pub-id-type="doi">10.3390/rs10111682</pub-id>
</mixed-citation>
    </ref>
    <ref id="B71">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Bezouw</surname><given-names>R. F. H. M.</given-names></name><name><surname>Keurentjes</surname><given-names>J. J. B.</given-names></name><name><surname>Harbinson</surname><given-names>J.</given-names></name><name><surname>Aarts</surname><given-names>M. G. M.</given-names></name></person-group> (<year>2019</year>). <article-title>Converging phenomics and genomics to study natural variation in plant photosynthetic efficiency</article-title>. <source>Plant J.</source>
<volume>97</volume>, <fpage>112</fpage>–<lpage>133</lpage>. doi: <pub-id pub-id-type="doi">10.1111/tpj.14190</pub-id>
<pub-id pub-id-type="pmid">30548574</pub-id></mixed-citation>
    </ref>
    <ref id="B1001">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Virtanen</surname><given-names>P.</given-names></name><name><surname>Gommers</surname><given-names>R.</given-names></name><name><surname>Oliphant</surname><given-names>T. E.</given-names></name><name><surname>Haberland</surname><given-names>M.</given-names></name><name><surname>Reddy</surname><given-names>T.</given-names></name><name><surname>Cournapeau</surname><given-names>D.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>SciPy 1.0: Fundamental algorithms for scientific computing in Python</article-title>. <source>Nature methods</source><volume>17</volume>(<issue>3</issue>), <fpage>261</fpage>–<lpage>272</lpage>.<pub-id pub-id-type="pmid">32015543</pub-id></mixed-citation>
    </ref>
    <ref id="B72">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walter</surname><given-names>J. D. C.</given-names></name><name><surname>Edwards</surname><given-names>J.</given-names></name><name><surname>McDonald</surname><given-names>G.</given-names></name><name><surname>Kuchel</surname><given-names>H.</given-names></name></person-group> (<year>2019</year>). <article-title>Estimating biomass and canopy height with LiDAR for field crop breeding</article-title>. <source>Front. Plant Sci.</source>
<volume>10</volume>. doi: <pub-id pub-id-type="doi">10.3389/fpls.2019.01145</pub-id>
</mixed-citation>
    </ref>
    <ref id="B1002">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Sun</surname><given-names>Y.</given-names></name><name><surname>Liu</surname><given-names>Z.</given-names></name><name><surname>Sarma</surname><given-names>S. E.</given-names></name><name><surname>Bronstein</surname><given-names>M. M.</given-names></name><name><surname>Solomon</surname><given-names>J. M.</given-names></name></person-group> (<year>2019</year>). <article-title>Dynamic graph cnn for learning on point clouds</article-title>. <source>Acm Transactions On Graphics (tog)</source>. <volume>38</volume>(<issue>5</issue>), <fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation>
    </ref>
    <ref id="B73">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ward</surname><given-names>J. H.</given-names></name></person-group> (<year>1963</year>). <article-title>Hierarchical grouping to optimize an objective function</article-title>. <source>J. Am. Stat. Assoc.</source>
<volume>58</volume>, <fpage>236</fpage>–<lpage>244</lpage>. doi: <pub-id pub-id-type="doi">10.1080/01621459.1963.10500845</pub-id>
</mixed-citation>
    </ref>
    <ref id="B74">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waskom</surname><given-names>M. L.</given-names></name></person-group> (<year>2021</year>). <article-title>Seaborn: Statistical data visualization</article-title>. <source>J. Open Source Software</source>
<volume>6</volume>(<issue>60</issue>), <fpage>3021</fpage>. doi: <pub-id pub-id-type="doi">10.21105/joss.03021</pub-id>
</mixed-citation>
    </ref>
    <ref id="B75">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>White</surname><given-names>J. W.</given-names></name><name><surname>Conley</surname><given-names>M. M.</given-names></name></person-group> (<year>2013</year>). <article-title>A flexible, low-cost cart for proximal sensing</article-title>. <source>Crop Sci.</source>
<volume>53</volume>, <fpage>1646</fpage>–<lpage>1649</lpage>. doi: <pub-id pub-id-type="doi">10.2135/cropsci2013.01.0054</pub-id>
</mixed-citation>
    </ref>
    <ref id="B76">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>H.</given-names></name><name><surname>Wang</surname><given-names>N.</given-names></name><name><surname>Bennett</surname><given-names>R.</given-names></name><name><surname>Burditt</surname><given-names>D.</given-names></name><name><surname>Cannon</surname><given-names>A.</given-names></name><name><surname>Chamberlin</surname><given-names>K.</given-names></name></person-group> (<year>2018</year>). <source>Development of a ground-based peanut canopy phenotyping system</source> (<publisher-loc>Beijing, China</publisher-loc>: <publisher-name>Elsevier B.V</publisher-name>), <fpage>162</fpage>–<lpage>165</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.ifacol.2018.08.081</pub-id>
</mixed-citation>
    </ref>
    <ref id="B77">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zarei</surname><given-names>A.</given-names></name><name><surname>Gonzalez</surname><given-names>E.</given-names></name><name><surname>Merchant</surname><given-names>N.</given-names></name><name><surname>Pauli</surname><given-names>D.</given-names></name><name><surname>Lyons</surname><given-names>E.</given-names></name><name><surname>Barnard</surname><given-names>K.</given-names></name></person-group> (<year>2022</year>). <article-title>MegaStitch: Robust Large-scale image stitching</article-title>. <source>IEEE Trans. Geosci. Remote Sens.</source>
<volume>60</volume>, <fpage>1</fpage>–<lpage>9</lpage>. doi: <pub-id pub-id-type="doi">10.1109/TGRS.2022.3141907</pub-id>
</mixed-citation>
    </ref>
    <ref id="B1003">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Z.</given-names></name><name><surname>Chang</surname><given-names>C.</given-names></name><name><surname>Lin</surname><given-names>H.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Arora</surname><given-names>R.</given-names></name><name><surname>Jin</surname><given-names>X.</given-names></name></person-group> (<year>2020</year>). <article-title>Is network the bottleneck of distributed training</article-title>? In <source>Proceedings of the Workshop on Network Meets AI &amp; ML</source> (pp. <fpage>8</fpage>–<lpage>13</lpage>).</mixed-citation>
    </ref>
    <ref id="B78">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Q.-Y.</given-names></name><name><surname>Park</surname><given-names>J.</given-names></name><name><surname>Koltun</surname><given-names>V.</given-names></name></person-group> (<year>2018</year>) <source>Open3D: A modern library for 3D data processing</source>. Available at: <uri xlink:href="http://arxiv.org/abs/1801.09847">http://arxiv.org/abs/1801.09847</uri> (Accessed <date-in-citation content-type="access-date">August 5, 2021</date-in-citation>). ArXiv180109847 Cs.</mixed-citation>
    </ref>
    <ref id="B79">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>X.</given-names></name><name><surname>Leiser</surname><given-names>W. L.</given-names></name><name><surname>Hahn</surname><given-names>V.</given-names></name><name><surname>Würschum</surname><given-names>T.</given-names></name></person-group> (<year>2021</year>). <article-title>Phenomic selection is competitive with genomic selection for breeding of complex traits</article-title>. <source>Plant Phenome J.</source>
<volume>4</volume>, <elocation-id>e20027</elocation-id>. doi: <pub-id pub-id-type="doi">10.1002/ppj2.20027</pub-id>
</mixed-citation>
    </ref>
  </ref-list>
</back>
