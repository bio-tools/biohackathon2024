<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9985174</article-id>
    <article-id pub-id-type="pmid">36821425</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btad099</article-id>
    <article-id pub-id-type="publisher-id">btad099</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Gene Expression</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CLAIRE: contrastive learning-based batch correction framework for better balance between batch mixing and preservation of cellular heterogeneity</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Yan</surname>
          <given-names>Xuhua</given-names>
        </name>
        <aff><institution>Hunan Provincial Key Lab on Bioinformatics, School of Computer Science and Engineering, Central South University</institution>, Changsha 410083, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6372-6798</contrib-id>
        <name>
          <surname>Zheng</surname>
          <given-names>Ruiqing</given-names>
        </name>
        <aff><institution>Hunan Provincial Key Lab on Bioinformatics, School of Computer Science and Engineering, Central South University</institution>, Changsha 410083, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-4593-9332</contrib-id>
        <name>
          <surname>Wu</surname>
          <given-names>Fangxiang</given-names>
        </name>
        <aff><institution>Division of Biomedical Engineering, Department of Computer Science, Department of Mechanical Engineering, University of Saskatchewan</institution>, <addr-line>Saskatoon, SK S7N 5A9</addr-line>, <country country="CA">Canada</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-0188-1394</contrib-id>
        <name>
          <surname>Li</surname>
          <given-names>Min</given-names>
        </name>
        <aff><institution>Hunan Provincial Key Lab on Bioinformatics, School of Computer Science and Engineering, Central South University</institution>, Changsha 410083, <country country="CN">China</country></aff>
        <xref rid="btad099-cor1" ref-type="corresp"/>
        <!--limin@mail.csu.edu.cn-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Birol</surname>
          <given-names>Inanc</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btad099-cor1">To whom correspondence should be addressed. <email>limin@mail.csu.edu.cn</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>3</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-02-23">
      <day>23</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>23</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <volume>39</volume>
    <issue>3</issue>
    <elocation-id>btad099</elocation-id>
    <history>
      <date date-type="received">
        <day>04</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>27</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>13</day>
        <month>2</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>22</day>
        <month>2</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>03</day>
        <month>3</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btad099.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Integration of growing single-cell RNA sequencing datasets helps better understand cellular identity and function. The major challenge for integration is removing batch effects while preserving biological heterogeneities. Advances in contrastive learning have inspired several contrastive learning-based batch correction methods. However, existing contrastive-learning-based methods exhibit noticeable <italic toggle="yes">ad hoc</italic> trade-off between batch mixing and preservation of cellular heterogeneities (mix-heterogeneity trade-off). Therefore, a deliberate mix-heterogeneity trade-off is expected to yield considerable improvements in scRNA-seq dataset integration.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We develop a novel contrastive learning-based batch correction framework, CIAIRE, which achieves superior mix-heterogeneity trade-off. The key contributions of CLAIRE are proposal of two complementary strategies: construction strategy and refinement strategy, to improve the appropriateness of positive pairs. Construction strategy dynamically generates positive pairs by augmenting inter-batch mutual nearest neighbors (MNN) with intra-batch k-nearest neighbors (KNN), which improves the coverage of positive pairs for the whole distribution of shared cell types between batches. Refinement strategy aims to automatically reduce the potential false positive pairs from the construction strategy, which resorts to the memory effect of deep neural networks. We demonstrate that CLAIRE possesses superior mix-heterogeneity trade-off over existing contrastive learning-based methods. Benchmark results on six real datasets also show that CLAIRE achieves the best integration performance against eight state-of-the-art methods. Finally, comprehensive experiments are conducted to validate the effectiveness of CLAIRE.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The source code and data used in this study can be found in <ext-link xlink:href="https://github.com/CSUBioGroup/CLAIRE-release" ext-link-type="uri">https://github.com/CSUBioGroup/CLAIRE-release</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>62225209</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Single-cell RNA sequencing (scRNA-seq) was developed to characterize high-throughput gene expression profiles for populations of individual cells, which has enabled an unprecedented resolution of cellular heterogeneity in complex tissues and has profoundly changed our understandings of cell-to-cell heterogeneity in various biological areas (<xref rid="btad099-B3" ref-type="bibr">Cao and Gao, 2022</xref>; <xref rid="btad099-B12" ref-type="bibr">Heath <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btad099-B17" ref-type="bibr">Lawson <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btad099-B28" ref-type="bibr">Tabula Muris Consortium <italic toggle="yes">et al.</italic>, 2018</xref>). Widespread adoption of scRNA-seq has produced a number of datasets. The integration of scRNA-seq datasets from multiple sources is critical for deciphering cellular heterogeneity in complex biological systems (<xref rid="btad099-B34" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2021</xref>). However, inherent technical differences among datasets caused by different experimental batches, sample donors or platforms lead to inevitable batch effects which can confound the biological variations (<xref rid="btad099-B21" ref-type="bibr">Luecken <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btad099-B32" ref-type="bibr">Tran <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btad099-B45" ref-type="bibr">Zheng <italic toggle="yes">et al.</italic>, 2019</xref>). Therefore, it’s vital to develop computational methods to correct batch effects.</p>
    <p>Limma (<xref rid="btad099-B25" ref-type="bibr">Smyth and Speed, 2003</xref>) and ComBat (<xref rid="btad099-B14" ref-type="bibr">Johnson <italic toggle="yes">et al.</italic>, 2007</xref>) that were developed for bulk datasets were first applied to integrate scRNA-seq datasets. However, due to heterogeneous composition of cell populations between datasets and technical noise such as ‘dropout’ events (<xref rid="btad099-B4" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2022</xref>), Limma and ComBat were proven insufficient for single-cell datasets. To handle data with such characteristics, a number of batch correction methods have been proposed recently. A typical class of methods, such as MNNCorrect (<xref rid="btad099-B9" ref-type="bibr">Haghverdi <italic toggle="yes">et al.</italic>, 2018</xref>), Seurat (<xref rid="btad099-B27" ref-type="bibr">Stuart <italic toggle="yes">et al.</italic>, 2019</xref>), Scanorama (<xref rid="btad099-B13" ref-type="bibr">Hie <italic toggle="yes">et al.</italic>, 2019</xref>), use mutual nearest neighbors (MNN) between batches as anchors to map one dataset to another. To improve the effectiveness of MNN-based methods, some researchers propose to take cluster information into consideration, which cluster each batch first and then find MNN between clusters, such as scMerge (<xref rid="btad099-B20" ref-type="bibr">Lin <italic toggle="yes">et al.</italic>, 2019</xref>) and sMNN (<xref rid="btad099-B41" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2021c</xref>). Similarly, Harmony (<xref rid="btad099-B16" ref-type="bibr">Korsunsky <italic toggle="yes">et al.</italic>, 2019</xref>) employs soft clustering to maximize mixture of batches within clusters. With the increasing number of scRNA-seq datasets, the application of deep learning techniques, especially unsupervised ones, has received greater attention in this field. MMD-ResNet (<xref rid="btad099-B23" ref-type="bibr">Shaham <italic toggle="yes">et al.</italic>, 2017</xref>) assumes that the difference between the whole distributions of two batches is moderate and then trains a residual network with maximum mean discrepancy (MMD) loss to learn a map from one distribution to another. Bermuda (<xref rid="btad099-B35" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2019</xref>) also adopts the MMD loss, but it optimizes loss at the cluster level instead of the whole batch. To strengthen the expressiveness of traditional autoencoders, iMAP (<xref rid="btad099-B34" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2021</xref>) proposes a novel deep learning framework by combining the power of autoencoders and generative adversarial networks.</p>
    <p>Recently, contrastive learning (CL) has shown striking advantages in various domains (<xref rid="btad099-B36" ref-type="bibr">Wei <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btad099-B42" ref-type="bibr">Zeng <italic toggle="yes">et al.</italic>, 2021</xref>). Some CL-based batch correction methods have also been proposed. CL learns representations by concentrating positive pairs and separating negative pairs (<xref rid="btad099-B5" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2020</xref>). The basic idea behind CL-based batch correction methods is to construct inter-batch positive cell pairs with similar transcription and negative cell pairs with dissimilar transcription. Then, they employ a contrastive loss to concentrate positive pairs and separate negative pairs, thereby mitigating batch effects. For instance, INSCT (<xref rid="btad099-B24" ref-type="bibr">Simon <italic toggle="yes">et al.</italic>, 2021</xref>) and MAT<sup>2</sup> (<xref rid="btad099-B43" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2021</xref>) find inter-batch MNN as positive pairs and use random sampling to construct negative pairs. In addition, INSCT applies within-batch k-nearest neighbors (KNN) to complete positive samples for those cells without MNN. Then, INSCT and MAT<sup>2</sup> optimize with triplet loss (<xref rid="btad099-B5" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2020</xref>). SMILE (<xref rid="btad099-B37" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2022</xref>) and CLEAR (<xref rid="btad099-B10" ref-type="bibr">Han <italic toggle="yes">et al.</italic>, 2021</xref>) employ random augmentations to generate positive pairs and use random sampling to construct negative pairs, and then optimize with InfoNCE loss (<xref rid="btad099-B33" ref-type="bibr">van den Oord <italic toggle="yes">et al.</italic>, 2018</xref>). In general, positive pairs play an important role in the performance of CL methods (<xref rid="btad099-B8" ref-type="bibr">Grill <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btad099-B30" ref-type="bibr">Tian <italic toggle="yes">et al.</italic>, 2020</xref>) and they basically determine the degree of batch effect removal. More positive pairs can better cover shared populations between batches but may introduce more false positive pairs (pairs of cells with different types) without the help of cell type annotations, implying better batch mixing but tending to over-correct. In contrast, inadequate positive pairs can guarantee the correctness of positive pairs but poorly cover the shared populations between batches, implying better preservation of cellular heterogeneity but compromising to batch mixing. However, it’s hard to determine ideal positive pairs in different situations and thus, CL-based methods have to make a trade-off between batch correction and preserving heterogeneity. We call this problem the mix-heterogeneity trade-off and find that most of existing CL-based methods suffer from this trade-off.</p>
    <p>To achieve better mix-heterogeneity trade-off, we propose a novel CL-based batch correction framework with AutomatIc label REfinement (CLAIRE). The key contributions of CLAIRE are proposal of two complementary strategies to ensure the appropriate positive pairs during learning process. The first strategy dynamically generates positive pairs by augmenting inter-batch MNN using intra-batch KNN, which greatly improves the diversity of positive pairs and promotes better batch correction. The second strategy is proposed to remove the potential false positive pairs by resorting to the memorization effect of deep neural networks, which improves the correctness of generated positive pairs and promotes better preservation of cellular heterogeneity. These two effective strategies help CLAIRE achieve superior mix-heterogeneity trade-off over existing CL-based batch correction methods. Benchmarking results on six real datasets also show that CLAIRE achieves the best integration performance and has comparable computational consumptions to other methods. We further conduct comprehensive ablation experiments to validate the effectiveness of our proposed method.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Overview</title>
      <p>CLAIRE projects multiple scRNA-seq datasets into a low-dimensional space, as shown in <xref rid="btad099-F1" ref-type="fig">Figure 1</xref>. Before CL, CLAIRE computes MNN between batches and KNN within each batch. In CL, CLAIRE uses these inter-batch MNN pairs as seeds of positive pairs and augments these seeds with intra-batch KNN to generate positive pairs (<xref rid="btad099-F1" ref-type="fig">Fig. 1b</xref>, construction strategy). During the learning process, to reduce potential false positive pairs, CLAIRE divides model training into two stages. In the first stage, CLAIRE trains a neural network adapted from Moco (<xref rid="btad099-B11" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2020</xref>) architecture. Then, CLAIRE exploits the embeddings from the neural network to filter those MNNs that could introduce false positive pairs (<xref rid="btad099-F1" ref-type="fig">Fig. 1c</xref>, refinement strategy). The retained MNNs are used for the second stage training. In the following sections, we elaborate on the detail of CLAIRE.</p>
      <fig position="float" id="btad099-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>Architecture of CLARIE. (<bold>a</bold>) CLAIRE’s framework. Cells of multiple batches are projecting into a batch-corrected latent space in two stages. (<bold>b</bold>) Our proposed construction strategy for positive pairs, corresponding to the <bold>generator</bold> in (a). (<bold>c</bold>) Our proposed refinement strategy, corresponding to the <bold>filter</bold> in (a)</p>
        </caption>
        <graphic xlink:href="btad099f1" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>2.2 Dynamic construction of positive pairs</title>
      <p>Suppose there are <italic toggle="yes">M</italic> batches to be integrated, <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo>}</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> denotes the preprocessed cell representations within batch <italic toggle="yes">m</italic>. <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>n</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> respectively denote inter-batch MNNs between batch <italic toggle="yes">m</italic>, <italic toggle="yes">n</italic> and intra-batch KNNs within batch <italic toggle="yes">m</italic>. The parameter <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> defines the number of nearest neighbors for searching intra-batch KNNs. Following Seurat (<xref rid="btad099-B27" ref-type="bibr">Stuart <italic toggle="yes">et al.</italic>, 2019</xref>), before finding MNNs between batches, CLAIRE applies canonical correlation analysis to map cells into low-dimensional representations. Those found inter-batch MNNs, <italic toggle="yes">E</italic>, are regarded as seeds of positive pairs. One potential problem of directly feeding these seed pairs into training is that they may not fully cover the whole distributions of the shared cell types between batches (<xref rid="btad099-B34" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2021</xref>). Hence, CLAIRE proposes using the intra-batch KNNs to augment those seed pairs. Specifically, for each seed pair <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>n</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, CLAIRE mix up cell <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> with their KNNs, respectively:</p>
      <disp-formula id="E1">
        <label>(1)</label>
        <mml:math id="M1" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mtable>
              <mml:mtr columnalign="left">
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mrow>
                          <mml:mover accent="true">
                            <mml:mi>x</mml:mi>
                            <mml:mo>˜</mml:mo>
                          </mml:mover>
                        </mml:mrow>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mi>m</mml:mi>
                    </mml:msubsup>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mo>=</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mo>λ</mml:mo>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>x</mml:mi>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mi>m</mml:mi>
                    </mml:msubsup>
                    <mml:mo>+</mml:mo>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mrow>
                        <mml:mn>1</mml:mn>
                        <mml:mo>−</mml:mo>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mo>λ</mml:mo>
                          </mml:mrow>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mo>)</mml:mo>
                    </mml:mrow>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>x</mml:mi>
                      </mml:mrow>
                      <mml:mi>k</mml:mi>
                      <mml:mi>m</mml:mi>
                    </mml:msubsup>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:mrow>
          <mml:mo>,</mml:mo>
        </mml:math>
      </disp-formula>
      <disp-formula id="E2">
        <label>(2)</label>
        <mml:math id="M2" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msubsup>
              <mml:mrow>
                <mml:mrow>
                  <mml:mover accent="true">
                    <mml:mi>x</mml:mi>
                    <mml:mo>˜</mml:mo>
                  </mml:mover>
                </mml:mrow>
              </mml:mrow>
              <mml:mi>j</mml:mi>
              <mml:mi>n</mml:mi>
            </mml:msubsup>
            <mml:mo>=</mml:mo>
            <mml:msub>
              <mml:mrow>
                <mml:mo>λ</mml:mo>
              </mml:mrow>
              <mml:mi>j</mml:mi>
            </mml:msub>
            <mml:msubsup>
              <mml:mrow>
                <mml:mi>x</mml:mi>
              </mml:mrow>
              <mml:mi>j</mml:mi>
              <mml:mi>n</mml:mi>
            </mml:msubsup>
            <mml:mo>+</mml:mo>
            <mml:mrow>
              <mml:mo>(</mml:mo>
              <mml:mrow>
                <mml:mn>1</mml:mn>
                <mml:mo>−</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mo>λ</mml:mo>
                  </mml:mrow>
                  <mml:mi>j</mml:mi>
                </mml:msub>
              </mml:mrow>
              <mml:mo>)</mml:mo>
            </mml:mrow>
            <mml:msubsup>
              <mml:mrow>
                <mml:mi>x</mml:mi>
              </mml:mrow>
              <mml:mi>l</mml:mi>
              <mml:mi>n</mml:mi>
            </mml:msubsup>
          </mml:mrow>
          <mml:mo>,</mml:mo>
        </mml:math>
      </disp-formula>
      <p>where <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>n</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are dynamically sampled from a uniform distribution <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mi>U</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>α</mml:mo><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mo>α</mml:mo></mml:math></inline-formula> is a positive constant &lt;1. Note that for each generation, <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are re-sampled from the uniform distribution. By such augmentation, more diverse positive pairs <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>j</mml:mi><mml:mi>n</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> can be derived from original seed pairs. Essentially, CLAIRE derives two local regions from each seed pair, and turns the alignment of inter-batch MNNs into alignment of local regions between batches, thereby expanding the coverage of positive pairs for the distribution of shared populations between batches. Moreover, such generation can be implemented dynamically during model training, which requires little computational overhead. Except interpolation, other operations for mixing up cells with their KNNs can also be applied to augment the positive pairs, such as exchanging elements of two vectors. Apart from positive pairs, our CL framework needs negative pairs for training. Following other CL-based methods, CLAIRE randomly samples cells from the whole dataset to generate negative samples for each positive pair. Although random sampling can result in false negative pairs, the number of false negative pairs is supposed to be small because the number of negative samples for each cell is much larger than that of positive samples. Those rare false negative pairs have small impact on the results.</p>
    </sec>
    <sec>
      <title>2.3 Automatic refinement of positive pairs</title>
      <p>Instead of refining those generated positive pairs, we focus more on refining the seeds of positive pairs, which is the main source of false positive pairs. True seeds (MNNs with same cell type) generally lead to true positive pairs while false seeds (MNNs with different cell types) generally lead to false positive pairs. Thus, our goal here is to discriminate between true seeds and false seeds. According to the assumptions of MNNCorrect, the batch-effect variation is much smaller than the biological-effect variation between different cell types (<xref rid="btad099-B9" ref-type="bibr">Haghverdi <italic toggle="yes">et al.</italic>, 2018</xref>). A natural idea is to calculate the similarities between each pair of seed using raw expressions and MNNCorrect’s assumptions assure that the similarities between true seeds are much higher than false ones. Then, we can filter those false seeds with low similarities. However, in real situations, differences between batch-effect variation and biological-effect variation are not always distinct (<xref rid="btad099-B40" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2021b</xref>), which means that it’s not easy to directly discriminate between true seeds and false seeds. Therefore, our goal becomes to distinct false seeds from the true ones. Fortunately, <xref rid="btad099-B39" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> (2021a</xref>) have found that true negative pairs are easier to optimize than false (noisy) negative pairs in the early training stage of CL, which is believed to be caused by the memorization effect of deep neural network (<xref rid="btad099-B1" ref-type="bibr">Arpit <italic toggle="yes">et al.</italic>, 2017</xref>), i.e. deep neural network tends to prioritize learning simple patterns first, and they exploit this finding to distinct false negative pairs from true negative ones.</p>
      <p>Motivated by finding in <xref rid="btad099-B39" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> (2021a</xref>) and MNNCorrect’s assumptions, CLAIRE proposes to use CL to amplify the difference between true seeds and false seeds. Specially, CLAIRE assumes that true seeds and false seeds have different patterns, and true seeds account for the majority of seeds and have simpler patterns (e.g. smaller distance or more consistent orientation) than false seeds. Then, true seeds (and their generations) are easier to fit than false ones (and their generations) in the early stage of CL. In other words, after early stage of training, the latent representations’ similarities between true seeds are supposed to be higher than false ones, which provides the foundation for removing false seeds.</p>
      <p>Formally, CLAIRE divides model training into two stages. In the first stage, CLAIRE trains an encoder network, <italic toggle="yes">f</italic>, in a few epochs (e.g. 2–4 epochs). The encoder network, <italic toggle="yes">f</italic>, embeds samples <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> into latent representations <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mi>Z</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. Then, CLAIRE computes cosine similarities between each seed pair in the latent space:</p>
      <disp-formula id="E3">
        <label>(3)</label>
        <mml:math id="M3" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mi>S</mml:mi>
            <mml:mrow>
              <mml:mo>(</mml:mo>
              <mml:mrow>
                <mml:msubsup>
                  <mml:mrow>
                    <mml:mi>z</mml:mi>
                  </mml:mrow>
                  <mml:mi>i</mml:mi>
                  <mml:mi>m</mml:mi>
                </mml:msubsup>
                <mml:mo>,</mml:mo>
                <mml:msubsup>
                  <mml:mrow>
                    <mml:mi>z</mml:mi>
                  </mml:mrow>
                  <mml:mi>j</mml:mi>
                  <mml:mi>n</mml:mi>
                </mml:msubsup>
              </mml:mrow>
              <mml:mo>)</mml:mo>
            </mml:mrow>
            <mml:mo>=</mml:mo>
            <mml:mfrac>
              <mml:mrow>
                <mml:mrow>
                  <mml:mo>〈</mml:mo>
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>z</mml:mi>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mi>m</mml:mi>
                    </mml:msubsup>
                    <mml:mo>,</mml:mo>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>z</mml:mi>
                      </mml:mrow>
                      <mml:mi>j</mml:mi>
                      <mml:mi>n</mml:mi>
                    </mml:msubsup>
                  </mml:mrow>
                  <mml:mo>〉</mml:mo>
                </mml:mrow>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:mo>‖</mml:mo>
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>z</mml:mi>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mi>m</mml:mi>
                    </mml:msubsup>
                  </mml:mrow>
                  <mml:mo>‖</mml:mo>
                </mml:mrow>
                <mml:mo>⋅</mml:mo>
                <mml:mrow>
                  <mml:mo>‖</mml:mo>
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>z</mml:mi>
                      </mml:mrow>
                      <mml:mi>j</mml:mi>
                      <mml:mi>n</mml:mi>
                    </mml:msubsup>
                  </mml:mrow>
                  <mml:mo>‖</mml:mo>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
          <mml:mo>,</mml:mo>
        </mml:math>
      </disp-formula>
      <p>where <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>n</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>n</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>n</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>n</mml:mi></mml:msubsup></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> denotes inner produce of two vectors and <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> denotes the <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm of <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>. CLAIRE applies a two-component Gaussian Mixture Model (GMM) to fit the similarity distribution:</p>
      <disp-formula id="E4">
        <label>(4)</label>
        <mml:math id="M4" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mi>p</mml:mi>
            <mml:mo stretchy="false">(</mml:mo>
            <mml:mi>S</mml:mi>
            <mml:mo stretchy="false">)</mml:mo>
            <mml:mo>=</mml:mo>
            <mml:munderover>
              <mml:mo>∑</mml:mo>
              <mml:mrow>
                <mml:mi>k</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mn>1</mml:mn>
              </mml:mrow>
              <mml:mrow>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>K</mml:mi>
                  </mml:mrow>
                  <mml:mi>g</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mn>2</mml:mn>
              </mml:mrow>
            </mml:munderover>
            <mml:mrow>
              <mml:msub>
                <mml:mrow>
                  <mml:mo>γ</mml:mo>
                </mml:mrow>
                <mml:mi>k</mml:mi>
              </mml:msub>
            </mml:mrow>
            <mml:mo>φ</mml:mo>
            <mml:mo stretchy="false">(</mml:mo>
            <mml:mi>S</mml:mi>
            <mml:mo>|</mml:mo>
            <mml:mi>k</mml:mi>
            <mml:mo stretchy="false">)</mml:mo>
          </mml:mrow>
          <mml:mo>,</mml:mo>
        </mml:math>
      </disp-formula>
      <p>where <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>γ</mml:mo></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:mo>φ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>|</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> are the mixture coefficients and probability density of the <italic toggle="yes">k</italic>-th component, respectively. After fitting the GMM with maximum likelihood estimations, the confidence of each seed belonging to true seeds can be inferred:</p>
      <disp-formula id="E5">
        <label>(5)</label>
        <mml:math id="M5" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mi>c</mml:mi>
            <mml:mrow>
              <mml:mo>(</mml:mo>
              <mml:mrow>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>x</mml:mi>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mi>m</mml:mi>
                    </mml:msubsup>
                    <mml:mo>,</mml:mo>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>x</mml:mi>
                      </mml:mrow>
                      <mml:mi>j</mml:mi>
                      <mml:mi>n</mml:mi>
                    </mml:msubsup>
                  </mml:mrow>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:mrow>
              <mml:mo>)</mml:mo>
            </mml:mrow>
            <mml:mo>=</mml:mo>
            <mml:mi>p</mml:mi>
            <mml:mrow>
              <mml:mo>(</mml:mo>
              <mml:mrow>
                <mml:mi>k</mml:mi>
                <mml:mo>|</mml:mo>
                <mml:mi>S</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>z</mml:mi>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mi>m</mml:mi>
                    </mml:msubsup>
                    <mml:mo>,</mml:mo>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>z</mml:mi>
                      </mml:mrow>
                      <mml:mi>j</mml:mi>
                      <mml:mi>n</mml:mi>
                    </mml:msubsup>
                  </mml:mrow>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:mrow>
              <mml:mo>)</mml:mo>
            </mml:mrow>
          </mml:mrow>
          <mml:mo>,</mml:mo>
        </mml:math>
      </disp-formula>
      <p>where <italic toggle="yes">k</italic> denotes the true seed’s corresponding component. We select the component with larger mean of similarity scores. By setting a threshold <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mo>η</mml:mo></mml:math></inline-formula>, CLAIRE filters those pairs with low confidence. The rest seeds are fed into the second stage training.</p>
    </sec>
    <sec>
      <title>2.4 Network architecture and loss function</title>
      <p>CLAIRE’s network architecture is adapted from Moco, which contains an online encoder, <italic toggle="yes">f</italic>, and a momentum encoder, <italic toggle="yes">g</italic>. <italic toggle="yes">f</italic> and <italic toggle="yes">g</italic> share the same structure. Given <italic toggle="yes">N</italic> positive pairs <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> at each iteration, where <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> denotes a dynamically generated positive pair. CLAIRE optimizes the following InfoNCE loss:</p>
      <disp-formula id="E6">
        <label>(6)</label>
        <mml:math id="M6" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mtable>
              <mml:mtr columnalign="left">
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:mi>L</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mo>−</mml:mo>
                    <mml:mfrac>
                      <mml:mn>1</mml:mn>
                      <mml:mi>N</mml:mi>
                    </mml:mfrac>
                    <mml:munderover>
                      <mml:mo>∑</mml:mo>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mo>=</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                      <mml:mi>N</mml:mi>
                    </mml:munderover>
                    <mml:mrow>
                      <mml:mo> </mml:mo>
                      <mml:mtext>log</mml:mtext>
                      <mml:mo> </mml:mo>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mrow>
                        <mml:mfrac>
                          <mml:mrow>
                            <mml:mo>σ</mml:mo>
                            <mml:mrow>
                              <mml:mo>(</mml:mo>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mrow>
                                      <mml:mover accent="true">
                                        <mml:mi>x</mml:mi>
                                        <mml:mo>˜</mml:mo>
                                      </mml:mover>
                                    </mml:mrow>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mn>2</mml:mn>
                                    <mml:mi>i</mml:mi>
                                    <mml:mo>−</mml:mo>
                                    <mml:mn>1</mml:mn>
                                  </mml:mrow>
                                </mml:msub>
                                <mml:mo>,</mml:mo>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mrow>
                                      <mml:mover accent="true">
                                        <mml:mi>x</mml:mi>
                                        <mml:mo>˜</mml:mo>
                                      </mml:mover>
                                    </mml:mrow>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mn>2</mml:mn>
                                    <mml:mi>i</mml:mi>
                                  </mml:mrow>
                                </mml:msub>
                              </mml:mrow>
                              <mml:mo>)</mml:mo>
                            </mml:mrow>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mo>σ</mml:mo>
                            <mml:mrow>
                              <mml:mo>(</mml:mo>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mrow>
                                      <mml:mover accent="true">
                                        <mml:mi>x</mml:mi>
                                        <mml:mo>˜</mml:mo>
                                      </mml:mover>
                                    </mml:mrow>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mn>2</mml:mn>
                                    <mml:mi>i</mml:mi>
                                    <mml:mo>−</mml:mo>
                                    <mml:mn>1</mml:mn>
                                  </mml:mrow>
                                </mml:msub>
                                <mml:mo>,</mml:mo>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mrow>
                                      <mml:mover accent="true">
                                        <mml:mi>x</mml:mi>
                                        <mml:mo>˜</mml:mo>
                                      </mml:mover>
                                    </mml:mrow>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mn>2</mml:mn>
                                    <mml:mi>i</mml:mi>
                                  </mml:mrow>
                                </mml:msub>
                              </mml:mrow>
                              <mml:mo>)</mml:mo>
                            </mml:mrow>
                            <mml:mo>+</mml:mo>
                            <mml:munder>
                              <mml:mo>∑</mml:mo>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mi>q</mml:mi>
                                  </mml:mrow>
                                  <mml:mi>j</mml:mi>
                                </mml:msub>
                                <mml:mo>∈</mml:mo>
                                <mml:mi>D</mml:mi>
                              </mml:mrow>
                            </mml:munder>
                            <mml:mo>σ</mml:mo>
                            <mml:mrow>
                              <mml:mo>(</mml:mo>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mrow>
                                      <mml:mover accent="true">
                                        <mml:mi>x</mml:mi>
                                        <mml:mo>˜</mml:mo>
                                      </mml:mover>
                                    </mml:mrow>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mn>2</mml:mn>
                                    <mml:mi>i</mml:mi>
                                    <mml:mo>−</mml:mo>
                                    <mml:mn>1</mml:mn>
                                  </mml:mrow>
                                </mml:msub>
                                <mml:mo>,</mml:mo>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mi>q</mml:mi>
                                  </mml:mrow>
                                  <mml:mi>j</mml:mi>
                                </mml:msub>
                              </mml:mrow>
                              <mml:mo>)</mml:mo>
                            </mml:mrow>
                          </mml:mrow>
                        </mml:mfrac>
                      </mml:mrow>
                      <mml:mo>)</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr columnalign="left">
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:mo>+</mml:mo>
                    <mml:mtext>log</mml:mtext>
                    <mml:mo> </mml:mo>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mrow>
                        <mml:mfrac>
                          <mml:mrow>
                            <mml:mo>σ</mml:mo>
                            <mml:mrow>
                              <mml:mo>(</mml:mo>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mrow>
                                      <mml:mover accent="true">
                                        <mml:mi>x</mml:mi>
                                        <mml:mo>˜</mml:mo>
                                      </mml:mover>
                                    </mml:mrow>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mn>2</mml:mn>
                                    <mml:mi>i</mml:mi>
                                  </mml:mrow>
                                </mml:msub>
                                <mml:mo>,</mml:mo>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mrow>
                                      <mml:mover accent="true">
                                        <mml:mi>x</mml:mi>
                                        <mml:mo>˜</mml:mo>
                                      </mml:mover>
                                    </mml:mrow>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mn>2</mml:mn>
                                    <mml:mi>i</mml:mi>
                                    <mml:mo>−</mml:mo>
                                    <mml:mn>1</mml:mn>
                                  </mml:mrow>
                                </mml:msub>
                              </mml:mrow>
                              <mml:mo>)</mml:mo>
                            </mml:mrow>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mo>σ</mml:mo>
                            <mml:mrow>
                              <mml:mo>(</mml:mo>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mrow>
                                      <mml:mover accent="true">
                                        <mml:mi>x</mml:mi>
                                        <mml:mo>˜</mml:mo>
                                      </mml:mover>
                                    </mml:mrow>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mn>2</mml:mn>
                                    <mml:mi>i</mml:mi>
                                  </mml:mrow>
                                </mml:msub>
                                <mml:mo>,</mml:mo>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mrow>
                                      <mml:mover accent="true">
                                        <mml:mi>x</mml:mi>
                                        <mml:mo>˜</mml:mo>
                                      </mml:mover>
                                    </mml:mrow>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mn>2</mml:mn>
                                    <mml:mi>i</mml:mi>
                                    <mml:mo>−</mml:mo>
                                    <mml:mn>1</mml:mn>
                                  </mml:mrow>
                                </mml:msub>
                              </mml:mrow>
                              <mml:mo>)</mml:mo>
                            </mml:mrow>
                            <mml:mo>+</mml:mo>
                            <mml:munder>
                              <mml:mo>∑</mml:mo>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mi>q</mml:mi>
                                  </mml:mrow>
                                  <mml:mi>j</mml:mi>
                                </mml:msub>
                                <mml:mo>∈</mml:mo>
                                <mml:mi>D</mml:mi>
                              </mml:mrow>
                            </mml:munder>
                            <mml:mo>σ</mml:mo>
                            <mml:mrow>
                              <mml:mo>(</mml:mo>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mrow>
                                      <mml:mover accent="true">
                                        <mml:mi>x</mml:mi>
                                        <mml:mo>˜</mml:mo>
                                      </mml:mover>
                                    </mml:mrow>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mn>2</mml:mn>
                                    <mml:mi>i</mml:mi>
                                  </mml:mrow>
                                </mml:msub>
                                <mml:mo>,</mml:mo>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mi>q</mml:mi>
                                  </mml:mrow>
                                  <mml:mi>j</mml:mi>
                                </mml:msub>
                              </mml:mrow>
                              <mml:mo>)</mml:mo>
                            </mml:mrow>
                          </mml:mrow>
                        </mml:mfrac>
                      </mml:mrow>
                      <mml:mo>)</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:mrow>
          <mml:mo>,</mml:mo>
        </mml:math>
      </disp-formula>
      <p>where <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:mo>σ</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>exp</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>τ</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with a constant parameter <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mo>τ</mml:mo></mml:math></inline-formula>. The dictionary <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>Q</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> denotes a memory queue which is used to save negative keys and is often of large size. By fixing <italic toggle="yes">g</italic> and updating <italic toggle="yes">f</italic> in equation, CLAIRE pushes positive pairs closer in the latent space while pushing each sample away from its negative keys in dictionary <italic toggle="yes">D</italic>. For <italic toggle="yes">g</italic>, it’s updated via exponential moving average, i.e. <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo>ϵ</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:mo>ϵ</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:math></inline-formula> with a small constant <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mrow><mml:mo>ϵ</mml:mo><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. After each iteration, <italic toggle="yes">D</italic> is updated by the mini-batch features <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> in a first-in and first-out order. The main difference between original Moco architecture and CLAIRE is the way of aligning the positive samples, which is reflected in two aspects. First, CLAIRE inputs positive pairs into model symmetrically. More specifically, Moco inputs the anchor cell to <italic toggle="yes">f</italic> and inputs its positive to <italic toggle="yes">g</italic> while CLAIRE not only inputs the anchor to <italic toggle="yes">f</italic>, positive to <italic toggle="yes">g</italic> but also inputs positive to <italic toggle="yes">f</italic>, anchor to <italic toggle="yes">g</italic>. Second, CLAIRE’s loss function will align the anchor to positive and also align the positive to anchor whereas Moco only aligns the anchor to positive.</p>
    </sec>
    <sec>
      <title>2.5 Implementation details</title>
      <p>The encoder network in CLAIRE consists of three fully connected layers and one L2-normalization layer. Its input sizes are equal to the number of input genes while the output size is set to 128 by default. ReLU (<xref rid="btad099-B7" ref-type="bibr">Glorot <italic toggle="yes">et al.</italic>, 2011</xref>) is used as the activation function for the hidden layer. Dropout (<xref rid="btad099-B26" ref-type="bibr">Srivastava <italic toggle="yes">et al.</italic>, 2014</xref>) layer is used after each hidden layer during training and discarded during inference. The dropout rate is set to 0.3. The proposed CL framework is implemented with Pytorch and trained with Adam (<xref rid="btad099-B15" ref-type="bibr">Kingma and Ba, 2014</xref>) with initial learning rate 1e−4. During training, the uniform distribution parameter <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mo>α</mml:mo></mml:math></inline-formula> is set to 0.5 and <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is set to 10. The minibatch size, <italic toggle="yes">N</italic>, is set to 256. <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mo>τ</mml:mo></mml:math></inline-formula> is set to 0.1. <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mo>ϵ</mml:mo></mml:math></inline-formula> is set to 0.001. Dictionary size, <italic toggle="yes">Q</italic>, is set to 2048.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Datasets and preprocessing</title>
      <p>We collect six real datasets for experiments. These datasets cover different integration tasks, including integration across samples and across platforms (10×, Drop-seq, and SMART-seq, etc.), separation of cell subtypes, integration of two batches or multiple batches. They also cover diverse cell types and different species, such as mouse cells, human lung cells and human immune cells. The cell type annotations and batch labels of these datasets are known in advance. The details for six real datasets are shown in <xref rid="btad099-T1" ref-type="table">Table 1</xref>.</p>
      <table-wrap position="float" id="btad099-T1">
        <label>Table 1.</label>
        <caption>
          <p>Details of six real datasets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Dataset</th>
              <th rowspan="1" colspan="1">Platform</th>
              <th align="center" rowspan="1" colspan="1">Number of batches</th>
              <th align="center" rowspan="1" colspan="1">Number of cells</th>
              <th align="center" rowspan="1" colspan="1">Number of cell types</th>
              <th align="center" rowspan="1" colspan="1">Number of shared types</th>
              <th rowspan="1" colspan="1">References</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">MCA</td>
              <td rowspan="1" colspan="1">Microwell-seq, Smart-Seq2</td>
              <td rowspan="1" colspan="1">2</td>
              <td rowspan="1" colspan="1">6954</td>
              <td rowspan="1" colspan="1">11</td>
              <td rowspan="1" colspan="1">11</td>
              <td rowspan="1" colspan="1">
                <xref rid="btad099-B32" ref-type="bibr">Tran <italic toggle="yes">et al.</italic> (2020)</xref>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PBMC</td>
              <td rowspan="1" colspan="1">10X 3′, 10X 5′</td>
              <td rowspan="1" colspan="1">2</td>
              <td rowspan="1" colspan="1">15 476</td>
              <td rowspan="1" colspan="1">9</td>
              <td rowspan="1" colspan="1">9</td>
              <td rowspan="1" colspan="1">
                <xref rid="btad099-B32" ref-type="bibr">Tran <italic toggle="yes">et al.</italic> (2020)</xref>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Pancreas</td>
              <td rowspan="1" colspan="1">inDrop, CEL-Seq2, Smart-Seq2, SMARTer, SMARTer</td>
              <td rowspan="1" colspan="1">5</td>
              <td rowspan="1" colspan="1">14 767</td>
              <td rowspan="1" colspan="1">15</td>
              <td rowspan="1" colspan="1">4</td>
              <td rowspan="1" colspan="1">
                <xref rid="btad099-B32" ref-type="bibr">Tran <italic toggle="yes">et al.</italic> (2020)</xref>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Immune (human)</td>
              <td rowspan="1" colspan="1">10X, Smart-Seq2</td>
              <td rowspan="1" colspan="1">10</td>
              <td rowspan="1" colspan="1">33 506</td>
              <td rowspan="1" colspan="1">16</td>
              <td rowspan="1" colspan="1">2</td>
              <td rowspan="1" colspan="1">
                <xref rid="btad099-B21" ref-type="bibr">Luecken <italic toggle="yes">et al.</italic> (2022)</xref>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Lung</td>
              <td rowspan="1" colspan="1">10X, Drop-seq</td>
              <td rowspan="1" colspan="1">16</td>
              <td rowspan="1" colspan="1">32 472</td>
              <td rowspan="1" colspan="1">17</td>
              <td rowspan="1" colspan="1">2</td>
              <td rowspan="1" colspan="1">
                <xref rid="btad099-B21" ref-type="bibr">Luecken <italic toggle="yes">et al.</italic> (2022)</xref>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Muris</td>
              <td rowspan="1" colspan="1">Droplet, FACS</td>
              <td rowspan="1" colspan="1">2</td>
              <td rowspan="1" colspan="1">67 354</td>
              <td rowspan="1" colspan="1">28</td>
              <td rowspan="1" colspan="1">26</td>
              <td rowspan="1" colspan="1">
                <xref rid="btad099-B38" ref-type="bibr">Yan <italic toggle="yes">et al.</italic> (2022)</xref>
              </td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>Six datasets are preprocessed in the following steps. First, low informative genes expressed in fewer than three cells are removed. Then, the total counts of each cell are normalized to 10 000 followed by log-transformation. After normalization, highly variable genes (HVGs) are selected for each dataset through the dispersion-based method (<xref rid="btad099-B22" ref-type="bibr">Satija <italic toggle="yes">et al.</italic>, 2015</xref>). By default, top 2000 HVGs are selected for each dataset. For Muris dataset (the largest one), top 5000 HVGs are used to have better preservation of cellular heterogeneity.</p>
    </sec>
    <sec>
      <title>3.2 Evaluation metrics</title>
      <p>We use average silhouette width with batch labels (bASW) (<xref rid="btad099-B21" ref-type="bibr">Luecken <italic toggle="yes">et al.</italic>, 2022</xref>) and k-nearest-neighbor Batch-Effect Test (kBET) (<xref rid="btad099-B21" ref-type="bibr">Luecken <italic toggle="yes">et al.</italic>, 2022</xref>) to evaluate the performance of batch correction methods on batch mixing. bASW is obtained by calculating the silhouette width with batch labels for each cell type and averaging over all cell types. bASW describes mixing of batches within cell clusters, where 1 indicates ideally mixed batches and 0 indicates poorly mixed batches(<xref rid="btad099-B21" ref-type="bibr">Luecken <italic toggle="yes">et al.</italic>, 2022</xref>). kBET measures how well mixed the batches are, which is calculated based on the local batch label distribution in randomly sampled nearest-neighbor cells compared against the global batch label distribution (<xref rid="btad099-B44" ref-type="bibr">Zhao <italic toggle="yes">et al.</italic>, 2021</xref>). kBET is calculated as in <xref rid="btad099-B44" ref-type="bibr">Zhao <italic toggle="yes">et al.</italic> (2021)</xref>, and the k is set to 15. Higher kBET indicates better batch effect removal.</p>
      <p>Adjusted rand index (ARI) and normalized mutual information (NMI) are employed to evaluate the performance of batch correction methods on preserving cellular heterogeneity. NMI and ARI compare the overlap between clustering results and annotated labels (<xref rid="btad099-B19" ref-type="bibr">Liang <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btad099-B31" ref-type="bibr">Tian <italic toggle="yes">et al.</italic>, 2021</xref>). Higher NMI and ARI indicate better match between clustering results and annotations. Louvain is applied to determine the clusters with increased resolutions from 0.1 to 2.0 at the increment of 0.1. The clustering output with the highest NMI is chosen as the final clustering result. To better demonstrate the performance of batch correction methods on batch mixing and preserving heterogeneity, four metrics are aggregated into two scores: <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>bio</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>batch</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. For dataset <italic toggle="yes">i</italic>, two scores are calculated via:</p>
      <disp-formula id="E7">
        <label>(7)</label>
        <mml:math id="M7" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mtable>
              <mml:mtr columnalign="left">
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>S</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mtext>bio</mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>=</mml:mo>
                  </mml:mrow>
                </mml:mtd>
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mrow>
                              <mml:mtext>NMI</mml:mtext>
                            </mml:mrow>
                          </mml:mrow>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:mo>+</mml:mo>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mrow>
                              <mml:mtext>ARI</mml:mtext>
                            </mml:mrow>
                          </mml:mrow>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mn>2</mml:mn>
                    </mml:mfrac>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:mrow>
          <mml:mo>.</mml:mo>
        </mml:math>
      </disp-formula>
      <disp-formula id="E8">
        <label>(8)</label>
        <mml:math id="M8" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi>S</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mtext>batch</mml:mtext>
              </mml:mrow>
            </mml:msub>
            <mml:mo>=</mml:mo>
            <mml:mfrac>
              <mml:mrow>
                <mml:msub>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mtext>bASW</mml:mtext>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:mo>+</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mtext>kBET</mml:mtext>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mi>i</mml:mi>
                </mml:msub>
              </mml:mrow>
              <mml:mn>2</mml:mn>
            </mml:mfrac>
          </mml:mrow>
          <mml:mo>.</mml:mo>
        </mml:math>
      </disp-formula>
      <p>Following <xref rid="btad099-B21" ref-type="bibr">Luecken <italic toggle="yes">et al.</italic> (2022)</xref>, each metric is min–max scaled before metrics aggregation so that all metrics have equal weights. Then two scores are integrated by calculating a <italic toggle="yes">F</italic>1-score (batch correction) as follows:</p>
      <disp-formula id="E9">
        <label>(9)</label>
        <mml:math id="M9" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mi>F</mml:mi>
            <mml:msub>
              <mml:mrow>
                <mml:mn>1</mml:mn>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>b</mml:mi>
                <mml:mi>c</mml:mi>
              </mml:mrow>
            </mml:msub>
            <mml:mo>=</mml:mo>
            <mml:mn>2</mml:mn>
            <mml:mfrac>
              <mml:mrow>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>S</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mtext>bio</mml:mtext>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>*</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>S</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mtext>batch</mml:mtext>
                  </mml:mrow>
                </mml:msub>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>S</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mtext>bio</mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>+</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>S</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mtext>batch</mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
          <mml:mo>.</mml:mo>
        </mml:math>
      </disp-formula>
    </sec>
    <sec>
      <title>3.3 CLAIRE achieves superior mix-heterogeneity trade-off over other CL-based batch correction methods</title>
      <p>To study the mix-heterogeneity trade-off throughout the training process, we plot CLAIRE’s bASW, kBET, ARI and NMI curves with training epochs on Pancreas, Immune and Lung datasets. Curves of other CL-based methods including INSCT, MAT<sup>2</sup>, SMILE and CLEAR are also plotted. Settings for these competing methods are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Note S1</xref>. All methods are trained until the loss plateaus or decreasing quantity below 0.01, and they are run five times on each dataset. Results are shown in <xref rid="btad099-F2" ref-type="fig">Figure 2a</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref>. From the results after convergence, CLAIRE shows superior balance between batch mixing scores and heterogeneity preservation scores. In particular, CLAIRE distinctly outperforms other methods with respect to batch mixing scores on Pancreas and Immune datasets, while achieving competitive heterogeneity preservation scores on three datasets. From the convergence process, although CLAIRE’s kBET has a low start point but it greatly benefits from training and rises throughout the training process. Similar to CLAIRE, CLEAR and MAT<sup>2</sup> also have a low start point of kBET but MAT<sup>2</sup>’s kBET does not benefit from training while CLEAR’s kBET even decreases with training, which implies that CLAIRE’s construction strategy of positive pairs provides stronger integration target. What’s more, even though CLAIRE mixes batches better as training proceeds, its heterogeneity preservation scores do not drop from the peak values. Inspired by this finding, it can be interpretted that CLAIRE first concentrates cells with the same type from a global standpoint, and then mixes batches within local cell clusters.</p>
      <fig position="float" id="btad099-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>Mix-heterogeneity trade-off of CL-based batch correction methods. (<bold>a</bold>) Curves of four evaluation metrics with training epochs from CLAIRE, SMILE, CLEAR, MAT<sup>2</sup>, INSCT on Pancreas and Immune datasets. (<bold>b</bold>) UMAP visualizations of raw expressions of Pancreas dataset. Cells in the first row are colored by cell type annotations, and colored by batch labels in the second row. (<bold>c</bold>) UMAP visualizations of CLAIRE’s embeddings at different training epochs. Cells are colored by cell type in the first row and colored by batch labels in the second row. The cell color markers are consistent with b</p>
        </caption>
        <graphic xlink:href="btad099f2" position="float"/>
      </fig>
      <p>To explain above results more intuitively, we plot all methods’ outputs at different epochs on Pancreas dataset using Uniform Manifold Approximation and Projection (UMAP) (<xref rid="btad099-B2" ref-type="bibr">Becht <italic toggle="yes">et al.</italic>, 2019</xref>). <xref rid="btad099-F2" ref-type="fig">Figure 2b</xref> shows the visualizations of raw expressions without integration. <xref rid="btad099-F2" ref-type="fig">Figure 2c</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2</xref> show the visualizations of CLARIE and other methods, respectively. It can be observed from these figures that different methods have distinct embeddings at epoch 0. This is caused by many factors including different model architectures, different weight initialization, and different preprocessing steps. In <xref rid="btad099-F2" ref-type="fig">Figure 2c</xref>, cell clusters at 0 epoch are clearly separated due to batch effects, but with epoch increasing, CLAIRE mixes batches more sufficiently while cell clusters of different types remain clearly separated to each other, which is consistent with CLAIRE’s metric curves. In <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2b</xref>, cells are closely distributed in SMILE’s embedding space at 0 epoch. Thus, batch effect is small and cellular heterogeneity is also low, which explains SMILE high kBET/bASW and low ARI/NMI at initial training stage. With epoch increasing, boundaries between cells clusters of different types become clearer while batches become less sufficiently mixed than beginning, which explains SMILE’s increasing ARI/NMI and decreasing kBET/bASW. The similar phenomena can also be found in INSCT and MAT<sup>2</sup>’s results. For CLEAR, it’s observed that the batch mixing results become worse as training proceeds and its cellular heterogeneity becomes more ambiguous. That might be because CLEAR’s construction strategy of positive pairs defines an unreasonable integration target. From these results, we can conclude that CLAIRE realizes remarkable improvement over existing CL-based batch correction methods with respect to mix-heterogeneity trade-off.</p>
    </sec>
    <sec>
      <title>3.4 Benchmarking of CLAIRE against other state-of-the-art batch correction methods</title>
      <p>We benchmark CLAIRE against eight state-of-the-art batch correction methods on six real datasets. Three classical methods, Seurat, Scanorama and Harmony, and four CL-based methods, INSCT, MAT<sup>2</sup>, SMILE and CLEAR are included for comparison. In addition, we also include iSMNN (<xref rid="btad099-B40" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2021b</xref>) in our benchmarking, which performs iterative MNN refinement in a non-neural network style to facilitate sufficient batch correction. The main differences between iSMNN’s refinement strategy and CLAIRE’s are that iSMNN adds more MNNs within multiple iterations of MNN refinement while CLAIRE directly removes some MNNs within only one iteration. All competing methods’ settings are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Note S1</xref>. The benchmarking results are displayed in <xref rid="btad099-F3" ref-type="fig">Figure 3</xref>. <xref rid="btad099-F3" ref-type="fig">Figure 3a</xref> shows that CLAIRE reaches the highest F-scores on all datasets, indicating that CLAIRE achieves the best trade-off between batch mixing and preservation of cellular heterogeneity. More specifically, CLAIRE reaches the highest batch mixing scores on all datasets except for Lung dataset and the top-2 heterogeneity conservation scores on five datasets (<xref rid="btad099-F3" ref-type="fig">Fig. 3b</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). In particular, CLAIRE outperforms the second-best methods by 22% in terms of kBET on average on five datasets other than Lung dataset. Note that for Lung dataset, SMILE and INSCT are the only two methods that obtain higher kBET scores than CLAIRE while they greatly compromise to ARI and NMI (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>).</p>
      <fig position="float" id="btad099-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>Benchmarking of CLAIRE against eight state-of-the-art batch correction methods. (<bold>a</bold>) F1 scores (batch correction) of <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>bio</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>batch</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> from nine methods. (<bold>b</bold>) <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>bio</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>batch</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> of nine methods on six datasets. (<bold>c</bold>) UMAP visualizations of nine methods’ outputs on Pancreas datasets</p>
        </caption>
        <graphic xlink:href="btad099f3" position="float"/>
      </fig>
      <p>To better illustrate CLAIRE’s performance, we visualize all methods’ outputs on six datasets by UMAP in <xref rid="btad099-F3" ref-type="fig">Figure 3c</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figures S3–S7</xref>. From the visualizations, it can be seen that CLAIRE retains clearly separable cell clusters and batches are mixed sufficiently within each cluster, which is consistent with the evaluation results. Particularly, on Pancreas dataset, batches are uniformly distributed within each cell type cluster in CLAIRE’s results while in other methods’ results, there is always a small part of ‘Baron_b1’ batch isolated in an area, which explains CLAIRE’s remarkable improvement of kBET on this dataset. Moreover, though adopting only one iteration of MNN refinement, CLAIRE achieves more sufficient batch mixing than iSMNN and there are less over-correction phenomena in its visualizations, which demonstrates the advantages of our proposed CL framework. What’s more, though CLAIRE accomplishes highly sufficient batch mixing results, it does not mix rare cell types with common cell types. For instance, on PBMC dataset, CLAIRE retains clearly separated clusters of hematopoietic stem cells and Megakaryocytes, epsilon cells in Pancreas dataset, and ionocytes cluster in Lung dataset.</p>
      <p>Time and memory consumptions are important issues when evaluating batch correction methods. We evaluate CLAIRE and other batch correction methods with respect to their computation time and memory usage with a Linux server with 48-core Intel Xeon Silver 4116 CPU, 256 GB RAM and GeForce RTX 2080 Ti. We sample various number of cells from Tabular Muris Senis dataset (<xref rid="btad099-B29" ref-type="bibr">Tabula Muris Consortium, 2020</xref>) with range from 2000 to 120 000, and assess all methods on these sampled datasets. Time of reading data is not recorded for all methods. Evaluation results are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S2 and S3</xref>. From the results, it can be seen that CLAIRE’s time and memory consumptions both increase nearly linearly to the number of cells, and its overall consumption is comparable with other state-of-the-art methods.</p>
    </sec>
    <sec>
      <title>3.5 Effectiveness of CLAIRE’s construction and refinement strategy</title>
      <p>To validate the effectiveness of CLAIRE’s construction and refinement strategy, we conduct an ablation study. In particular, we compare CLAIRE with two variants: (i) CLAIRE without our proposed construction strategy, which follows INSCT and directly uses inter-batch MNNs as positive pairs and intra-batch KNNs as positive samples for those cells without MNN, denoted as CLAIRE-var1; and (ii) CLAIRE without refinement strategy, denoted as CLAIRE-var2. Each variant is run for five times on Pancreas dataset and Immune datasets, respectively. Ablation results are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S8a</xref>. We observe that the CLAIRE shows higher kBET scores than CLAIRE-var1 after convergence, which verifies that our construction strategy better covers the whole distributions of shared populations between batches. CLAIRE-var2 achieves similar batch mixing scores as CLAIRE and their ARI/NMI increase to similar values after several epochs. However, as training proceeds, CLAIRE-var2’s ARI and NMI continuously drop while CLAIRE’s ARI and NMI are almost unchanged. On Pancreas dataset, CLAIRE-var2’s final NMI drops 10% compared to the peak value, and on Immune dataset, its NMI drops 13% compared to the peak value. By visualizing CLAIRE-var2’s embeddings on Pancreas dataset at different epochs (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S8b</xref>), we find that CLAIRE-var2 gradually mixes some cell clusters of different cell types, which indicates that there exist number of false positive pairs leading to over-correction. Nevertheless, we observe that CLAIRE’s results do not show obvious decline of heterogeneity, which verifies the importance of refinement strategy for reducing the impact of false positive pairs. Overall, our proposed construction strategy and refinement strategy both are indispensable for CLAIRE’s superior performance.</p>
      <p>To investigate whether two training stages are necessary for the refinement, we design two different approaches to filter seeds (inter-batch MNNs) directly based on the cellular expression profiles: (i) using HVG. After preprocessing dataset, calculating the cosine similarity between each seed pair using normalized expressions, and then building a two-component Gaussian mixture model on the similarities to infer false seeds. (ii) Using MNN scores. Following Seurat (<xref rid="btad099-B27" ref-type="bibr">Stuart <italic toggle="yes">et al.</italic>, 2019</xref>), we find the intra-batch KNN and inter-batch KNN for each cell. Each seed pair is scored by computing the overlap of their shared nearest neighbors. A Gaussian mixture model is built on the scores to infer false seeds. <xref rid="btad099-F4" ref-type="fig">Figure 4a</xref> shows the true seeds’ percentage of retained seeds after filtering using three approaches. It can be seen that filtering on the learned representations leads to more correct seeds than other two approaches and training with 2–4 epochs generally lead the best results. Next, we apply the retained seeds (<inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mo>η</mml:mo></mml:math></inline-formula> = 0.2) from approach 1 for only one stage training. Interestingly, <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S9a</xref> shows that filtering using HVGs performs similarly with CLAIRE on Pancreas dataset while its performance drops on Immune dataset. We think their performance difference on Immune dataset is because CLAIRE obtains much higher percentage of true seeds. To study the generalizability of CLAIRE’s refinement strategy, we further evaluate three filtering approaches on other four datasets with respect to the true seeds’ percentage of retained seeds. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S9b</xref> shows that CLAIRE outperforms the other two approaches on four datasets and shows significant improvements on complex datasets, such as Lung and Immune dataset, suggesting the superiority of our proposed refinement strategy.</p>
      <fig position="float" id="btad099-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Ablation studies of CLAIRE on Pancreas and Immune datasets. (<bold>a</bold>) True seeds’ percentage of retained seeds obtained using three filtering approaches. ‘CLAIRE (epoch = 2)’ means filtering using CLAIRE’s embeddings after training 2 epochs. (<bold>b</bold>) CLAIRE’s NMI and kBET on Pancreas and Immune datasets by setting different <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mo>α</mml:mo></mml:math></inline-formula> and <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></p>
        </caption>
        <graphic xlink:href="btad099f4" position="float"/>
      </fig>
      <p>We also explore the effect of hyper-parameters on two strategies, i.e. <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mo>α</mml:mo></mml:math></inline-formula> and <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for the construction strategy, <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mo>η</mml:mo></mml:math></inline-formula> for the refinement strategy. <inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:mo>α</mml:mo></mml:math></inline-formula> refers to the parameter of uniform distribution during preparing positive pairs. <inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> refers to the number of nearest neighbors for searching intra-batch KNNs. <inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:mo>η</mml:mo></mml:math></inline-formula> refers to the confidence threshold for filtering inter-batch MNNs. Results are shown in <xref rid="btad099-F4" ref-type="fig">Figure 4b</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S10</xref>. We find that smaller <inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:mo>α</mml:mo></mml:math></inline-formula> and <inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> favor heterogeneity preservation scores while higher <inline-formula id="IE51"><mml:math id="IM51" display="inline" overflow="scroll"><mml:mo>α</mml:mo></mml:math></inline-formula> and <inline-formula id="IE52"><mml:math id="IM52" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> favor batch mixing scores. Overall, we find that <inline-formula id="IE53"><mml:math id="IM53" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE54"><mml:math id="IM54" display="inline" overflow="scroll"><mml:mrow><mml:mo>α</mml:mo><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> achieve desirable results. Interestingly, we find that CLAIRE is insensitive to <inline-formula id="IE55"><mml:math id="IM55" display="inline" overflow="scroll"><mml:mo>η</mml:mo></mml:math></inline-formula>. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S10b</xref> shows that when <inline-formula id="IE56"><mml:math id="IM56" display="inline" overflow="scroll"><mml:mo>η</mml:mo></mml:math></inline-formula> increases, all metrics show small changes, which indicates that CLAIRE infers true seeds with very high confidence and further demonstrates the robustness of our refinement strategy.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>We present a novel CL-based batch correction framework, CLAIRE, for integrating scRNA-seq datasets. The key idea is to improve the appropriateness of positive pairs which can dominate the results of batch correction. We propose two complementary strategies to realize appropriate positive pairs. First, to improve the coverage of positive pairs for the distribution of shared populations between batches, we propose a dynamical construction strategy for positive pairs by exploiting inter-batch MNN and intra-batch KNN. Our construction strategy not only helps positive pairs better cover the shared distributions between batches but is also computationally efficient. Second, to improve the correctness of positive pairs, we propose a refinement strategy to remove false positive pairs. Experiment results show that CLAIRE achieves superior mix-heterogeneity trade-off over existing CL-based batch correction methods. When benchmarking on six real datasets, CLAIRE outperforms eight state-of-the-art batch correction methods with respect to the best comprehensive performance of dataset integration.</p>
    <p>We conduct extensive ablation experiments to verify the effectiveness of CLAIRE. Two variants of CLAIRE, CLAIRE-var1 and CLAIRE-var2, both show inferior performance than CLAIRE in terms of batch mixing score and heterogeneity preservation score. In particular, even with the refinement strategy, CLAIRE-var1’s final NMI values still show distinct drop compared to the initial peak values. The probable reason for the drop is that positive pairs defined by intra-batch NNs have inconsistent pattern with those defined by inter-batch MNNs, interfering the refinement process. These findings demonstrate that our proposed two strategies are indispensable for CLAIRE’s superior performance. Moreover, we show that two-stage training greatly helps to discriminate true seeds and false seeds, which promotes better refinement of positive pairs and validates the memorization effect of deep neural networks.</p>
    <p>To further demonstrate the utility of CLAIRE for single-cell data analysis, we conduct various downstream analysis, including label transfer between scRNA-seq datasets, cross-omics label transfer, and trajectory analysis, based on CLAIRE’s outputs (<xref rid="sup1" ref-type="supplementary-material">Supplementary Note S2</xref>). Analysis results demonstrate that CLAIRE’s integrated embeddings can accurately transfer labels between scRNA-seq datasets and across omics. Additionally, CLAIRE can preserve the contiguous structure among cells after removing batch effects, which can facilitate further analysis about cell development.</p>
    <p>Although CLAIRE achieves notable performance, there are still some limitations to be improved. One major limitation is that CLAIRE needs MNNs as signals to merge batches. However, computing MNNs between every pair of batches is time consuming, which is the major bottleneck of CLAIRE’s computation consumption. Some MNN-free batch correction methods, such as DESC (<xref rid="btad099-B18" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2020</xref>), can also achieve robust correction performance. Therefore, we can combine ideas from those MNN-free methods with CL to realize more effective batch correction framework. Another limitation is that CLAIRE adopts Moco-style CL architecture, which relies on negative pairs to achieve robust representations. Recently, some negative-free CL methods have been proposed and they are more resilient than its counterparts in many aspects (<xref rid="btad099-B6" ref-type="bibr">Chen and He, 2021</xref>; <xref rid="btad099-B8" ref-type="bibr">Grill <italic toggle="yes">et al.</italic>, 2020</xref>), which can be adapted into CLAIRE’s framework. What’s more, considering CLAIRE’s excellent performance in integrating scRNA-seq datasets, we believe it has a great potential to migrate to multi-omics data integration problems.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btad099_Supplementary_Data</label>
      <media xlink:href="btad099_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Funding</title>
    <p>This work was supported in part by the National Natural Science Foundation of China (62225209), and the Hunan Provincial Science and Technology Program (2019CB1007 and 2021RC4008).</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btad099-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Arpit</surname><given-names>D.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) A closer look at memorization in deep networks. In: <italic toggle="yes">International Conference on Machine Learning</italic>. PMLR, Sydney, Australia, pp. <fpage>233</fpage>–<lpage>242</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Becht</surname><given-names>E.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Dimensionality reduction for visualizing single-cell data using UMAP</article-title>. <source>Nat. Biotechnol</source>., <volume>37</volume>, <fpage>38</fpage>–<lpage>44</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cao</surname><given-names>Z.-J.</given-names></string-name>, <string-name><surname>Gao</surname><given-names>G.</given-names></string-name></person-group> (<year>2022</year>) <article-title>Multi-omics single-cell data integration and regulatory inference with graph-linked embedding</article-title>. <source>Nat. Biotechnol</source>., <volume>40</volume>, <fpage>1458</fpage>–<lpage>1466</lpage>.<pub-id pub-id-type="pmid">35501393</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>Bubble: a fast single-cell RNA-seq imputation using an autoencoder constrained by bulk RNA-seq data</article-title>. <source>Brief. Bioinform</source>., <volume>24</volume>, <fpage>bbac580</fpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) A simple framework for contrastive learning of visual representations. In: <italic toggle="yes">International Conference on Machine Learning</italic>. PMLR, Vienna, Austria, pp. <fpage>1597</fpage>–<lpage>1607</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B6">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>X.</given-names></string-name>, <string-name><surname>He</surname><given-names>K.</given-names></string-name></person-group> (<year>2021</year>) Exploring simple Siamese representation learning. In: <italic toggle="yes">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</italic>, Virtual/Online, United States, pp. <fpage>15750</fpage>–<lpage>15758</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B7">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Glorot</surname><given-names>X.</given-names></string-name></person-group><etal>et al</etal> (<year>2011</year>) Deep sparse rectifier neural networks. In: <italic toggle="yes">Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics</italic>, Fort Lauderdale, FL, United States, pp. <fpage>315</fpage>–<lpage>323</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Grill</surname><given-names>J.-B.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Bootstrap your own latent-a new approach to self-supervised learning</article-title>. <source>Adv. Neural Inf. Process. Syst</source>., <volume>33</volume>, <fpage>21271</fpage>–<lpage>21284</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Haghverdi</surname><given-names>L.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors</article-title>. <source>Nat. Biotechnol</source>., <volume>36</volume>, <fpage>421</fpage>–<lpage>427</lpage>.<pub-id pub-id-type="pmid">29608177</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B10">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Han</surname><given-names>W.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) Self-supervised contrastive learning for integrative single cell RNA-seq data analysis. <italic toggle="yes">Brief. Bioinform.</italic>, <bold>23</bold>, bbac377.</mixed-citation>
    </ref>
    <ref id="btad099-B11">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) Momentum contrast for unsupervised visual representation learning. In: <italic toggle="yes">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</italic>, Virtual/Online, United States, pp. <fpage>9729</fpage>–<lpage>9738</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heath</surname><given-names>J.R.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>Single-cell analysis tools for drug discovery and development</article-title>. <source>Nat. Rev. Drug Discov</source>., <volume>15</volume>, <fpage>204</fpage>–<lpage>216</lpage>.<pub-id pub-id-type="pmid">26669673</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hie</surname><given-names>B.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Efficient integration of heterogeneous single-cell transcriptomes using scanorama</article-title>. <source>Nat. Biotechnol</source>., <volume>37</volume>, <fpage>685</fpage>–<lpage>691</lpage>.<pub-id pub-id-type="pmid">31061482</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname><given-names>W.E.</given-names></string-name></person-group><etal>et al</etal> (<year>2007</year>) <article-title>Adjusting batch effects in microarray expression data using empirical Bayes methods</article-title>. <source>Biostatistics</source>, <volume>8</volume>, <fpage>118</fpage>–<lpage>127</lpage>.<pub-id pub-id-type="pmid">16632515</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>D.P.</given-names></string-name>, <string-name><surname>Ba</surname><given-names>J.</given-names></string-name></person-group> (<year>2014</year>) Adam: a method for stochastic optimization. In: <italic toggle="yes">International Conference for Learning Representations 2015</italic>, San Diego, CA, United States.</mixed-citation>
    </ref>
    <ref id="btad099-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Korsunsky</surname><given-names>I.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Fast, sensitive and accurate integration of single-cell data with harmony</article-title>. <source>Nat. Methods</source>, <volume>16</volume>, <fpage>1289</fpage>–<lpage>1296</lpage>.<pub-id pub-id-type="pmid">31740819</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lawson</surname><given-names>D.A.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>Tumour heterogeneity and metastasis at single-cell resolution</article-title>. <source>Nat. Cell Biol</source>., <volume>20</volume>, <fpage>1349</fpage>–<lpage>1360</lpage>.<pub-id pub-id-type="pmid">30482943</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>X.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Deep learning enables accurate clustering with batch effect removal in single-cell RNA-seq analysis</article-title>. <source>Nat. Commun</source>., <volume>11</volume>, <fpage>1</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">31911652</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liang</surname><given-names>Z.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>SSRE: cell type detection based on sparse subspace representation and similarity enhancement</article-title>. <source>Genomics Proteomics Bioinformatics</source>, <volume>19</volume>, <fpage>282</fpage>–<lpage>291</lpage>.<pub-id pub-id-type="pmid">33647482</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Scmerge leverages factor analysis, stable expression, and pseudoreplication to merge multiple single-cell RNA-seq datasets</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>116</volume>, <fpage>9775</fpage>–<lpage>9784</lpage>.<pub-id pub-id-type="pmid">31028141</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luecken</surname><given-names>M.D.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>Benchmarking atlas-level data integration in single-cell genomics</article-title>. <source>Nat. Methods</source>, <volume>19</volume>, <fpage>41</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">34949812</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Satija</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) <article-title>Spatial reconstruction of single-cell gene expression data</article-title>. <source>Nat. Biotechnol</source>., <volume>33</volume>, <fpage>495</fpage>–<lpage>502</lpage>.<pub-id pub-id-type="pmid">25867923</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shaham</surname><given-names>U.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Removal of batch effects using distribution-matching residual networks</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>2539</fpage>–<lpage>2546</lpage>.<pub-id pub-id-type="pmid">28419223</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Simon</surname><given-names>L.M.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Integration of millions of transcriptomes using batch-aware triplet neural networks</article-title>. <source>Nat. Mach. Intell</source>., <volume>3</volume>, <fpage>705</fpage>–<lpage>715</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Smyth</surname><given-names>G.K.</given-names></string-name>, <string-name><surname>Speed</surname><given-names>T.</given-names></string-name></person-group> (<year>2003</year>) <article-title>Normalization of cDNA microarray data</article-title>. <source>Methods</source>, <volume>31</volume>, <fpage>265</fpage>–<lpage>273</lpage>.<pub-id pub-id-type="pmid">14597310</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Srivastava</surname><given-names>N.</given-names></string-name></person-group><etal>et al</etal> (<year>2014</year>) <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>. <source>J. Mach. Learn. Res</source>., <volume>15</volume>, <fpage>1929</fpage>–<lpage>1958</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stuart</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Comprehensive integration of single-cell data</article-title>. <source>Cell</source>, <volume>177</volume>, <fpage>1888</fpage>–<lpage>1902.e21</lpage>.<pub-id pub-id-type="pmid">31178118</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B28">
      <mixed-citation publication-type="journal"><collab>Tabula Muris Consortium</collab><etal>et al</etal> (<year>2018</year>) <article-title>Single-cell transcriptomics of 20 mouse organs creates a tabula muris</article-title>. <source>Nature</source>, <volume>562</volume>, <fpage>367</fpage>–<lpage>372</lpage>.<pub-id pub-id-type="pmid">30283141</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B29">
      <mixed-citation publication-type="journal"><collab>Tabula Muris Consortium</collab><etal>et al</etal> (<year>2020</year>) <article-title>A single-cell transcriptomic atlas characterizes ageing tissues in the mouse</article-title>. <source>Nature</source>, <volume>583</volume>, <fpage>590</fpage>–<lpage>595</lpage>.<pub-id pub-id-type="pmid">32669714</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tian</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>What makes for good views for contrastive learning?</article-title><source>Adv. Neural Inf. Process. Syst</source>., <volume>33</volume>, <fpage>6827</fpage>–<lpage>6839</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tian</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>A data-driven clustering recommendation method for single-cell RNA-sequencing data</article-title>. <source>Tsinghua Sci. Technol</source>., <volume>26</volume>, <fpage>772</fpage>–<lpage>789</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tran</surname><given-names>H.T.N.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>A benchmark of batch-effect correction methods for single-cell RNA sequencing data</article-title>. <source>Genome Biol</source>., <volume>21</volume>, <fpage>1</fpage>–<lpage>32</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B33">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>van den Oord</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) Representation learning with contrastive predictive coding. <italic toggle="yes">arXiv, arXiv:1807.03748</italic>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btad099-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>D.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>iMAP: integration of multiple single-cell datasets by adversarial paired transfer networks</article-title>. <source>Genome Biol</source>., <volume>22</volume>, <fpage>1</fpage>–<lpage>24</lpage>.<pub-id pub-id-type="pmid">33397451</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>BERMUDA: a novel deep transfer learning method for single-cell RNA sequencing batch correction reveals hidden high-resolution cellular subtypes</article-title>. <source>Genome Biol</source>., <volume>20</volume>, <fpage>1</fpage>–<lpage>15</lpage>.<pub-id pub-id-type="pmid">30606230</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B36">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wei</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) Contrastive learning for cold-start recommendation. In: <italic toggle="yes">Proceedings of the 29th ACM International Conference on Multimedia</italic>, Chengdu, Sichuan, China, pp. <fpage>5382</fpage>–<lpage>5390</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>Smile: mutual information learning for integration of single-cell omics data</article-title>. <source>Bioinformatics</source>, <volume>38</volume>, <fpage>476</fpage>–<lpage>486</lpage>.<pub-id pub-id-type="pmid">34623402</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yan</surname><given-names>X.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>Globe: a contrastive learning-based framework for integrating single-cell transcriptome datasets</article-title>. <source>Brief. Bioinform</source>., <volume>23</volume>, <fpage>bbac311</fpage>.<pub-id pub-id-type="pmid">35901449</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B39">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2021a</year>) Partially view-aligned representation learning with noise-robust contrastive loss. In: <italic toggle="yes">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</italic>, Virtual/Online, United States, pp. <fpage>1134</fpage>–<lpage>1143</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2021b</year>) <article-title>iSMNN: batch effect correction for single-cell RNA-seq data via iterative supervised mutual nearest neighbor refinement</article-title>. <source>Brief. Bioinform</source>., <volume>22</volume>, <fpage>bbab122</fpage>.<pub-id pub-id-type="pmid">33839756</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2021c</year>) <article-title>SMNN: batch effect correction for single-cell RNA-seq data via supervised mutual nearest neighbor detection</article-title>. <source>Brief. Bioinform</source>., <volume>22</volume>, <fpage>bbaa097</fpage>.<pub-id pub-id-type="pmid">32591778</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B42">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Zeng</surname><given-names>D.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) Positional contrastive learning for volumetric medical image segmentation. In: <italic toggle="yes">International Conference on Medical Image Computing and Computer-Assisted Intervention</italic>. Springer, Strasbourg, France, pp. <fpage>221</fpage>–<lpage>230</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>MAT2: manifold alignment of single-cell transcriptomes with cell triplets</article-title>. <source>Bioinformatics</source>, <volume>37</volume>, <fpage>3263</fpage>–<lpage>3269</lpage>.</mixed-citation>
    </ref>
    <ref id="btad099-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Learning interpretable cellular and gene signature embeddings from single-cell transcriptomic data</article-title>. <source>Nat. Commun</source>., <volume>12</volume>, <fpage>1</fpage>–<lpage>15</lpage>.<pub-id pub-id-type="pmid">33397941</pub-id></mixed-citation>
    </ref>
    <ref id="btad099-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zheng</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>SinNLRR: a robust subspace clustering method for cell type detection by non-negative and low-rank representation</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>3642</fpage>–<lpage>3650</lpage>.<pub-id pub-id-type="pmid">30821315</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
