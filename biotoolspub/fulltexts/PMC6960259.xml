<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName archivearticle.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Genet</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Genet</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Genet.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Genetics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1664-8021</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6960259</article-id>
    <article-id pub-id-type="doi">10.3389/fgene.2019.01303</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Genetics</subject>
        <subj-group>
          <subject>Methods</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A Novel Hybrid CNN-SVR for CRISPR/Cas9 Guide RNA Activity Prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Guishan</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/804291"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Dai</surname>
          <given-names>Zhiming</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="author-notes" rid="fn001">
          <sup>*</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/754032"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Dai</surname>
          <given-names>Xianhua</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="author-notes" rid="fn001">
          <sup>*</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>School of Electronics and Information Technology, Sun Yat-sen University</institution>, <addr-line>Guangzhou</addr-line>, <country>China</country></aff>
    <aff id="aff2"><sup>2</sup><institution>School of Data and Computer Science, Sun Yat-sen University</institution>, <addr-line>Guangzhou</addr-line>, <country>China</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Guangdong Province Key Laboratory of Big Data Analysis and Processing, Sun Yat-sen University</institution>, <addr-line>Guangzhou</addr-line>, <country>China</country></aff>
    <aff id="aff4"><sup>4</sup><institution>Southern Marine Science and Engineering Guangdong Laboratory</institution>, <addr-line>Zhuhai</addr-line>, <country>China</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Shizhong Han, Johns Hopkins Medicine, United States</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Xiang Li, Harvard Medical School, United States; Qi Liu, Tongji University, China</p>
      </fn>
      <corresp id="fn001">*Correspondence: Zhiming Dai, <email xlink:href="mailto:daizhim@mail.sysu.edu.cn" xlink:type="simple">daizhim@mail.sysu.edu.cn</email>; Xianhua Dai, <email xlink:href="mailto:issdxh@mail.sysu.edu.cn" xlink:type="simple">issdxh@mail.sysu.edu.cn</email></corresp>
      <fn fn-type="other" id="fn002">
        <p>This article was submitted to Bioinformatics and Computational Biology, a section of the journal Frontiers in Genetics</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>08</day>
      <month>1</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>10</volume>
    <elocation-id>1303</elocation-id>
    <history>
      <date date-type="received">
        <day>15</day>
        <month>9</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>26</day>
        <month>11</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2020 Zhang, Dai and Dai</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Zhang, Dai and Dai</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Accurate prediction of guide RNA (gRNA) on-target efficacy is critical for effective application of CRISPR/Cas9 system. Although some machine learning-based and convolutional neural network (CNN)-based methods have been proposed, prediction accuracy remains to be improved. Here, firstly we improved architectures of current CNNs for predicting gRNA on-target efficacy. Secondly, we proposed a novel hybrid system which combines our improved CNN with support vector regression (SVR). This CNN-SVR system is composed of two major components: a merged CNN as the front-end for extracting gRNA feature and an SVR as the back-end for regression and predicting gRNA cleavage efficiency. We demonstrate that CNN-SVR can effectively exploit features interactions from feed-forward directions to learn deeper features of gRNAs and their corresponding epigenetic features. Experiments on commonly used datasets show that our CNN-SVR system outperforms available state-of-the-art methods in terms of prediction accuracy, generalization, and robustness. Source codes are available at <uri xlink:type="simple" xlink:href="https://github.com/Peppags/CNN-SVR">https://github.com/Peppags/CNN-SVR</uri>.</p>
    </abstract>
    <kwd-group>
      <kwd>CRISPR/Cas9</kwd>
      <kwd>guide RNA</kwd>
      <kwd>convolutional neural network</kwd>
      <kwd>on-target</kwd>
      <kwd>support vector regression</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source id="cn001">National Natural Science Foundation of China<named-content content-type="fundref-id">10.13039/501100001809</named-content></funding-source>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="5"/>
      <table-count count="4"/>
      <equation-count count="2"/>
      <ref-count count="48"/>
      <page-count count="13"/>
      <word-count count="8469"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="s1">
    <title>Introduction</title>
    <p>The CRISPR/Cas9 system, adapted from a bacterial defense mechanism, is a promising genomic editing tool that has recently revolutionized the field of biology, biotechnology, and medicine (<xref rid="B4" ref-type="bibr">Barrangou et al., 2007</xref>). This system consists of a nuclease activity-carrying Cas9 protein and the specificity-programming single guide RNA (gRNA), and the latter of which targets the complex to a genomic region flanked by a protospacer adjacent motif (PAM) (<xref rid="B21" ref-type="bibr">Jinek et al., 2012</xref>). Though the CRISPR/Cas9 system is considered to be very specific to perform the preconcerted cleavage on genome, numerous studies have indicated that Cas9 complex also binds to other unintended genomic sites, termed as off-target (<xref rid="B37" ref-type="bibr">Pattanayak et al., 2013</xref>; <xref rid="B14" ref-type="bibr">Doench et al., 2016</xref>). Thus, design of a gRNA with high on-target efficacy and low off-target effects is an important issue in CRISPR/Cas9 system. It has been shown that on-target activity is partly determined by gRNA intrinsic sequence and chromatin structure of target genomic region, but the underlying molecular mechanism is still not fully understood. Accurate prediction of gRNA on-target activity facilitates maximization of on-target efficacy and minimization of off-target effects, further contributing to the success application of CRISPR/Cas9 system (<xref rid="B19" ref-type="bibr">Hsu et al., 2013</xref>; <xref rid="B13" ref-type="bibr">Doench et al., 2014</xref>; <xref rid="B48" ref-type="bibr">Xu et al., 2015</xref>; <xref rid="B9" ref-type="bibr">Chuai et al., 2016</xref>; <xref rid="B14" ref-type="bibr">Doench et al., 2016</xref>).</p>
    <p>Previous efforts have been made to assist gRNA on-target identification and efficacy prediction based on different design rules. The alignment-based methods align the gRNAs from the given genome purely by locating the PAM [e.g. CCTop (<xref rid="B40" ref-type="bibr">Stemmer et al., 2015</xref>)]. Hypothesis driven-based tools empirically score the gRNA efficacy by incorporating the effect of genomic context factors [i.e. CFD (<xref rid="B14" ref-type="bibr">Doench et al., 2016</xref>)]. Machine learning-based methods predict the cleavage propensity of a genomic site for a given gRNA by considering different nucleotide features, such as position specific nucleotides and dinucleotides (<xref rid="B13" ref-type="bibr">Doench et al., 2014</xref>), GC content (<xref rid="B6" ref-type="bibr">Chari et al., 2015</xref>) as well as non-sequence features including thermodynamic stability of gRNA (<xref rid="B13" ref-type="bibr">Doench et al., 2014</xref>), amino acid cut position (<xref rid="B7" ref-type="bibr">Chen et al., 2017</xref>), and chromatin accessibility (<xref rid="B17" ref-type="bibr">Hinz et al., 2015</xref>; <xref rid="B18" ref-type="bibr">Horlbeck et al., 2016</xref>; <xref rid="B31" ref-type="bibr">Listgarten et al., 2018</xref>). For example, support vector machine (SVM)-based sgRNA Designer found that the position of the target site relative to the transcription start site and position within the protein are the most important factors for gRNA activity prediction (<xref rid="B14" ref-type="bibr">Doench et al., 2016</xref>). L1-regularized linear regression-based SSC reported that DNA sequence composition incorporating the preference for cytosine at the cleavage site improved the performance of gRNA on-target prediction (<xref rid="B48" ref-type="bibr">Xu et al., 2015</xref>). WU-CRISPR combined sequence and structural features of the gRNA to identify highly active gRNA (<xref rid="B46" ref-type="bibr">Wong et al., 2015</xref>). In general, no single feature but rather a combination of feature interactions governs gRNA cleavage efficacy (<xref rid="B44" ref-type="bibr">Wilson et al., 2018</xref>). Sophisticated models considering the interactions between the individual features achieved better performance (<xref rid="B1" ref-type="bibr">Aach et al., 2014</xref>; <xref rid="B15" ref-type="bibr">Erard et al., 2017</xref>). Nevertheless, some correlated features may result in the redundancy (<xref rid="B2" ref-type="bibr">Abadi et al., 2017</xref>), further rendering poor prediction outcome. Moreover, the outcomes of machine learning-based tools mainly depend on laborious manual feature engineering. They require considerable domain expertise to design the feature extractor (<xref rid="B28" ref-type="bibr">LeCun et al., 2015</xref>).</p>
    <p>Deep learning allows computational models that consist of multiple processing layers to learn representations of features with multiple levels of abstraction (<xref rid="B28" ref-type="bibr">LeCun et al., 2015</xref>). The layers of features are learned from data by a general-purpose learning procedure instead of human engineers. Recently, several successful deep learning-based models have been provided for predicting CRISPR gRNA on-target activity. For example, Kim et al. proposed Seq-deepCpf1, which used convolutional neural networks (CNNs) to learn the nucleotide features of CRISPR gRNA, and it outperformed previous machine learning algorithms (<xref rid="B24" ref-type="bibr">Kim et al., 2018</xref>). Chuai et al. proposed DeepCRISPR that used deep convolutionary denosing neural network-based autoencoder to extract the CRISPR/Cas9 gRNA sequence representation and utilized the fully CNN model to predict the gRNA efficacy (<xref rid="B10" ref-type="bibr">Chuai et al., 2018</xref>). Extensive numerical experiments demonstrated DeepCRISPR surpassed the state-of-the-art tools across a variety of human datasets.</p>
    <p>The above two CNN-based models showed good performance in CRISPR gRNA efficacy prediction compared with machine learning-based methods. CNNs are multi-layer architectures where the successive layers are designed to learn progressively higher-level features, until the last layer which produces the classifiers (<xref rid="B20" ref-type="bibr">Huang and LeCun, 2006</xref>). The last layer of CNN can be considered as a linear classifier operator on feature representation extracted by previous layers. CNN performs well in automatically learning nonlinearity features. However, CNN is not always an optimal choice for classification because the MLP layer following the feature extraction layer contains many trainable parameters. On the contrary, SVM with fixed kernel function has good utility on minimizing generalization error bound when applied to well-behaved feature vectors. Inspired by this, it is interesting to explore the hybrid CNN-SVM system in which CNN is trained to extract features and SVM computes a classifier function in the learned high dimensional feature spaces. To date, CNN-SVM models have shown impressive performance in a wide range of applications, such as object categorization (<xref rid="B20" ref-type="bibr">Huang and LeCun, 2006</xref>) and image recognition (<xref rid="B34" ref-type="bibr">Mori et al., 2005</xref>; <xref rid="B36" ref-type="bibr">Niu and Suen, 2012</xref>). For example, Niu et al. put forward a CNN-SVM model for handwritten digitals recognition with recognition rate of 99.81%. In their work, the proposed CNN-SVM replaced the back propagation neural network classifier with SVM in the last layer of the CNN model (<xref rid="B36" ref-type="bibr">Niu and Suen, 2012</xref>). Mori et al. trained a convolutional spiking neural network using different fragment images. The outputs of each layer in the model were input to the SVM model. A 100% face recognition rate was obtained for 600 images of 20 people (<xref rid="B34" ref-type="bibr">Mori et al., 2005</xref>). In terms of regression problem, Li et al. proposed CNN combined with support vector regression (CNN-SVR) for no-reference image quality assessment. This method achieved advanced outstanding performance compared with traditional CNN model (<xref rid="B29" ref-type="bibr">Li et al., 2016</xref>).</p>
    <p>The prior success of CNN-SVM in computer vision inspired us to extend CNN-SVM application to CRISPR/Cas9 gRNA efficacy prediction. Until now, to the best of our knowledge, there is no such application. Previous studies have suggested that CRISPR gRNA efficacy prediction using linear regression achieved better performance than classification (<xref rid="B33" ref-type="bibr">Moreno-Mateos et al., 2015</xref>; <xref rid="B24" ref-type="bibr">Kim et al., 2018</xref>). Therefore, SVR, which is a common application form of SVM for regression, may be more appropriate for gRNA efficacy prediction when applied to well-behaved feature vectors. In this work, we developed a hybrid architecture incorporating CNN and SVR for CRISPR/Cas9 gRNA on-target activity prediction. The key idea of our system is to train a specialized CNN to extract robust gRNA sequence and epigenetic features, and to provide them to the SVR classifier for predicting gRNA cleavage efficacy. First, we trained the CNN model with back-propagation on the benchmark dataset, aiming at model selection and parameters tuning. Second, the initial CNN features were input into the SVR for training and evaluating. A two-step strategy was performed to select the important features from well-trained CNN intrinsic gradients features. Third, the well-trained CNN-SVR was used to test the independent cell-line dataset. Specifically, the test data was input to the well-trained CNN model to obtain the test features. Using the test feature vector, the well-trained SVR classifier was performed to predict the gRNA cleavage efficacy. Experiments showed improved performance of the proposed CNN-SVR model for CRISPR/Cas9 gRNA on-target activity prediction compared with state-of-the-art algorithms.</p>
  </sec>
  <sec sec-type="materials|methods" id="s2">
    <title>Materials and Methods</title>
    <sec id="s2_1">
      <title>Data Resources</title>
      <sec id="s2_1_1">
        <title>Benchmark Dataset</title>
        <p>Previous studies have shown that PAM-distal region has a high tolerance for sequence mismatches (<xref rid="B22" ref-type="bibr">Kim et al., 2016</xref>; <xref rid="B26" ref-type="bibr">Kleinstiver et al., 2016</xref>). To be specific, gRNAs with two mismatches in the first two positions from the 5’ end has little influence on cleavage efficiency (<xref rid="B13" ref-type="bibr">Doench et al., 2014</xref>; <xref rid="B14" ref-type="bibr">Doench et al., 2016</xref>). Inspired by these studies, Chuai et al. applied a data augmentation procedure by changing each gRNA into a new one with two mismatches in the PAM distal region (<xref rid="B10" ref-type="bibr">Chuai et al., 2018</xref>). Consequently, a 23-nt gRNA sequence can be expanded into 16 gRNAs with identical cleavage efficacy. The augmented dataset was generated from ~15,000 gRNAs with known on-target cleavage efficacy. By adopting this data augmentation strategy, they obtained 180512 non-redundant gRNAs. Each observation in the data contains a 23-nt gRNA sequence and its corresponding cleavage efficiency. In this work, we used this augmented dataset as the benchmark data for model selection and pre-training.</p>
      </sec>
      <sec id="s2_1_2">
        <title>Four Cell Line Independent Test Datasets</title>
        <p>In order to evaluate the performance of our method, we used four public experimental validated gRNA on-target cleavage efficacy independent human datasets, which were integrated and processed by Chuai et al (<xref rid="B10" ref-type="bibr">Chuai et al., 2018</xref>). These experimented-based datasets were originally collected from public datasets (<xref rid="B41" ref-type="bibr">Wang et al., 2014</xref>; <xref rid="B16" ref-type="bibr">Hart et al., 2015</xref>; <xref rid="B14" ref-type="bibr">Doench et al., 2016</xref>). They covered gRNAs targeting 1071 genes from four different cell lines, including HCT116 (4239 samples) (<xref rid="B16" ref-type="bibr">Hart et al., 2015</xref>), HEK293T (2333 samples) (<xref rid="B14" ref-type="bibr">Doench et al., 2016</xref>), HELA (8101 samples) (<xref rid="B16" ref-type="bibr">Hart et al., 2015</xref>), and HL60 (2076 samples) (<xref rid="B41" ref-type="bibr">Wang et al., 2014</xref>) with redundancy removed. The gRNA on-target activity was strictly restricted to experimental assay, where the cleavage efficiency was defined as the log-fold change in the measured knockout efficacy. Readouts of cleavage efficacies without in vivo (in vitro) experimental validation were excluded.</p>
        <p>Each entry in the datasets contained the 23-nt gRNA sequence, four kinds of corresponding symbolic epigenetic features, as well as numerical and binary cleavage efficacy. The epigenetic features information was obtained from ENCODE (<xref rid="B12" ref-type="bibr">Consortium, 2004</xref>), including CTCF binding information obtained from ChIP-Seq assay, H3K4me3 information from ChIP-Seq assay, chromatin accessibility information from DNase-Seq assay, and DNA methylation information from RRBS assay. Each epigenetic feature was represented by an “A-N” symbolic sequence with length of 23. Here, the presence of the epigenetic feature at a particular base position of DNA regions was denoted by “A,” and its absence was represented by “N.”</p>
        <p>Numerical cleavage efficiency of candidate gRNA was calculated using a collaborative filtering-based data normalization technique (<xref rid="B3" ref-type="bibr">Badaro et al., 2013</xref>). In particular, a matrix Y was formulated where each row denoted the experiments and each column represented one gRNA. <italic>y<sub>mn</sub></italic> represented the n-th gRNA on-target cleavage efficacy in the m-th experiment. Normalized numerical gRNA on-target efficiency value was defined as</p>
        <disp-formula>
          <label>(1)</label>
          <mml:math id="M1">
            <mml:mrow>
              <mml:msub>
                <mml:mi>y</mml:mi>
                <mml:mrow>
                  <mml:mi>n</mml:mi>
                  <mml:mi>o</mml:mi>
                  <mml:mi>r</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mo>=</mml:mo>
              <mml:msub>
                <mml:mi>y</mml:mi>
                <mml:mrow>
                  <mml:mi>m</mml:mi>
                  <mml:mi>n</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mo>−</mml:mo>
              <mml:mo stretchy="false">(</mml:mo>
              <mml:msub>
                <mml:mi>m</mml:mi>
                <mml:mrow>
                  <mml:mi>r</mml:mi>
                  <mml:mi>o</mml:mi>
                  <mml:mi>w</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mo>+</mml:mo>
              <mml:msub>
                <mml:mi>m</mml:mi>
                <mml:mrow>
                  <mml:mi>c</mml:mi>
                  <mml:mi>o</mml:mi>
                  <mml:mi>l</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mo>+</mml:mo>
              <mml:msub>
                <mml:mi>m</mml:mi>
                <mml:mrow>
                  <mml:mi>a</mml:mi>
                  <mml:mi>l</mml:mi>
                  <mml:mi>l</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mo stretchy="false">)</mml:mo>
              <mml:mo stretchy="false">/</mml:mo>
              <mml:mn>3</mml:mn>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>where <italic>m<sub>row</sub></italic> denoted the mean value for each row, <italic>m<sub>col</sub></italic> represented the mean value for each column, and <italic>m<sub>all</sub></italic> denoted the mean value of Y. Next, a rank-based normalization method (<xref rid="B14" ref-type="bibr">Doench et al., 2016</xref>) was applied for gRNAs within each gene, and these normalized ranks were averaged across cell types, then were rescaled in [0, 1], where 1 indicated the successful on-target cleavage efficacy. The binary cleavage efficiency of gRNA was determined by using a log-fold change of 1 as the cut off, where 1 and 0 represented the high-efficiency and low-efficiency gRNAs, respectively. The processed datasets can be downloaded at <uri xlink:type="simple" xlink:href="https://github.com/bm2-lab/DeepCRISPR">https://github.com/bm2-lab/DeepCRISPR</uri>.</p>
      </sec>
    </sec>
    <sec id="s2_2">
      <title>Sequence Encoding</title>
      <p>We formulated one-hot encoding to encode gRNA sequence with 23 nucleotides in length. Each base in the sequence can be encoded as one of the four one-hot vectors [1,0,0,0], [0,1,0,0], [0,0,1,0] and [0,0,0,1]. Therefore, the 1-by-23 nucleotide sequence was represented by four binary channels: A-channel, C-channel, G-channel, and T-channel. Taking A-channel as an example, the presence of the nucleotide A at a particular base pair position was denoted by 1 and the absence of the nucleotide A was represented by 0. Consequently, each gRNA was expressed by a 4 × 23 matrix, where 23 was the length of the gRNA sequence.</p>
      <p>Analogously, epigenetic feature information including CTCF binding, H3K4me3, chromatin accessibility, and DNA methylation were represented by a 4 × 23 binary matrix. Each type of epigenetic information was denoted by a 1 × 23 matrix using “A” and “N,” with these notations meaning presence and absence of that epigenetic feature at specific position of DNA regions, respectively. To encode the epigenetic feature information, we derived a 23-length vector to encode each epigenetic feature. Thus, four epigenetic features were donated by a 4 × 23 binary matrix (see <xref ref-type="supplementary-material" rid="SM1"><bold>Figure S1</bold></xref> for an example). The encoded sequence and epigenetic matrix of gRNA were then fed into CNN-based gRNA stream and epigenetic stream sub-networks for model training and testing.</p>
    </sec>
    <sec id="s2_3">
      <title>CNN Model Structure</title>
      <p>We developed a CNN model to learn deep features of gRNA sequence and its corresponding epigenetic information (<xref ref-type="supplementary-material" rid="SM1"><bold>Figure S2</bold></xref>). The proposed CNN is composed of two branches, namely gRNA stream and epigenetic stream. These two sub-networks are structurally identical, including two one-dimensional (1D) convolution layers, two average-pooling layers, and four fully connected layers.</p>
      <p>Taking gRNA stream as an example, the input is a 4 (size of nucleotides vocabulary) × 23 (sequence length) binary matrix. The first layer of the sub-network is a 1D convolution layer (conv_1), which is designed for extracting the important local features between neighboring element values of gRNA sequence information using 256 convolution kernels of size 5. Rectified linear unit (ReLU) (<xref rid="B27" ref-type="bibr">Krizhevsky et al., 2012</xref>) is used as the activation function to the convolution outputs.</p>
      <p>The second layer is a local average pooling layer (pool_1) with window size of 2 connected with the outputs of previous layer for down-sampling. Each of the average-pooling windows only outputs the average value of its respective convolution layer outputs.</p>
      <p>The structures of the following convolution layer (conv_2) and average pooling layer (pool_2) are identical with the first (conv_1) and second (pool_1) layers mentioned above. After being flatten, the features are followed by four fully connected layers (fc_1, fc_2, fc_3 and fc_4) with the sizes of 256, 128, 64, and 40, respectively. We used dropout for model regularization to avoid overfitting.</p>
      <p>The feature maps of the fourth fully connected layer from both gRNA and epigenetic branches are concatenated by the “concatenate” operator. Subsequently, the outputs of the concatenation layer are input to the last fully connected layer of the merged CNN network. The final output layer consists of one neuron corresponding to a regression score that highly correlates with gRNA activity. The loss function for our CNN is mean squared error (MSE) which was adapted in a previous study (<xref rid="B24" ref-type="bibr">Kim et al., 2018</xref>). We chose MSE because it is a good measure to prevent undesired outliers in the dataset.</p>
    </sec>
    <sec id="s2_4">
      <title>Hybrid CNN-SVR Model</title>
      <p>We next proposed a network combining CNN and SVR called CNN-SVR to provide a data-driven and deep learning method for CRISPR/Cas9 gRNA activity prediction. For cell line-specific prediction, CNN-SVR receives a 23-nt gRNA sequence and four “A-N” symbolic epigenetic sequences with length of 23 as inputs, and it produces a regression score of gRNA on-target cleavage efficacy. Compared with machine learning-based methods that rely heavily on hand-crafted features, CNN-SVR can get rid of the dependence on manual feature engineering. The basic flowchart of CNN-SVR consists of two major stages, namely model selection and pre-training stage as well as fine-tuning and testing stage (<xref ref-type="supplementary-material" rid="SM1"><bold>Figure S3</bold></xref>). The dataset was randomly divided into two separate sets of training and testing, respectively. One-hot encoding converts the input sequences into binary representations for downstream processing.</p>
      <p>In the model selection and pre-training stage, there are mainly three steps: first, the encoded benchmark dataset is fed into the proposed CNN model for pre-training by the back-propagation algorithm. Randomized five-fold cross-validation tests are conducted to determine hyperparameters of the merged CNN model. Model with the minimum average validation loss is regarded as the base model. Second, the initial CNN extracted features are input to SVR classifier for training and evaluating. SVR (i.e., cost C, gamma, and epsilon) is optimized using a grid search approach to achieve the optimal performance. Third, a two-step strategy is employed to remove the redundancy of CNN features (see details in the section <italic>Feature Representation Optimization</italic>). The extracted low-dimensional representative feature data and their corresponding gRNA cleavage efficacy values are fed into SVR classifier for model training.</p>
      <p>In the fine-tuning and testing stage, there are mainly two steps: First, the well-trained CNN model is applied to extract features from new cell line data. Only the fourth fully connected layer of gRNA stream and epigenetic stream, and the top fully connected layer of the merged CNN are fine tuned. MSE loss function is minimized by back-propagation approach. Second, the extracted low-dimensional representative features are fed into the well-trained SVR classifier to complete the final gRNA activity prediction. <xref ref-type="fig" rid="f1"><bold>Figure 1</bold></xref> displayed the overall framework of our CNN-SVR; the procedures were described as follows:</p>
      <fig id="f1" position="float">
        <label>Figure 1</label>
        <caption>
          <p>An illustration of procedures for cell line-specific gRNA on-target activity prediction based on CNN-SVR. Here, [f_1,f_2,⋯,f_n ] is the subset of [f_1,f_2,⋯,f_80 ].</p>
        </caption>
        <graphic xlink:href="fgene-10-01303-g001"/>
      </fig>
      <list list-type="bullet">
        <list-item>
          <p>The gRNA sequence and epigenetic feature sequences are converted into two 4×23 binary matrices by one-hot encoding.</p>
        </list-item>
        <list-item>
          <p>The encoded gRNA and epigenetic sequences are fed into the well-trained CNN-based gRNA stream and epigenetic feature stream to fine-tune and extract features, respectively.</p>
        </list-item>
        <list-item>
          <p>SVR classifier is trained based on the optimal feature set. Ultimately, the well-trained SVR model assigns a prediction cleavage efficacy score for the candidate gRNA.</p>
        </list-item>
      </list>
    </sec>
    <sec id="s2_5">
      <title>Experimental Setup</title>
      <p>To evaluate feasibility of CNN-SVR for gRNA activity prediction, we conducted numerical experiments on public datasets. We implemented our algorithms using Keras (2.1.0) with Tensorflow (1.4.0) as the backend, running on Intel Core i7 CPU at 3.6 GHz with 16 GB RAM and NVIDIA 8 GB GTX 1080 GPU. The optimized parameters were tuned automatically under the Adam optimizer (<xref rid="B25" ref-type="bibr">Kingma and Ba, 2014</xref>).</p>
    </sec>
    <sec id="s2_6">
      <title>Implementation of the Hybrid CNN-SVR Model</title>
      <sec id="s2_6_1">
        <title>CNN Model Selection and Training</title>
        <p>In the proposed architecture, the distribution of each network parameter was determined empirically. The main purpose of hyperparameter optimization was to choose a set of hyperparameters for a deep architecture, usually with the goal of optimizing performance of the architecture on an independent dataset. Grid search from the Scikit-learn Python library was adopted to tune the hyperparameters of the proposed architectures. Hyperparameter optimization experiments were performed sequentially as follows: the network weight initialization over the choice (“zero,” “he_uniform,” “uniform,” “glorot_uniform,” “lecun_uniform,” “normal,” “he_normal”), dropout regularization over the choice (0.2, 0.3, 0.4, 0.5, 0.6), batch size over the choice (64, 128, 256, 512), and number of epochs over the choice (50, 100, 200, 300).</p>
        <p>All the constructed neural network models were trained and validated on the benchmark dataset (180512 samples). We randomly assigned the samples of the no-redundant dataset with 80% of samples for training and 20% of samples for testing with five-fold cross-validation in the training phase. Cross-validation contributed to avoiding overfitting and guaranteeing the accuracy of our model in which the datasets were divided into five equal parts randomly. In each training, one part was regarded as the testing dataset, while the remaining four parts were taken as the training dataset. Thus, we obtained 115528 training samples, 28881 validation samples, and 36103 testing samples, respectively. Separate training and validation data were applied to train the model, while the test data was used to evaluate the performance of the trained model. We chose the model that showed the minimum average validation loss as the final CNN model. After optimization, the hyperparameters were as follows: kernel_initializer: glorot_uniform; batch size: 256; epoch: 200; dropout: 0.3 (keeping 70% of the connections).</p>
      </sec>
      <sec id="s2_6_2">
        <title>SVR Training and Testing</title>
        <p>Next, CNN extracted features were fed into the SVR classifier. We implemented the SVR algorithm in Scikit-learn library. Grid search procedure was performed to find the optimal penalty parameter C, kernel parameter gamma, and epsilon. For training SVR with Gaussian radial basis kernel (RBF) classifier, grid search range of each parameter was as follows: cost C from the choice (1.0,1.1,⋯,1.9), kernel coefficient gamma over the choice (0.11,0.12,⋯,0.15), epsilon from the choice (0.08,0.09,⋯,0.12). We selected the parameters that maximized the maximum average area under ROC curve (AUROC) value as the final parameters of SVR classifier. The optimized parameters of the SVR were as follows: C was 1.7, gamma was 0.12, epsilon was 0.11. These parameters were then used to train the CNN-SVR model.</p>
      </sec>
      <sec id="s2_6_3">
        <title>Feature Representation Optimization</title>
        <p>Considering that CNN extracted features might introduce redundancy which can undermine model performance, we employed a two-step feature optimization strategy to identify important feature subsets from the initial CNN features. To be specific, we first applied random forest to the learnt feature representation from well-trained CNN model and obtained the ranked feature list based on information gain (<xref rid="B30" ref-type="bibr">Liaw and Wiener, 2002</xref>). We trained the random forest model with 250 decision trees using Scikit-learn. The feature importance distribution of the top 20 features based on their importance scores was illustrated in <xref ref-type="supplementary-material" rid="SM1"><bold>Figure S4</bold></xref>. As can be seen, the seventeenth feature of CNN extracted initial features was the most predictive feature. Second, the sequential forward search (SFS) (<xref rid="B43" ref-type="bibr">Whitney, 2006</xref>) was performed to determine the optimal feature set. We gradually added features from random forest feature rank from higher score (lower rank) to lower score (higher rank) to reconstruct the SVR models. The feature subset with the relatively higher value of AUROC was regarded as the optimal feature set. We used the AUROC since it is a good indicator to evaluate the real performance of models. We noted that, when the feature number reached at 13, the model achieved the maximum AUROC of 0.9769. Hence, the top 13 features (i.e., “feat_17,” “feat_26,” “feat_9,” “feat_19,” “feat_30,” “feat_6,” “feat_12,” “feat_39,” “feat_36,” “feat_21,” “feat_22,” “feat_3,” “feat_25”) in the random forest rank list were integrated into SVR classifier to train the prediction scheme. Here, “feat_17” means the 17th feature of CNN extracted initial features (total 80 features). Thereby, we carried out the determined hyperparameters by integrating the optimal features on the benchmark dataset under five-fold cross-validation to obtain the well-trained CNN-SVR model. The training data, validation data, and testing data were built consistent with the above mentioned data partitioning way in the <italic>CNN Model Selection and Training</italic> section. The well-trained CNN-SVR reached an overall Spearman correlation of 0.952, AUROC value of 0.977.</p>
      </sec>
      <sec id="s2_6_4">
        <title>Transfer Learning for New Cell Line Specific Prediction</title>
        <p>In this section, we proposed a fine-tune strategy by borrowing information from the benchmark data, aiming at boosting the prediction performance on small sample size cell line-specific data. To this end, four above cell-line datasets were combined together for model training and testing. We constructed the training, validation, and test data from total four datasets based on gRNA sequence composition and epigenetic feature information. The training data (13401 samples) and test data (3748 samples) were also generated in the same way in the <italic>CNN Model Selection and Training</italic> section. Randomized five-fold cross-validation was implemented in the training phase.</p>
        <p>Considering training a full CNN network with small number of cell line data may result in overfitting, which may lead to poor performance. Transfer learning (<xref rid="B5" ref-type="bibr">Bengio, 2012</xref>) is effective to address the challenge where the learned parameters of well-trained networks on a large dataset are shared. The main idea of transfer learning is to use a pre-trained model which is trained on large dataset and to transfer its well-trained parameters (e.g. weights) to the targeted network model. Though the dataset is different from the one that the network was trained on, the lower-level features are similar. Thus, the last fully connected layers are usually trained on the new dataset. Transfer learning has been widely applied to computer vision (<xref rid="B38" ref-type="bibr">Shin et al., 2016</xref>; <xref rid="B8" ref-type="bibr">Cheng and Malhi, 2017</xref>) and achieved a valuable efficacy in terms of accuracy. We applied transfer learning from the benchmark dataset pre-trained CNN model, and fine-tuned for small sample cell line data. Note that, the low-level features between the benchmark data and cell line-specific data are similar. Therefore, we froze the convolution layers, average pooling layers and the first three fully connected layers of both gRNA stream and epigenetic stream. After borrowing weights of the well pre-trained CNN base network, we fine-tuned the weights of the last fully connected layers of both gRNA and epigenetic sub-networks and those of the merged fully connected layer to optimize the mean validation squared error loss function. During fine tuning, we only updated 5281 free parameters. By fixing the weights parameters in the other layers, CNN-SVR could prevent overfitting and effectively learn to integrate the sequence representative and epigenetic information. For any given cell line of interest, the training process was described as follows:<list list-type="bullet"><list-item><p>Pre-train a CNN model with the benchmark data for 200 epochs.</p></list-item><list-item><p>Freeze the convolution layers, average pooling layers, the first three fully connected layers (for both the gRNA stream and epigenetic stream).</p></list-item><list-item><p>Train the fourth fully connected layer of the above two streams and the top fully connected layer of the merged CNN model with training data from the cell line of interest for another 200 epochs.</p></list-item><list-item><p>Evaluate the model on the test data.</p></list-item></list></p>
      </sec>
    </sec>
    <sec id="s2_7">
      <title>Settings of Other Methods</title>
      <p>For the L1-regularized linear regression (L1), we applied LassoCV from Scikit-learn Python library to find out the optimal parameters of alpha by cross-validation. Grid searching range of regularization parameter alpha was (0.01, 0.02,⋯,0.1). Other parameters were set with default values. We achieved an optimal value of 0.01. Similarly, we applied RidgeCV and ElasticNetCV with the same grid searching range of L1 to set parameter alpha for L2-regularized linear regression (L2) and L1L2-regularized linear regression (L1L2), respectively. After optimization, the best alpha values of L2 and L1L2 were 0.04 and 0.01, respectively. These parameters were then used to train the CNN-L1, CNN-L2, and CNN-L1L2 models. Other parameters of L2 and L1L2 were set with default values.</p>
      <p>We ran the code of Seq_deepCpf1 using the same data and basic training process (downloaded from GitHub at <uri xlink:type="simple" xlink:href="https://github.com/MyungjaeSong/Paired-Library">https://github.com/MyungjaeSong/Paired-Library</uri>). Note that, the input of Seq_deepCpf1 was a 4-by-34 dimensional binary matrix. Here, we changed the input shape of Seq_deepCpf1 model into 4-by-23 to match the size of the data in this study. Besides, we used the benchmark dataset to pre-train the Seq_deepCpf1 model. To make a fair comparison, we only fine-tuned the weights parameters in the last two layers (1681 free parameters) for cell line-specific prediction. The numerical experimental condition was set consistent with DeepCRISPR. The source codes of DeepCRISPR were downloaded from <uri xlink:type="simple" xlink:href="https://github.com/bm2-lab/DeepCRISPR">https://github.com/bm2-lab/DeepCRISPR</uri>. SSC, sgRNA Designer and WU-CRISPR provided available web based applications. More details can be found in <xref ref-type="supplementary-material" rid="SM1"><bold>Table S1</bold></xref>.</p>
    </sec>
    <sec id="s2_8">
      <title>Performance Measurements</title>
      <p>To quantitatively evaluate the performance of our CNN-SVR, Spearman correlation coefficient between predicted and measured on-target activity was calculated. We chose Spearman correlation is due to it is more robust to outliers than Pearson’s correlation coefficient (<xref rid="B35" ref-type="bibr">Mukaka, 2012</xref>). Besides, it was adapted in previous studies (<xref rid="B14" ref-type="bibr">Doench et al., 2016</xref>; <xref rid="B10" ref-type="bibr">Chuai et al., 2018</xref>; <xref rid="B24" ref-type="bibr">Kim et al., 2018</xref>). Spearman correlation was calculated using SciPy library (<uri xlink:type="simple" xlink:href="http://scipy.org">http://scipy.org</uri>). In addition, AUROC was employed to comprehensively quantify the overall predictive model performance. The value of AUROC ranges from 0.5 to 1. A larger AUROC value represents that model achieves better and more robust performance. Note that, we used 0.5 AUROC as the baseline. Statistical test was performed using SciPy library for comparing the differences between GC content distributions of different datasets. Two-sample Kolmogorov–Smirnov test was used for testing the distance between two distributions under the null hypothesis that samples from the same continuous distribution. P &lt; 0.05 was considered to indicate statistically significant difference.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="s3">
    <title>Results</title>
    <sec id="s3_1">
      <title>Comparison CNN-SVR With CNN Model</title>
      <p>To verify the feasibility of our approach, we compared our CNN-SVR with CNN model on the above four cell-line datasets. The current practice of training a model was to use cell-line specific data for prediction. Each data set was randomly split into a training set and an independent testing set with 80% and 20% classes. <xref rid="T1" ref-type="table"><bold>Table 1</bold></xref> summarized the results regarding evaluation criteria including Spearman correlation and AUROC under 10-round 10-fold cross-validation tests. CNN-SVR showed substantially better performance in terms of Spearman correlation. As for AUROC, CNN-SVR was superior to CNN on datasets HEK293T, HELA, and HL60. These results showed that CNN-SVR is more predictive than CNN for gRNA on-target activity, further conforming the feasibility and effectiveness of the combination of CNN and SVR classifier.</p>
      <table-wrap id="T1" position="float">
        <label>Table 1</label>
        <caption>
          <p>Performance comparison between CNN-SVR and CNN models for gRNA activity prediction on four cell-line datasets under 10-time 10-fold cross-validation.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" rowspan="2" colspan="1">Model</th>
              <th valign="top" rowspan="1" colspan="1">CNN-SVR</th>
              <th valign="top" rowspan="1" colspan="1">CNN</th>
              <th valign="top" rowspan="1" colspan="1">CNN-SVR</th>
              <th valign="top" rowspan="1" colspan="1">CNN</th>
            </tr>
            <tr>
              <th valign="top" align="center" colspan="2" rowspan="1">Spearman</th>
              <th valign="top" align="center" colspan="2" rowspan="1">AUROC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" rowspan="1" colspan="1">HCT116</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.719 ± 0.008</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.661 ± 0.030</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.933 ± 0.001</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.932 ± 0.001</td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">HEK293T</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.807 ± 0.016</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.725 ± 0.029</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.983 ± 0.002</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.972 ± 0.001</td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">HELA</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.699 ± 0.006</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.702 ± 0.007</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.933 ± 0.001</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.916 ± 0.001</td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">HL60</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.589 ± 0.006</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.576 ± 0.040</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.934 ± 0.003</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.914 ± 0.003</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>Performance is shown as mean ± standard deviation. This representation also applies to <xref rid="T2" ref-type="table"><bold>Table 2</bold></xref>. The best performance across different folds cross-validation method is highlighted in bold for clarification. These highlights also apply to <xref rid="T2" ref-type="table"><bold>Tables 2</bold></xref> to <xref rid="T4" ref-type="table"><bold>4</bold></xref> and <xref ref-type="supplementary-material" rid="SM1"><bold>Tables S3</bold></xref> to <xref ref-type="supplementary-material" rid="SM1"><bold>S5</bold></xref>.</p>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="s3_2">
      <title>Comparison of Various CNN Combined Regression Models</title>
      <p>We then attempted to access the regression performance of CNN-SVR. To this end, we compared CNN-SVR with three CNNs plus regression approaches, including CNN plus L1 (CNN-L1), CNN plus L2 (CNN-L2), and CNN plus L1L2 (CNN-L1L2) on the above four cell lines datasets. Note that for each cell line, the training data and test data were generated in the same way as described in the section <italic>Comparison CNN-SVR With CNN Model</italic>. Ten-time 10-fold cross-validation tests were randomly performed and the average of the individual performance were summarized in <xref rid="T2" ref-type="table"><bold>Table 2</bold></xref>. Overall, CNN-SVR performed better than CNNs with different regression methods on all datasets. These observations revealed that the regression learning performance of our SVR surpasses other regression methods on gRNA activity prediction.</p>
      <table-wrap id="T2" position="float">
        <label>Table 2</label>
        <caption>
          <p>Performance comparison of CNN-SVR and different CNNs combined regression models for gRNA activity prediction on four cell-line datasets under 10-time 10-fold cross-validation.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="center" rowspan="1" colspan="1">Model</th>
              <th valign="top" align="center" rowspan="1" colspan="1">HCT116</th>
              <th valign="top" align="center" rowspan="1" colspan="1">HEK293T</th>
              <th valign="top" align="center" rowspan="1" colspan="1">HELA</th>
              <th valign="top" align="center" rowspan="1" colspan="1">HL60</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" colspan="5" rowspan="1">
                <bold>(A) Spearman correlation</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">CNN-SVR</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.719 ± 0.008</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.807 ± 0.016</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.699± 0.006</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.589± 0.006</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">CNN-L1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.712± 0.010</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.793 ± 0.004</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.633± 0.020</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.542± 0.033</td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">CNN-L2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.670± 0.025</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.731 ± 0.032</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.683± 0.009</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.517± 0.034</td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">CNN-L1L2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.701± 0.008</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.803 ± 0.012</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.682± 0.005</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.589± 0.018</td>
            </tr>
            <tr>
              <td valign="top" colspan="5" rowspan="1">
                <bold>(B) AUROC</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">CNN-SVR</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.933 ± 0.001</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.983 ± 0.002</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.933 ± 0.001</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.934 ± 0.003</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">CNN-L1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.931 ± 0.001</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.982 ± 0.001</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.924 ± 0.002</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.930 ± 0.003</td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">CNN-L2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.919± 0.002</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.975 ± 0.002</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.923± 0.002</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.895± 0.008</td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">CNN-L2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.918± 0.003</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.977 ± 0.001</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.915± 0.002</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.912± 0.004</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>The tables from top to bottom respectively record the Spearman correlation and AUROC of CNN-SVR and three CNN combined regression methods.</p>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="s3_3">
      <title>Comparison With State-Of-the-Art Methods</title>
      <p>To validate the performance of proposed CNN-SVR, we compared it with one deep learning-based method (DeepCRISPR) and three machine learning methods including sgRNA Designer, SSC, and WU-CRISPR (<xref ref-type="supplementary-material" rid="SM1"><bold>Table S2</bold></xref>). Note that Seq-deepCpf1 only allows for receiving gRNA sequence as input. So, this approach was not compatible with other methods when considering both gRNA sequence and epigenetic information. To make a fair comparison, we trained CNN-SVR model based on the training data strictly consistent with other methods. The above four datasets were used for performance evaluation. For each cell line, the training and test data were constructed in the same way as described in the section <italic>Comparison CNN-SVR With CNN Model</italic>. For any given cell line of interest, the training data was built by integrating all the training data from four cell lines. The performance was evaluated on each cell line-specific testing set, respectively.</p>
      <p>On the whole, CNN-SVR achieved the highest average Spearman correlation (<xref ref-type="fig" rid="f2"><bold>Figure 2A</bold></xref>). Specifically, CNN-SVR exhibited better Spearman correlation on three datasets (i.e., Total, HCT116, HELA and HL60), whereas for dataset HEK293T, it performed slightly worse than DeepCRISPR. <xref ref-type="fig" rid="f2"><bold>Figure 2B</bold></xref> illustrated the performance in terms of AUROC. Some interesting conclusions can be extracted from this figure. First, deep learning models were superior to machine learning methods. Second, CNN-SVR exhibited better predictive power than another deep learning model DeepCRISPR. The details of their performance can be found in <xref ref-type="supplementary-material" rid="SM1"><bold>Table S3</bold></xref>. To sum up, these observations indicated that CNN-SVR outperforms the compared state-of-the-art methods for predicting gRNA on-target activity.</p>
      <fig id="f2" position="float">
        <label>Figure 2</label>
        <caption>
          <p>Performance comparison of CNN-SVR and other prediction models on various testing cell line data.</p>
        </caption>
        <graphic xlink:href="fgene-10-01303-g002"/>
      </fig>
    </sec>
    <sec id="s3_4">
      <title>Assessment of Generalization Performance With a Leave-One-Cell-Out Procedure</title>
      <p>Next, we investigated the generalizability ability of CNN-SVR in new cell types. For this purpose, we took turns to test the model on the above four cell-line datasets using a leave-one-cell-out approach. The training data and test data for each cell line were built in advance. Note that, the partitioning method for each cell line data followed the way illustrated in the section <italic>Comparison CNN-SVR With CNN Model</italic> In the training phase, for a given cell line to be predicted, we just used the training data from all other three cell lines (lacking training data of given cell-line of interest). In the testing stage, we evaluated the performance on the test data of the given cell-line of interest. Taking leave-HCT116-out procedure as an example, we trained the model by combining training data of HEK293T, HELA and HL60 cell lines (without HCT116 cell line training data), and evaluated the model on HCT116 cell line testing set. For fair comparison, we tested the proposed CNN-SVR under the same condition with DeepCRISPR, sgRNA Designer, SSC, and WU-CRISPR on the four cell-line datasets.</p>
      <p>As can be seen from <xref ref-type="fig" rid="f3"><bold>Figure 3A</bold></xref>, among the compared models, CNN-SVR exhibited the best predictive power, with average Spearman correlation of 0.714. Compared with DeepCRISPR, which was one of the best state-of-the-art approaches, CNN-SVR showed superior performance on all datasets except for dataset HCT116. DeepCRISPR got comparable performance with CNN-SVR on HCT116 dataset. Furthermore, CNN-SVR outperformed other methods on all datasets in terms of AUROC (<xref ref-type="fig" rid="f3"><bold>Figure 3B</bold></xref>). Together, these results demonstrated the excellent generalizability of CNN-SVR. More details of the performance can be found in <xref ref-type="supplementary-material" rid="SM1"><bold>Table S4</bold></xref>.</p>
      <fig id="f3" position="float">
        <label>Figure 3</label>
        <caption>
          <p>Performance comparison of CNN-SVR and other prediction models on various testing cell line data with a leave-one-cell-out procedure.</p>
        </caption>
        <graphic xlink:href="fgene-10-01303-g003"/>
      </fig>
    </sec>
    <sec id="s3_5">
      <title>Evaluation of Robustness of Prediction Models</title>
      <p>In this section, we aimed to compare the robustness of the above methods. To this end, we examined the changes between Spearman correlation and AUROC values obtained by training with four cell datasets (<xref ref-type="fig" rid="f2"><bold>Figure 2</bold></xref>) and those produced by the leave-one-cell-out approach (<xref ref-type="fig" rid="f3"><bold>Figure 3</bold></xref>). For each evaluation criterion, we calculated the difference of each model by subtracting the results of training with leave-one-cell-out (<xref ref-type="supplementary-material" rid="SM1"><bold>Table S4</bold></xref>) from the cell-line independent (<xref ref-type="supplementary-material" rid="SM1"><bold>Table S3</bold></xref>). Taking CNN-SVR as an example, the AUROC difference of HCT116 dataset was calculated as follows:</p>
      <disp-formula>
        <label>(2)</label>
        <mml:math id="M2">
          <mml:mrow>
            <mml:mi mathvariant="bold">Δ</mml:mi>
            <mml:msub>
              <mml:mi mathvariant="bold">AUROC</mml:mi>
              <mml:mrow>
                <mml:mi mathvariant="bold-italic">CNN</mml:mi>
                <mml:mo>−</mml:mo>
                <mml:mi mathvariant="bold-italic">SVR</mml:mi>
              </mml:mrow>
            </mml:msub>
            <mml:mo>=</mml:mo>
            <mml:mn mathvariant="bold">0.936</mml:mn>
            <mml:mo>−</mml:mo>
            <mml:mn mathvariant="bold">0.939</mml:mn>
            <mml:mo>=</mml:mo>
            <mml:mo>−</mml:mo>
            <mml:mn mathvariant="bold">0.003</mml:mn>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>where “ΔAUROC” means the difference value of AUROC. It can be seen that our CNN-SVR substantially showed smaller changes than DeepCRISPR in terms of the above mentioned two evaluation measures (<xref rid="T3" ref-type="table"><bold>Table 3</bold></xref>). Interestingly, we observed that the performance of DeepCRISPR on dataset HEK293T using the whole training set was significantly better than that by leave-one-cell-out approach (with Spearman correlation difference value of 0.805, AUROC difference value of 0.455). Previous studies have shown that gRNAs with low or high GC content tended to be less active (<xref rid="B13" ref-type="bibr">Doench et al., 2014</xref>; <xref rid="B41" ref-type="bibr">Wang et al., 2014</xref>). We analyzed GC content of the four cell datasets. As expected, dataset HEK293T has the lowest GC content (vs. dataset HCT116, P=1.35E-52; vs. dataset HELA, P=1.14E-69, vs. dataset HL60, P=1.45E-07, two-sample Kolmogorov-Smirnov test, <xref ref-type="supplementary-material" rid="SM1"><bold>Figure S5</bold></xref>).</p>
      <table-wrap id="T3" position="float">
        <label>Table 3</label>
        <caption>
          <p>The differences of Spearman correlation and AUROC between independent test and a leave-one-cell-out approach between CNN-SVR and DeepCRISPR.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="center" rowspan="1" colspan="1">Model</th>
              <th valign="top" align="center" rowspan="1" colspan="1">HCT116</th>
              <th valign="top" align="center" rowspan="1" colspan="1">HEK293T</th>
              <th valign="top" align="center" rowspan="1" colspan="1">HELA</th>
              <th valign="top" align="center" rowspan="1" colspan="1">HL60</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" colspan="5" rowspan="1">
                <bold>(A) Spearman correlation</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">CNN-SVR</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>-0.017</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>-0.002</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.011</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">-0.015</td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">DeepCRISPR</td>
              <td valign="top" align="center" rowspan="1" colspan="1">-0.107</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.805</td>
              <td valign="top" align="center" rowspan="1" colspan="1">-0.043</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.012</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" colspan="5" rowspan="1">
                <bold>(B) AUROC</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">CNN-SVR</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>-0.003</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>-0.001</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>-0.008</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>-0.045</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">DeepCRISPR</td>
              <td valign="top" align="center" rowspan="1" colspan="1">-0.045</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.455</td>
              <td valign="top" align="center" rowspan="1" colspan="1">-0.038</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.096</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="s3_6">
      <title>Effect of Epigenetic Features on gRNA Cleavage Efficacy</title>
      <p>In this section, we determined whether cell line-specific epigenetic features really boost the predictive performance. We examined the performance of deep learning-based methods on the four cell-line datasets only considering gRNA sequence composition and compared them with those considering both gRNA sequence and epigenetic information (see the section <italic>Assessment of Generalization Performance With a Leave-One-Cell-Out Procedure</italic>). We trained the prediction models without epigenetic information (sequence only) for each cell line with a leave-one-cell-out procedure. Note that, we trained the model just considering the gRNA stream. Other numerical experimental conditions were in accord with the section <italic>Assessment of Generalization Performance With a Leave-One-Cell-Out Procedure</italic>. For fair comparison, we compared our methods with two deep learning-based methods (i.e., DeepCRISPR and Seq-deepCpf1) only considering sequence composition.</p>
      <p><xref ref-type="fig" rid="f4"><bold>Figure 4</bold></xref> and <xref rid="T4" ref-type="table"><bold>Table 4</bold></xref> compared the prediction performance of various deep learning methods trained using different datasets. Two interesting conclusions can be drawn as below. First, CNN-SVR showed better performance compared with other models. Second, as expected, the prediction accuracies of models trained only considering sequence composition (<xref ref-type="fig" rid="f4"><bold>Figure 4A</bold></xref> and <xref rid="T4" ref-type="table"><bold>Table 4A</bold></xref>) became lower compared with those trained with both sequence and epigenetic data (<xref ref-type="fig" rid="f4"><bold>Figure 4B</bold></xref> and <xref rid="T4" ref-type="table"><bold>Table 4B</bold></xref>). To conclude, these observations confirm that cell line-specific epigenetic features contribute to gRNA activity and specificity. More details of their performance of Spearman correlation can be found in <xref ref-type="supplementary-material" rid="SM1"><bold>Table S5</bold></xref>.</p>
      <fig id="f4" position="float">
        <label>Figure 4</label>
        <caption>
          <p>Spearman correlation between different deep learning-based models and datasets. Models considering <bold>(A)</bold> gRNA sequence composition only and <bold>(B)</bold> both gRNA sequence and epigenetic information.</p>
        </caption>
        <graphic xlink:href="fgene-10-01303-g004"/>
      </fig>
      <table-wrap id="T4" position="float">
        <label>Table 4</label>
        <caption>
          <p>AUROC of different deep learning-based methods by considering gRNA sequence only and incorporating both gRNA sequence and epigenetic features.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="center" rowspan="1" colspan="1">Model</th>
              <th valign="top" align="center" rowspan="1" colspan="1">HCT116</th>
              <th valign="top" align="center" rowspan="1" colspan="1">HEK293T</th>
              <th valign="top" align="center" rowspan="1" colspan="1">HELA</th>
              <th valign="top" align="center" rowspan="1" colspan="1">HL60</th>
              <th valign="top" align="center" rowspan="1" colspan="1">Average</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" colspan="6" rowspan="1">
                <bold>(A) Sequence-only</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">CNN-SVR</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.938</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.976</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.930</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.928</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.943</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">DeepCRISPR</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.887</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.474</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.788</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.584</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.683</td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">Seq-deepCpf1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.931</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.976</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.925</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.920</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.938</td>
            </tr>
            <tr>
              <td valign="top" colspan="6" rowspan="1">
                <bold>(B) Sequence composition and epigenetic features</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">CNN-SVR</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.939</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.979</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.932</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.938</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.947</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" rowspan="1" colspan="1">DeepCRISPR</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.919</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.506</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.820</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.643</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.722</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="s3_7">
      <title>Visualizing Importance of Position-Specific Nucleotides</title>
      <p>Finally, we aimed to investigate what sequence patterns of gRNA contribute to its on-target activity. Using the method in a previous study (<xref rid="B47" ref-type="bibr">Xie et al., 2013</xref>), we investigated the feature importance of all possible position-specific nucleotides. In brief, we constructed a specific sequence and its corresponding epigenetic features to feed the well-trained CNN model and took the outputs for visualization. More details can be found in <xref ref-type="supplementary-material" rid="SM1"><bold>Supplementary Material</bold></xref>. <xref ref-type="fig" rid="f5"><bold>Figure 5A</bold></xref> depicts the importance of all four nucleotides and epigenetic features at different positions. Several interesting results can be observed: (i) Most of the top features were generated by convolving the middle region of input matrix. (ii) Thymines are found to be disfavored at the fourth position adjacent to the PAM. The same observation was obtained by <xref rid="B10" ref-type="bibr">Chuai et al., (2018)</xref>, which is consistent with previous finding that multiple uracils in the spacer result in low gRNA expression (<xref rid="B13" ref-type="bibr">Doench et al., 2014</xref>). Another study also found that thymine in the seed sequence might destabilize interactions between the protein and crRNA (<xref rid="B23" ref-type="bibr">Kim et al., 2017</xref>). (iii) Cytosine is informative at 3-nt upstream of the PAM since the cleavage site usually resides 3 nt upstream the PAM. (iv) Our model suggests that cytosine is also preferred at position 17, which coincides with a previous finding that the cleavage is 3 nt, 4 nt or even further upstream of the PAM (<xref rid="B39" ref-type="bibr">Shou et al., 2018</xref>). (v) In general, the middle region contains more information of the epigenetic features. Notably, 3 nt upstream of the PAM has a consistent preference for opening-chromatin information of Dnase. This observation is in accordance with a previous study, which corroborates that consideration of target site accessibility can boost the accuracy of gRNA activity prediction (<xref rid="B24" ref-type="bibr">Kim et al., 2018</xref>). Besides, we presented the sequence logo to visualize the nucleotide differences on the benchmark dataset. Overall, the result is in line with our feature analysis (see <xref ref-type="fig" rid="f5"><bold>Figure 5B</bold></xref>).</p>
      <fig id="f5" position="float">
        <label>Figure 5</label>
        <caption>
          <p><bold>(A)</bold> Visualization of the importance of different nucleotides and epigenetic features at different positions for our model trained on the benchmark dataset. The colors represent the contribution of the position-specific nucleotides to determining an efficient gRNA. The x-axis shows the positions of the nucleotide in the sequence. The y-axis lists all possible nucleotides. This representation also applies to. <bold>(B)</bold> Preference of nucleotide sequences that impact CRISPR/Cas9 gRNAs activity.</p>
        </caption>
        <graphic xlink:href="fgene-10-01303-g005"/>
      </fig>
      <p>We also explored the importance of dimers. Here, by adopting the method proposed above, we generated a sequence which only contains one dimer (out of 16 possible dimers) at every position k and repeated the aforementioned process for all subsequences. The scores of all the constructed subsequences for all the positions were plotted as a heatmap in <xref ref-type="supplementary-material" rid="SM1"><bold>Figure S6</bold></xref>. We note that most of the top features were generated by convolving the region of the seed sequence of the gRNAs. This observation coincides with previous finding that a prototypical 10–12 nt PAM-proximal seed sequence largely determines target efficacy (<xref rid="B21" ref-type="bibr">Jinek et al., 2012</xref>; <xref rid="B11" ref-type="bibr">Cong et al., 2013</xref>).</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s4">
    <title>Discussion</title>
    <p>Accurate prediction of gRNA cleavage efficacy is pivotal to understanding the mechanisms of CRISPR/Cas9 system. Although computational prediction of gRNA cleavage efficiency has made much progress recently, the accuracy remains to be improved. In this study, we introduced a novel and interpretable deep learning framework named CNN-SVR for CRISPR/Cas9 gRNA on-target activity prediction. Specifically, CNN works as a trainable feature extractor and SVR performs as a gRNA cleavage efficacy predictor. Compared with CNN and three CNNs combined regression-based algorithms, CNN-SVR achieved the best performance. CNN-SVR could not only automatically extract gRNA sequence and the corresponding epigenetic features using the CNN, but also improve the generalization ability of CNN and regression accuracy.</p>
    <p>Previous studies suggested that ensemble learning (<xref rid="B45" ref-type="bibr">Woźniak et al., 2014</xref>) by incorporating multiple neural networks together can achieve higher accuracy than a single learner (<xref rid="B32" ref-type="bibr">Maqsood et al., 2004</xref>). Inspired by this, instead of using a single convolution network to train the feature vectors of gRNA like Seq-deepCpf1, we merged two sub-networks (i.e., gRNA stream and epigenetic stream) to train gRNA sequence and its corresponding epigenetic information. In addition, the architecture of the proposed sub-networks was considerably shallower than DeepCRISPR. Compared with several current state-of-the-art learning-based methods, CNN-SVR can effectively exploit deep features of gRNA sequences. Experimental results demonstrated the power of our CNN-SVR for CRISPR/Cas9 gRNA activity prediction.</p>
    <p>Besides, we found our CNN-SVR system has good generalizability in new cell types by using leave-one-cell-out approach on the four testing datasets. By analyzing the changes of prediction results with and without considering epigenetic information, we observed that considering of epigenetic features slightly improves the accuracy of CRISPR/Cas9 gRNA activity prediction. This result was consistent with previous studies (<xref rid="B7" ref-type="bibr">Chen et al., 2017</xref>; <xref rid="B10" ref-type="bibr">Chuai et al., 2018</xref>; <xref rid="B24" ref-type="bibr">Kim et al., 2018</xref>). Chuai et al. found that the prediction on HEK293T became poor (<xref rid="B10" ref-type="bibr">Chuai et al., 2018</xref>). They speculated that it was mainly due to the insufficient training data of the HEK293T training dataset. Note that our findings suggested that the reducing epigenetic features may be one possible explanation for the observation. Additionally, the low GC content of dataset HEK293T may be another possible explanation. We concluded that our CNN-SVR gained better generalization and robustness than DeepCRISPR.</p>
    <p>Our model focused on gRNA sequence and four kinds of epigenetic features for CRISPR/Cas9 on-target prediction. A recent study on protein-related prediction has shown that integration of other manual extracted features, such as molecular weight and hydrophobicity into the deep learning model could improve the predictive power (<xref rid="B42" ref-type="bibr">Wang et al., 2016</xref>). It has been reported that GC content is associated with gRNA activity (<xref rid="B13" ref-type="bibr">Doench et al., 2014</xref>; <xref rid="B41" ref-type="bibr">Wang et al., 2014</xref>). We thus made a preliminary exploration of adding this sequence-derived feature with our CNN-SVR for gRNA activity prediction on the above four datasets. Note that, the training data and test data were constructed in the same way as described in the section <italic>Comparison CNN-SVR With CNN Model</italic>. Overall, addition of GC content to CNN-SVR increased the predictive ability, with Spearman correlation coefficients of 0.645, 0.656 and 0.608 on datasets HCT116, HELA and HELA, respectively. Detailed results can be found in <xref ref-type="supplementary-material" rid="SM1"><bold>Table S6</bold></xref>. Therefore, manual design of proper gRNA features will contribute to the prediction ability. In the future, we plan to develop deep learning models incorporating indirect sequence-derived sequence features to improve the prediction performance, such as chromatin accessibility (<xref rid="B24" ref-type="bibr">Kim et al., 2018</xref>), RNA thermodynamics (<xref rid="B2" ref-type="bibr">Abadi et al., 2017</xref>), secondary structure of gRNA (<xref rid="B2" ref-type="bibr">Abadi et al., 2017</xref>), and GC content, which cannot be automatically obtained by deep learning models.</p>
    <p>Visualization method was applied to our model. Note that the PAM and the core region (1-5 nt adjacent to the PAM) are very important for gRNA target efficacy. However, we observed that the most top features were generated by convolving the middle region of the input matrix. Therefore, we believe expanding the upstream and downstream of the target sequence in a proper length can enhance the generalization performance of the model. For example, Kim et al. found 34 bp (4 bp + PAM + 23bp protospacer + 3bp) was adequate as the input sequence of their models in CRISPR/Cpf1 system (<xref rid="B24" ref-type="bibr">Kim et al., 2018</xref>).</p>
    <p>Several future improvements are expected. First, in the present study, taking advantage of CNN and SVR, we designed the relative concise hybrid CNN-SVR architecture. Research on the deep learning-based model for CRISPR/Cas9 system gRNA cleavage efficiency prediction is still at an early stage. Numerous complex and modern deep learning models await exploration. Second, as pre-training technique has great influence on the final predictive performance, therefore critical to know on what a model was trained before use. In general, sequencing-based models are more general applicable, but are only capable of predicting the genotype changes rather than functional result. On the contrary, phenotypic trained models are fit for recognizing target sites that cause functional changes but limited to numerical experiments with the same condition as the training set. However, the amount of available gRNA knockout data is relatively small, which provides a big challenge for training the deep learning model. Consequently, appropriate data augmentation techniques are needed to increase the training sample size. Third, reasonable encoding schemes, which provide maximum biological characteristics information as well as reducing the compute costs, will boost the CRISPR/Cas9 gRNA activity prediction accuracy. Finally, it is possible that integration of manual extracted features associated with gRNA activity can also improve predictive power of deep learning models.</p>
  </sec>
  <sec sec-type="conclusions" id="s5">
    <title>Conclusions</title>
    <p>In this study, we present CNN-SVR, an efficient and extendable method to automatically learn the sequence features for CRISPR/Cas9 gRNA activity prediction. We adopt a merged CNN architecture for gRNA and its corresponding epigenetic features extraction, and subsequently incorporate SVR classifier to predict gRNA cleavage efficiency. Compared with CNN, two state-of-the-art deep neural network based models (e.g. DeepCRISPR and Seq-deepCpf1) and three machine learning tools (i.e., sgRNA Designer, SSC, and WU-CRISPR), CNN-SVR can effectively exploit features interactions from feed-forward directions to learn deeper features of gRNAs and their corresponding epigenetic features. Experimental results on the published datasets demonstrate the superiority of our CNN-SVR for CRISPR/Cas9 gRNAs on-target activity prediction.</p>
  </sec>
  <sec sec-type="data-availability" id="s6">
    <title>Data Availability Statement</title>
    <p>Publicly available datasets were analyzed in this study. This data can be found here: <uri xlink:type="simple" xlink:href="https://github.com/Peppags/CNN-SVR">https://github.com/Peppags/CNN-SVR</uri>.</p>
  </sec>
  <sec id="s7">
    <title>Author Contributions</title>
    <p>All authors contributed to the project design. GZ wrote the analysis source code, analyzed the data, and drafted the full manuscript. ZD and XD critically revised the final manuscript. All authors read and approved the final manuscript.</p>
  </sec>
  <sec sec-type="funding-information" id="s8">
    <title>Funding</title>
    <p>This research was funded by the National Natural Science Foundation of China (NSFC) (Grant 61872396, 61872395 and U1611265), and also by Pearl River Nova Program of Guangzhou (201710010044).</p>
  </sec>
  <sec id="s9">
    <title>Conflict of Interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
</body>
<back>
  <sec sec-type="supplementary-material" id="s10">
    <title>Supplementary Material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fgene.2019.01303/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/fgene.2019.01303/full#supplementary-material</ext-link></p>
    <supplementary-material content-type="local-data" id="SM1">
      <media xlink:href="DataSheet_1.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Aach</surname><given-names>J.</given-names></name><name><surname>Mali</surname><given-names>P.</given-names></name><name><surname>Church</surname><given-names>G. M.</given-names></name></person-group> (<year>2014</year>). <article-title>CasFinder: flexible algorithm for identifying specific Cas9 targets in genomes</article-title>. <source>BioRxiv</source>, <elocation-id>005074</elocation-id>. <pub-id pub-id-type="doi">10.1101/005074</pub-id>
</mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abadi</surname><given-names>S.</given-names></name><name><surname>Yan</surname><given-names>W. X.</given-names></name><name><surname>Amar</surname><given-names>D.</given-names></name><name><surname>Mayrose</surname><given-names>I.</given-names></name></person-group> (<year>2017</year>). <article-title>A machine learning approach for predicting CRISPR-Cas9 cleavage efficiencies and patterns underlying its mechanism of action</article-title>. <source>PloS Comput. Biol.</source>
<volume>13</volume> (<issue>10</issue>), <elocation-id>e1005807</elocation-id>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005807</pub-id>
<pub-id pub-id-type="pmid">29036168</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Badaro</surname><given-names>G.</given-names></name><name><surname>Hajj</surname><given-names>H.</given-names></name><name><surname>El-Hajj</surname><given-names>W.</given-names></name><name><surname>Nachman</surname><given-names>L.</given-names></name></person-group> (<year>2013</year>). “<article-title>A hybrid approach with collaborative filtering for recommender systems</article-title>,” in: <conf-name>2013 9th International Wireless Communications and Mobile Computing Conference (IWCMC)</conf-name> (<publisher-name>Publisher: IEEE</publisher-name>), pp. <fpage>349</fpage>–<lpage>354</lpage>. <pub-id pub-id-type="doi">10.1109/IWCMC.2013.6583584</pub-id>
</mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrangou</surname><given-names>R.</given-names></name><name><surname>Fremaux</surname><given-names>C.</given-names></name><name><surname>Deveau</surname><given-names>H.</given-names></name><name><surname>Richards</surname><given-names>M.</given-names></name><name><surname>Boyaval</surname><given-names>P.</given-names></name><name><surname>Moineau</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2007</year>). <article-title>CRISPR provides acquired resistance against viruses in Prokaryotes</article-title>. <source>Science</source>
<volume>315</volume> (<issue>5819</issue>), <fpage>1709</fpage>–<lpage>1712</lpage>. <pub-id pub-id-type="doi">10.1126/science.1138140</pub-id>
<pub-id pub-id-type="pmid">17379808</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bengio</surname><given-names>Y.</given-names></name></person-group> (<year>2012</year>). “<article-title>Deep learning of representations for unsupervised and transfer learning</article-title>,” in: <conf-name>Proceedings of ICML workshop on unsupervised and transfer learning</conf-name>, <source>Conferences sand Proceedings.</source> pp. <fpage>17</fpage>–<lpage>36</lpage>.</mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chari</surname><given-names>R.</given-names></name><name><surname>Mali</surname><given-names>P.</given-names></name><name><surname>Moosburner</surname><given-names>M.</given-names></name><name><surname>Church</surname><given-names>G. M.</given-names></name></person-group> (<year>2015</year>). <article-title>Unraveling CRISPR-Cas9 genome engineering parameters via a library-on-library approach</article-title>. <source>Nat. Methods</source>
<volume>12</volume> (<issue>9</issue>), <fpage>823</fpage>–<lpage>826</lpage>. <pub-id pub-id-type="doi">10.1038/nmeth3473</pub-id>
<pub-id pub-id-type="pmid">26167643</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>L.</given-names></name><name><surname>Wang</surname><given-names>S. P.</given-names></name><name><surname>Zhang</surname><given-names>Y. H.</given-names></name><name><surname>Li</surname><given-names>J. R.</given-names></name><name><surname>Xing</surname><given-names>Z. H.</given-names></name><name><surname>Yang</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Identify key sequence features to improve CRISPR sgRNA efficacy</article-title>. <source>IEEE Access</source>
<volume>PP</volume> (<issue>99</issue>), <fpage>1</fpage>–<lpage>1</lpage>. <pub-id pub-id-type="doi">10.1109/ACCESS.2017.2775703</pub-id>
</mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>P. M.</given-names></name><name><surname>Malhi</surname><given-names>H. S.</given-names></name></person-group> (<year>2017</year>). <article-title>Transfer learning with convolutional neural networks for classification of abdominal ultrasound images</article-title>. <source>J. Digit. Imaging</source>
<volume>30</volume> (<issue>2</issue>), <fpage>234</fpage>. <pub-id pub-id-type="doi">10.1007/s10278-016-9929-2</pub-id>
<pub-id pub-id-type="pmid">27896451</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chuai</surname><given-names>G. H.</given-names></name><name><surname>Wang</surname><given-names>Q. L.</given-names></name><name><surname>Liu</surname><given-names>Q.</given-names></name></person-group> (<year>2016</year>). <article-title>In Silico Meets In Vivo : towards computational CRISPR-based sgRNA design</article-title>. <source>Trends In Biotechnol.</source>
<volume>35</volume> (<issue>1</issue>), <fpage>12</fpage>. <pub-id pub-id-type="doi">10.1016/j.tibtech.2016.06.008</pub-id>
</mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chuai</surname><given-names>G.</given-names></name><name><surname>Ma</surname><given-names>H.</given-names></name><name><surname>Yan</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>M.</given-names></name><name><surname>Hong</surname><given-names>N.</given-names></name><name><surname>Xue</surname><given-names>D.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>DeepCRISPR: optimized CRISPR guide RNA design by deep learning</article-title>. <source>Genome Biol.</source>
<volume>19</volume> (<issue>1</issue>), <fpage>80</fpage>. <pub-id pub-id-type="doi">10.1186/s13059-018-1459-4</pub-id>
<pub-id pub-id-type="pmid">29945655</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cong</surname><given-names>L.</given-names></name><name><surname>Ran</surname><given-names>F. A.</given-names></name><name><surname>Cox</surname><given-names>D.</given-names></name><name><surname>Lin</surname><given-names>S.</given-names></name><name><surname>Barretto</surname><given-names>R.</given-names></name><name><surname>Habib</surname><given-names>N.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Multiplex genome engineering using CRISPR/Cas systems</article-title>. <source>Science</source>
<volume>339</volume> (<issue>6121</issue>), <fpage>819</fpage>–<lpage>823</lpage>. <pub-id pub-id-type="doi">10.1126/science.1231143</pub-id>
<pub-id pub-id-type="pmid">23287718</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Consortium</surname><given-names>E. P.</given-names></name></person-group> (<year>2004</year>). <article-title>The ENCODE (ENCyclopedia Of DNA Elements) Project</article-title>. <source>Science</source>
<volume>306</volume> (<issue>5696</issue>), <fpage>636</fpage>–<lpage>640</lpage>. <pub-id pub-id-type="doi">10.1126/science.1105136</pub-id>
<pub-id pub-id-type="pmid">15499007</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doench</surname><given-names>J. G.</given-names></name><name><surname>Hartenian</surname><given-names>E.</given-names></name><name><surname>Graham</surname><given-names>D. B.</given-names></name><name><surname>Tothova</surname><given-names>Z.</given-names></name><name><surname>Hegde</surname><given-names>M.</given-names></name><name><surname>Smith</surname><given-names>I.</given-names></name><etal/></person-group> (<year>2014</year>). <article-title>Rational design of highly active sgRNAs for CRISPR-Cas9-mediated geneinactivation</article-title>. <source>Nat. Biotechnol.</source>
<volume>32</volume> (<issue>12</issue>), <fpage>1262</fpage>. <pub-id pub-id-type="doi">10.1038/nbt3026</pub-id>
<pub-id pub-id-type="pmid">25184501</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doench</surname><given-names>J. G.</given-names></name><name><surname>Fusi</surname><given-names>N.</given-names></name><name><surname>Sullender</surname><given-names>M.</given-names></name><name><surname>Hegde</surname><given-names>M.</given-names></name><name><surname>Vaimberg</surname><given-names>E. W.</given-names></name><name><surname>Donovan</surname><given-names>K. F.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>Optimized sgRNA design to maximize activity and minimize off-target effects of CRISPR-Cas9</article-title>. <source>Nat. Biotechnol.</source>
<volume>34</volume> (<issue>2</issue>), <fpage>184</fpage>. <pub-id pub-id-type="doi">10.1038/nbt3437</pub-id>
<pub-id pub-id-type="pmid">26780180</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erard</surname><given-names>N.</given-names></name><name><surname>Knott</surname><given-names>S. R. V.</given-names></name><name><surname>Hannon</surname><given-names>G. J.</given-names></name></person-group> (<year>2017</year>). <article-title>A CRISPR resource for individual, combinatorial, or multiplexed gene knockout</article-title>. <source>Mol. Cell</source>
<volume>67</volume> (<issue>2</issue>), <fpage>348</fpage>–<lpage>354 e344</lpage>. <pub-id pub-id-type="doi">10.1016/j.molcel.2017.06.030</pub-id>
<pub-id pub-id-type="pmid">28732207</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hart</surname><given-names>T.</given-names></name><name><surname>Chandrashekhar</surname><given-names>M.</given-names></name><name><surname>Aregger</surname><given-names>M.</given-names></name><name><surname>Steinhart</surname><given-names>Z.</given-names></name><name><surname>Brown</surname><given-names>K. R.</given-names></name><name><surname>MacLeod</surname><given-names>G.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>High-resolution CRISPR screens reveal fitness genes and genotype-specific cancer liabilities</article-title>. <source>Cell</source>
<volume>163</volume> (<issue>6</issue>), <fpage>1515</fpage>–<lpage>1526</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2015.11.015</pub-id>
<pub-id pub-id-type="pmid">26627737</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hinz</surname><given-names>J. M.</given-names></name><name><surname>Laughery</surname><given-names>M. F.</given-names></name><name><surname>Wyrick</surname><given-names>J. J.</given-names></name></person-group> (<year>2015</year>). <article-title>Nucleosomes inhibit Cas9 endonuclease activity in vitro</article-title>. <source>Biochemistry</source>
<volume>54</volume> (<issue>48</issue>), <fpage>7063</fpage>–<lpage>7066</lpage>. <pub-id pub-id-type="doi">10.1021/acs.biochem.5b01108</pub-id>
<pub-id pub-id-type="pmid">26579937</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horlbeck</surname><given-names>M. A.</given-names></name><name><surname>Gilbert</surname><given-names>L. A.</given-names></name><name><surname>Villalta</surname><given-names>J. E.</given-names></name><name><surname>Adamson</surname><given-names>B.</given-names></name><name><surname>Pak</surname><given-names>R. A.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>Compact and highly active next-generation libraries for CRISPR-mediated gene repression and activation</article-title>. <source>Elife</source>
<volume>5</volume>, <fpage>e19760</fpage>. <pub-id pub-id-type="doi">10.7554/eLife.19760.031</pub-id>
<pub-id pub-id-type="pmid">27661255</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hsu</surname><given-names>P. D.</given-names></name><name><surname>Scott</surname><given-names>D. A.</given-names></name><name><surname>Weinstein</surname><given-names>J. A.</given-names></name><name><surname>Ran</surname><given-names>F. A.</given-names></name><name><surname>Konermann</surname><given-names>S.</given-names></name><name><surname>Agarwala</surname><given-names>V.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>DNA targeting specificity of RNA-guided Cas9 nucleases</article-title>. <source>Nat. Biotechnol.</source>
<volume>31</volume> (<issue>9</issue>), <fpage>827</fpage>. <pub-id pub-id-type="doi">10.1038/nbt2647</pub-id>
<pub-id pub-id-type="pmid">23873081</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>F.</given-names></name><name><surname>LeCun</surname><given-names>Y.</given-names></name></person-group> (<year>2006</year>). “<article-title>Large-scale learning with svm and convolutional nets for generic object recognition</article-title>,” in <source>2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</source>. (<publisher-name>Publisher: IEEE</publisher-name>).</mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jinek</surname><given-names>M.</given-names></name><name><surname>Chylinski</surname><given-names>K.</given-names></name><name><surname>Fonfara</surname><given-names>I.</given-names></name><name><surname>Hauer</surname><given-names>M.</given-names></name><name><surname>Doudna</surname><given-names>J. A.</given-names></name><name><surname>Charpentier</surname><given-names>E.</given-names></name></person-group> (<year>2012</year>). <article-title>A programmable dual-RNA-guided DNA endonuclease in adaptive bacterial immunity</article-title>. <source>Science</source>
<volume>337</volume> (<issue>6096</issue>), <fpage>816</fpage>–<lpage>821</lpage>. <pub-id pub-id-type="doi">10.1126/science.1225829</pub-id>
<pub-id pub-id-type="pmid">22745249</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>D.</given-names></name><name><surname>Kim</surname><given-names>J.</given-names></name><name><surname>Hur</surname><given-names>J. K.</given-names></name><name><surname>Been</surname><given-names>K. W.</given-names></name><name><surname>Yoon</surname><given-names>S. H.</given-names></name><name><surname>Kim</surname><given-names>J. S.</given-names></name></person-group> (<year>2016</year>). <article-title>Genome-wide analysis reveals specificities of Cpf1 endonucleases in human cells</article-title>. <source>Nat. Biotechnol.</source>
<volume>34</volume> (<issue>8</issue>), <fpage>863</fpage>–<lpage>868</lpage>. <pub-id pub-id-type="doi">10.1038/nbt3609</pub-id>
<pub-id pub-id-type="pmid">27272384</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>H. K.</given-names></name><name><surname>Song</surname><given-names>M.</given-names></name><name><surname>Lee</surname><given-names>J.</given-names></name><name><surname>Menon</surname><given-names>A. V.</given-names></name><name><surname>Jung</surname><given-names>S.</given-names></name><name><surname>Kang</surname><given-names>Y. M.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>In vivo high-throughput profiling of CRISPR-Cpf1 activity</article-title>. <source>Nat. Methods</source>
<volume>14</volume> (<issue>2</issue>), <fpage>153</fpage>–<lpage>159</lpage>. <pub-id pub-id-type="doi">10.1038/nmeth4104</pub-id>
<pub-id pub-id-type="pmid">27992409</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>H. K.</given-names></name><name><surname>Min</surname><given-names>S.</given-names></name><name><surname>Song</surname><given-names>M.</given-names></name><name><surname>Jung</surname><given-names>S.</given-names></name><name><surname>Choi</surname><given-names>J. W.</given-names></name><name><surname>Kim</surname><given-names>Y.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Deep learning improves prediction of CRISPR-Cpf1 guide RNA activity</article-title>. <source>Nat. Biotechnol.</source>
<volume>36</volume> (<issue>3</issue>), <fpage>239</fpage>–<lpage>241</lpage>. <pub-id pub-id-type="doi">10.1038/nbt4061</pub-id>
<pub-id pub-id-type="pmid">29431740</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>D. P.</given-names></name><name><surname>Ba</surname><given-names>J.</given-names></name></person-group> (<year>2014</year>). <article-title>Adam: a method for stochastic optimization</article-title>. <source>Comput. Sci.</source>
</mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleinstiver</surname><given-names>B. P.</given-names></name><name><surname>Tsai</surname><given-names>S. Q.</given-names></name><name><surname>Prew</surname><given-names>M. S.</given-names></name><name><surname>Nguyen</surname><given-names>N. T.</given-names></name><name><surname>Welch</surname><given-names>M. M.</given-names></name><name><surname>Lopez</surname><given-names>J. M.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>Genome-wide specificities of CRISPR-Cas Cpf1 nucleases in human cells</article-title>. <source>Nat. Biotechnol.</source>
<volume>34</volume> (<issue>8</issue>), <fpage>869</fpage>–<lpage>874</lpage>. <pub-id pub-id-type="doi">10.1038/nbt3620</pub-id>
<pub-id pub-id-type="pmid">27347757</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Krizhevsky</surname><given-names>A.</given-names></name><name><surname>Sutskever</surname><given-names>I.</given-names></name><name><surname>Hinton</surname><given-names>G. E.</given-names></name></person-group> (<year>2012</year>). “<article-title>ImageNet Classification with Deep Convolutional Neural Networks</article-title>,” in <source>International Conference on Neural Information Processing Systems</source>. (<publisher-name>Publisher: Neural Information Processing Systems Foundation, Inc. (NIPS)</publisher-name>).</mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y.</given-names></name><name><surname>Bengio</surname><given-names>Y.</given-names></name><name><surname>Hinton</surname><given-names>G.</given-names></name></person-group> (<year>2015</year>). <article-title>Deep learning</article-title>. <source>Nature</source>
<volume>521</volume> (<issue>7553</issue>), <fpage>436</fpage>–<lpage>444</lpage>. <pub-id pub-id-type="doi">10.1038/nature14539</pub-id>
<pub-id pub-id-type="pmid">26017442</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Yan</surname><given-names>J.</given-names></name><name><surname>Deng</surname><given-names>D.</given-names></name><name><surname>Shi</surname><given-names>W.</given-names></name><name><surname>Deng</surname><given-names>S.</given-names></name></person-group> (<year>2016</year>). <article-title>No-reference image quality assessment based on hybrid model</article-title>. <source>Signal Image Video Process.</source>
<volume>11</volume> (<issue>6</issue>), <fpage>985</fpage>–<lpage>992</lpage>. <pub-id pub-id-type="doi">10.1007/s11760-016-1048-5</pub-id>
</mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liaw</surname><given-names>A.</given-names></name><name><surname>Wiener</surname><given-names>M.</given-names></name></person-group> (<year>2002</year>). <article-title>Classification and regression by randomForest</article-title>. <source>R News</source>
<volume>2</volume> (<issue>3</issue>), <fpage>18</fpage>–<lpage>22</lpage>.</mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Listgarten</surname><given-names>J.</given-names></name><name><surname>Weinstein</surname><given-names>M.</given-names></name><name><surname>Kleinstiver</surname><given-names>B. P.</given-names></name><name><surname>Sousa</surname><given-names>A. A.</given-names></name><name><surname>Joung</surname><given-names>J. K.</given-names></name><name><surname>Crawford</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Prediction of off-target activities for the end-to-end design of CRISPR guide RNAs</article-title>. <source>Nat. BioMed. Eng.</source>
<volume>2</volume> (<issue>1</issue>), <fpage>38</fpage>–<lpage>47</lpage>. <pub-id pub-id-type="doi">10.1038/s41551-017-0178-6</pub-id>
<pub-id pub-id-type="pmid">29998038</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maqsood</surname><given-names>I.</given-names></name><name><surname>Khan</surname><given-names>M. R.</given-names></name><name><surname>Abraham</surname><given-names>A.</given-names></name></person-group> (<year>2004</year>). <article-title>An ensemble of neural networks for weather forecasting</article-title>. <source>Neural Comput. Appl.</source>
<volume>13</volume> (<issue>2</issue>), <fpage>112</fpage>–<lpage>122</lpage>. <pub-id pub-id-type="doi">10.1007/s00521-004-0413-4</pub-id>
</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreno-Mateos</surname><given-names>M. A.</given-names></name><name><surname>Vejnar</surname><given-names>C. E.</given-names></name><name><surname>Beaudoin</surname><given-names>J. D.</given-names></name><name><surname>Fernandez</surname><given-names>J. P.</given-names></name><name><surname>Mis</surname><given-names>E. K.</given-names></name><name><surname>Khokha</surname><given-names>M. K.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>CRISPRscan: designing highly efficient sgRNAs for CRISPR-Cas9 targeting in vivo</article-title>. <source>Nat. Methods</source>
<volume>12</volume> (<issue>10</issue>), <fpage>982</fpage>–<lpage>988</lpage>. <pub-id pub-id-type="doi">10.1038/nmeth3543</pub-id>
<pub-id pub-id-type="pmid">26322839</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mori</surname><given-names>K.</given-names></name><name><surname>Matsugu</surname><given-names>M.</given-names></name><name><surname>Suzuki</surname><given-names>T.</given-names></name></person-group> (<year>2005</year>). “<article-title>Face Recognition Using SVM Fed with Intermediate Output of CNN for Face Detection</article-title>,” in <italic>MVA</italic>, <source>Conferences and Proceedings</source>. <fpage>410</fpage>–<lpage>413</lpage>.</mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mukaka</surname><given-names>M. M.</given-names></name></person-group> (<year>2012</year>). <article-title>Statistics corner: a guide to appropriate use of correlation coefficient in medical research</article-title>. <source>Malawi Med. J.</source>
<volume>24</volume> (<issue>3</issue>), <fpage>69</fpage>–<lpage>71</lpage>. <pub-id pub-id-type="doi">10.2166/wh.2012.000</pub-id>
<pub-id pub-id-type="pmid">23638278</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niu</surname><given-names>X.-X.</given-names></name><name><surname>Suen</surname><given-names>C. Y.</given-names></name></person-group> (<year>2012</year>). <article-title>A novel hybrid CNN–SVM classifier for recognizing handwritten digits</article-title>. <source>Pattern Recognit.</source>
<volume>45</volume> (<issue>4</issue>), <fpage>1318</fpage>–<lpage>1325</lpage>. <pub-id pub-id-type="doi">10.1016/j.patcog.2011.09.021</pub-id>
</mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pattanayak</surname><given-names>V.</given-names></name><name><surname>Lin</surname><given-names>S.</given-names></name><name><surname>Guilinger</surname><given-names>J. P.</given-names></name><name><surname>Ma</surname><given-names>E.</given-names></name><name><surname>Doudna</surname><given-names>J. A.</given-names></name><name><surname>Liu</surname><given-names>D. R.</given-names></name></person-group> (<year>2013</year>). <article-title>High-throughput profiling of off-target DNA cleavage reveals RNA-programmed Cas9 nuclease specificity</article-title>. <source>Nat. Biotechnol.</source>
<volume>31</volume> (<issue>9</issue>), <fpage>839</fpage>. <pub-id pub-id-type="doi">10.1038/nbt2673</pub-id>
<pub-id pub-id-type="pmid">23934178</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shin</surname><given-names>H. C.</given-names></name><name><surname>Roth</surname><given-names>H. R.</given-names></name><name><surname>Gao</surname><given-names>M.</given-names></name><name><surname>Lu</surname><given-names>L.</given-names></name><name><surname>Xu</surname><given-names>Z.</given-names></name><name><surname>Nogues</surname><given-names>I.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning</article-title>. <source>IEEE Trans. Med. Imaging</source>
<volume>35</volume> (<issue>5</issue>), <fpage>1285</fpage>–<lpage>1298</lpage>. <pub-id pub-id-type="doi">10.1109/TMI.2016.2528162</pub-id>
<pub-id pub-id-type="pmid">26886976</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shou</surname><given-names>J.</given-names></name><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name><name><surname>Wu</surname><given-names>Q.</given-names></name></person-group> (<year>2018</year>). <article-title>Precise and predictable CRISPR chromosomal rearrangements reveal principles of Cas9-mediated nucleotide insertion</article-title>. <source>Mol. Cell</source>
<volume>71</volume> (<issue>4</issue>), <fpage>498</fpage>–<lpage>509.e494</lpage>. <pub-id pub-id-type="doi">10.1016/j.molcel.2018.06.021</pub-id>
<pub-id pub-id-type="pmid">30033371</pub-id></mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stemmer</surname><given-names>M.</given-names></name><name><surname>Thumberger</surname><given-names>T.</given-names></name><name><surname>del Sol Keyer</surname><given-names>M.</given-names></name><name><surname>Wittbrodt</surname><given-names>J.</given-names></name><name><surname>Mateo</surname><given-names>J. L.</given-names></name></person-group> (<year>2015</year>). <article-title>CCTop: an intuitive, flexible and reliable CRISPR/Cas9 target prediction tool</article-title>. <source>PloS One</source>
<volume>10</volume> (<issue>4</issue>), <fpage>e0124633</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0124633</pub-id>
<pub-id pub-id-type="pmid">25909470</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>T.</given-names></name><name><surname>Wei</surname><given-names>J. J.</given-names></name><name><surname>Sabatini</surname><given-names>D. M.</given-names></name><name><surname>Lander</surname><given-names>E. S.</given-names></name></person-group> (<year>2014</year>). <article-title>Genetic screens in human cells using the CRISPR-Cas9 system</article-title>. <source>Science</source>
<volume>343</volume> (<issue>6166</issue>), <fpage>80</fpage>–<lpage>84</lpage>. <pub-id pub-id-type="doi">10.1126/science.1246981</pub-id>
<pub-id pub-id-type="pmid">24336569</pub-id></mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>S.</given-names></name><name><surname>Peng</surname><given-names>J.</given-names></name><name><surname>Ma</surname><given-names>J.</given-names></name><name><surname>Xu</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>Protein secondary structure prediction using deep convolutional neural fields</article-title>. <source>Sci. Rep.</source>
<volume>6</volume>, <elocation-id>18962</elocation-id>. <pub-id pub-id-type="doi">10.1038/srep18962</pub-id>
<pub-id pub-id-type="pmid">26752681</pub-id></mixed-citation>
    </ref>
    <ref id="B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitney</surname><given-names>A. W.</given-names></name></person-group> (<year>2006</year>). <article-title>A direct method of nonparametric measurement selection</article-title>. <source>IEEE Trans. Comput.</source>
<volume>C-20</volume> (<issue>9</issue>), <fpage>1100</fpage>–<lpage>1103</lpage>. <pub-id pub-id-type="doi">10.1109/T-C.1971.223410</pub-id>
</mixed-citation>
    </ref>
    <ref id="B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>L. O. W.</given-names></name><name><surname>O’Brien</surname><given-names>A. R.</given-names></name><name><surname>Bauer</surname><given-names>D. C.</given-names></name></person-group> (<year>2018</year>). <article-title>The current state and future of CRISPR-Cas9 gRNA design tools</article-title>. <source>Front. Pharmacol.</source>
<volume>9</volume>, <elocation-id>749</elocation-id>. <pub-id pub-id-type="doi">10.3389/fphar.2018.00749</pub-id>
<pub-id pub-id-type="pmid">30050439</pub-id></mixed-citation>
    </ref>
    <ref id="B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woźniak</surname><given-names>M.</given-names></name><name><surname>Graña</surname><given-names>M.</given-names></name><name><surname>Corchado</surname><given-names>E.</given-names></name></person-group> (<year>2014</year>). <article-title>A survey of multiple classifier systems as hybrid systems</article-title>. <source>Inf. Fusion</source>
<volume>16</volume>, <fpage>3</fpage>–<lpage>17</lpage>. <pub-id pub-id-type="doi">10.1016/j.inffus.2013.04.006</pub-id>
</mixed-citation>
    </ref>
    <ref id="B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>N.</given-names></name><name><surname>Liu</surname><given-names>W.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name></person-group> (<year>2015</year>). <article-title>WU-CRISPR: characteristics of functional guide RNAs for the CRISPR/Cas9 system</article-title>. <source>Genome Biol.</source>
<volume>16</volume>, <fpage>218</fpage>. <pub-id pub-id-type="doi">10.1186/s13059-015-0784-0</pub-id>
<pub-id pub-id-type="pmid">26521937</pub-id></mixed-citation>
    </ref>
    <ref id="B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xie</surname><given-names>B.</given-names></name><name><surname>Jankovic</surname><given-names>B. R.</given-names></name><name><surname>Bajic</surname><given-names>V. B.</given-names></name><name><surname>Song</surname><given-names>L.</given-names></name><name><surname>Gao</surname><given-names>X.</given-names></name></person-group> (<year>2013</year>). <article-title>Poly(A) motif prediction using spectral latent features from human DNA sequences</article-title>. <source>Bioinformatics</source>
<volume>29</volume> (<issue>13</issue>), <fpage>i316</fpage>–<lpage>i325</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btt218</pub-id>
<pub-id pub-id-type="pmid">23813000</pub-id></mixed-citation>
    </ref>
    <ref id="B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>H.</given-names></name><name><surname>Xiao</surname><given-names>T.</given-names></name><name><surname>Chen</surname><given-names>C. H.</given-names></name><name><surname>Li</surname><given-names>W.</given-names></name><name><surname>Meyer</surname><given-names>C. A.</given-names></name><name><surname>Wu</surname><given-names>Q.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>Sequence determinants of improved CRISPR sgRNA design</article-title>. <source>Genome Res.</source>
<volume>25</volume> (<issue>8</issue>), <fpage>1147</fpage>–<lpage>1157</lpage>. <pub-id pub-id-type="doi">10.1101/gr.191452.115</pub-id>
<pub-id pub-id-type="pmid">26063738</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
