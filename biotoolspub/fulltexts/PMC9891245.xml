<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9891245</article-id>
    <article-id pub-id-type="pmid">36688699</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btad047</article-id>
    <article-id pub-id-type="publisher-id">btad047</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Systems Biology</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Accurately modeling biased random walks on weighted networks using <italic toggle="yes">node2vec+</italic></article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-6025-6492</contrib-id>
        <name>
          <surname>Liu</surname>
          <given-names>Renming</given-names>
        </name>
        <aff><institution>Department of Computational Mathematics, Science &amp; Engineering, Michigan State University</institution>, East Lansing, MI 48824, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-0290-4292</contrib-id>
        <name>
          <surname>Hirn</surname>
          <given-names>Matthew</given-names>
        </name>
        <aff><institution>Department of Computational Mathematics, Science &amp; Engineering, Michigan State University</institution>, East Lansing, MI 48824, <country country="US">USA</country></aff>
        <aff><institution>Department of Mathematics, Michigan State University</institution>, East Lansing, MI 48824, <country country="US">USA</country></aff>
        <aff><institution>Center for Quantum Computing, Science &amp; Engineering, Michigan State University</institution>, East Lansing, MI 48824, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-7980-4110</contrib-id>
        <name>
          <surname>Krishnan</surname>
          <given-names>Arjun</given-names>
        </name>
        <aff><institution>Department of Computational Mathematics, Science &amp; Engineering, Michigan State University</institution>, East Lansing, MI 48824, <country country="US">USA</country></aff>
        <aff><institution>Department of Biomedical Informatics, University of Colorado Anschutz Medical Campus</institution>, Aurora, CO 80045, <country country="US">USA</country></aff>
        <xref rid="btad047-cor1" ref-type="corresp"/>
        <!--arjun.krishnan@cuanschutz.edu-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btad047-cor1">To whom correspondence should be addressed. <email>arjun@msu.edu</email> or <email>arjun.krishnan@cuanschutz.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-01-23">
      <day>23</day>
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>23</day>
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <volume>39</volume>
    <issue>1</issue>
    <elocation-id>btad047</elocation-id>
    <history>
      <date date-type="received">
        <day>14</day>
        <month>8</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>16</day>
        <month>1</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>18</day>
        <month>1</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>1</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>01</day>
        <month>2</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btad047.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Accurately representing biological networks in a low-dimensional space, also known as network embedding, is a critical step in network-based machine learning and is carried out widely using <italic toggle="yes">node2vec</italic>, an unsupervised method based on biased random walks. However, while many networks, including functional gene interaction networks, are dense, weighted graphs, <italic toggle="yes">node2vec</italic> is fundamentally limited in its ability to use edge weights during the biased random walk generation process, thus under-using all the information in the network.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Here, we present <italic toggle="yes">node2vec+</italic>, a natural extension of <italic toggle="yes">node2vec</italic> that accounts for edge weights when calculating walk biases and reduces to <italic toggle="yes">node2vec</italic> in the cases of unweighted graphs or unbiased walks. Using two synthetic datasets, we empirically show that <italic toggle="yes">node2vec+</italic> is more robust to additive noise than <italic toggle="yes">node2vec</italic> in weighted graphs. Then, using genome-scale functional gene networks to solve a wide range of gene function and disease prediction tasks, we demonstrate the superior performance of <italic toggle="yes">node2vec+</italic> over <italic toggle="yes">node2vec</italic> in the case of weighted graphs. Notably, due to the limited amount of training data in the gene classification tasks, graph neural networks such as GCN and GraphSAGE are outperformed by both <italic toggle="yes">node2vec</italic> and <italic toggle="yes">node2vec+.</italic></p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The data and code are available on GitHub at <ext-link xlink:href="https://github.com/krishnanlab/node2vecplus_benchmarks" ext-link-type="uri">https://github.com/krishnanlab/node2vecplus_benchmarks.</ext-link> All additional data underlying this article are available on Zenodo at <ext-link xlink:href="https://doi.org/10.5281/zenodo.7007164" ext-link-type="uri">https://doi.org/10.5281/zenodo.7007164</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p>Supplementary data are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NIH</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>GM128765</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NSF</institution>
            <institution-id institution-id-type="DOI">10.13039/100000001</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Graphs and networks naturally appear in many real-world datasets, including social networks and biological networks. The graph structure provides insightful information about the role of each node in the graph, such as protein function in a protein–protein interaction network (<xref rid="btad047-B22" ref-type="bibr">Krishnan <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btad047-B24" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2020</xref>). To more efficiently and effectively mine information from large-scale graphs with thousands or millions of nodes, several node embedding methods have been developed (<xref rid="btad047-B8" ref-type="bibr">Cui <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btad047-B16" ref-type="bibr">Hamilton <italic toggle="yes">et al.</italic>, 2017</xref>). Among them, <italic toggle="yes">node2vec</italic> has been the top choice in bioinformatics due to its superior performance compared to many other methods (<xref rid="btad047-B2" ref-type="bibr">Ata <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btad047-B43" ref-type="bibr">Yue <italic toggle="yes">et al.</italic>, 2019</xref>). However, many biological networks, such as <xref rid="btad047-B12" ref-type="bibr">Greene <italic toggle="yes">et al.</italic> (2015)</xref> and <xref rid="btad047-B19" ref-type="bibr">Johnson and Krishnan (2022)</xref>, are dense and weighted by construction, which we demonstrate to be undesirable conditions for <italic toggle="yes">node2vec</italic> that can lead to sub-optimal performance.</p>
    <p><italic toggle="yes">Node2vec</italic> (<xref rid="btad047-B14" ref-type="bibr">Grover and Leskovec, 2016</xref>) is a second-order random walk-based embedding method. It is widely used for unsupervised node embedding for various tasks, particularly in computational biology (<xref rid="btad047-B27" ref-type="bibr">Nelson <italic toggle="yes">et al.</italic>, 2019</xref>), such as for gene function prediction (<xref rid="btad047-B24" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2020</xref>), disease gene prediction (<xref rid="btad047-B1" ref-type="bibr">Ata <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btad047-B30" ref-type="bibr">Peng <italic toggle="yes">et al.</italic>, 2019</xref>), and essential protein prediction (<xref rid="btad047-B39" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2021a</xref>; <xref rid="btad047-B44" ref-type="bibr">Zeng <italic toggle="yes">et al.</italic>, 2021</xref>). Some recent works built on top of <italic toggle="yes">node2vec</italic> aim to adapt <italic toggle="yes">node2vec</italic> to more specific types of networks (<xref rid="btad047-B38" ref-type="bibr">Valentini <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btad047-B40" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2021b</xref>), generalize <italic toggle="yes">node2vec</italic> to higher dimensions (<xref rid="btad047-B15" ref-type="bibr">Hacker, 2021</xref>), augment <italic toggle="yes">node2vec</italic> with additional downstream processing (<xref rid="btad047-B5" ref-type="bibr">Chattopadhyay and Ganguly, 2020</xref>; <xref rid="btad047-B17" ref-type="bibr">Hu <italic toggle="yes">et al.</italic>, 2020</xref>), or to study <italic toggle="yes">node2vec</italic> theoretically (<xref rid="btad047-B9" ref-type="bibr">Davison and Austern, 2021</xref>; <xref rid="btad047-B13" ref-type="bibr">Grohe, 2020</xref>; <xref rid="btad047-B33" ref-type="bibr">Qiu <italic toggle="yes">et al.</italic>, 2018</xref>). Nevertheless, none of these follow-up works account for the fact that <italic toggle="yes">node2vec</italic> is less effective for weighted graphs, where the edge weights reflect the (potentially noisy) similarities between pairs of nodes. This failing is due to the inability of <italic toggle="yes">node2vec</italic> to differentiate between small and large edges connecting the previous vertex with a potential next vertex in the random walk, which subsequently causes less accurate modeling of the intended walk bias.</p>
    <p>Meanwhile, another line of recent works on graph neural networks (GNNs) has shown remarkable performance in prediction tasks that involve graph structure, including node classification (<xref rid="btad047-B3" ref-type="bibr">Bronstein <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btad047-B42" ref-type="bibr">Wu <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btad047-B46" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2021</xref>). Although GNNs and embedding methods like <italic toggle="yes">node2vec</italic> are related in that they both aim at projecting nodes in the graph to a feature space, two main differences set them apart. First, GNNs typically require labeled data, while embedding methods do not. This label dependency makes the embeddings generated by a GNN tied to the quality of the labels, which in some cases, like in biological networks, are noisy and scarce. Second, GNNs typically require node features as input to train, which are not always available. In the absence of given node features, one needs to generate them, and often GNN algorithms use trivial node features such as the constant features or node degree features. These two differences give node embedding methods a unique place in node classification, apart from the GNN methods.</p>
    <p>Here, we propose an improved version of <italic toggle="yes">node2vec</italic> that is more effective for weighted graphs by taking into account the edge weight connecting the previous vertex and the potential next vertex. The proposed method <italic toggle="yes">node2vec+</italic> is a natural extension of <italic toggle="yes">node2vec</italic>; when the input graph is unweighted, the resulting embeddings of <italic toggle="yes">node2vec+</italic> and <italic toggle="yes">node2vec</italic> are equivalent in expectation. Moreover, when the bias parameters are set to neutral, <italic toggle="yes">node2vec+</italic> recovers a first-order random walk, just as <italic toggle="yes">node2vec</italic> does. Finally, we demonstrate the superior performance of <italic toggle="yes">node2vec+</italic> through extensive benchmarking on both synthetic datasets and network-based gene classification datasets using various functional gene interaction networks. <italic toggle="yes">Node2vec+</italic> is implemented as part of <monospace>PecanPy</monospace> (<xref rid="btad047-B23" ref-type="bibr">Liu and Krishnan, 2021</xref>) and is available on GitHub: <ext-link xlink:href="https://github.com/krishnanlab/PecanPy" ext-link-type="uri">https://github.com/krishnanlab/PecanPy</ext-link>.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <p>We start by briefly reviewing the <italic toggle="yes">node2vec</italic> method. Then, we illustrate that <italic toggle="yes">node2vec</italic> is less effective for weighted graphs due to its inability to identify <italic toggle="yes">out</italic> edges. Finally, we present a natural extension of <italic toggle="yes">node2vec</italic> that resolves this issue.</p>
    <sec>
      <title>2.1 <italic toggle="yes">Node2vec</italic> overview</title>
      <p>In the setting of node embeddings, we are interested in finding a mapping <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:mi>V</mml:mi><mml:mo>→</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> that maps each node <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:math></inline-formula> to a <italic toggle="yes">d</italic>-dimensional vector so that the mutual proximity between pairs of nodes in the graph is preserved. In particular, a random walk-based approach aims to maximize the probability of reconstructing the neighborhoods for any node in the graph based on some sampling strategy <italic toggle="yes">S</italic>. Formally, given a graph <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> (the analysis generalizes to directed and/or weighted graphs), we want to maximize the log probability of reconstructing the sampled neighborhood <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script" class="calligraphy">N</mml:mi></mml:mrow><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> for each <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:math></inline-formula>:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo></mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script" class="calligraphy">N</mml:mi></mml:mrow><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>|</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p>
      <p>Under the conditional independence assumption, and the parameterization of the probabilities as the softmax normalized inner products (<xref rid="btad047-B14" ref-type="bibr">Grover and Leskovec, 2016</xref>; <xref rid="btad047-B26" ref-type="bibr">Mikolov <italic toggle="yes">et al.</italic>, 2013b</xref>), the objective function above simplifies to:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="true">(</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script" class="calligraphy">N</mml:mi></mml:mrow><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:mo>〈</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>〉</mml:mo><mml:mo>−</mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p>
      <p>In practice, the partition function <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>〈</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo></mml:mrow><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>〉</mml:mo></mml:mrow></mml:math></inline-formula> is approximated by negative sampling (<xref rid="btad047-B25" ref-type="bibr">Mikolov <italic toggle="yes">et al.</italic>, 2013a</xref>) to save computational time. Given any sampling strategy <italic toggle="yes">S</italic>, <xref rid="E2" ref-type="disp-formula">Equation (2)</xref> can find the corresponding embedding <italic toggle="yes">f</italic>, which is achieved in practice by feeding the random walks generated to the skipgram with negative sampling (<xref rid="btad047-B26" ref-type="bibr">Mikolov <italic toggle="yes">et al.</italic>, 2013b</xref>).</p>
      <p><italic toggle="yes">Node2vec</italic> devises a second-order random walk as the sampling strategy. Unlike a first-order random walk (<xref rid="btad047-B31" ref-type="bibr">Perozzi <italic toggle="yes">et al.</italic>, 2014</xref>), where the transition probability of moving to the next vertex <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, denoted as <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, depends only on the current vertex <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, a second-order random walk also depends on the previous vertex <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, with transition probability <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. It does so by applying a bias factor<inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>α</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to the edge <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:math></inline-formula> that connects the current vertex and a potential next vertex. This bias factor is a function that depends on the relation between the previous vertex and the potential next vertex, and is parameterized by the <italic toggle="yes">return</italic> parameter <italic toggle="yes">p</italic> and the <italic toggle="yes">in–out</italic> parameter <italic toggle="yes">q</italic>. In this way, the random walk can be generated based on the following transition probabilities:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mo>α</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mo>α</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo> </mml:mo><mml:mtext>if</mml:mtext><mml:mo> </mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>  otherwise</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where the bias factor is defined as:
<disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mo>α</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>p</mml:mi></mml:mfrac></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mtext>and</mml:mtext><mml:mo> </mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>q</mml:mi></mml:mfrac></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mtext>and</mml:mtext><mml:mo> </mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∉</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p>
      <p>According to this bias factor, <italic toggle="yes">node2vec</italic> differentiates three types of edges: (i) the <italic toggle="yes">return</italic> edge, where the potential next vertex is the previous vertex (<xref rid="btad047-F1" ref-type="fig">Fig. 1a</xref>); (ii) the <italic toggle="yes">out</italic> edge, where the potential next vertex is <italic toggle="yes">not</italic> connected to the previous vertex (<xref rid="btad047-F1" ref-type="fig">Fig. 1b</xref>); and (iii) the <italic toggle="yes">in</italic> edge, where the potential next vertex is connected to the previous vertex (<xref rid="btad047-F1" ref-type="fig">Fig. 1c</xref>). Note that the first-order (or unbiased) random walk can be seen as a special case of the second-order random walk where both the <italic toggle="yes">return</italic> parameter and the <italic toggle="yes">in–out</italic> parameter are set to neutral (<inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>).</p>
      <fig position="float" id="btad047-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>Illustration of different settings of <italic toggle="yes">return</italic> and <italic toggle="yes">in–out</italic> edges. <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> indicate the previous, current, and next vertices. The solid and dotted lines represent edges with large and small edge weights, respectively. (<bold>a–c</bold>) <italic toggle="yes">return</italic>, <italic toggle="yes">out</italic> and <italic toggle="yes">in</italic> edges considered by <italic toggle="yes">node2vec</italic>. (<bold>d–f</bold>) Variations of (c) when taking into account of edge weights, where node2vec fail to distinguish from (c)</p>
        </caption>
        <graphic xlink:href="btad047f1" position="float"/>
      </fig>
      <p>We now turn our attention to weighted networks, where the edge weights are not necessarily zeros or ones. Consider the case where <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is connected to <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, but with a small weight (<xref rid="btad047-F1" ref-type="fig">Fig. 1d</xref>), i.e. <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>≪</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. According to the definition of the bias factor, no matter how small <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is, <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> would always be considered as an <italic toggle="yes">in</italic> edge. Since in this case <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are barely connected, <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> should in fact be considered as an <italic toggle="yes">out</italic> edge. In the extreme case of a fully connected weighted graph, where <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:math></inline-formula> for all <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mrow><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:math></inline-formula>, <italic toggle="yes">node2vec</italic> completely loses its ability to identify <italic toggle="yes">out</italic> edges.</p>
      <p>Thus, <italic toggle="yes">node2vec</italic> is less effective for weighted networks due to its inability to identify potential <italic toggle="yes">out</italic> edges where the terminal vertex <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is loosely connected to a previous vertex <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Next, we propose an extension of <italic toggle="yes">node2vec</italic> that resolves this issue, by taking into account of the edge weight <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> in the bias factor.</p>
    </sec>
    <sec>
      <title>2.2 <italic toggle="yes">Node2vec+</italic></title>
      <p>The main idea of extending <italic toggle="yes">node2vec</italic> is to identify potential <italic toggle="yes">out</italic> edges <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:math></inline-formula> coming from <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is loosely connected to <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Intuitively, we can determine the ‘looseness’ of <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> based on some threshold edge value. However, given that the distribution of edge weights of any given node in the graph is not known a priori, it is hard to come up with a reasonable threshold value for all networks. Instead, we define the looseness of <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> based on the edge weight statistics for each node <italic toggle="yes">v</italic>.
<disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>μ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>= </mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>= </mml:mo><mml:msqrt><mml:mrow><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo>μ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:msqrt></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>= </mml:mo><mml:mfrac><mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>max</mml:mi><mml:mo>{</mml:mo><mml:mo>μ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo>γ</mml:mo><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo>ϵ</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p>
      <p>Formally, we first define <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, a normalized version of the edge weight <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, based on the mean <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mrow><mml:mo>μ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and the standard deviation <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> of the edge weights connecting <italic toggle="yes">v</italic>, as in <xref rid="E5" ref-type="disp-formula">Equation (5)</xref>. In practice, we clip the denominator of <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> by a small number <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mo>ϵ</mml:mo></mml:math></inline-formula> (1e−6 by default) to prevent divide by zero in some cases when <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula> is set to be negative. Then, we say <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:math></inline-formula> is <inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula><italic toggle="yes">-loosely connected</italic> (or simply <italic toggle="yes">loosely connected</italic> if <inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mrow><mml:mo>γ</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) to <inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:mrow><mml:mi>u</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:math></inline-formula> if <inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. Intuitively, we would like to treat an edge as being ‘not connected’ if it is ‘small enough’. Finally, an edge <inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is <inline-formula id="IE51"><mml:math id="IM51" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula><italic toggle="yes">-loose</italic> if <italic toggle="yes">v</italic> is <inline-formula id="IE52"><mml:math id="IM52" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula>-loosely connected to <italic toggle="yes">u</italic>, and otherwise it is <inline-formula id="IE53"><mml:math id="IM53" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula><italic toggle="yes">-tight</italic>. Without loss of generality, we consider the case of <inline-formula id="IE54"><mml:math id="IM54" display="inline" overflow="scroll"><mml:mrow><mml:mo>γ</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> in the subsequent sections to simplify the notion of <italic toggle="yes">looseness</italic>.</p>
      <p>Based on the definition of looseness of edges, and assuming <inline-formula id="IE55"><mml:math id="IM55" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, there are four types of <inline-formula id="IE56"><mml:math id="IM56" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> edges (see <xref rid="btad047-F1" ref-type="fig">Fig. 1c–f</xref>). Following <italic toggle="yes">node2vec</italic>, we categorize these edge types into <italic toggle="yes">in</italic> and <italic toggle="yes">out</italic> edges. Furthermore, to prevent amplification of noisy connections, we added one more edge type called the <italic toggle="yes">noisy</italic> edge, which is always suppressed.</p>
      <sec>
        <title>2.2.1 <italic toggle="yes">Out</italic> edge</title>
        <p>As a direct generalization to <italic toggle="yes">node2vec</italic>, we consider <inline-formula id="IE57"><mml:math id="IM57" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to be an <italic toggle="yes">out</italic> edge if <inline-formula id="IE58"><mml:math id="IM58" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is tight and <inline-formula id="IE59"><mml:math id="IM59" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is loose (<xref rid="btad047-F1" ref-type="fig">Fig. 1b and d</xref>). The <italic toggle="yes">in–out</italic> parameter <italic toggle="yes">q</italic> then modifies the out edge to differentiate ‘inward’ and ‘outward’ nodes, and subsequently leads to Breadth First Search or Depth First Search like searching strategies (<xref rid="btad047-B14" ref-type="bibr">Grover and Leskovec, 2016</xref>). Unlike <italic toggle="yes">node2vec</italic>, however, we further parameterize the bias factor <inline-formula id="IE60"><mml:math id="IM60" display="inline" overflow="scroll"><mml:mo>α</mml:mo></mml:math></inline-formula> based on <inline-formula id="IE61"><mml:math id="IM61" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Any choice of monotonic function should work, but we choose to use the linear interpolation in this study for simplicity and leave it as future work to explore more sophisticated interpolation functions such as the sigmoidal functions. Specifically, for an <italic toggle="yes">out</italic> edge <inline-formula id="IE62"><mml:math id="IM62" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, the bias factor is computed as <inline-formula id="IE63"><mml:math id="IM63" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>α</mml:mo></mml:mrow><mml:mrow><mml:mo>γ</mml:mo><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>q</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>q</mml:mi></mml:mfrac><mml:mo stretchy="true">)</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Thus, the amount of modification to the <italic toggle="yes">out</italic> edge depends on the level of looseness of <inline-formula id="IE64"><mml:math id="IM64" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. When <inline-formula id="IE65"><mml:math id="IM65" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, or equivalently <inline-formula id="IE66"><mml:math id="IM66" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∉</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:math></inline-formula>, the bias factor for <inline-formula id="IE67"><mml:math id="IM67" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is <inline-formula id="IE68"><mml:math id="IM68" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>q</mml:mi></mml:mfrac></mml:mrow></mml:math></inline-formula>, same as that defined in <italic toggle="yes">node2vec</italic>.</p>
      </sec>
      <sec>
        <title>2.2.2 <italic toggle="yes">Noisy</italic> edge</title>
        <p>We consider <inline-formula id="IE69"><mml:math id="IM69" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to be a <italic toggle="yes">noisy</italic> edge if both <inline-formula id="IE70"><mml:math id="IM70" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE71"><mml:math id="IM71" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> are loose (<xref rid="btad047-F1" ref-type="fig">Fig. 1e</xref>). Heuristically, the <italic toggle="yes">noisy</italic> edges are not very informative and thus should be suppressed regardless of the setting of <italic toggle="yes">q</italic> to prevent amplification of noise. Thus, the bias factor for a <italic toggle="yes">noisy</italic> edge is set to be <inline-formula id="IE72"><mml:math id="IM72" display="inline" overflow="scroll"><mml:mrow><mml:mi>min</mml:mi><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>q</mml:mi></mml:mfrac><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
        <p>Notice that by introducing the noisy-edge term, we create discontinuity to the bias factor when <inline-formula id="IE73"><mml:math id="IM73" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE74"><mml:math id="IM74" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> switches from greater than one to less than one. We provide an alternative solution to <italic toggle="yes">node2vec+</italic> in the Supplementary material, which continuously extends the <italic toggle="yes">out</italic> edge term with the <italic toggle="yes">noisy</italic> edge term. However, we empirically show that the continuous version of <italic toggle="yes">node2vec+</italic> performs no better than <italic toggle="yes">node2vec+</italic>. Hence, in the main paper, we stick to the ‘discontinuous’ but simpler version of <italic toggle="yes">node2vec+</italic>.</p>
      </sec>
      <sec>
        <title>2.2.3 <italic toggle="yes">In</italic> edge</title>
        <p>Finally, we consider <inline-formula id="IE75"><mml:math id="IM75" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to be an <italic toggle="yes">in</italic> edge if <inline-formula id="IE76"><mml:math id="IM76" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is tight, regardless of <inline-formula id="IE77"><mml:math id="IM77" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> (<xref rid="btad047-F1" ref-type="fig">Fig. 1c and f</xref>). The corresponding bias factor is set to neutral as in <italic toggle="yes">node2vec</italic>.</p>
        <p>Combining the above, the bias factor for <italic toggle="yes">node2vec+</italic> is defined as follows:
<disp-formula id="E6"><label>(6)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mo>α</mml:mo></mml:mrow><mml:mrow><mml:mo>γ</mml:mo><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>p</mml:mi></mml:mfrac></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>min</mml:mi><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>q</mml:mi></mml:mfrac><mml:mo>}</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo> </mml:mo><mml:mtext>and</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>q</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mo stretchy="true">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>q</mml:mi></mml:mfrac><mml:mo stretchy="true">)</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo> </mml:mo><mml:mtext>and</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p>
        <p>Note that the last two cases in <xref rid="E6" ref-type="disp-formula">Equation (6)</xref> include cases of <inline-formula id="IE78"><mml:math id="IM78" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∉</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:math></inline-formula>. Based on the biased random walk searching strategy using this bias factor, the embedding can be generated accordingly using (2). One can verify, by checking <xref rid="E6" ref-type="disp-formula">Equation (6)</xref>, that this is indeed a natural extension of <italic toggle="yes">node2vec</italic> in the sense that
</p>
        <list list-type="bullet">
          <list-item>
            <p>For an unweighted graph, the <italic toggle="yes">node2vec+</italic> is equivalent to <italic toggle="yes">node2vec</italic>.</p>
          </list-item>
          <list-item>
            <p>When <italic toggle="yes">p</italic> and <italic toggle="yes">q</italic> are set to 1, <italic toggle="yes">node2vec+</italic> recovers a first-order random walk, same as <italic toggle="yes">node2vec</italic> does.</p>
          </list-item>
        </list>
        <p>Finally, by design, <italic toggle="yes">node2vec+</italic> is able to identify potential <italic toggle="yes">out</italic> edges that would have been obliviated by <italic toggle="yes">node2vec</italic>.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 Experiments</title>
    <sec>
      <title>3.1 Synthetic datasets</title>
      <p>We start by demonstrating the ability of <italic toggle="yes">node2vec+</italic> to identify potential <italic toggle="yes">out</italic> edges in weighted graphs using a barbell graph and the hierarchical cluster graphs. For simplicity, we fix <inline-formula id="IE79"><mml:math id="IM79" display="inline" overflow="scroll"><mml:mrow><mml:mo>γ</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for all experiments in this section.</p>
      <sec>
        <title>3.1.1 Barbell graph</title>
        <p>A barbell graph, denoted as <italic toggle="yes">B</italic>, is constructed by connecting two complete graphs of size 20 with a common bridge node (<xref rid="btad047-F2" ref-type="fig">Fig. 2a</xref>). All edges in <italic toggle="yes">B</italic> are weighted 1. There are three types of nodes in <italic toggle="yes">B</italic>, (i) the bridge node; (ii) the peripheral nodes that connect the two modules with the bridge node; and (iii) the interior nodes of the two modules. By changing the <italic toggle="yes">in–out</italic> parameter <italic toggle="yes">q</italic>, <italic toggle="yes">node2vec</italic> could put the peripheral nodes closer to the bridge node or interior nodes in the embedding space.</p>
        <fig position="float" id="btad047-F2">
          <label>Fig. 2.</label>
          <caption>
            <p>Barbell graph. (<bold>a</bold>) Illustration of the barbell graph, and three different types of nodes indicated by the different marker styles. (<bold>b</bold>) Embedding of the barbell graph <italic toggle="yes">B</italic> using <italic toggle="yes">node2vec</italic>. (<bold>c, d</bold>) Embedding of the noisy barbell graph <inline-formula id="IE80"><mml:math id="IM80" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> using <italic toggle="yes">node2vec</italic> and <italic toggle="yes">node2vec+</italic>, respectively. Each one of (b–d) contains three different settings of q: 1, 100 and 0.01</p>
          </caption>
          <graphic xlink:href="btad047f2" position="float"/>
        </fig>
        <p>When <italic toggle="yes">q</italic> is large, <italic toggle="yes">node2vec</italic> suppresses the <italic toggle="yes">out</italic> edges, e.g. an edge connecting a peripheral node to the bridge node, coming from an interior node. Consequently, the biased random walks are restricted to the network modules. In this case, the transition from the peripheral nodes to the bridge node becomes less likely compared to a first-order random walk, thus pushing the embeddings between the bridge node and the peripheral nodes away from each other. Conversely, when <italic toggle="yes">q</italic> is small, the transition between the peripheral nodes and the bridge node is encouraged. In this case, the embeddings of the bridge node and the peripheral nodes are pulled together. To see this, we run <italic toggle="yes">node2vec</italic> with fixed <inline-formula id="IE81"><mml:math id="IM81" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, and three different settings of <inline-formula id="IE82"><mml:math id="IM82" display="inline" overflow="scroll"><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>0.01</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. Indeed, for <inline-formula id="IE83"><mml:math id="IM83" display="inline" overflow="scroll"><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula>, <italic toggle="yes">node2vec</italic> tightly clusters interior nodes and pushes the bridge node away from the peripheral nodes, and for <inline-formula id="IE84"><mml:math id="IM84" display="inline" overflow="scroll"><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>, the peripheral nodes are pushed away from the interior nodes (<xref rid="btad047-F2" ref-type="fig">Fig. 2b</xref>). Since <italic toggle="yes">node2vec</italic> and <italic toggle="yes">node2vec+</italic> are equivalent when the graph is unweighted (see Section 2), we omit the visualization of <italic toggle="yes">node2vec+</italic> embeddings for <italic toggle="yes">B</italic> in the main paper (see <xref rid="sup1" ref-type="supplementary-material">Supplementary material</xref>).</p>
        <p>Next, we perturb the barbell graph by adding loose edges with edge weights of 0.1, making the graph fully connected. This perturbed barbell graph is denoted <inline-formula id="IE85"><mml:math id="IM85" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>. As expected, <italic toggle="yes">node2vec</italic> failed to make use of the <italic toggle="yes">q</italic> parameter (<xref rid="btad047-F2" ref-type="fig">Fig. 2c</xref>), since none of the edges are identified as an <italic toggle="yes">out</italic> edge. On the other hand, <italic toggle="yes">node2vec+</italic> can pick up potential <italic toggle="yes">out</italic> edges and thus qualitatively recovers the desired outcome (<xref rid="btad047-F2" ref-type="fig">Fig. 2d</xref>). Note that both <italic toggle="yes">node2vec</italic> and <italic toggle="yes">node2vec+</italic> have similar results for <inline-formula id="IE86"><mml:math id="IM86" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> when <inline-formula id="IE87"><mml:math id="IM87" display="inline" overflow="scroll"><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. This confirms that <italic toggle="yes">node2vec+</italic> and <italic toggle="yes">node2vec</italic> are equivalent when <italic toggle="yes">p</italic> and <italic toggle="yes">q</italic> are set to neutral, corresponding to embedding with unbiased random walks. Finally, when using non-neutral settings of <italic toggle="yes">q</italic>, <italic toggle="yes">node2vec+</italic> is able to suppress some noisy edges, resulting in less scattered embeddings of the interior nodes (<xref rid="btad047-F2" ref-type="fig">Fig. 2d</xref>).</p>
      </sec>
      <sec>
        <title>3.1.2 Hierarchical CLUSTER graph</title>
        <p>We use a modified version of the CLUSTER dataset (<xref rid="btad047-B11" ref-type="bibr">Dwivedi <italic toggle="yes">et al.</italic>, 2022</xref>) to further demonstrate the advantage of the <italic toggle="yes">node2vec+</italic> due to identifying potential <italic toggle="yes">out</italic> edges. Specifically, the hierarchical cluster graph K3L2 contains <inline-formula id="IE88"><mml:math id="IM88" display="inline" overflow="scroll"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> levels (3 including the root level) of clusters, and each parent cluster is associated with <inline-formula id="IE89"><mml:math id="IM89" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula> children clusters (<xref rid="btad047-F3" ref-type="fig">Fig. 3a</xref>). There are 30 nodes in each cluster, resulting in a total of 390 nodes. To generate the hierarchical cluster graph, we first generate point clouds via a Gaussian process in a latent space so that the Euclidean distance between two points from two sibling clusters is about twice (<inline-formula id="IE90"><mml:math id="IM90" display="inline" overflow="scroll"><mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mrow></mml:math></inline-formula> to be precise) the expected Euclidean distance from one of the two points to a point in the parent cluster, which is set to be 1. The noisiness of the clusters is controlled by the parameter <inline-formula id="IE91"><mml:math id="IM91" display="inline" overflow="scroll"><mml:mo>σ</mml:mo></mml:math></inline-formula>, which is set to 0.1 by default. These data points are then turned into a fully connected weighted graph using a RBF kernel (see <xref rid="sup1" ref-type="supplementary-material">Supplementary material</xref>). We consider two different tasks (<xref rid="btad047-F3" ref-type="fig">Fig. 3a), (i)</xref><italic toggle="yes">cluster classification</italic>: identifying individual cluster identity of each node in the graph and (ii) <italic toggle="yes">level classification</italic>: identifying the level to which the clusters correspond to. We split the nodes into 10% training and 90% testing and use the multinomial logistic regression model with l2 regularization for prediction. The evaluation process, including the embedding generation, is repeated 10 times, and the final results are reported by Macro F1 scores.</p>
        <fig position="float" id="btad047-F3">
          <label>Fig. 3.</label>
          <caption>
            <p>Hierarchical CLUSTER graph classification task. (<bold>a</bold>) Illustrations of the K3L2 hierarchical clusters. Left: top-down view of the clusters. Right: adjacency matrix of K3L2; colored brackets indicate the corresponding cluster levels of the nodes. (<bold>b</bold>) Classification evaluation on K3L2. (<bold>c</bold>) Classification evaluation on K3L2c45</p>
          </caption>
          <graphic xlink:href="btad047f3" position="float"/>
        </fig>
        <p>As shown in <xref rid="btad047-F3" ref-type="fig">Figure 3b</xref>, the performance of <italic toggle="yes">node2vec</italic> is not affected by the <italic toggle="yes">q</italic> parameter because the graph is fully connected. Meanwhile, <italic toggle="yes">node2vec+</italic> achieves significantly better performance than <italic toggle="yes">node2vec</italic> for large <italic toggle="yes">q</italic> settings for both tasks, demonstrating the ability of <italic toggle="yes">node2vec+</italic> to identify potential <italic toggle="yes">out</italic> edges and use this information to perform localized biased random walks. Similar results are observed on a couple of different hierarchical cluster graphs K3L3, K5L1 and K5L2 (see <xref rid="sup1" ref-type="supplementary-material">Supplementary material</xref>).</p>
        <p>On the other hand, one might suspect that the issue with the fully connected graph can be alleviated by sparsifying the graph based on certain edge weight thresholds. Such an approach is widely adopted as a post-processing step for constructing functional gene interaction networks. Here, we show that even after sparsifying the graph aggressively, <italic toggle="yes">node2vec+</italic> still outperforms <italic toggle="yes">node2vec</italic>. In particular, we sparsify the K3L2 graph using the edge weight threshold 0.45, which is the largest value that keeps the graph connected. We then perform the same evaluation analysis above on this sparsified graph K3L2c45. In this case, <italic toggle="yes">node2vec</italic> indeed performs significantly better than before the sparsification for both tasks. Nonetheless, <italic toggle="yes">node2vec+</italic> achieves even better performance, still out-competing node2vec (<xref rid="btad047-F3" ref-type="fig">Fig. 3c</xref>).</p>
        <p>Finally, we conduct a fine-grained evaluation analysis, showing that node2vec+ consistently outperforms node2vec under a wide range of conditions, including edge threshold, train-test ratio and noise level (see <xref rid="sup1" ref-type="supplementary-material">Supplementary material</xref>).</p>
      </sec>
    </sec>
    <sec>
      <title>3.2 Real-world datasets</title>
      <p>Our primary motivation for developing <italic toggle="yes">node2vec+</italic> stems from the fact that many functional gene interaction networks are dense and weighted. To systematically evaluate the ability of <italic toggle="yes">node2vec+</italic> to embed such biological networks, we consider various challenging gene classification tasks, including gene function and disease gene predictions. Furthermore, we devise experiments with previously benchmarked datasets BlogCatalog and Wikipedia (<xref rid="btad047-B14" ref-type="bibr">Grover and Leskovec, 2016</xref>) and confirm that <italic toggle="yes">node2vec+</italic> performs equal to or better than <italic toggle="yes">node2vec</italic>, depending on whether the network is weighted (see <xref rid="sup1" ref-type="supplementary-material">Supplementary material</xref>).</p>
      <sec>
        <title>3.2.1 Datasets</title>
        <p><bold>Human functional gene interaction networks</bold>: We consider functional gene interaction networks, which is a broader class of gene interaction networks that are routinely used to capture gene functional relationships.
</p>
        <list list-type="bullet">
          <list-item>
            <p><bold>STRING</bold> (<xref rid="btad047-B35" ref-type="bibr">Szklarczyk <italic toggle="yes">et al.</italic>, 2021</xref>) is an integrative gene interaction network that combines evidence of protein interactions from various sources, such as text-mining, high-throughput experiments, etc.</p>
          </list-item>
          <list-item>
            <p><bold>HumanBase-global</bold> is a tissue-naive version of the HumanBase (<xref rid="btad047-B12" ref-type="bibr">Greene <italic toggle="yes">et al.</italic>, 2015</xref>) tissue-specific networks (previously known as GIANT), which are constructed by integrating hundreds of thousands of publicly available gene expression studies, protein–protein interactions and protein–DNA interactions via a Bayesian approach, calibrated against high-quality known functional gene interactions.</p>
          </list-item>
          <list-item>
            <p><bold>HumanBaseTop-global</bold> is a sparsified version of HumanBase-global that eliminates all edges below the prior of 0.1.</p>
          </list-item>
        </list>
        <p><bold>Multi-label gene classification tasks</bold>: We follow the procedure detailed in <xref rid="btad047-B24" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2020)</xref> to prepare the multi-label gene classification datasets. More specifically, we prepare two collections of gene classification tasks (each is called a gene set collection):
</p>
        <list list-type="bullet">
          <list-item>
            <p><bold>GOBP</bold>: Gene function prediction tasks derived from the Biological Processes gene sets from <xref rid="btad047-B37" ref-type="bibr">The Gene Ontology Consortium (2018)</xref>.</p>
          </list-item>
          <list-item>
            <p><bold>DisGeNET</bold>: Disease gene prediction tasks derived from the disease gene sets from the DisGeNET database (<xref rid="btad047-B32" ref-type="bibr">Piñero <italic toggle="yes">et al.</italic>, 2016</xref>).</p>
          </list-item>
        </list>
        <p>After filtering and cleaning up the raw gene set collections, we end up with ∼45 functional gene prediction tasks and ∼100 disease gene prediction tasks (<xref rid="btad047-T1" ref-type="table">Table 1</xref>). These gene classification tasks are challenging primarily due to the scarcity of the labeled examples, with on average 100 and 200 positive examples per task for GOBP and DisGeNET, respectively, relative to the (order of) tens of thousands of nodes in the networks.</p>
        <table-wrap position="float" id="btad047-T1">
          <label>Table 1.</label>
          <caption>
            <p>Number of tasks (i.e. gene sets or node classes) for each combination of network and gene set collection</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="(" span="1"/>
              <col valign="top" align="char" char="(" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1">GOBP</th>
                <th rowspan="1" colspan="1">DisGeNET</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">HumanBase</td>
                <td rowspan="1" colspan="1">46 (98.3)</td>
                <td rowspan="1" colspan="1">103 (225.9)</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">STRING</td>
                <td rowspan="1" colspan="1">41 (100.0)</td>
                <td rowspan="1" colspan="1">97 (221.5)</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <p><italic toggle="yes">Note</italic>: The number in the parenthesis is the average number of positive examples.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>We split the genes into 60% training, 20% validation and 20% testing according to the level at which they have been studied in the literature (based on the number of PubMed publications associated with each gene). In particular, the top 60% most well-studied genes are used for training; the 20% least-studied genes are used for testing, and the rest are used for validation. For GNNs, we report the test scores at the epoch where the best validation score is achieved.</p>
      </sec>
      <sec>
        <title>3.2.2 Baseline methods</title>
        <p>We exclude several popular node embedding methods, such as DeepWalk (<xref rid="btad047-B31" ref-type="bibr">Perozzi <italic toggle="yes">et al.</italic>, 2014</xref>), LINE (<xref rid="btad047-B36" ref-type="bibr">Tang <italic toggle="yes">et al.</italic>, 2015</xref>) and GraRep (<xref rid="btad047-B4" ref-type="bibr">Cao <italic toggle="yes">et al.</italic>, 2015</xref>), from our main analysis, as it has been shown previously in various contexts (<xref rid="btad047-B2" ref-type="bibr">Ata <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btad047-B14" ref-type="bibr">Grover and Leskovec, 2016</xref>; <xref rid="btad047-B43" ref-type="bibr">Yue <italic toggle="yes">et al.</italic>, 2019</xref>) that <italic toggle="yes">node2vec</italic> is superior.</p>
        <p>On the other hand, we include two popular GNNs, GCN (<xref rid="btad047-B21" ref-type="bibr">Kipf and Welling, 2016</xref>) and GraphSAGE (<xref rid="btad047-B16" ref-type="bibr">Hamilton <italic toggle="yes">et al.</italic>, 2017</xref>) in our comparison. Both methods have shown exceptional performance on many node classification tasks, but their performance on the gene classification tasks here still needs to be better studied. For GraphSAGE, we consider the full-batch training strategy with mean pooling aggregation following the Open Graph Benchmark (<xref rid="btad047-B18" ref-type="bibr">Hu <italic toggle="yes">et al.</italic>, 2021</xref>).</p>
      </sec>
      <sec>
        <title>3.2.3 Experiment setup</title>
        <p><bold>Evaluation metric</bold>: Following (<xref rid="btad047-B24" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2020</xref>), we use the <inline-formula id="IE92"><mml:math id="IM92" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mfrac><mml:mrow><mml:mtext>auPRC</mml:mtext></mml:mrow><mml:mrow><mml:mtext>prior</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> as our evaluation metric, which represents the <inline-formula id="IE93"><mml:math id="IM93" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> fold change of the average precision compared to the prior. This metric is more suitable than other commonly used metrics like AUROC as it corrects for the class imbalance issue that is prevalent in the gene classification tasks here, as well as emphasizes the correctness of top predictions.</p>
        <p><bold>Tuning embeddings parameters</bold>: For <italic toggle="yes">node2vec</italic> and node2vec+, we train a one versus rest logistic regression with l2 regularization using the embeddings learned. The parameters for embeddings including dimension, window-size, walk-length and number of walks per node are set to 128, 10, 80 and 10, respectively, by default. We tune the hyperparameters for <italic toggle="yes">node2vec</italic> <inline-formula id="IE94"><mml:math id="IM94" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and for <italic toggle="yes">node2vec+</italic> <inline-formula id="IE95"><mml:math id="IM95" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo>,</mml:mo><mml:mo>γ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> via grid search using the validation sets. To keep the grid search budget comparable, we search <italic toggle="yes">p</italic> and <italic toggle="yes">q</italic> over <inline-formula id="IE96"><mml:math id="IM96" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>0.05</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>50</mml:mn><mml:mo>,</mml:mo><mml:mn>100</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> for <italic toggle="yes">node2vec</italic> <inline-formula id="IE97"><mml:math id="IM97" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>81</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>; we search <italic toggle="yes">p</italic> and <italic toggle="yes">q</italic> over <inline-formula id="IE98"><mml:math id="IM98" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>100</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, together with <inline-formula id="IE99"><mml:math id="IM99" display="inline" overflow="scroll"><mml:mrow><mml:mo>γ</mml:mo><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> for <italic toggle="yes">node2vec+</italic> <inline-formula id="IE100"><mml:math id="IM100" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>75</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
        <p><bold>Tuning GNN parameters</bold>: For both GNNs, we train one model for each combination of a network and a gene set collection in an end-to-end fashion. The architectures are fixed to five hidden layers with a hidden dimension of 128. Since the gene interaction networks here do not come with node features, we use the constant feature for GCN and the degree feature for GraphSAGE, respectively. We use the Adam optimizer (<xref rid="btad047-B20" ref-type="bibr">Kingma and Ba, 2014</xref>) to train the GNNs with 100 000 max number of epochs. The learning rates are tuned via grid search from <inline-formula id="IE101"><mml:math id="IM101" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> to <inline-formula id="IE102"><mml:math id="IM102" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> based on the validation performance. The optimal learning rates that result in a decent convergence rate without diverging are 0.01 and 0.0005 for GCN and GraphSAGE, respectively (see <xref rid="sup1" ref-type="supplementary-material">Supplementary material</xref>).</p>
      </sec>
      <sec>
        <title>3.2.4 Experimental results</title>
        <p><bold>Tuning</bold><inline-formula id="IE103"><mml:math id="IM103" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula><bold>significantly improves performance for dense graph</bold>: The <inline-formula id="IE104"><mml:math id="IM104" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula> parameter in <italic toggle="yes">node2vec+</italic> (see Section 2.2) controls the threshold of distinguishing <italic toggle="yes">in</italic> edges and <italic toggle="yes">out</italic> edges. A small or negative valued <inline-formula id="IE105"><mml:math id="IM105" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula> considers most non-zero edges as <italic toggle="yes">out</italic> edges. Conversely, a large valued <inline-formula id="IE106"><mml:math id="IM106" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula> identifies less <italic toggle="yes">out</italic> edges. When the input graph is noisy and dense, assigning a larger <inline-formula id="IE107"><mml:math id="IM107" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula> (e.g. 1) can act as a stronger denoiser to suppress spurious <italic toggle="yes">out</italic> edges. <xref rid="btad047-F4" ref-type="fig">Figure 4</xref> compares the gene classification test performance between <inline-formula id="IE108"><mml:math id="IM108" display="inline" overflow="scroll"><mml:mrow><mml:mo>γ</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE109"><mml:math id="IM109" display="inline" overflow="scroll"><mml:mrow><mml:mo>γ</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> with optimally tuned <italic toggle="yes">p</italic>, <italic toggle="yes">q</italic> using the HumanBase-global network. Higher testing scores are achieved by larger <inline-formula id="IE110"><mml:math id="IM110" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula> settings, illustrating that, to properly ‘denoise’ the fully connected weighted graph HumanBase-global, we need to increase the noisy edge thresholds. On the contrary, the difference in performance due to the <inline-formula id="IE111"><mml:math id="IM111" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula> settings is less pronounced for sparse networks like HumanBaseTop-global and STRING (see <xref rid="sup1" ref-type="supplementary-material">Supplementary material</xref>).</p>
        <fig position="float" id="btad047-F4">
          <label>Fig. 4.</label>
          <caption>
            <p>Comparison of different <inline-formula id="IE112"><mml:math id="IM112" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula> settings in <italic toggle="yes">node2vec+</italic> using HumanBase-global. Each dot represents the testing performance (<inline-formula id="IE113"><mml:math id="IM113" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mfrac><mml:mrow><mml:mtext>auPRC</mml:mtext></mml:mrow><mml:mrow><mml:mtext>prior</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>) of a specific gene set, with optimally tuned <italic toggle="yes">p</italic> and <italic toggle="yes">q</italic> settings</p>
          </caption>
          <graphic xlink:href="btad047f4" position="float"/>
        </fig>
        <p><bold>GNN methods performs worse than <italic toggle="yes">node2vec(+)</italic></bold>: In all settings, <italic toggle="yes">node2vec+</italic> significantly outperforms both GNN methods (<xref rid="btad047-F5" ref-type="fig">Fig. 5</xref>). Notably, for the STRING network, both <italic toggle="yes">node2vec</italic> and <italic toggle="yes">node2vec+</italic> outperform the two GNNs by a large margin. The sub-optimal GNN performance here illustrates that, despite being powerful neural network architectures that can leverage the graph structures, GNNs alone cannot learn effectively given a limited number of labeled examples. On the contrary, the embedding processes of <italic toggle="yes">node2vec(+)</italic> are task agnostic and can be carried out effectively without labels. These results indicate that gene classification tasks based on gene interaction network are more effectively solved by unsupervised shallow embedding methods than GNNs.<bold><italic toggle="yes">nod2vec</italic>+ matches or outperforms <italic toggle="yes">node2vec</italic></bold>: <italic toggle="yes">node2vec+</italic> significantly outperforms <italic toggle="yes">node2vec</italic> [Wilcoxon paired test (<xref rid="btad047-B41" ref-type="bibr">Wilcoxon, 1945</xref>) <italic toggle="yes">P</italic> &lt; 0.05] except for the DisGeNET tasks using HumanBaseTop-global and STRING networks, in which cases the two methods perform equally (<xref rid="btad047-F5" ref-type="fig">Fig. 5</xref>). The performance differences are especially pronounced when using the fully connected and noisy HumanBase-global network, demonstrating <italic toggle="yes">node2vec+</italic>’s ability to learn robust node representations in the presence of noise. Nevertheless, when the network is less dense (e.g. HumanBaseTop-global), <italic toggle="yes">node2vec+</italic> is still able to perform at least as well as <italic toggle="yes">node2vec</italic>, indicating that <italic toggle="yes">node2vec+</italic> is overall a good replacement of <italic toggle="yes">node2vec</italic>.</p>
        <fig position="float" id="btad047-F5">
          <label>Fig. 5.</label>
          <caption>
            <p>Gene classification tasks using protein–protein interaction networks. Each panel corresponds to a specific protein–protein interaction network (HumanBase-global, HumanBaseTop-global and STRING). Each point in a boxplot represents the final test score for a specific task (gene set) in the gene set collection (GOBP or DisGeNET). Starred (*) pairs indicate that the performance between <italic toggle="yes">node2vec</italic> and <italic toggle="yes">node2vec+</italic> are significantly different (Wilcoxon <italic toggle="yes">P</italic> &lt; 0.05)</p>
          </caption>
          <graphic xlink:href="btad047f5" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>3.2.5 Tissue-specific functional gene classification</title>
        <p>A key feature of functional gene interaction networks constructed using gene expression data is capturing biological context specificity, such as tissue-specificity provided by the HumanBase networks. Thus, we further demonstrate the use case of <italic toggle="yes">node2vec+</italic> using tissue-specific functional gene classification tasks derived from <xref rid="btad047-B47" ref-type="bibr">Zitnik and Leskovec (2017)</xref>. After processing, there are 25 tissue-specific functional gene classification tasks, with 12 different tissues found in the HumanBase database. We follow a similar experimental setup as above, and for each tissue-specific functional gene classification task, we report the followings: (i) <italic toggle="yes">matched</italic>: the prediction performance using the corresponding tissue-specific network; (ii) <italic toggle="yes">other</italic>: the average prediction performance using tissue-specific networks other than the corresponding tissue; (iii) <italic toggle="yes">global</italic>: the prediction performance using the tissue-naive network.</p>
        <p><xref rid="btad047-F6" ref-type="fig">Figure 6</xref> shows that <italic toggle="yes">node2vec+</italic> outperforms <italic toggle="yes">node2vec</italic> in most scenarios, especially when using the full HumanBase networks. In particular, <italic toggle="yes">node2vec+</italic>, using the <italic toggle="yes">matched</italic> tissue-specific full networks for the given functional gene classification tasks, results in significantly better performance than using <italic toggle="yes">other</italic> (unrelated) tissue-specific networks, as well as the <italic toggle="yes">global</italic> (tissue-naive) network. On the contrary, <italic toggle="yes">node2vec</italic> cannot fully utilize the tissue-specific networks, as indicated by the lack of difference in performance between <italic toggle="yes">matched</italic> and <italic toggle="yes">global</italic> networks.</p>
        <fig position="float" id="btad047-F6">
          <label>Fig. 6.</label>
          <caption>
            <p>Tissue-specific functional gene classification performance comparison between node2vec and node2vec+ using HumanBase and HumanBaseTop tissue-specific networks</p>
          </caption>
          <graphic xlink:href="btad047f6" position="float"/>
        </fig>
        <p>We observe similar results using another collection of tissue-specific co-expression networks, GTExCoExp, that are generated using a benchmarked co-expression network generation workflow by <xref rid="btad047-B19" ref-type="bibr">Johnson and Krishnan (2022)</xref> (see <xref rid="sup1" ref-type="supplementary-material">Supplementary material</xref>).</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion and conclusion</title>
    <p>In this article, we proposed <italic toggle="yes">node2vec+</italic> that improves upon the second-order random walk in <italic toggle="yes">node2vec</italic> for weighted graphs by considering edge weights. Consequently, the corresponding node embeddings are improved whenever the <italic toggle="yes">in–out</italic> walks positively influence the task (meaning that the optimal <italic toggle="yes">q</italic> setting is not 1).</p>
    <p>We showed that <italic toggle="yes">node2vec+</italic> better identifies potential out edges on weighted graphs than <italic toggle="yes">node2vec</italic> using two synthetic datasets, including the barbell graph and the hierarchical cluster graphs. Furthermore, evaluations on various challenging gene classification tasks demonstrated that embedding methods like <italic toggle="yes">node2vec(+)</italic> are superior to GNNs. GNNs learn how to orient the nodes in a low-dimensional space to maximize the separation between nodes of different classes in an end-to-end fashion. The suboptimal GNN performance here highlights their need for a much larger labeled training dataset to fully exploit the expressive power of their architectures. Unfortunately, many real-world biological applications, such as the function or disease gene classification problems here, still lack large amounts of labeled data. For these applications, an unsupervised approach like <italic toggle="yes">node2vec(+)</italic> may be more suitable as it arranges the latent space purely based on the underlying graph structure, after which a less data-hungry model, such as logistic regression, can be applied to perform the classifications.</p>
    <p>Dense weighted graphs are common in biology, directly based on the experiment [e.g. genetic interactions (<xref rid="btad047-B7" ref-type="bibr">Costanzo <italic toggle="yes">et al.</italic>, 2016</xref>)], by construction [e.g. co-expression (<xref rid="btad047-B45" ref-type="bibr">Zhang and Horvath, 2005</xref>)] or by integrating multiple network datasets sources [<xref rid="btad047-B12" ref-type="bibr">Greene <italic toggle="yes">et al.</italic>, 2015</xref>; <xref rid="btad047-B35" ref-type="bibr">Szklarczyk <italic toggle="yes">et al.</italic>, 2021</xref>]. Network embedding has recently found applications in studying co-expression networks, e.g. in the context of evolutionary and cross-species network alignment (<xref rid="btad047-B28" ref-type="bibr">Ovens <italic toggle="yes">et al.</italic>, 2021a</xref>,<xref rid="btad047-B29" ref-type="bibr">b</xref>), cancer prognostic gene identification (<xref rid="btad047-B6" ref-type="bibr">Choi <italic toggle="yes">et al.</italic>, 2018</xref>) and gene functional interaction prediction (<xref rid="btad047-B10" ref-type="bibr">Du <italic toggle="yes">et al.</italic>, 2019</xref>). These applications, especially the ones that leverage dense weighted graphs, are likely to benefit from using <italic toggle="yes">node2vec+</italic>.</p>
    <p>Sparsification using a hard threshold is a common technique for dealing with fully connected weighted graphs like co-expression (<xref rid="btad047-B10" ref-type="bibr">Du <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btad047-B45" ref-type="bibr">Zhang and Horvath, 2005</xref>). However, finding the optimal cut threshold could be quite challenging [usually relying on heuristics (<xref rid="btad047-B28" ref-type="bibr">Ovens <italic toggle="yes">et al.</italic>, 2021a</xref>)], and such thresholding may change the graph significantly in terms of its spectrum (<xref rid="btad047-B34" ref-type="bibr">Spielman and Teng, 2010</xref>). <italic toggle="yes">Node2vec+</italic>, on the other hand, can be seen as a soft thresholding approach that suppresses transitions over <italic toggle="yes">noisy</italic> edges.</p>
    <p>Overall, <italic toggle="yes">node2vec+</italic> is a natural extension of <italic toggle="yes">node2vec</italic> for weighted graphs and has several desirable properties. With its general procedure for biased random walks, <italic toggle="yes">node2vec+</italic> can be easily adapted into other methods such as KG2Vec (<xref rid="btad047-B40" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2021b</xref>) and Het-Node2vec (<xref rid="btad047-B38" ref-type="bibr">Valentini <italic toggle="yes">et al.</italic>, 2021</xref>) that are built on top of <italic toggle="yes">node2vec</italic>. <italic toggle="yes">Node2vec+</italic> is available as an open-source software as part of the PecanPy package: <ext-link xlink:href="https://github.com/krishnanlab/PecanPy" ext-link-type="uri">https://github.com/krishnanlab/PecanPy</ext-link>.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btad047_Supplementary_Data</label>
      <media xlink:href="btad047_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the US National Institutes of Health (NIH) [R35 GM128765 to A.K.] and [R01 GM135929 to M.H.]; It was also supported by the National Science Foundation (NSF) CAREER [1845856 to M.H.].</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btad047-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ata</surname><given-names>S.K.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>Integrating node embeddings and biological annotations for genes to predict disease-gene associations</article-title>. <source>BMC Syst. Biol</source>., <volume>12</volume>, <fpage>138</fpage>.<pub-id pub-id-type="pmid">30598097</pub-id></mixed-citation>
    </ref>
    <ref id="btad047-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ata</surname><given-names>S.K.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Recent advances in network-based methods for disease gene prediction</article-title>. <source>Brief. Bioinform</source>., <volume>22</volume>, bbaa303.</mixed-citation>
    </ref>
    <ref id="btad047-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Bronstein</surname><given-names>M.M.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) Geometric deep learning: grids, groups, graphs, geodesics, and gauges. arXiv, arXiv:2104.13478 [cs, stat], preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btad047-B4">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Cao</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) GraRep: learning graph representations with global structural information. In: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, CIKM ’15, pp. <fpage>891</fpage>–<lpage>900</lpage>. Association for Computing Machinery, New York, NY, USA.</mixed-citation>
    </ref>
    <ref id="btad047-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Chattopadhyay</surname><given-names>S.</given-names></string-name>, <string-name><surname>Ganguly</surname><given-names>D.</given-names></string-name></person-group> (<year>2020</year>) Community structure aware embedding of nodes in a network. arXiv, arXiv:2006.15313 [physics], preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btad047-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Choi</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>G2vec: distributed gene representations for identification of cancer prognostic genes</article-title>. <source>Nat. Sci. Rep</source>.</mixed-citation>
    </ref>
    <ref id="btad047-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Costanzo</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>A global genetic interaction network maps a wiring diagram of cellular function</article-title>. <source>Science</source>, <volume>353</volume>, <fpage>aaf1420</fpage>.<pub-id pub-id-type="pmid">27708008</pub-id></mixed-citation>
    </ref>
    <ref id="btad047-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cui</surname><given-names>P.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>A survey on network embedding</article-title>. <source>IEEE Trans. Knowl. Data Eng</source>., <volume>31</volume>(5), 833–<lpage>852</lpage>.</mixed-citation>
    </ref>
    <ref id="btad047-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Davison</surname><given-names>A.</given-names></string-name>, <string-name><surname>Austern</surname><given-names>M.</given-names></string-name></person-group> (<year>2021</year>) Asymptotics of network embeddings learned via subsampling. arXiv, arXiv:2107.02363 [cs, math, stat], preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btad047-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Du</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Gene2vec: distributed representation of genes based on co-expression</article-title>. <source>BMC Genomics</source>, <volume>20</volume>.</mixed-citation>
    </ref>
    <ref id="btad047-B11">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Dwivedi</surname><given-names>V.P.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) Benchmarking graph neural networks. <italic toggle="yes">JMLR</italic>, <bold>24</bold>(43), <fpage>1</fpage>–<lpage>48</lpage>.</mixed-citation>
    </ref>
    <ref id="btad047-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Greene</surname><given-names>C.S.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) <article-title>Understanding multicellular function and disease with human tissue-specific networks</article-title>. <source>Nat. Genet</source>., <volume>47</volume>, <fpage>569</fpage>–<lpage>576</lpage>.<pub-id pub-id-type="pmid">25915600</pub-id></mixed-citation>
    </ref>
    <ref id="btad047-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Grohe</surname><given-names>M.</given-names></string-name></person-group> (<year>2020</year>) word2vec, node2vec, graph2vec, X2vec: towards a theory of vector embeddings of structured data. In: <italic toggle="yes">Proceedings of the 39th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems, PODS</italic>'20, pp.1–16. AMC, New York, NY, USA; Portland, Oregon, USA.</mixed-citation>
    </ref>
    <ref id="btad047-B14">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Grover</surname><given-names>A.</given-names></string-name>, <string-name><surname>Leskovec</surname><given-names>J.</given-names></string-name></person-group> (<year>2016</year>) <part-title>Node2Vec: scalable feature learning for networks</part-title>. In: <source>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’16</source>, pp. <fpage>855</fpage>–<lpage>864</lpage>. <publisher-loc>ACM, New York, NY, USA; San Francisco, California, USA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btad047-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Hacker</surname><given-names>C.</given-names></string-name></person-group> (<year>2021</year>) k-simplex2vec: a simplicial extension of node2vec. arXiv, arXiv:2010.05636 [cs, math], preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btad047-B16">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Hamilton</surname><given-names>W.L.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) Inductive representation learning on large graphs. In: <italic toggle="yes">31st Conference on Neural Information Processing Systems, Long Beach, CA, USA</italic>.</mixed-citation>
    </ref>
    <ref id="btad047-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hu</surname><given-names>F.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Community detection in complex networks using Node2vec with spectral clustering</article-title>. <source>Physica A</source>, <volume>545</volume>, <fpage>123633</fpage>.</mixed-citation>
    </ref>
    <ref id="btad047-B18">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Hu</surname><given-names>W.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) Open graph benchmark: datasets for machine learning on graphs. In: <italic toggle="yes">34th Conference on Neural Information Processing Systems, Vancouver, Canada</italic>.</mixed-citation>
    </ref>
    <ref id="btad047-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname><given-names>K.A.</given-names></string-name>, <string-name><surname>Krishnan</surname><given-names>A.</given-names></string-name></person-group> (<year>2022</year>) <article-title>Robust normalization and transformation techniques for constructing gene coexpression networks from RNA-seq data</article-title>. <source>Genome Biol</source>., <volume>23</volume>, <fpage>1</fpage>–<lpage>26</lpage>.<pub-id pub-id-type="pmid">34980209</pub-id></mixed-citation>
    </ref>
    <ref id="btad047-B20">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>D.P.</given-names></string-name>, <string-name><surname>Ba</surname><given-names>J.</given-names></string-name></person-group> (<year>2014</year>) Adam: a method for stochastic optimization. In: <italic toggle="yes">3rd International Conference on Learning Representations, San Diego, CA, USA</italic>.</mixed-citation>
    </ref>
    <ref id="btad047-B21">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kipf</surname><given-names>T.N.</given-names></string-name>, <string-name><surname>Welling</surname><given-names>M.</given-names></string-name></person-group> (<year>2016</year>) Semi-supervised classification with graph convolutional networks. In: <italic toggle="yes">5th International Conference on Learning Representations, Toulon, France</italic>.</mixed-citation>
    </ref>
    <ref id="btad047-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krishnan</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>Genome-wide prediction and functional characterization of the genetic basis of autism spectrum disorder</article-title>. <source>Nat. Neurosci</source>., <volume>19</volume>, <fpage>1454</fpage>–<lpage>1462</lpage>.<pub-id pub-id-type="pmid">27479844</pub-id></mixed-citation>
    </ref>
    <ref id="btad047-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>R.</given-names></string-name>, <string-name><surname>Krishnan</surname><given-names>A.</given-names></string-name></person-group> (<year>2021</year>) <article-title>PecanPy: a fast, efficient and parallelized python implementation of node2vec</article-title>. <source>Bioinformatics</source>, <volume>37</volume>, <fpage>3377</fpage>–<lpage>3379</lpage>.<pub-id pub-id-type="pmid">33760066</pub-id></mixed-citation>
    </ref>
    <ref id="btad047-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Supervised learning is an accurate method for network-based gene classification</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>3457</fpage>–<lpage>3465</lpage>.<pub-id pub-id-type="pmid">32129827</pub-id></mixed-citation>
    </ref>
    <ref id="btad047-B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Mikolov</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2013a</year>) Distributed representations of words and phrases and their compositionality. In: <italic toggle="yes">Proceedings of the 26th International Conference on Neural Information Processing Systems, NIPS'13; Lake Tahoe, Nevada, USA</italic>.</mixed-citation>
    </ref>
    <ref id="btad047-B26">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Mikolov</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2013b</year>) Efficient estimation of word representations in vector space. In: <italic toggle="yes">1st International Conference on Learning Representations; Scottsdale, Arizona, USA</italic>.</mixed-citation>
    </ref>
    <ref id="btad047-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nelson</surname><given-names>W.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>To Embed or not: network embedding as a paradigm in computational biology</article-title>. <source>Front. Genet</source>., <volume>10</volume>, <fpage>381</fpage>.<pub-id pub-id-type="pmid">31118945</pub-id></mixed-citation>
    </ref>
    <ref id="btad047-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ovens</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2021a</year>) <article-title>Comparative analyses of gene co-expression networks: implementations and applications in the study of evolution</article-title>. <source>Front. Genet</source>., <volume>12</volume>, <fpage>695399</fpage>.<pub-id pub-id-type="pmid">34484293</pub-id></mixed-citation>
    </ref>
    <ref id="btad047-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ovens</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2021b</year>) <article-title>Juxtapose: a gene-embedding approach for comparing co-expression networks</article-title>. <source>BMC Bioinformatics</source>, <volume>22</volume>, 125.</mixed-citation>
    </ref>
    <ref id="btad047-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peng</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Predicting parkinson’s disease genes based on node2vec and autoencoder</article-title>. <source>Front. Genet</source>., <volume>10</volume>, <fpage>226</fpage>.<pub-id pub-id-type="pmid">31001311</pub-id></mixed-citation>
    </ref>
    <ref id="btad047-B31">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Perozzi</surname><given-names>B.</given-names></string-name></person-group><etal>et al</etal> (<year>2014</year>) DeepWalk: online learning of social representations. <italic toggle="yes">Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD ’14</italic>, pp. <fpage>701</fpage>–<lpage>710</lpage>. arXiv: 1403.6652.</mixed-citation>
    </ref>
    <ref id="btad047-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Piñero</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>DisGeNET: a comprehensive platform integrating information on human disease-associated genes and variants</article-title>. <source>Nucleic Acids Res</source>., <volume>45</volume>, D833–D839.</mixed-citation>
    </ref>
    <ref id="btad047-B33">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Qiu</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) Network embedding as matrix factorization: unifying DeepWalk, LINE, PTE, and node2vec. In: Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining, WSDM ’18, pp. <fpage>459</fpage>–<lpage>467</lpage>. Association for Computing Machinery, New York, NY, USA.</mixed-citation>
    </ref>
    <ref id="btad047-B34">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Spielman</surname><given-names>D.A.</given-names></string-name>, <string-name><surname>Teng</surname><given-names>S.-H.</given-names></string-name></person-group> (<year>2010</year>) Spectral sparsification of graphs. <italic toggle="yes">SIAM Journal on Computing</italic>, <bold>40</bold>(4), <fpage>981</fpage>–<lpage>1025</lpage>.</mixed-citation>
    </ref>
    <ref id="btad047-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Szklarczyk</surname><given-names>D.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>The STRING database in 2021: customizable protein–protein networks, and functional characterization of user-uploaded gene/measurement sets</article-title>. <source>Nucleic Acids Res</source>., <volume>49</volume>, <fpage>D605</fpage>–<lpage>D612</lpage>.<pub-id pub-id-type="pmid">33237311</pub-id></mixed-citation>
    </ref>
    <ref id="btad047-B36">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Tang</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) LINE: large-scale information network embedding. In: <italic toggle="yes">Proceedings of the 24th International Conference on World Wide Web</italic>, WWW' 15, pp. <fpage>1067</fpage>–<lpage>1077</lpage>. Republic and Canton of Geneva, CHE. International World Wide Web Conferences Steering Committee.; Florence, Italy</mixed-citation>
    </ref>
    <ref id="btad047-B37">
      <mixed-citation publication-type="journal"><collab>The Gene Ontology Consortium</collab>. (<year>2018</year>) <article-title>The Gene Ontology Resource: 20 years and still GOing strong</article-title>. <source>Nucleic Acids Res</source>., <volume>47</volume>, <fpage>D330</fpage>–<lpage>D338</lpage>.</mixed-citation>
    </ref>
    <ref id="btad047-B38">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Valentini</surname><given-names>G.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) Het-node2vec: second order random walk sampling for heterogeneous multigraphs embedding. arXiv, arXiv:2101.01425 [physics], preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btad047-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>N.</given-names></string-name></person-group><etal>et al</etal> (<year>2021a</year>) <article-title>Essential protein prediction based on node2vec and XGBoost</article-title>. <source>J. Comput. Biol</source>., <volume>28</volume>, <fpage>687</fpage>–<lpage>700</lpage>.<pub-id pub-id-type="pmid">34152838</pub-id></mixed-citation>
    </ref>
    <ref id="btad047-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2021b</year>) <article-title>KG2Vec: a node2vec-based vectorization model for knowledge graph</article-title>. <source>PLoS One</source>, <volume>16</volume>, <fpage>e0248552</fpage>.<pub-id pub-id-type="pmid">33784319</pub-id></mixed-citation>
    </ref>
    <ref id="btad047-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilcoxon</surname><given-names>F.</given-names></string-name></person-group> (<year>1945</year>) <article-title>Individual comparisons by ranking methods</article-title>. <source>Biometrics Bull</source>., <volume>1</volume>, <fpage>80</fpage>–<lpage>83</lpage>.</mixed-citation>
    </ref>
    <ref id="btad047-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname><given-names>Z.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>A comprehensive survey on graph neural networks</article-title>. <source>IEEE Trans. Neural Netw. Learn. Syst</source>., <volume>32</volume>, <fpage>4</fpage>–<lpage>24</lpage>.<pub-id pub-id-type="pmid">32217482</pub-id></mixed-citation>
    </ref>
    <ref id="btad047-B43">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Yue</surname><given-names>X.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) Graph embedding on biomedical networks: methods, applications, and evaluations. <italic toggle="yes">Bioinformatics</italic>, <bold>36</bold>(4), <fpage>1241</fpage>–<lpage>1251</lpage>.</mixed-citation>
    </ref>
    <ref id="btad047-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zeng</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>A deep learning framework for identifying essential proteins by integrating multiple types of biological information</article-title>. <source>IEEE/ACM Trans. Comput. Biol. Bioinform</source>., <volume>18</volume>, <fpage>296</fpage>–<lpage>305</lpage>.<pub-id pub-id-type="pmid">30736002</pub-id></mixed-citation>
    </ref>
    <ref id="btad047-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>B.</given-names></string-name>, <string-name><surname>Horvath</surname><given-names>S.</given-names></string-name></person-group> (<year>2005</year>) <article-title>A general framework for weighted gene co-expression network analysis</article-title>. <source>Stat. Appl. Genet. Mol. Biol</source>., <volume>4</volume>.</mixed-citation>
    </ref>
    <ref id="btad047-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>X.-M.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Graph neural networks and their current applications in bioinformatics</article-title>. <source>Front. Genet</source>., <volume>12</volume>, <fpage>1073</fpage>.</mixed-citation>
    </ref>
    <ref id="btad047-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zitnik</surname><given-names>M.</given-names></string-name>, <string-name><surname>Leskovec</surname><given-names>J.</given-names></string-name></person-group> (<year>2017</year>) <article-title>Predicting multicellular function through multi-layer tissue networks</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>i190</fpage>–<lpage>i198</lpage>.<pub-id pub-id-type="pmid">28881986</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
