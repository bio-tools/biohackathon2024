{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fce75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import classification_report\n",
    "from datasets import Dataset, DatasetDict, Features, Sequence, Value, ClassLabel\n",
    "# Add evaluate import\n",
    "import evaluate\n",
    "import wandb\n",
    "from huggingface_hub import HfFolder\n",
    "# from wandb.integration.sb3 import WandbCallback\n",
    "import argparse\n",
    "# Initialize the metric\n",
    "#metric = load_metric(\"seqeval\")\n",
    "# Initialize the metric using evaluate\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b955286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve HF token from environment and authenticate\n",
    "hf_token = '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' #Zunaira\n",
    "data_folder = '../data/IOB/'\n",
    "model_checkpoint = 'bioformers/bioformer-16L'\n",
    "model_save_path = '../models/'\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13072ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_checkpoints(output_dir, keep_last=True, best_model_dir=None, last_model_dir=None):\n",
    "    \"\"\"\n",
    "    Deletes unnecessary model checkpoints created during training.\n",
    "    Keeps the best model directory and optionally the last model directory.\n",
    "\n",
    "    :param output_dir: Base directory where the checkpoints are saved.\n",
    "    :param keep_last: Whether to keep the last checkpoint.\n",
    "    :param best_model_dir: Directory of the best model checkpoint.\n",
    "    :param last_model_dir: Directory of the last model checkpoint.\n",
    "    \"\"\"\n",
    "    for item in os.listdir(output_dir):\n",
    "        item_path = os.path.join(output_dir, item)\n",
    "        if os.path.isdir(item_path) and item.startswith(\"checkpoint\"):\n",
    "            # Check if this path is not the one we want to keep\n",
    "            if item_path != best_model_dir and (not keep_last or item_path != last_model_dir):\n",
    "                shutil.rmtree(item_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be5533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_IOB_transformer(test_list, pattern):\n",
    "    new_list = []\n",
    "    sub_list = []\n",
    "    for i in test_list:\n",
    "\n",
    "        if i != pattern:\n",
    "            sub_list.append(i)\n",
    "        else:\n",
    "            new_list.append(sub_list)\n",
    "            sub_list = []\n",
    "\n",
    "    return new_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e11500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_ner_tags(df_, split_name, label2id_):\n",
    "    ner_tag_list_ = df_['ner_tags'].map(label2id_).fillna(\n",
    "        '#*#*#*#*#*#*#*#*').tolist()  # convert the list to a pandas series temporarily before mapping\n",
    "    token_list_ = df_['tokens'].tolist()\n",
    "\n",
    "    token_list = convert_IOB_transformer(test_list=token_list_, pattern='')\n",
    "    ner_tag_list = convert_IOB_transformer(test_list=ner_tag_list_, pattern='#*#*#*#*#*#*#*#*')\n",
    "\n",
    "    df = pd.DataFrame(list(zip(token_list, ner_tag_list)),\n",
    "                      columns=['tokens', 'ner_tags'])\n",
    "\n",
    "    # df.to_csv(path_+'GP-DS-OG-CD-Santosh/'+split_name+'_formatted.tsv', index=None, sep ='\\t', header=None)\n",
    "\n",
    "    return token_list, ner_tag_list, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec487990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p, id2label):\n",
    "    \"\"\"\n",
    "    Computes evaluation metrics and prints a detailed classification report.\n",
    "\n",
    "    Parameters:\n",
    "    p (tuple): A tuple containing predictions and labels.\n",
    "    id2label (dict): A dictionary mapping label IDs to label names.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with precision, recall, f1, and accuracy metrics.\n",
    "    \"\"\"\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)  # Assuming predictions are logits or probabilities\n",
    "\n",
    "    # Decode predictions and labels using id2label\n",
    "    true_predictions = [\n",
    "        [id2label[pred] for (pred, label) in zip(prediction, label_ids) if label != -100]\n",
    "        for prediction, label_ids in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label[label] for (pred, label) in zip(prediction, label_ids) if label != -100]\n",
    "        for prediction, label_ids in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    # Flatten the lists for classification_report\n",
    "    flat_predictions = [pred for sublist in true_predictions for pred in sublist]\n",
    "    flat_labels = [label for sublist in true_labels for label in sublist]\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(flat_labels, flat_predictions, digits=4)\n",
    "\n",
    "    # Print the classification report to the screen\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(report)\n",
    "\n",
    "    # Compute overall metrics using your existing metric (e.g., seqeval for NER)\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3122e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_function(p):\n",
    "    return compute_metrics(p, id2label)\n",
    "\n",
    "def tokenize_and_align_labels(examples, device):\n",
    "    task = \"ner\"\n",
    "    label_all_tokens = True\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], max_length=512, truncation=True, padding=\"max_length\", is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"{task}_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "    # labels = torch.tensor(labels).to(dtype=torch.int64)\n",
    "    # tokenized_inputs[\"labels\"] = labels\n",
    "    # return tokenized_inputs\n",
    "    labels = torch.tensor(labels).to(dtype=torch.int64).to(device)  # Move labels to the specified device\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507e45e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare dataset\n",
    "train = pd.read_csv(os.path.join(data_folder, 'train_IOB.tsv'), sep='\\t', names=['tokens', 'ner_tags'], skip_blank_lines=False, na_filter=False)\n",
    "\n",
    "dev = pd.read_csv(os.path.join(data_folder, 'dev_IOB.tsv'), sep='\\t', names=['tokens', 'ner_tags'], skip_blank_lines=False, na_filter=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c37d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Dataset processing\n",
    "label_list_ = train['ner_tags'].dropna().unique().tolist()\n",
    "label_list = [x for x in label_list_ if x]\n",
    "id2label = {idx: tag for idx, tag in enumerate(label_list)}\n",
    "label2id = {tag: idx for idx, tag in enumerate(label_list)}\n",
    "\n",
    "\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470864e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tokens, dev_tags, dev_df = get_token_ner_tags(df_=dev, split_name='dev', label2id_=label2id)\n",
    "train_tokens, train_tags, train_df = get_token_ner_tags(df_=train, split_name='train', label2id_= label2id)\n",
    "train_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca50cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trds = Dataset.from_pandas(train_df)#, features=features)\n",
    "vds = Dataset.from_pandas(dev_df)#, features=features)\n",
    "# tds = Dataset.from_pandas(test_df)#, features=features)\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds['train'] = trds\n",
    "ds['validation'] = vds\n",
    "\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8600c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list), id2label=id2label, label2id=label2id)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    model.to(device)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    # assert torch.cuda.is_available() == True\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b718f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_datasets = ds.map(tokenize_and_align_labels, batched=True)\n",
    "    # Apply the tokenize_and_align_labels function to the datasets\n",
    "tokenized_datasets = ds.map(lambda x: tokenize_and_align_labels(x, device), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets['train'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc17ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets['validation'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8493ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "            output_dir=model_save_path,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=1e-5,\n",
    "            lr_scheduler_type='cosine',\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=8,\n",
    "            num_train_epochs=10,\n",
    "            weight_decay=0.01,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model='f1',\n",
    "            logging_dir='./logs',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188a517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=metric_function  # Define your compute_metrics function\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2ef7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = '../models/checkpoint-1380'\n",
    "# Create the pipeline with an aggregation strategy\n",
    "classifier = pipeline(\"ner\", model=model_path, tokenizer=tokenizer, aggregation_strategy=\"max\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76798e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Manual tests\n",
    "text = ['The 445 identified proteins were searched against the S2EuroPhenome, Jalview and UniProt B. A total of 316 sequences of PSEN1 were recovered from different vertebrates, and a multiple sequence alignment (MSA) was constructed using Jalview.']\n",
    "classified_text = classifier(text)\n",
    "\n",
    "print(classified_text)\n",
    "\n",
    "text = ['In addition, the S2EuroPhenome server allows users to upload and search their own protein sequence collection or to quarry public protein sequence data bases with individual saHMMs. ']\n",
    "classified_text = classifier(text)\n",
    "\n",
    "print(classified_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biohackathon-2024",
   "language": "python",
   "name": "biohackathon-2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
