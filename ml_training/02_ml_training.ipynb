{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37fce75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/bh24-literature-mining-Vwh2BCYY-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification, TrainingArguments, Trainer, pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from datasets import Dataset, DatasetDict\n",
    "import wandb\n",
    "# from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "# Add evaluate import\n",
    "import evaluate\n",
    "# Initialize the metric using evaluate\n",
    "metric = evaluate.load(\"seqeval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b955286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve HF token from environment and authenticate\n",
    "hf_token = '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' #Zunaira\n",
    "data_checkpoint = '../data/IOB/'\n",
    "model_checkpoint = 'bioformers/bioformer-16L'\n",
    "model_save_path = '../models/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13072ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_checkpoints(output_dir, keep_last=True, best_model_dir=None, last_model_dir=None):\n",
    "    \"\"\"\n",
    "    Deletes unnecessary model checkpoints created during training.\n",
    "    Keeps the best model directory and optionally the last model directory.\n",
    "\n",
    "    :param output_dir: Base directory where the checkpoints are saved.\n",
    "    :param keep_last: Whether to keep the last checkpoint.\n",
    "    :param best_model_dir: Directory of the best model checkpoint.\n",
    "    :param last_model_dir: Directory of the last model checkpoint.\n",
    "    \"\"\"\n",
    "    for item in os.listdir(output_dir):\n",
    "        item_path = os.path.join(output_dir, item)\n",
    "        if os.path.isdir(item_path) and item.startswith(\"checkpoint\"):\n",
    "            # Check if this path is not the one we want to keep\n",
    "            if item_path != best_model_dir and (not keep_last or item_path != last_model_dir):\n",
    "                shutil.rmtree(item_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be5533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_IOB_transformer(test_list, pattern):\n",
    "    new_list = []\n",
    "    sub_list = []\n",
    "    for i in test_list:\n",
    "\n",
    "        if i != pattern:\n",
    "            sub_list.append(i)\n",
    "        else:\n",
    "            new_list.append(sub_list)\n",
    "            sub_list = []\n",
    "\n",
    "    return new_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e11500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_ner_tags(df_, split_name, label2id_):\n",
    "    ner_tag_list_ = df_['ner_tags'].map(label2id_).fillna(\n",
    "        '#*#*#*#*#*#*#*#*').tolist()  # convert the list to a pandas series temporarily before mapping\n",
    "    token_list_ = df_['tokens'].tolist()\n",
    "\n",
    "    token_list = convert_IOB_transformer(test_list=token_list_, pattern='')\n",
    "    ner_tag_list = convert_IOB_transformer(test_list=ner_tag_list_, pattern='#*#*#*#*#*#*#*#*')\n",
    "\n",
    "    df = pd.DataFrame(list(zip(token_list, ner_tag_list)),\n",
    "                      columns=['tokens', 'ner_tags'])\n",
    "\n",
    "    # df.to_csv(path_+'GP-DS-OG-CD-Santosh/'+split_name+'_formatted.tsv', index=None, sep ='\\t', header=None)\n",
    "\n",
    "    return token_list, ner_tag_list, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec487990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p, id2label):\n",
    "    \"\"\"\n",
    "    Computes evaluation metrics and prints a detailed classification report.\n",
    "\n",
    "    Parameters:\n",
    "    p (tuple): A tuple containing predictions and labels.\n",
    "    id2label (dict): A dictionary mapping label IDs to label names.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with precision, recall, f1, and accuracy metrics.\n",
    "    \"\"\"\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)  # Assuming predictions are logits or probabilities\n",
    "\n",
    "    # Decode predictions and labels using id2label\n",
    "    true_predictions = [\n",
    "        [id2label[pred] for (pred, label) in zip(prediction, label_ids) if label != -100]\n",
    "        for prediction, label_ids in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label[label] for (pred, label) in zip(prediction, label_ids) if label != -100]\n",
    "        for prediction, label_ids in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    # Flatten the lists for classification_report\n",
    "    flat_predictions = [pred for sublist in true_predictions for pred in sublist]\n",
    "    flat_labels = [label for sublist in true_labels for label in sublist]\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(flat_labels, flat_predictions, digits=4, zero_division=1)\n",
    "\n",
    "    # Print the classification report to the screen\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(report)\n",
    "\n",
    "    # Compute overall metrics using your existing metric (e.g., seqeval for NER)\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3122e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_function(p):\n",
    "    return compute_metrics(p, id2label)\n",
    "\n",
    "def tokenize_and_align_labels(examples, device):\n",
    "    task = \"ner\"\n",
    "    label_all_tokens = True\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], max_length=512, truncation=True, padding=\"max_length\", is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"{task}_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "    labels = torch.tensor(labels).to(dtype=torch.int64).to(device)  # Move labels to the specified device\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507e45e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare dataset\n",
    "train = pd.read_csv(os.path.join(data_checkpoint, 'train_IOB.tsv'), sep='\\t', names=['tokens', 'ner_tags'], skip_blank_lines=False, na_filter=False)\n",
    "dev = pd.read_csv(os.path.join(data_checkpoint, 'dev_IOB.tsv'), sep='\\t', names=['tokens', 'ner_tags'], skip_blank_lines=False, na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c37d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'O', 1: 'B-BT', 2: 'I-BT'}\n"
     ]
    }
   ],
   "source": [
    "# Dataset processing\n",
    "label_list_ = train['ner_tags'].dropna().unique().tolist()\n",
    "label_list = [x for x in label_list_ if x]\n",
    "id2label = {idx: tag for idx, tag in enumerate(label_list)}\n",
    "label2id = {tag: idx for idx, tag in enumerate(label_list)}\n",
    "\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "470864e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Glyco',\n",
       " '@',\n",
       " 'Expasy',\n",
       " '[',\n",
       " '26',\n",
       " ']',\n",
       " 'uses',\n",
       " 'a',\n",
       " 'combination',\n",
       " 'of',\n",
       " 'text',\n",
       " 'mining',\n",
       " 'tools',\n",
       " 'and',\n",
       " 'manual',\n",
       " 'opportunistic',\n",
       " 'selection',\n",
       " 'to',\n",
       " 'identify',\n",
       " 'sources',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_tokens, dev_tags, dev_df = get_token_ner_tags(df_=dev, split_name='dev', label2id_=label2id)\n",
    "train_tokens, train_tags, train_df = get_token_ner_tags(df_=train, split_name='train', label2id_= label2id)\n",
    "train_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca50cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trds = Dataset.from_pandas(train_df)#, features=features)\n",
    "vds = Dataset.from_pandas(dev_df)#, features=features)\n",
    "# tds = Dataset.from_pandas(test_df)#, features=features)\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds['train'] = trds\n",
    "ds['validation'] = vds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8600c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bioformers/bioformer-16L and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Model initialization\n",
    "# Increase dropout as the model is overfitting our small dataset\n",
    "hidden_droput_prob = 0.2\n",
    "attention_probs_dropout_prob = 0.2\n",
    "config = BertConfig.from_pretrained(model_checkpoint, num_labels=len(label_list), id2label=id2label, label2id=label2id,  attn_implementation=\"sdpa\")\n",
    "config.hidden_dropout_prob = hidden_droput_prob\n",
    "config.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(model_checkpoint, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff81c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    model.to(device)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    # assert torch.cuda.is_available() == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0da8bbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2244/2244 [00:00<00:00, 3605.16 examples/s]\n",
      "Map: 100%|██████████| 560/560 [00:00<00:00, 4415.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['CDBProm', \"'\", 's', 'predictor', 'identified', '24', '313', '419', 'promoter', 'sequences'], 'ner_tags': [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'input_ids': [101, 2247, 3721, 1523, 112, 188, 6983, 2326, 2524, 28830], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 1, 1, 1, 0, 0, 0, 0, 0, 0]}\n",
      "{'tokens': ['Different', 'tools', 'have', 'been', 'introduced', 'for', 'this', 'task', ',', 'including'], 'ner_tags': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'input_ids': [101, 10984, 5457, 1641, 1723, 6035, 1471, 1603, 3603, 117], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_checkpoint, strip_accents=True, lowercase=False)\n",
    "\n",
    "# Apply the tokenize_and_align_labels function to the datasets\n",
    "tokenized_datasets = ds.map(lambda x: tokenize_and_align_labels(x, device), batched=True)\n",
    "\n",
    "print({k: v[:10] for k, v in tokenized_datasets['train'][4].items()})\n",
    "print({k: v[:10] for k, v in tokenized_datasets['validation'][4].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8493ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "training_args = TrainingArguments(\n",
    "            output_dir=model_save_path,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=1e-5,\n",
    "            lr_scheduler_type='linear',\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=15,\n",
    "            warmup_ratio=0.1,\n",
    "            weight_decay=0.01,\n",
    "            gradient_accumulation_steps=2,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model='f1',\n",
    "            greater_is_better=True,\n",
    "            bf16=True,\n",
    "            logging_dir='./logs',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "188a517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=metric_function,  # Define your compute_metrics function\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ef9e76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mafanasyeva-tess\u001b[0m (\u001b[33mafanasyeva-team\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/biohackathon2024/ml_training/wandb/run-20250307_233522-aiibl2pq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/afanasyeva-team/huggingface/runs/aiibl2pq' target=\"_blank\">../models/</a></strong> to <a href='https://wandb.ai/afanasyeva-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/afanasyeva-team/huggingface' target=\"_blank\">https://wandb.ai/afanasyeva-team/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/afanasyeva-team/huggingface/runs/aiibl2pq' target=\"_blank\">https://wandb.ai/afanasyeva-team/huggingface/runs/aiibl2pq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4200' max='4200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4200/4200 14:38, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.116317</td>\n",
       "      <td>0.582197</td>\n",
       "      <td>0.666393</td>\n",
       "      <td>0.621456</td>\n",
       "      <td>0.960057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.361200</td>\n",
       "      <td>0.106067</td>\n",
       "      <td>0.580529</td>\n",
       "      <td>0.793755</td>\n",
       "      <td>0.670600</td>\n",
       "      <td>0.962208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.361200</td>\n",
       "      <td>0.104650</td>\n",
       "      <td>0.598592</td>\n",
       "      <td>0.838127</td>\n",
       "      <td>0.698391</td>\n",
       "      <td>0.963667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.105406</td>\n",
       "      <td>0.620150</td>\n",
       "      <td>0.814297</td>\n",
       "      <td>0.704085</td>\n",
       "      <td>0.965280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.110565</td>\n",
       "      <td>0.616759</td>\n",
       "      <td>0.822514</td>\n",
       "      <td>0.704930</td>\n",
       "      <td>0.964243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.105999</td>\n",
       "      <td>0.647449</td>\n",
       "      <td>0.802794</td>\n",
       "      <td>0.716801</td>\n",
       "      <td>0.968007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.106331</td>\n",
       "      <td>0.676144</td>\n",
       "      <td>0.801150</td>\n",
       "      <td>0.733358</td>\n",
       "      <td>0.969889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.110287</td>\n",
       "      <td>0.695931</td>\n",
       "      <td>0.801150</td>\n",
       "      <td>0.744843</td>\n",
       "      <td>0.971694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>0.118143</td>\n",
       "      <td>0.661397</td>\n",
       "      <td>0.824979</td>\n",
       "      <td>0.734186</td>\n",
       "      <td>0.968775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>0.117107</td>\n",
       "      <td>0.675289</td>\n",
       "      <td>0.815119</td>\n",
       "      <td>0.738645</td>\n",
       "      <td>0.969774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.119005</td>\n",
       "      <td>0.689510</td>\n",
       "      <td>0.810189</td>\n",
       "      <td>0.744994</td>\n",
       "      <td>0.971272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.127473</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.816763</td>\n",
       "      <td>0.736024</td>\n",
       "      <td>0.969236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.131089</td>\n",
       "      <td>0.664219</td>\n",
       "      <td>0.817584</td>\n",
       "      <td>0.732965</td>\n",
       "      <td>0.968929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.130356</td>\n",
       "      <td>0.672043</td>\n",
       "      <td>0.821693</td>\n",
       "      <td>0.739372</td>\n",
       "      <td>0.969851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-BT     0.5915    0.6771    0.6314      1217\n",
      "        I-BT     1.0000    0.0000    0.0000       114\n",
      "           O     0.9809    0.9784    0.9797     24706\n",
      "\n",
      "    accuracy                         0.9601     26037\n",
      "   macro avg     0.8575    0.5518    0.5370     26037\n",
      "weighted avg     0.9628    0.9601    0.9591     26037\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-BT     0.5922    0.8077    0.6834      1217\n",
      "        I-BT     0.5758    0.1667    0.2585       114\n",
      "           O     0.9880    0.9735    0.9807     24706\n",
      "\n",
      "    accuracy                         0.9622     26037\n",
      "   macro avg     0.7186    0.6493    0.6408     26037\n",
      "weighted avg     0.9677    0.9622    0.9636     26037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-BT     0.6110    0.8480    0.7103      1217\n",
      "        I-BT     0.4510    0.4035    0.4259       114\n",
      "           O     0.9904    0.9720    0.9811     24706\n",
      "\n",
      "    accuracy                         0.9637     26037\n",
      "   macro avg     0.6841    0.7411    0.7058     26037\n",
      "weighted avg     0.9703    0.9637    0.9660     26037\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-BT     0.6314    0.8233    0.7147      1217\n",
      "        I-BT     0.5000    0.5614    0.5289       114\n",
      "           O     0.9895    0.9741    0.9818     24706\n",
      "\n",
      "    accuracy                         0.9653     26037\n",
      "   macro avg     0.7070    0.7863    0.7418     26037\n",
      "weighted avg     0.9706    0.9653    0.9673     26037\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-BT     0.6382    0.8365    0.7240      1217\n",
      "        I-BT     0.3799    0.7632    0.5073       114\n",
      "           O     0.9912    0.9715    0.9813     24706\n",
      "\n",
      "    accuracy                         0.9642     26037\n",
      "   macro avg     0.6698    0.8570    0.7375     26037\n",
      "weighted avg     0.9721    0.9642    0.9672     26037\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-BT     0.6589    0.8127    0.7277      1217\n",
      "        I-BT     0.5507    0.6667    0.6032       114\n",
      "           O     0.9894    0.9771    0.9832     24706\n",
      "\n",
      "    accuracy                         0.9680     26037\n",
      "   macro avg     0.7330    0.8188    0.7714     26037\n",
      "weighted avg     0.9720    0.9680    0.9696     26037\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-BT     0.6921    0.8127    0.7475      1217\n",
      "        I-BT     0.4773    0.7368    0.5793       114\n",
      "           O     0.9897    0.9787    0.9842     24706\n",
      "\n",
      "    accuracy                         0.9699     26037\n",
      "   macro avg     0.7197    0.8427    0.7703     26037\n",
      "weighted avg     0.9735    0.9699    0.9713     26037\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-BT     0.7086    0.8094    0.7557      1217\n",
      "        I-BT     0.5290    0.7193    0.6097       114\n",
      "           O     0.9894    0.9809    0.9851     24706\n",
      "\n",
      "    accuracy                         0.9717     26037\n",
      "   macro avg     0.7424    0.8365    0.7835     26037\n",
      "weighted avg     0.9743    0.9717    0.9728     26037\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-BT     0.6785    0.8357    0.7489      1217\n",
      "        I-BT     0.4462    0.7632    0.5631       114\n",
      "           O     0.9908    0.9763    0.9835     24706\n",
      "\n",
      "    accuracy                         0.9688     26037\n",
      "   macro avg     0.7051    0.8584    0.7652     26037\n",
      "weighted avg     0.9739    0.9688    0.9707     26037\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-BT     0.6898    0.8242    0.7510      1217\n",
      "        I-BT     0.4674    0.7544    0.5772       114\n",
      "           O     0.9902    0.9779    0.9841     24706\n",
      "\n",
      "    accuracy                         0.9698     26037\n",
      "   macro avg     0.7158    0.8522    0.7708     26037\n",
      "weighted avg     0.9739    0.9698    0.9714     26037\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-BT     0.7004    0.8184    0.7548      1217\n",
      "        I-BT     0.5276    0.7544    0.6209       114\n",
      "           O     0.9900    0.9798    0.9849     24706\n",
      "\n",
      "    accuracy                         0.9713     26037\n",
      "   macro avg     0.7393    0.8509    0.7869     26037\n",
      "weighted avg     0.9744    0.9713    0.9725     26037\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-BT     0.6853    0.8266    0.7493      1217\n",
      "        I-BT     0.4531    0.7632    0.5686       114\n",
      "           O     0.9904    0.9772    0.9838     24706\n",
      "\n",
      "    accuracy                         0.9692     26037\n",
      "   macro avg     0.7096    0.8557    0.7672     26037\n",
      "weighted avg     0.9738    0.9692    0.9710     26037\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-BT     0.6818    0.8274    0.7476      1217\n",
      "        I-BT     0.4518    0.7807    0.5723       114\n",
      "           O     0.9905    0.9768    0.9836     24706\n",
      "\n",
      "    accuracy                         0.9689     26037\n",
      "   macro avg     0.7080    0.8616    0.7678     26037\n",
      "weighted avg     0.9737    0.9689    0.9708     26037\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-BT     0.6840    0.8324    0.7509      1217\n",
      "        I-BT     0.4635    0.7807    0.5817       114\n",
      "           O     0.9908    0.9771    0.9839     24706\n",
      "\n",
      "    accuracy                         0.9694     26037\n",
      "   macro avg     0.7128    0.8634    0.7722     26037\n",
      "weighted avg     0.9741    0.9694    0.9712     26037\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-BT     0.6875    0.8316    0.7527      1217\n",
      "        I-BT     0.4734    0.7807    0.5894       114\n",
      "           O     0.9907    0.9775    0.9841     24706\n",
      "\n",
      "    accuracy                         0.9699     26037\n",
      "   macro avg     0.7172    0.8633    0.7754     26037\n",
      "weighted avg     0.9743    0.9699    0.9715     26037\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4200, training_loss=0.07866793802806309, metrics={'train_runtime': 882.2852, 'train_samples_per_second': 38.151, 'train_steps_per_second': 4.76, 'total_flos': 2925853998391296.0, 'train_loss': 0.07866793802806309, 'epoch': 14.94830659536542})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b2ef7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Get the last created checkpoint in the directory\n",
    "def get_last_created_checkpoint(directory):\n",
    "    folders = [os.path.join(directory, d) for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "    if not folders:\n",
    "        return None\n",
    "    latest_folder = max(folders, key=os.path.getctime)\n",
    "    return latest_folder\n",
    "\n",
    "last_created_checkpoint_path = get_last_created_checkpoint('../models')\n",
    "\n",
    "classifier = pipeline(\"ner\", model=last_created_checkpoint_path, tokenizer=tokenizer, aggregation_strategy=\"max\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75c95af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Comet<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">BT</span></span> is written in C++ and uses POSIX threads for Linux and Windows compatible multithreading.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">It is generally agreed that comets, in order to incorporate the ices needed to produce the observed outgassing, must have formed outside the water-ice line, with some of them having formed as far out as beyond the CO-ice line.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">To address these needs, we report the <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">COmposable Mammalian Elements<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">BT</span></span> of Transcription (<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">COMET<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">BT</span></span>)—an ensemble of engineered promoters and modular ZF-TFs with tunable properties. We incorporate into <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">COMET<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">BT</span></span> a panel of 19 TFs that were originally developed in yeast</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipymarkup import show_span_box_markup\n",
    "\n",
    "text =  ['Comet is written in C++ and uses POSIX threads for Linux and Windows compatible multithreading.', 'It is generally agreed that comets, in order to incorporate the ices needed to produce the observed outgassing, must have formed outside the water-ice line, with some of them having formed as far out as beyond the CO-ice line.','To address these needs, we report the COmposable Mammalian Elements of Transcription (COMET)—an ensemble of engineered promoters and modular ZF-TFs with tunable properties. We incorporate into COMET a panel of 19 TFs that were originally developed in yeast']\n",
    "\n",
    "for t in text:\n",
    "    classified_text = classifier(t)\n",
    "    annotations_char_spans = [(item['start'], item['end'], item['entity_group']) for item in classified_text]\n",
    "    show_span_box_markup(t, annotations_char_spans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bh24-literature-mining-Vwh2BCYY-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
